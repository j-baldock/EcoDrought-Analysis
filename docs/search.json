[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EcoDrought Capstone",
    "section": "",
    "text": "1 Introduction\nThis book provides a visual story of the USGS Eco-Drought Capstone Project. Our goals are to (1) quantify fine-scale spatial heterogeneity in flow regimes in headwater stream networks, (2) demonstrate the limitations of existing tools that model flow in headwater streams, and (3) assess the subsequent effects of streamflow heterogeneity on fish population dynamics and vulnerability to climatic variation, particularly drought.\nThis information is preliminary or provisional and is subject to revision. It is being provided to meet the need for timely best science. The information has not received final approval by the U.S. Geological Survey (USGS) and is provided on the condition that neither the USGS nor the U.S. Government shall be held liable for any damages resulting from the authorized or unauthorized use of the information.\nProject team: Jeff Baldock, Jenn Fair, Ben Letcher, Robert Al-Chokhachy, Clint Muhlfeld, and Jason Dunham\n\n\nSession Information\n\n\n\n\n\nCode\nsessionInfo()\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 22631)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Denver\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.1    fastmap_1.2.0     cli_3.6.3        \n [5] tools_4.4.1       htmltools_0.5.8.1 rstudioapi_0.17.1 rmarkdown_2.29   \n [9] knitr_1.48        jsonlite_1.8.9    xfun_0.49         digest_0.6.37    \n[13] rlang_1.1.4       evaluate_1.0.1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html",
    "href": "Data Availability/CollateData.html",
    "title": "2  Collate Data",
    "section": "",
    "text": "2.1 Gather site information\nPurpose: Collate EcoDrought streamflow and temperature data, povided by EcoD PIs/partners and NWIS\nNotes:\nCode\n# West Brook\nsiteinfo_wb &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Mass/MA_site_info.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_Name = factor(Site_Name)) %&gt;%\n  rename(site_id = Site_ID, station_no = Station_No, site_name = Site_Name, lat = Latitude_dec_deg, long = Longitude_dec_deg, elev_ft = Elevation_ft, area_sqmi = Drainage_Area_sqmi) %&gt;%\n  mutate(designation = \"little\", basin = \"West Brook\", region = \"Mass\") #%&gt;% select(-c(elev_ft, area_sqmi)) \n\n# Shenandoah\nsiteinfo_shen &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/VA_site_info.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_Name = factor(Site_Name)) %&gt;%\n  rename(site_id = Site_ID, station_no = Station_No, site_name = Site_Name, lat = Latitude_dec_deg, long = Longitude_dec_deg, elev_ft = Elevation_ft, area_sqmi = Drainage_Area_sqmi) %&gt;%\n  mutate(designation = ifelse(str_detect(site_id, \"10FL\"), \"big\", \"little\"), \n         basin = str_sub(site_name, 1, str_length(site_name)-3), region = \"Shen\") #%&gt;% select(-c(elev_ft, area_sqmi))\n\n# Flathead/Muhlfeld\nsiteinfo_flat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Flathead/Flathead_SiteInfo_UpdateOct25.csv\") %&gt;% \n  select(basin, site_name, site_id, region, designation, lat, long) %&gt;%\n  rename(subbasin = basin) %&gt;%\n  mutate(basin = \"Flathead\", region = \"Flat\") %&gt;%\n  select(site_id, site_name, lat, long, designation, basin, subbasin, region) %&gt;%\n  filter(designation == \"little\")\n  \n# GYA/Al-Chokhachy\nsiteinfo_gya &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/Al-Chokhachy_sites.csv\") %&gt;%\n  mutate(region = ifelse(basin == \"Snake River\", \"Snake\", \"Shields\"), \n         designation = \"little\") %&gt;%\n  select(site_id, site_name, latitude, longitude, designation, basin, region) %&gt;% \n  rename(lat = latitude, long = longitude)\n  \n\n# NWIS Medium/Big/Super G\nsites &lt;- c(\"01169900\", # South River at Conway, Massachusetts\n           \"13011500\", # Pacific Creek, Snake River, Wyoming\n           \"06195600\", # Shields River at Livingston, Montana\n           \"12355500\", # North Fork Flathead River, Montana\n           \"10396000\", # Donner Blitzen River near Frenchglen, Oregon\n           # Medium G\n           \"12355347\", # Big Creek (Flathead)\n           \"12355342\", # Hallowat Creek (Flathead)\n           \"06192980\", # Shields Rivera above Smith Creek (GYA)\n           \"06192900\", # Dugout Creek Mouth (GYA)\n           \"13012475\", # South Fork Spread Creek (GYA)\n           \"13012465\", # Leidy Creek, lower (GYA)\n           \"01171100\", # West Brook (Mass)\n           \"01171000\",  # Avery Brook (Mass)\n           \"424551118503200\", # Fish Creek at DB confluence (Oreg)\n           \"424547118503500\", # DB above Fish Creek (Oreg)\n           \"424325118495900\", # DB near Burnt Car Spring (Oreg)\n           \"424003118453700\", # Little Blitzen River (Oreg)\n           \"423830118453200\", # Indian Creek (Oreg)\n           \"423815118453900\" # DB above Indian Creek (Oreg)\n           )\nsiteinfo_nwis &lt;- tibble(readNWISsite(sites)[,c(2:3,7,8,20,30)]) # get site info\nnames(siteinfo_nwis) &lt;- c(\"station_no\", \"site_name\", \"lat\", \"long\", \"elev_ft\", \"area_sqmi\") # rename columns\nsiteinfo_nwis &lt;- siteinfo_nwis %&gt;% mutate(site_name = c(\"South River Conway NWIS\", \n                                                        \"Avery Broook NWIS\", \n                                                        \"West Brook NWIS\", \n                                                        \"Dugout Creek NWIS\", \n                                                        \"Shields River ab Smith NWIS\", \n                                                        \"Shields River nr Livingston NWIS\", \n                                                        \"Donner Blitzen River nr Frenchglen NWIS\", \n                                                        \"Hallowat Creek NWIS\", \n                                                        \"Big Creek NWIS\", \n                                                        \"North Fork Flathead River NWIS\", \n                                                        \"Pacific Creek at Moran NWIS\", \n                                                        \"Leidy Creek Mouth NWIS\", \n                                                        \"SF Spread Creek Lower NWIS\",\n                                                        \"Donner Blitzen ab Indian NWIS\",\n                                                        \"Indian Creek NWIS\",\n                                                        \"Little Blizten River NWIS\",\n                                                        \"Donner Blitzen nr Burnt Car NWIS\",\n                                                        \"Donner Blitzen ab Fish NWIS\",\n                                                        \"Fish Creek\"),\n                                          site_id = c(\"SRC\", \"AVB\", \"WBR\", \"DUG\", \"SRS\", \"SRL\", \"DBF\", \"HAL\", \"BIG\", \"NFF\", \"PCM\", \"LEI\", \"SFS\", \"DBI\", \"IND\", \"LBL\", \"DBB\", \"DBA\", \"FSH\"),\n                                          designation = c(\"big\", \"medium\", \"medium\", \"medium\", \"medium\", \"big\", \"big\", \"medium\", \"medium\", \"big\", \"big\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\"),\n                                          basin = c(\"West Brook\", \"West Brook\", \"West Brook\", \"Shields River\", \"Shields River\", \"Shields River\", \"Donner Blitzen\", \"Flathead\", \"Flathead\", \"Flathead\", \"Snake River\", \"Snake River\", \"Snake River\", \"Donner Blitzen\", \"Donner Blitzen\", \"Donner Blitzen\", \"Donner Blitzen\", \"Donner Blitzen\", \"Donner Blitzen\"),\n                                          region = c(\"Mass\", \"Mass\", \"Mass\", \"Shields\", \"Shields\", \"Shields\", \"Oreg\", \"Flat\", \"Flat\", \"Flat\", \"Snake\", \"Snake\", \"Snake\",\"Oreg\", \"Oreg\", \"Oreg\", \"Oreg\", \"Oreg\", \"Oreg\")) %&gt;% \n  select(site_id, site_name, lat, long, station_no, designation, basin, region, elev_ft, area_sqmi)\n#mapview(st_as_sf(siteinfo_nwis, coords = c(\"long\", \"lat\"), crs = 4326))\n\n\n# bind together, fill in ragged subbasin\nsiteinfo &lt;- bind_rows(siteinfo_wb, siteinfo_shen, siteinfo_flat, siteinfo_gya, siteinfo_nwis)\nsiteinfo$subbasin[siteinfo$site_name == \"Hallowat Creek NWIS\"] &lt;- \"Big Creek\"\nsiteinfo$subbasin[siteinfo$site_name == \"Big Creek NWIS\"] &lt;- \"Big Creek\"\nsiteinfo &lt;- siteinfo %&gt;% mutate(subbasin = ifelse(is.na(subbasin), basin, subbasin))\n\n\n# fix Shields River Valley Ranch site locations\nsiteinfo$lat[siteinfo$site_id == \"SH07\"] &lt;- siteinfo$lat[siteinfo$site_id == \"SRS\"]\nsiteinfo$long[siteinfo$site_id == \"SH07\"] &lt;- siteinfo$long[siteinfo$site_id == \"SRS\"]\n\n\n# add elevation and area variables (from watershed delineation)\nareafiles &lt;- list.files(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Area and Elevation\")\narealist &lt;- list()\nfor (i in 1:length(areafiles)) { arealist[[i]] &lt;- read_csv(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Area and Elevation/\", areafiles[i], sep = \"\"))}\nareaelev &lt;- do.call(rbind, arealist)\n# how well do provided and delineation area/elevation match?\n# siteinfo %&gt;% left_join(areaelev, by = \"site_id\") %&gt;% ggplot() + geom_point(aes(x = area_sqmi.x, y = area_sqmi.y)) + geom_abline(intercept = 0, slope = 1) + facet_wrap(~basin, scales = \"free\")\n# test %&gt;% ggplot() + geom_point(aes(x = elev_ft.x, y = elev_ft.y)) + geom_abline(intercept = 0, slope = 1) + facet_wrap(~basin, scales = \"free\")\n# add delineated variables\nsiteinfo &lt;- siteinfo %&gt;% select(-c(area_sqmi, elev_ft)) %&gt;% left_join(areaelev)\n# fix NF Flathead (no dem from Canada)\nsiteinfo$area_sqmi[siteinfo$site_id == \"NFF\"] &lt;- 1556\nWrite and re-load site information\nCode\nwrite_csv(siteinfo, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nView unique basin names\nCode\nunique(siteinfo$basin)\n\n\n[1] \"West Brook\"     \"Paine Run\"      \"Piney River\"    \"Staunton River\"\n[5] \"Flathead\"       \"Duck Creek\"     \"Shields River\"  \"Snake River\"   \n[9] \"Donner Blitzen\"\nView unique site names\nCode\nunique(siteinfo$site_name)\n\n\n  [1] \"Avery Brook\"                            \n  [2] \"Jimmy Brook\"                            \n  [3] \"Mitchell Brook\"                         \n  [4] \"Obear Brook Lower\"                      \n  [5] \"Sanderson Brook\"                        \n  [6] \"West Brook Lower\"                       \n  [7] \"West Brook Upper\"                       \n  [8] \"West Brook Reservoir\"                   \n  [9] \"West Whately Brook\"                     \n [10] \"West Brook 0\"                           \n [11] \"Paine Run 01\"                           \n [12] \"Paine Run 02\"                           \n [13] \"Paine Run 03\"                           \n [14] \"Paine Run 04\"                           \n [15] \"Paine Run 05\"                           \n [16] \"Paine Run 06\"                           \n [17] \"Paine Run 07\"                           \n [18] \"Paine Run 08\"                           \n [19] \"Paine Run 09\"                           \n [20] \"Paine Run 10\"                           \n [21] \"Piney River 01\"                         \n [22] \"Piney River 02\"                         \n [23] \"Piney River 03\"                         \n [24] \"Piney River 04\"                         \n [25] \"Piney River 05\"                         \n [26] \"Piney River 06\"                         \n [27] \"Piney River 08\"                         \n [28] \"Piney River 09\"                         \n [29] \"Piney River 10\"                         \n [30] \"Staunton River 01\"                      \n [31] \"Staunton River 02\"                      \n [32] \"Staunton River 03\"                      \n [33] \"Staunton River 04\"                      \n [34] \"Staunton River 05\"                      \n [35] \"Staunton River 06\"                      \n [36] \"Staunton River 07\"                      \n [37] \"Staunton River 08\"                      \n [38] \"Staunton River 09\"                      \n [39] \"Staunton River 10\"                      \n [40] \"BigCreekLower\"                          \n [41] \"BigCreekMiddle\"                         \n [42] \"BigCreekUpper\"                          \n [43] \"CoalCreekHeadwaters\"                    \n [44] \"CoalCreekLower\"                         \n [45] \"CoalCreekMiddle\"                        \n [46] \"CycloneCreekLower\"                      \n [47] \"CycloneCreekMiddle\"                     \n [48] \"CycloneCreekUpper\"                      \n [49] \"HallowattCreekLower\"                    \n [50] \"LangfordCreekLower\"                     \n [51] \"LangfordCreekUpper\"                     \n [52] \"McGeeCreekLower\"                        \n [53] \"McGeeCreekTrib\"                         \n [54] \"McGeeCreekUpper\"                        \n [55] \"MeadowCreek\"                            \n [56] \"NicolaCreek\"                            \n [57] \"CoalCreekNorth\"                         \n [58] \"SkookoleelCreek\"                        \n [59] \"WernerCreek\"                            \n [60] \"WoundedBuckCreek\"                       \n [61] \"EF Duck Creek be HF\"                    \n [62] \"EF Duck Creek ab HF\"                    \n [63] \"Henrys Fork\"                            \n [64] \"Brackett Creek\"                         \n [65] \"Buck Creek\"                             \n [66] \"Crandall Creek\"                         \n [67] \"Deep Creek\"                             \n [68] \"Dugout Creek\"                           \n [69] \"Lodgepole Creek\"                        \n [70] \"Shields River Valley Ranch\"             \n [71] \"Shields River ab Dugout\"                \n [72] \"Grizzly Creek\"                          \n [73] \"Grouse Creek\"                           \n [74] \"Leidy Creek Lower\"                      \n [75] \"Leidy Creek Upper\"                      \n [76] \"Leidy Creek Mouth\"                      \n [77] \"NF Spread Creek Lower\"                  \n [78] \"NF Spread Creek Upper\"                  \n [79] \"Rock Creek\"                             \n [80] \"SF Spread Creek Lower\"                  \n [81] \"SF Spread Creek Upper\"                  \n [82] \"Spread Creek Dam\"                       \n [83] \"South River Conway NWIS\"                \n [84] \"Avery Broook NWIS\"                      \n [85] \"West Brook NWIS\"                        \n [86] \"Dugout Creek NWIS\"                      \n [87] \"Shields River ab Smith NWIS\"            \n [88] \"Shields River nr Livingston NWIS\"       \n [89] \"Donner Blitzen River nr Frenchglen NWIS\"\n [90] \"Hallowat Creek NWIS\"                    \n [91] \"Big Creek NWIS\"                         \n [92] \"North Fork Flathead River NWIS\"         \n [93] \"Pacific Creek at Moran NWIS\"            \n [94] \"Leidy Creek Mouth NWIS\"                 \n [95] \"SF Spread Creek Lower NWIS\"             \n [96] \"Donner Blitzen ab Indian NWIS\"          \n [97] \"Indian Creek NWIS\"                      \n [98] \"Little Blizten River NWIS\"              \n [99] \"Donner Blitzen nr Burnt Car NWIS\"       \n[100] \"Donner Blitzen ab Fish NWIS\"            \n[101] \"Fish Creek\"\nMap sites\nCode\n# convert to spatial object and view on map\n#| fig-cap: \"Map of EcoDrought project locations\"\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#load-ecod-data",
    "href": "Data Availability/CollateData.html#load-ecod-data",
    "title": "2  Collate Data",
    "section": "2.2 Load EcoD data",
    "text": "2.2 Load EcoD data\n\n\nCode\n# West Brook\ndat_wb &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Mass/EcoDrought Continuous_MA.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_Name = factor(Site_Name)) %&gt;%\n  rename(station_no = Station_No, site_name = Site_Name, datetime = DateTime_EST, height = GageHeight_Hobo_ft, flow = Discharge_Hobo_cfs, tempf = WaterTemperature_HOBO_DegF) %&gt;%\n  mutate(tempc = (tempf - 32)*(5/9)) %&gt;% select(station_no, site_name, datetime, height, flow, tempc) %&gt;%\n  left_join(siteinfo %&gt;% select(-station_no)) \n\n\n# Shenandoah\ndat_shen &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/EcoDrought_Continuous_VA.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_ID = factor(Site_ID), Discharge_Hobo_cfs = as.numeric(Discharge_Hobo_cfs)) %&gt;%\n  rename(station_no = Station_No, site_id = Site_ID, datetime = DateTime_EST, height = GageHeight_Hobo_ft, flow = Discharge_Hobo_cfs, tempf = WaterTemperature_HOBO_DegF) %&gt;%\n  mutate(tempc = (tempf - 32)*(5/9)) %&gt;% select(station_no, site_id, datetime, height, flow, tempc) %&gt;%\n  left_join(siteinfo)\n# pull in Big G data separately (UVA long-term gage sites)\ndat_shen_uva_q &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/Shen_BigG_Discharge_hourly_UVA.csv\") %&gt;%\n  rename(flow = cfs)\ndat_shen_uva_t &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/Shen_BigG_TempEtc_hourly_UVA.csv\") %&gt;%\n  select(site_id, datetime, tempc_mean) %&gt;% rename(tempc = tempc_mean)\ndat_shen_uva &lt;- dat_shen_uva_q %&gt;% left_join(dat_shen_uva_t) %&gt;% left_join(siteinfo)\n# bind usgs and uva data\ndat_shen &lt;- bind_rows(dat_shen, dat_shen_uva)\n\n\n# Flathead/Muhlfeld\nflatfiles &lt;- list.files(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Flathead/Export2/EMA/Continuous Data\")\nflatlist &lt;- list()\nfor (i in 1:length(flatfiles)) { \n  #print(flatfiles[i])\n  flatlist[[i]] &lt;- read_csv(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Flathead/Export2/EMA/Continuous Data/\", flatfiles[i], sep = \"\")) %&gt;%\n    mutate(DateTime = mdy_hm(DateTime, tz = \"MST\"),\n           site_name = gsub(\"EMA.csv\", \"\", flatfiles[i]))\n  }\ndat_flat &lt;- bind_rows(flatlist) %&gt;% select(DateTime, GageHeightFT, DischargeCFS, TempF, TempC, site_name, DischargeReliability, TempReliability) %&gt;% \n  rename(datetime = DateTime, height = GageHeightFT, flow = DischargeCFS, tempf = TempF, tempc = TempC) %&gt;%\n  mutate(DischargeReliability = as_factor(DischargeReliability),\n         TempReliability = as_factor(TempReliability)) %&gt;%\n  mutate(tempf = ifelse(is.na(tempf), (tempc * (9/5)) + 32, tempf),\n         tempc = ifelse(is.na(tempc), (tempf - 32) * (5/9), tempc)) %&gt;%\n  left_join(siteinfo) %&gt;% select(-tempf)\n\n\n# Greater Yellowstone/Al-Chokhachy\ngyafiles &lt;- list.files(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/Al-Chokhachy data files\")\ngyalist &lt;- list()\nfor (i in 1:length(gyafiles)) { \n  #print(gyafiles[i])\n  gyalist[[i]] &lt;- read_csv(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/Al-Chokhachy data files/\", gyafiles[i], sep = \"\")) %&gt;%\n    mutate(date = mdy(date), DateTime = ymd_hms(paste(date, time, sep = \" \"), tz = \"MST\"), discharge = as.numeric(discharge)*35.314666212661)\n}\ndat_gya &lt;- bind_rows(gyalist) %&gt;% select(DateTime, depth, discharge, temperature, location) %&gt;% \n  rename(datetime = DateTime, height = depth, flow = discharge, tempc = temperature, site_name = location) %&gt;%\n  filter(site_name != \"EF Henrys\") %&gt;% # drop weird duplicate site/year?\n  mutate(site_name = dplyr::recode(site_name,\n                            \"EF Above Confluence\" = \"EF Duck Creek ab HF\",\n                            \"EF Below Confluence\" = \"EF Duck Creek be HF\",\n                            \"NF Spread Creek\" = \"NF Spread Creek Lower\",\n                            \"Upper NF Spread Creek\" = \"NF Spread Creek Upper\",\n                            \"SF Spread Creek\" = \"SF Spread Creek Lower\",\n                            \"Upper SF Spread Creek\" = \"SF Spread Creek Upper\",\n                            \"Shields River above Dugout Creek\" = \"Shields River ab Dugout\",\n                            \"Upper Leidy Creek\" = \"Leidy Creek Upper\", \n                            \"Leidy Creek\" = \"Leidy Creek Mouth\",\n                            \"Spread Creek\" = \"Spread Creek Dam\",\n                            \"Shields River above Smith Creek\" = \"Shields River Valley Ranch\")) %&gt;%\n  left_join(siteinfo) %&gt;% filter(tempc &lt;= 100)\n\n\nBind EcoD hourly flow/temp data with siteinfo and write to file\n\n\nCode\n# bind together\ndat &lt;- bind_rows(dat_wb, dat_shen, dat_flat, dat_gya)\n# unique(dat$site_name)\nwrite_csv(dat, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_Raw.csv\")\ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_Raw.csv\")\n\n\nCheck unique designations\n\n\nCode\nunique(dat$designation)\n\n\n[1] \"little\" \"big\"   \n\n\nCheck unique regions\n\n\nCode\nunique(dat$region)\n\n\n[1] \"Mass\"    \"Shen\"    \"Flat\"    \"Shields\" \"Snake\"  \n\n\nCheck unique basins\n\n\nCode\nunique(dat$basin)\n\n\n[1] \"West Brook\"     \"Paine Run\"      \"Staunton River\" \"Piney River\"   \n[5] \"Flathead\"       \"Shields River\"  \"Duck Creek\"     \"Snake River\"   \n\n\nCheck unique subbasins\n\n\nCode\nunique(dat$subbasin)\n\n\n [1] \"West Brook\"         \"Paine Run\"          \"Staunton River\"    \n [4] \"Piney River\"        \"Big Creek\"          \"Coal Creek\"        \n [7] \"McGee Creek\"        \"Wounded Buck Creek\" \"Shields River\"     \n[10] \"Duck Creek\"         \"Snake River\"       \n\n\n\n2.2.1 Inspect hourly data\n\n2.2.1.1 West Brook\nJoin data update\n\n\nCode\ndat_wb_new &lt;- dat_wb %&gt;%\n  bind_rows(read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Mass/EcoDrought Continuous_MA_updateDec2024.csv\") %&gt;% \n            rename(datetime = TimeStamp) %&gt;%\n            gather(key = \"station_no\", value = \"flow\", 2:9) %&gt;% \n            mutate(datetime = as_datetime(datetime),\n                   station_no = factor(sub(\".*Discharge@\", \"\", station_no))) %&gt;% \n            left_join(siteinfo %&gt;% mutate(station_no = factor(station_no))))\n\n\n\nAveryJimmyMitchellObearSandersonWB0WB LowerWB ReservoirWB UpperWest Whateley\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"Avery Brook\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"Jimmy Brook\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"Mitchell Brook\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"Obear Brook Lower\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"Sanderson Brook\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"West Brook 0\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"West Brook Lower\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"West Brook Reservoir\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"West Brook Upper\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"West Whately Brook\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\n\n2.2.1.2 Flathead\n\n\nCode\nmysites &lt;- unlist(unique(dat %&gt;% filter(basin == \"Flathead\") %&gt;% select(site_name)))\nmyplots &lt;- list()\nfor (i in 1:length(mysites)) {\n  test &lt;- dat %&gt;% filter(site_name == mysites[i]) %&gt;% select(datetime, flow, DischargeReliability) %&gt;% spread(key = DischargeReliability, value = flow) %&gt;% arrange(datetime) %&gt;% mutate(mindiff = as.numeric(lead(datetime) - (datetime)))\nna_index &lt;- which(test$mindiff &gt; 60)\n  ds_blank &lt;- tibble(index = na_index + 0.5, datetime = NA, \"0\" = NA, \"1\" = NA)\n  myplots[[i]] &lt;- test %&gt;% select(-mindiff) %&gt;% rowid_to_column(\"index\") %&gt;% union(ds_blank) %&gt;% arrange(index) %&gt;% select(-index) %&gt;% mutate(datetime = if_else(is.na(datetime), lag(datetime) + hours(1), datetime)) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n}\n\n\n\nBigCreekLowerBigCreekMiddleBigCreekUpperCoalCreekHeadwatersCoalCreekLowerCoalCreekMiddleCoalCreekNorthCycloneCreekLowerCycloneCreekMidddleCycloneCreekUpperHallowattCreekLowerLangfordCreekLowerLangfordCreekUpperMcGeeCreekLowerMcGeeCreekTribMcGeeCreekUpperMeadowCreekNicolaCreekSkookoleelCreekWernerCreekWoundedBuckCreek",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#load-nwis-data",
    "href": "Data Availability/CollateData.html#load-nwis-data",
    "title": "2  Collate Data",
    "section": "2.3 Load NWIS data",
    "text": "2.3 Load NWIS data\n\n\nCode\n# extract daily mean discharge and temp data from USGS NWIS website\ndat_superg_nwis &lt;- tibble(readNWISdv(siteNumbers = sites, parameterCd = c(\"00010\", \"00060\"), startDate = \"1980-01-01\", endDate = Sys.Date(), statCd = c(\"00003\", \"00001\", \"00002\")))[,-c(1,5,7,9,11)]\nnames(dat_superg_nwis) &lt;- c(\"station_no\", \"date\", \"tempc_max\", \"tempc_min\", \"tempc_mean\", \"flow_mean\")\ndat_superg_nwis &lt;- dat_superg_nwis %&gt;% left_join(siteinfo %&gt;% filter(designation %in% c(\"big\", \"medium\")))\n\n# Manually grab Donner Blitzen above Indian Creek at the original timescale\n# daily mean flow dropped from above query, perhaps b/c in 2020 flow measurements were made every minute\ndbabind &lt;- tibble(readNWISdata(sites = \"423815118453900\", service = \"uv\", startDate = \"1980-01-01\", endDate = Sys.Date()))[,c(2,3,6)] \ndbabind_daily &lt;- dbabind %&gt;% group_by(site_no, date(dateTime)) %&gt;% summarize(nobs = n(), flow_mean = mean(X_00060_00000)) %&gt;% filter(nobs %in% c(96, 1440)) %&gt;% select(c(1,2,4))\nnames(dbabind_daily) &lt;- c(\"station_no\", \"date\", \"flow_mean\") \ndbabind_daily &lt;- dat_superg_nwis %&gt;% filter(station_no == \"423815118453900\") %&gt;% select(-flow_mean) %&gt;% left_join(dbabind_daily)\n\n# bind DBabInd to reset of data\ndat_superg_nwis &lt;- rbind(dat_superg_nwis %&gt;% filter(station_no != \"423815118453900\"), dbabind_daily)\n\n\n\n\nCode\ndat_superg_nwis %&gt;% filter(designation == \"big\") %&gt;% ggplot() + geom_line(aes(x = date, y = log(flow_mean))) + facet_wrap(~site_name)\n\n\n\n\n\n(log) Stream flow (cfs) for Big G NWIS gages\n\n\n\n\n\n\nCode\ndat_superg_nwis %&gt;% filter(designation == \"medium\") %&gt;% ggplot() + geom_line(aes(x = date, y = log(flow_mean))) + facet_wrap(~site_name)\n\n\n\n\n\n(log) Stream flow (cfs) for Medium G NWIS gages",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#bind-data-and-calc.-daily-means",
    "href": "Data Availability/CollateData.html#bind-data-and-calc.-daily-means",
    "title": "2  Collate Data",
    "section": "2.4 Bind data and calc. daily means",
    "text": "2.4 Bind data and calc. daily means\n\n\nCode\n# daily flow/temp summaries\ndat_daily &lt;- dat %&gt;% mutate(date = as_date(datetime)) %&gt;% \n  group_by(station_no, site_name, site_id, basin, subbasin, region, lat, long, elev_ft, area_sqmi, designation, date) %&gt;% \n  summarize(disch_reli = max(DischargeReliability),\n            temp_reli = max(TempReliability),\n            flow_mean = mean(flow), flow_min = min(flow), flow_max = max(flow),\n            tempc_mean = mean(tempc), tempc_min = min(tempc), tempc_max = max(tempc)) %&gt;%\n  arrange(region, basin, site_name, date) %&gt;%\n  ungroup()\n\n# cbind EcoD and NWIS datasets\ndat_daily &lt;- bind_rows(dat_daily %&gt;% select(-flow_min, -flow_max, -tempc_min, -tempc_max), \n                       dat_superg_nwis %&gt;% select(-tempc_max, -tempc_min),\n                       dat_superg_nwis %&gt;% filter(site_id == \"SRL\") %&gt;% mutate(subbasin = \"Duck Creek\") %&gt;% select(-tempc_max, -tempc_min))\n\n# add missing dates\ndat_daily &lt;- fill_missing_dates(dat_daily, dates = date, groups = site_name)\n\n\nView daily mean time series data, for example, site_name = CoalCreekLower. Notice the many shorts gaps in the daily data.\n\n\nCode\nlibrary(dygraphs)\ndat_daily %&gt;% filter(site_name == \"CoalCreekLower\") %&gt;% select(date, flow_mean) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Mean daily flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#interpolate-missing-data",
    "href": "Data Availability/CollateData.html#interpolate-missing-data",
    "title": "2  Collate Data",
    "section": "2.5 Interpolate missing data",
    "text": "2.5 Interpolate missing data\nSmall periods of missing data (&lt;24 hours) become a problem when aggregating at the daily and weekly time scales. *Note that currently this discovers and fills missing data at the daily time scale, but should be changed to interpolate at the original timescale of the raw data (e.g., hourly).\n\n\nCode\n# explore data gaps\nmysites &lt;- unique(dat_daily$site_name)\nmynas &lt;- list()\nfor (i in 1:length(mysites)) {\n  mydisch &lt;- unlist(dat_daily$flow_mean[dat_daily$site_name == mysites[i]])\n  runsna &lt;- rle(is.na(mydisch))\n  mynas[[i]] &lt;- tibble(site_name = mysites[i], run = runsna$lengths[runsna$values == TRUE])\n}\nmynas &lt;- do.call(rbind, mynas)\n# mynas %&gt;% filter(run &lt; 100) %&gt;% ggplot() + geom_histogram(aes(x = run)) + facet_wrap_paginate(~site_name, nrow = 4, ncol = 4, page = 1)\n# mynas %&gt;% filter(run &lt; 100) %&gt;% ggplot() + geom_histogram(aes(x = run)) + facet_wrap_paginate(~site_name, nrow = 4, ncol = 4, page = 2)\n# mynas %&gt;% filter(run &lt; 100) %&gt;% ggplot() + geom_histogram(aes(x = run)) + facet_wrap_paginate(~site_name, nrow = 4, ncol = 4, page = 3)\n# mynas %&gt;% filter(run &lt; 100) %&gt;% ggplot() + geom_histogram(aes(x = run)) + facet_wrap_paginate(~site_name, nrow = 4, ncol = 4, page = 4)\n\n\nMost gaps are relatively short\n\n\nCode\nmynas %&gt;% ggplot() + geom_histogram(aes(x = run)) + xlab(\"Days\") + ylab(\"Frequency\")\n\n\n\n\n\nDistributiion of lengths of missing data (days)\n\n\n\n\nZoomed in…\n\n\nCode\nmynas %&gt;% filter(run &lt; 30) %&gt;% ggplot() + geom_histogram(aes(x = run))  + xlab(\"Days\") + ylab(\"Frequency\")\n\n\n\n\n\nDistributiion of lengths of missing data (days)\n\n\n\n\nConsidering just the short gaps, which are likely a function of logger malfunction or Aquarius export issues, which sites are problematic? Answer: Flathead\n\n\nCode\nmynas %&gt;% filter(run &lt; 30) %&gt;% ggplot() + geom_bar(aes(site_name))+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\nFrequency of short (&lt;40 days) data gaps by site\n\n\n\n\nFill short gaps (&lt;=14 days…2x smoothing period) using time series interpolation\n\n\nCode\n# fill short gaps (&lt;=14 days...2x smoothing period) using time series interpolation\ndatalist &lt;- list()\nfor (i in 1:length(mysites)) { datalist[[i]] &lt;- dat_daily %&gt;% filter(site_name == mysites[i]) %&gt;% mutate(flow_mean_filled = fillMissing(flow_mean, max.fill = 14, span = 100)) }\n# bind and check 1:1\ndat_daily_fill &lt;- do.call(rbind, datalist)\n# dat_daily_fill %&gt;% ggplot() + geom_point(aes(x = flow_mean, y = flow_mean_filled)) + facet_wrap(~site_name, scales = \"free\")\n\n\nExplore interpolated/filled time series relative to original (daily) data Again, CoalCreekLower as an example. Would like to replace with shiny/interactive app\n\n\nCode\nlibrary(dygraphs)\ndat_daily_fill %&gt;% filter(site_name == \"CoalCreekLower\") %&gt;% select(date, flow_mean, flow_mean_filled) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dySeries(\"flow_mean\", strokeWidth = 5, color = \"black\") %&gt;% dySeries(\"flow_mean_filled\", strokeWidth = 1, color = \"red\") %&gt;% dyAxis(\"y\", label = \"Mean daily flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#calculate-yield",
    "href": "Data Availability/CollateData.html#calculate-yield",
    "title": "2  Collate Data",
    "section": "2.6 Calculate yield",
    "text": "2.6 Calculate yield\n\n\nCode\n# convert cfs and basin area to metric\ndat_daily_fill &lt;- dat_daily_fill %&gt;% mutate(flow_mean_cms = flow_mean*0.02831683199881, \n                                            flow_mean_filled_cms = flow_mean_filled*0.02831683199881, \n                                            area_sqkm = area_sqmi*2.58999)\n\n# sites\nsites &lt;- unique(dat_daily_fill$site_name)\n\n# site-specific basin area in square km\nbasinarea &lt;- dat_daily_fill %&gt;% filter(!is.na(site_id)) %&gt;% group_by(site_name) %&gt;% summarize(area_sqkm = unique(area_sqkm))\n\n# calculate yield\nyield_list &lt;- list()\nfor (i in 1:length(sites)) {\n  d &lt;- dat_daily_fill %&gt;% filter(site_name == sites[i])\n  ba &lt;- unlist(basinarea %&gt;% filter(site_name == sites[i]) %&gt;% select(area_sqkm))\n  yield_list[[i]] &lt;-  add_daily_yield(data = d, values = flow_mean_cms, basin_area = as.numeric(ba)) %&gt;% left_join(add_daily_yield(data = d, values = flow_mean_filled_cms, basin_area = as.numeric(ba)) %&gt;% rename(Yield_filled_mm = Yield_mm))\n}\ndat_daily_fill_wyield &lt;- do.call(rbind, yield_list)",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#calculate-7-day-means",
    "href": "Data Availability/CollateData.html#calculate-7-day-means",
    "title": "2  Collate Data",
    "section": "2.7 Calculate 7-day means",
    "text": "2.7 Calculate 7-day means\n\n\nCode\ndat_daily_fill_wyield &lt;- dat_daily_fill_wyield %&gt;%\n  group_by(site_name) %&gt;%\n  mutate(flow_mean_7 = rollapply(flow_mean, FUN = mean, width = 7, align = \"center\", fill = NA),\n         flow_mean_filled_7 = rollapply(flow_mean_filled, FUN = mean, width = 7, align = \"center\", fill = NA),\n         tempc_mean_7 = rollapply(tempc_mean, FUN = mean, width = 7, align = \"center\", fill = NA),\n         Yield_mm_7 = rollapply(Yield_mm, FUN = mean, width = 7, align = \"center\", fill = NA),\n         Yield_filled_mm_7 = rollapply(Yield_filled_mm, FUN = mean, width = 7, align = \"center\", fill = NA)) %&gt;%\n  ungroup() %&gt;% filter(!is.na(site_id))\n\n# # view flow\n# dat_daily_fill_wyield %&gt;% filter(site_name == \"Avery Brook\") %&gt;% select(date, flow_mean_filled, flow_mean_filled_7) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% \n#   dySeries(\"flow_mean_filled\", strokeWidth = 5, color = \"black\") %&gt;% dySeries(\"flow_mean_filled_7\", strokeWidth = 1, color = \"red\")\n# \n# # view yield\n# dat_daily_fill_wyield %&gt;% filter(site_name == \"Avery Brook\") %&gt;% select(date, Yield_filled_mm, Yield_filled_mm_7) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% \n#   dySeries(\"Yield_filled_mm\", strokeWidth = 5, color = \"black\") %&gt;% dySeries(\"Yield_filled_mm_7\", strokeWidth = 1, color = \"red\")\n\n# unique(dat_daily_fill_wyield$basin)\n# unique(dat_daily_fill_wyield$subbasin)\n# unique(dat_daily_fill_wyield$region)\n# unique(dat_daily_fill_wyield$disch_reli)\n# unique(dat_daily_fill_wyield$temp_reli)\n\n\nView little and medium g time series data (7-day mean yield), by sub-basin. Use the handles below the x-axis to adjust the time frame.\n\n\nCode\nmysubbasins &lt;- unique(dat_daily_fill_wyield$subbasin)[-c(4,7,13)]\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  myplots[[i]] &lt;- dat_daily_fill_wyield %&gt;% filter(designation %in% c(\"little\", \"medium\"), subbasin == mysubbasins[i]) %&gt;% mutate(logYield = log(Yield_filled_mm_7)) %&gt;% select(date, site_name, logYield) %&gt;% spread(key = site_name, value = logYield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"ln(Yield, mm)\")\n}\n\n\n\nBig CreekCoal CreekMcGee CreekWest BrookPaine RunStaunton RiverDuck CreekShields RiverSnake RiverDonner Blitzen",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#write-out-and-read-data",
    "href": "Data Availability/CollateData.html#write-out-and-read-data",
    "title": "2  Collate Data",
    "section": "2.8 Write out and read data",
    "text": "2.8 Write out and read data\n\n\nCode\n# write out\nwrite_csv(dat_daily_fill_wyield, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\")\ndat_daily &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#view-data-availability",
    "href": "Data Availability/CollateData.html#view-data-availability",
    "title": "2  Collate Data",
    "section": "2.9 View data availability",
    "text": "2.9 View data availability\n\n\nCode\n# summarize data availability\ndat_summ &lt;- dat_daily %&gt;% filter(site_id != \"MRN\") %&gt;%\n  group_by(basin, date, designation) %&gt;% summarize(numflow = sum(!is.na(flow_mean)), numtemp = sum(!is.na(tempc_mean))) %&gt;% \n  gather(type, avail, numflow:numtemp) %&gt;% mutate(type2 = as.factor(paste(designation, type, sep = \"_\"))) %&gt;% \n  mutate(type3 = as.numeric(type2), avail = na_if(avail, 0)) %&gt;% ungroup() %&gt;% filter(!is.na(avail))\n# levels(dat_summ$type2)\n# unique(dat_summ$basin)\n\n\n\n\nCode\n# plot all years\n#| fig-cap: \"Data availability by basin, all years\"\nmyplot &lt;- dat_summ %&gt;% ggplot(aes(x = date, y = type3)) + \n  geom_errorbarh(aes(xmax = date, xmin = date, color = avail), size = 0.001) +\n  scale_color_continuous(trans = \"reverse\", na.value = \"grey60\") +\n  scale_y_discrete(limits = c(\"Big G flow\", \"Big G temp\", \"Medium g flow\", \"Medium g temp\", \"Little g flow\", \"Little g temp\")) + \n  labs(colour = \"Number \\nof sites\") + ylab(\"\") + xlab(\"Date\") + \n  facet_wrap(~ basin, nrow = 4,\n             labeller = as_labeller(c(`West Brook` = \"West Brook: G = South River Conway (NWIS)\", \n                                      `Staunton River` = \"Staunton River: G = Staunton River 10 (UVA)\",\n                                      `Paine Run` = \"Paine Run: G = Paine Run 10 (UVA)\",\n                                      `Piney River` = \"Piney River: G = Piney River 10 (UVA)\",\n                                      `Snake River` = \"Snake River: G = Pacific Creek Moran (NWIS)\",\n                                      `Shields River` = \"Shields River: G = Shields River Livingston (NWIS)\",\n                                      `Flathead` = \"NF Flathead River: G = NF Flathead (NWIS)\",\n                                      `Donner Blitzen` = \"Donner Blitzen River: G = DB Frenchglen (NWIS)\",\n                                      `Duck Creek` = \"Duck Creek: G = Shields River Livingston (NWIS)\")))\nmyplot\n\n\n\n\n\n\n\n\n\nCode\n# jpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Data Availability/DataAvailability_byBasin.jpg\", height = 6, width = 12, units = \"in\", res = 500)\n# myplot\n# dev.off()\n\n\n\n\nCode\n# plot recent years\n#| fig-cap: \"Data availability by basin, recent years\"\n# jpeg(\"./Data Availability/DataAvailability_byBasin_recent.jpg\", height = 6, width = 12, units = \"in\", res = 500)\nmyplot &lt;- dat_summ %&gt;% filter(date &gt;= \"2018-10-01\") %&gt;% ggplot(aes(x = date, y = type3)) + \n  geom_errorbarh(aes(xmax = date, xmin = date, color = avail), size = 0.001) +\n  scale_color_continuous(trans = \"reverse\", na.value = \"grey60\") +\n  scale_y_discrete(limits = c(\"Big G flow\", \"Big G temp\", \"Medium g flow\", \"Medium g temp\", \"Little g flow\", \"Little g temp\")) + \n  labs(colour = \"Number \\nof sites\") + ylab(\"\") + xlab(\"Date\") + \n  facet_wrap(~ basin, nrow = 4,\n             labeller = as_labeller(c(`West Brook` = \"West Brook: G = South River Conway (NWIS)\", \n                                      `Staunton River` = \"Staunton River: G = Staunton River 10 (UVA)\",\n                                      `Paine Run` = \"Paine Run: G = Paine Run 10 (UVA)\",\n                                      `Piney River` = \"Piney River: G = Piney River 10 (UVA)\",\n                                      `Snake River` = \"Snake River: G = Pacific Creek Moran (NWIS)\",\n                                      `Shields River` = \"Shields River: G = Shields River Livingston (NWIS)\",\n                                      `Flathead` = \"NF Flathead River: G = NF Flathead (NWIS)\",\n                                      `Donner Blitzen` = \"Donner Blitzen River: G = DB Frenchglen (NWIS)\",\n                                      `Duck Creek` = \"Duck Creek: G = Shields River Livingston (NWIS)\")))\nmyplot",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#compare-co-located-gages",
    "href": "Data Availability/CollateData.html#compare-co-located-gages",
    "title": "2  Collate Data",
    "section": "2.10 Compare co-located gages",
    "text": "2.10 Compare co-located gages\n\n2.10.1 Compare synchronous gages\nCompare streamflow data from co-located EcoDrought and NWIS gages with overlapping periods of record\n\n\nCode\n# WEST BROOK\np1 &lt;- dat_daily %&gt;% filter(site_name == \"West Brook 0\") %&gt;% select(date, flow_mean_7) %&gt;% rename(little = flow_mean_7) %&gt;% \n  left_join(dat_daily %&gt;% filter(site_name == \"West Brook NWIS\") %&gt;% select(date, flow_mean_7) %&gt;% rename(medium = flow_mean_7)) %&gt;%\n  ggplot() + geom_point(aes(x = log(medium), y = log(little))) + geom_abline(intercept = 0, slope = 1, color = \"red\")\n\np2 &lt;- dat_daily %&gt;% filter(site_name == \"Avery Brook\") %&gt;% select(date, flow_mean_7) %&gt;% rename(little = flow_mean_7) %&gt;% \n  left_join(dat_daily %&gt;% filter(site_name == \"Avery Broook NWIS\") %&gt;% select(date, flow_mean_7) %&gt;% rename(medium = flow_mean_7)) %&gt;%\n  ggplot() + geom_point(aes(x = log(medium), y = log(little))) + geom_abline(intercept = 0, slope = 1, color = \"red\")\n\n# FLATHEAD\np3 &lt;- dat_daily %&gt;% filter(site_name == \"BigCreekMiddle\") %&gt;% select(date, flow_mean_7) %&gt;% rename(little = flow_mean_7) %&gt;% \n  left_join(dat_daily %&gt;% filter(site_name == \"Big Creek NWIS\") %&gt;% select(date, flow_mean_7) %&gt;% rename(medium = flow_mean_7)) %&gt;%\n  ggplot() + geom_point(aes(x = log(medium), y = log(little))) + geom_abline(intercept = 0, slope = 1, color = \"red\")\n\n# jpeg(\"./Data Availability/LittleMedium_Co-Located_Gages.jpg\", height = 6, width = 6, units = \"in\", res = 500)\nggarrange(p1, p2, p3, ncol = 2, nrow = 2, labels = c(\"West Brook 0\", \"Avery Brook\", \"Big Creek (Flathead)\"))\n\n\n\n\n\nStreamflow measured at little g gages (EcoDrought) as a function of streamflow measured at medium g gages (NWIS), on a log-scale. Red line denotes 1:1\n\n\n\n\nCode\n# dev.off()\n\n\n\n\n2.10.2 Compare asynchronous gages\nFor Spread Creek and Shields River, compare data from co-located EcoDrought and NWIS gages, with NON-overlapping periods of record. Note that streamflow from NWIS gages is about ~1 order of magnitude greater than what is measured at EcoD gages.\n\nLeidy CreekSF Spread Creek LowerDugout CreekSheilds Valley Ranch",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html",
    "href": "Explore Data/ExploreData.html",
    "title": "3  Explore Long-Term Data",
    "section": "",
    "text": "3.1 Site info and daily data\nPurpose: Explore (long-term) data and (recent) climatic context of EcoD years\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# flow (and temp) data\ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html#daymet-air-temp-and-precip",
    "href": "Explore Data/ExploreData.html#daymet-air-temp-and-precip",
    "title": "3  Explore Long-Term Data",
    "section": "3.2 Daymet air temp and precip",
    "text": "3.2 Daymet air temp and precip\n\n\nCode\nmycols &lt;- brewer.pal(6, \"Dark2\")\nsiteinfo_big &lt;- siteinfo %&gt;% filter(designation == \"big\")\n\n# download point location Daymet data\nclimlist &lt;- vector(\"list\", length = dim(siteinfo_big)[1])\nfor (i in 1:dim(siteinfo_big)[1]) {\n  clim &lt;- download_daymet(site = siteinfo_big$site_name[i], lat = siteinfo_big$lat[i], lon = siteinfo_big$long[i], start = 1980, end = 2023, internal = T)\n  climlist[[i]] &lt;- tibble(clim$data) %&gt;% \n    mutate(air_temp_mean = (tmax..deg.c. + tmin..deg.c.)/2, \n           date = as.Date(paste(year, yday, sep = \"-\"), \"%Y-%j\"),\n           site_name = siteinfo_big$site_name[i]) %&gt;%\n    select(12,2,11,10,4,6) %&gt;% rename(precip_mmday = 5, swe_kgm2 = 6)\n  #print(i)\n}\n\n# combine and calculate 7-day moving averages\nclimdf &lt;- do.call(rbind, climlist) %&gt;% left_join(siteinfo_big) %&gt;% mutate(year = year(date)) %&gt;% \n  group_by(station_no, site_name, site_id, basin, region, lat, long, elev_ft, area_sqmi, designation) %&gt;%\n  mutate(air_mean_7 = rollapply(air_temp_mean, FUN = mean, width = 7, align = \"center\", fill = NA),\n         precip_mean_7 = rollapply(precip_mmday, FUN = mean, width = 7, align = \"center\", fill = NA),\n         swe_mean_7 = rollapply(swe_kgm2, FUN = mean, width = 7, align = \"center\", fill = NA)) %&gt;%\n  ungroup() \n\n# trim to Big G sites\nclimdf_big &lt;- climdf %&gt;% filter(designation == \"big\")\n\n\nView long-term trends in mean annual air temperature, by basin\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Daymet_AirTemp_AnnualTrend_BigG.jpg\", height = 8, width = 8, units = \"in\", res = 500)\nclimdf_big_summ &lt;- climdf_big %&gt;% group_by(site_name, year) %&gt;% summarize(anntemp = mean(air_temp_mean)) %&gt;% ungroup()\nclimdf_big_summ %&gt;% \n  ggplot(aes(x = year, y = anntemp)) + geom_point() + facet_wrap(~site_name) + \n  geom_smooth(method = \"lm\", se = TRUE) + xlab(\"Year\") + ylab(\"Mean annual air temperature (deg C)\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nView long-term trends in total annual precipitation, by basin\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Daymet_AirTemp_AnnualTrend_BigG.jpg\", height = 8, width = 8, units = \"in\", res = 500)\nclimdf_big_summ &lt;- climdf_big %&gt;% group_by(site_name, year) %&gt;% summarize(annprec = sum(precip_mmday)) %&gt;% ungroup()\nclimdf_big_summ %&gt;% \n  ggplot(aes(x = year, y = annprec)) + geom_point() + facet_wrap(~site_name) + \n  geom_smooth(method = \"lm\", se = TRUE) + xlab(\"Year\") + ylab(\"Total annual precipitaion (mm)\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nView annual air temperature time series\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Daymet_AirTemp_Regime_BigG.jpg\", height = 8, width = 8, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = climdf_big, aes(x = yday, y = air_mean_7, group = year, color = year), size = 0.2) +\n  facet_wrap(~ site_name) + xlab(\"Day of year\") + ylab(\"7-day mean air temperature (deg C)\") + \n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nView annual air temperature time series, highlight recent years\n\n\nCode\nclimdf_big_recent &lt;- climdf_big %&gt;% filter(year %in% c(2018:2023))\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Daymet_AirTemp_Regime_BigG_Recent.jpg\", height = 8, width = 8, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = climdf_big, aes(x = yday, y = air_mean_7, group = year), color = \"grey70\", size = 0.25) +\n  geom_line(data = climdf_big_recent, aes(x = yday, y = air_mean_7, group = as.factor(year), color = as.factor(year))) +\n  scale_colour_manual(values = mycols) + facet_wrap(~ site_name) +\n  xlab(\"Day of year\") + ylab(\"7-day mean air temperature\") + \n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html#big-g-temp-flow-and-yield",
    "href": "Explore Data/ExploreData.html#big-g-temp-flow-and-yield",
    "title": "3  Explore Long-Term Data",
    "section": "3.3 Big G temp, flow, and yield",
    "text": "3.3 Big G temp, flow, and yield\n\n\nCode\ndat_daily_G &lt;- dat %&gt;% filter(designation == \"big\", site_name != \"West Brook 0\") %&gt;% mutate(yday = yday(date), year = year(date))\ndat_daily_G_recent &lt;- dat_daily_G %&gt;% filter(year %in% c(2018:2023))\nyear_range &lt;- dat_daily_G %&gt;% group_by(site_name) %&gt;% summarize(minyear = min(year), maxyear = max(year)) %&gt;% mutate(yearrange = paste(minyear, maxyear, sep = \"-\"))\nmycols &lt;- brewer.pal(6, \"Dark2\")\ndat_daily_G %&gt;% group_by(site_name) %&gt;% summarize(mindate = min(date), maxdate = max(date)) %&gt;% kable(caption = \"Date range of Big G streamflow data\")\n\n\n\nDate range of Big G streamflow data\n\n\nsite_name\nmindate\nmaxdate\n\n\n\n\nDonner Blitzen River nr Frenchglen NWIS\n1980-01-01\n2024-11-17\n\n\nNorth Fork Flathead River NWIS\n1980-01-01\n2024-11-17\n\n\nPacific Creek at Moran NWIS\n1980-01-01\n2024-11-17\n\n\nPaine Run 10\n1992-10-01\n2023-12-31\n\n\nPiney River 10\n1992-10-01\n2023-12-31\n\n\nShields River nr Livingston NWIS\n1980-01-01\n2024-11-17\n\n\nSouth River Conway NWIS\n1980-01-01\n2024-11-17\n\n\nStaunton River 10\n1992-09-02\n2023-12-31\n\n\n\n\n\nIn-situ stream temperature\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_StreamTemp_BigG_Recent.jpg\", height = 8, width = 9, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = dat_daily_G, aes(x = yday, y = tempc_mean_7, group = year), color = \"grey70\", size = 0.25) +\n  geom_line(data = dat_daily_G_recent, aes(x = yday, y = tempc_mean_7, group = as.factor(year), color = as.factor(year))) +\n  scale_colour_manual(values = mycols) + facet_wrap(~ site_name, nrow = 3) + xlab(\"Day of calendar year\") + ylab(\"7-day mean temperature (deg C)\") + ylim(0,22) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.9,0.05), legend.justification = c(1,0)) + labs(color = \"Year\")\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nIn-situ streamflow\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_StreamFlow_BigG_Recent.jpg\", height = 8, width = 9, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = dat_daily_G, aes(x = yday, y = log(flow_mean_7), group = year), color = \"grey70\", size = 0.25) +\n  geom_line(data = dat_daily_G_recent, aes(x = yday, y = log(flow_mean_7), group = as.factor(year), color = as.factor(year))) +\n  scale_colour_manual(values = mycols) + \n  geom_text(data = year_range, aes(x = -Inf, y = -Inf, label = yearrange), hjust = -0.1, vjust = -1) +\n  facet_wrap(~ site_name, nrow = 3, scales = \"free_y\") + \n  xlab(\"Day of calendar year\") + ylab(\"ln 7-day mean streamflow (cfs)\") + labs(color = \"Year\") + theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.9,0.05), legend.justification = c(1,0))\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nStreamflow in Yield. Note same y-axis limits\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Yield_BigG_Recent.jpg\", height = 8, width = 9, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = dat_daily_G, aes(x = yday, y = log(Yield_filled_mm_7), group = year), color = \"grey70\", size = 0.25) +\n  geom_line(data = dat_daily_G_recent, aes(x = yday, y = log(Yield_filled_mm_7), group = as.factor(year), color = as.factor(year))) +\n  scale_colour_manual(values = mycols) + \n  geom_text(data = year_range, aes(x = -Inf, y = -Inf, label = yearrange), hjust = -0.1, vjust = -1) +\n  facet_wrap(~ site_name, nrow = 3) + \n  xlab(\"Day of year\") + ylab(\"ln 7-day mean yield\") + labs(color = \"Year\") + theme_bw() + ylim(-5,3.5) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.9,0.05), legend.justification = c(1,0))\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html#exceedance-probability",
    "href": "Explore Data/ExploreData.html#exceedance-probability",
    "title": "3  Explore Long-Term Data",
    "section": "3.4 Exceedance probability",
    "text": "3.4 Exceedance probability\n\n\nCode\nexceedance &lt;- dat_daily_G %&gt;% filter(!is.na(Yield_filled_mm)) %&gt;% \n  mutate(Yield_filled_mm_log = log(Yield_filled_mm)) %&gt;%\n  group_by(station_no, site_name, site_id, basin, region, lat, long, elev_ft, area_sqmi, designation, year) %&gt;% \n  arrange(desc(Yield_filled_mm_log), .by_group = TRUE) %&gt;% \n  mutate(exceedance = 100/length(Yield_filled_mm_log)*1:length(Yield_filled_mm_log)) %&gt;%\n  ungroup()\nexceedance_recent &lt;- exceedance %&gt;% filter(year %in% c(2018:2023))\n\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Yield_Recent_Exceedance.jpg\", height = 8, width = 9, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = exceedance, aes(x = exceedance, y = Yield_filled_mm_log, group = year), color = \"grey70\", size = 0.25) +\n  geom_line(data = exceedance_recent, aes(x = exceedance, y = Yield_filled_mm_log, group = as.factor(year), color = as.factor(year))) +\n  scale_colour_manual(values = mycols) + \n  geom_text(data = year_range, aes(x = -Inf, y = -Inf, label = yearrange), hjust = -0.1, vjust = -1) +\n  facet_wrap(~ site_name, nrow = 3) + \n  xlab(\"Exceedance probability\") + ylab(\"ln daily mean yield (mm)\") + labs(color = \"Year\") + theme_bw() + ylim(-5,5) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.9,0.05), legend.justification = c(1,0))\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html#dsci",
    "href": "Explore Data/ExploreData.html#dsci",
    "title": "3  Explore Long-Term Data",
    "section": "3.5 DSCI",
    "text": "3.5 DSCI\nView time series of drought severity and coverage index (DSCI), summarized over HUC08 basins. Accessed https://droughtmonitor.unl.edu/DmData/TimeSeries.aspx\n\n\nCode\n# get huc 8 codes\nhuctib &lt;- tibble(site_name = siteinfo$site_name, basin = siteinfo$basin, huc08 = NA)\nfor (i in 1:dim(siteinfo)[1]) {\n  huctib$huc08[i] &lt;- unlist(tibble(get_huc(siteinfo_sp[i,], type = \"huc08\"))[,11])\n  #print(i)\n}\nhuctib &lt;- huctib %&gt;% group_by(basin) %&gt;% summarize(huc08 = unique(huc08)) #%&gt;% filter(basin != \"Piney River\")\n# unique(huctib$huc08)\n\n# bring in drought indices\ndsci &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/dm_export_19800101_20241004.csv\") %&gt;%\n rename(huc08 = HUCID, name = Name, date = MapDate, dsci = DSCI) %&gt;% mutate(date = ymd(date)) %&gt;% left_join(huctib)\n\n# print table\ndsci %&gt;% group_by(basin) %&gt;% summarize(dsci_name = unique(name), huc08 = unique(huc08)) %&gt;% kable(caption = \"HUC08 basin codes for primary EcoDrought basins\")\n\n\n\nHUC08 basin codes for primary EcoDrought basins\n\n\nbasin\ndsci_name\nhuc08\n\n\n\n\nDonner Blitzen\nDonner und Blitzen\n17120003\n\n\nFlathead\nNorth Fork Flathead\n17010206\n\n\nPaine Run\nSouth Fork Shenandoah\n02070005\n\n\nPiney River\nRapidan-Upper Rappahannock\n02080103\n\n\nShields River\nShields\n10070003\n\n\nSnake River\nSnake Headwaters\n17040101\n\n\nStaunton River\nRapidan-Upper Rappahannock\n02080103\n\n\nWest Brook\nMiddle Connecticut\n01080201\n\n\n\n\n\n\n\nCode\n# calculate monthly means\ndsci_monthly &lt;- dsci %&gt;% \n  mutate(monthyear = as_date(paste(format_ISO8601(date, precision = \"ym\"), \"-01\", sep = \"\"))) %&gt;% \n  mutate(year = year(monthyear), month = month(monthyear)) %&gt;%\n  group_by(huc08, basin, year, month, monthyear) %&gt;% \n  summarize(dsci_monthly_1 = mean(dsci)) %&gt;% \n  ungroup() %&gt;%\n  group_by(huc08, basin) %&gt;%\n  mutate(dsci_monthly_2 = rollapply(dsci_monthly_1, FUN = mean, width = 2, align = \"right\", fill = NA),\n         dsci_monthly_3 = rollapply(dsci_monthly_1, FUN = mean, width = 3, align = \"right\", fill = NA),\n         dsci_monthly_4 = rollapply(dsci_monthly_1, FUN = mean, width = 4, align = \"right\", fill = NA),\n         dsci_monthly_5 = rollapply(dsci_monthly_1, FUN = mean, width = 5, align = \"right\", fill = NA),\n         dsci_monthly_6 = rollapply(dsci_monthly_1, FUN = mean, width = 6, align = \"right\", fill = NA),\n         dsci_monthly_7 = rollapply(dsci_monthly_1, FUN = mean, width = 7, align = \"right\", fill = NA),\n         dsci_monthly_8 = rollapply(dsci_monthly_1, FUN = mean, width = 8, align = \"right\", fill = NA),\n         dsci_monthly_9 = rollapply(dsci_monthly_1, FUN = mean, width = 9, align = \"right\", fill = NA),\n         dsci_monthly_10 = rollapply(dsci_monthly_1, FUN = mean, width = 10, align = \"right\", fill = NA),\n         dsci_monthly_11 = rollapply(dsci_monthly_1, FUN = mean, width = 11, align = \"right\", fill = NA),\n         dsci_monthly_12 = rollapply(dsci_monthly_1, FUN = mean, width = 12, align = \"right\", fill = NA),\n         dsci_monthly_13 = rollapply(dsci_monthly_1, FUN = mean, width = 13, align = \"right\", fill = NA),\n         dsci_monthly_14 = rollapply(dsci_monthly_1, FUN = mean, width = 14, align = \"right\", fill = NA),\n         dsci_monthly_15 = rollapply(dsci_monthly_1, FUN = mean, width = 15, align = \"right\", fill = NA),\n         dsci_monthly_16 = rollapply(dsci_monthly_1, FUN = mean, width = 16, align = \"right\", fill = NA),\n         dsci_monthly_17 = rollapply(dsci_monthly_1, FUN = mean, width = 17, align = \"right\", fill = NA),\n         dsci_monthly_18 = rollapply(dsci_monthly_1, FUN = mean, width = 18, align = \"right\", fill = NA),\n         dsci_monthly_19 = rollapply(dsci_monthly_1, FUN = mean, width = 19, align = \"right\", fill = NA),\n         dsci_monthly_20 = rollapply(dsci_monthly_1, FUN = mean, width = 20, align = \"right\", fill = NA),\n         dsci_monthly_21 = rollapply(dsci_monthly_1, FUN = mean, width = 21, align = \"right\", fill = NA),\n         dsci_monthly_22 = rollapply(dsci_monthly_1, FUN = mean, width = 22, align = \"right\", fill = NA),\n         dsci_monthly_23 = rollapply(dsci_monthly_1, FUN = mean, width = 23, align = \"right\", fill = NA),\n         dsci_monthly_24 = rollapply(dsci_monthly_1, FUN = mean, width = 24, align = \"right\", fill = NA),) %&gt;%\n  ungroup()\n\n# plot time series\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_DSCI_1-6-12.jpg\", height = 8, width = 9, units = \"in\", res = 500)\ndsci_monthly %&gt;% ggplot() + \n  geom_line(aes(x = monthyear, y = dsci_monthly_1), color = \"grey50\") + \n  geom_line(aes(x = monthyear, y = dsci_monthly_6), color = mycols[1]) + \n  geom_line(aes(x = monthyear, y = dsci_monthly_12), color = mycols[2]) + \n  facet_wrap(~ basin) + \n  xlab(\"\") + ylab(\"Drought severity and coverage index (DSCI): 1-, 6-, and 12-month\") + theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html#spi",
    "href": "Explore Data/ExploreData.html#spi",
    "title": "3  Explore Long-Term Data",
    "section": "3.6 SPI",
    "text": "3.6 SPI\nCalculate standardized precipiation index (SPI) for EcoDrought basins at multiple time scales (1-24 months). View time series data.\n\n\nCode\n# combine and calculate monthly totals\nclimdf_monthly &lt;- do.call(rbind, climlist) %&gt;% left_join(siteinfo_big) %&gt;% mutate(year = year(date), month = month(date)) %&gt;%\n  group_by(station_no, site_name, site_id, basin, region, lat, long, elev_ft, area_sqmi, designation, year, month) %&gt;%\n  summarize(precip_mmmonth = sum(precip_mmday)) %&gt;%\n  ungroup() %&gt;%\n  mutate(date = date(paste(year, month, \"01\", sep = \"-\")))\n\n# calculate SPI at various time scales\nspi_list &lt;- list()\nfor (i in 1:dim(siteinfo_big)[1]) {\n  d &lt;- climdf_monthly %&gt;% filter(site_name == siteinfo_big$site_name[i])\n  for (j in 1:24) {\n    myspi &lt;- spi(unlist(d %&gt;% select(precip_mmmonth)), scale = j)\n    myspi &lt;- myspi$fitted\n    myspi[is.infinite(myspi)] &lt;- NA\n    d[,paste(\"spi\", j, sep = \"_\")] &lt;- myspi\n  }\n  spi_list[[i]] &lt;- d\n  #print(i)\n}\n\n\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n\n\nCode\nspi_monthly &lt;- do.call(rbind, spi_list)\n# view(spi_monthly)\n\n# spi_monthly %&gt;% filter(site_id == \"SRL\") %&gt;% ggplot() + geom_line(aes(x = date, y = spi_1))\n# spi_monthly %&gt;% filter(site_id == \"SRL\") %&gt;% ggplot() + geom_line(aes(x = date, y = spi_3))\n# spi_monthly %&gt;% filter(site_id == \"SRL\") %&gt;% ggplot() + geom_line(aes(x = date, y = spi_6))\n# spi_monthly %&gt;% filter(site_id == \"SRL\") %&gt;% ggplot() + geom_line(aes(x = date, y = spi_12))\n# spi_monthly %&gt;% filter(site_id == \"SRL\") %&gt;% ggplot() + geom_line(aes(x = date, y = spi_24))\n\n\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_SPI_1-6-12.jpg\", height = 8, width = 9, units = \"in\", res = 500)\nspi_monthly %&gt;% ggplot() + \n  geom_line(aes(x = date, y = spi_1), color = \"grey50\") + \n  geom_line(aes(x = date, y = spi_6), color = mycols[1]) + \n  geom_line(aes(x = date, y = spi_12), color = mycols[2]) +\n  geom_line(aes(x = date, y = spi_24), color = mycols[3]) +\n  facet_wrap(~ basin) + \n  xlab(\"\") + ylab(\"Standardized precipitation index (SPI): 1-, 6-, 12-, and 24-month\") + theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/TemporalResolution.html",
    "href": "Explore Data/TemporalResolution.html",
    "title": "4  Explore Sub-Daily Data",
    "section": "",
    "text": "4.1 Data\nPurpose: Explore data at sub-daily temporal resolutions (e.g., 15-min and 1-hour time steps) and compare outputs to daily data.\nGiven that streamflow can change so quickly in small, headwater streams, are we missing a key part of the story by using flow data summarized as daily means? Using daily mean flow reduces the range of values, particularly at the upper end (i.e., high flows), and so we may be overlooking the g~G relationship at very high flows. (Note limited analysis of 15-min data as Montana and Wyoming data is collected at the hourly timescale).",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Explore Sub-Daily Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/TemporalResolution.html#data",
    "href": "Explore Data/TemporalResolution.html#data",
    "title": "4  Explore Sub-Daily Data",
    "section": "",
    "text": "4.1.1 Load data\nBring in site info and sub-daily data\n\n\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# flow/yield (and temp) data \ndat_sub &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_Raw.csv\") %&gt;%\n  filter(!site_name %in% c(\"WoundedBuckCreek\", \"Brackett Creek\"))\n\ndat_little &lt;- dat_sub %&gt;% \n  filter(site_name %in% c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")) %&gt;% \n  select(site_name, datetime, flow, area_sqmi)\n\n\nDownload 15-min NWIS data for big G (West Brook NWIS)\n\n\nCode\nwbnwis &lt;- tibble(readNWISdata(sites = \"01171100\", service = \"uv\", startDate = \"1980-01-01\", endDate = Sys.Date(), tz = \"America/New_York\"))\nwbnwis2 &lt;- wbnwis[,c(2,3,4)]\nnames(wbnwis2) &lt;- c(\"station_no\", \"datetime\", \"flow\") \ndat_big &lt;- wbnwis2 %&gt;% \n  left_join(siteinfo %&gt;% filter(site_name == \"West Brook NWIS\")) %&gt;% \n  select(site_name, datetime, flow, area_sqmi)\n\n\nOrganize 15-min and 1-hour datasets, load daily data\n\n\nCode\ndat_15min &lt;- bind_rows(dat_little, dat_big) %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\", \"West Brook NWIS\"))) %&gt;%\n  mutate(flow_cms = flow*0.02831683199881, area_sqkm = area_sqmi*2.58999) %&gt;%\n  mutate(yield = flow_cms * 900 * (1/(area_sqkm)) * (1/1000000) * 1000)\n\n\ndat_1hr &lt;- bind_rows(dat_little, dat_big) %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\", \"West Brook NWIS\"))) %&gt;%\n  filter(!is.na(flow)) %&gt;% \n  mutate(datetime = floor_date(datetime, unit = \"hour\")) %&gt;%\n  group_by(site_name, datetime) %&gt;% \n  summarise(flow = mean(flow), area_sqmi = unique(area_sqmi)) %&gt;%\n  ungroup() %&gt;%\n  mutate(flow_cms = flow*0.02831683199881, area_sqkm = area_sqmi*2.58999) %&gt;%\n  mutate(yield = flow_cms * 3600 * (1/(area_sqkm)) * (1/1000000) * 1000)\n\ndat_1day &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\") %&gt;%\n  filter(site_name %in% c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\", \"West Brook NWIS\")) %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\", \"West Brook NWIS\")))\n\n\n\n\n4.1.2 View 15-min data\nPlot 15 min time series data\n\n\nCode\ndat_15min %&gt;% select(datetime, site_name, yield) %&gt;% spread(key = site_name, value = yield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(colors = c(hcl.colors(9, \"Zissou 1\"), \"black\")) %&gt;% dyHighlight() \n\n\n\n\n\n\n\n\n4.1.3 View 1-hour data\nPlot 1-hour time series data\n\n\nCode\ndat_1hr %&gt;% select(datetime, site_name, yield) %&gt;% spread(key = site_name, value = yield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(colors = c(hcl.colors(9, \"Zissou 1\"), \"black\")) %&gt;% dyHighlight() \n\n\n\n\n\n\n\n\n4.1.4 View 1-day data\nPlot 1-day/daily time series data\n\n\nCode\ndat_1day %&gt;% select(date, site_name, Yield_filled_mm) %&gt;% spread(key = site_name, value = Yield_filled_mm) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(colors = c(hcl.colors(9, \"Zissou 1\"), \"black\")) %&gt;% dyHighlight()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Explore Sub-Daily Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/TemporalResolution.html#event-pairing",
    "href": "Explore Data/TemporalResolution.html#event-pairing",
    "title": "4  Explore Sub-Daily Data",
    "section": "4.2 Event pairing",
    "text": "4.2 Event pairing\nConduct event pairing using hydroEvents package to understand lag time between peak flows at big and little g’s\n\n4.2.1 Hourly data\n\n4.2.1.1 Conduct event pairing\n\n\nCode\n# baseflow separation and event delineation parameters\nalp &lt;- 0.925\nnumpass &lt;- 9\nthresh &lt;- 0.5\n\n# sites\nsites &lt;- unique(dat_1hr$site_name)[1:9]\n\n# empty list to store output\noutlist &lt;- list()\n\nfor (j in 1:length(sites)) {\n  # grab big and little g data and combine into a single tibble\n  littleg &lt;- dat_1hr %&gt;% filter(site_name == sites[j])\n  bigg &lt;- dat_1hr %&gt;% filter(site_name == \"West Brook NWIS\")\n  mytib &lt;- bigg %&gt;% select(datetime, yield) %&gt;% rename(yield_big = yield) %&gt;% left_join(littleg %&gt;% select(datetime, yield) %&gt;% rename(yield_little = yield))\n  \n  # baseflow separation\n  mytib_bf &lt;- mytib %&gt;% \n  filter(!is.na(yield_big), !is.na(yield_little)) %&gt;% \n  mutate(bf_big = baseflowB(yield_big, alpha = alp, passes = numpass)$bf, \n         bfi_big = baseflowB(yield_big, alpha = alp, passes = numpass)$bfi,\n         bf_little = baseflowB(yield_little, alpha = alp, passes = numpass)$bf, \n         bfi_little = baseflowB(yield_little, alpha = alp, passes = numpass)$bfi)\n  \n  # delineate events\n  events_little &lt;- eventBaseflow(mytib_bf$yield_little, BFI_Th = thresh, bfi = mytib_bf$bfi_little)\n  events_big &lt;- eventBaseflow(mytib_bf$yield_big, BFI_Th = thresh, bfi = mytib_bf$bfi_big)\n  \n  # event matching\n  mypairs &lt;- pairEvents(events_little, events_big, lag = 5, type = 1)\n  mypairs_com &lt;- mypairs[complete.cases(mypairs),]\n  \n  # get matched event info\n  matchpeaktib &lt;- tibble(datetime_little = rep(NA, times = dim(mypairs_com)[1]), datetime_big = rep(NA, times = dim(mypairs_com)[1]),\n                         yield_little = rep(NA, times = dim(mypairs_com)[1]), yield_big = rep(NA, times = dim(mypairs_com)[1]))\n  for (i in 1:dim(mypairs_com)[1]) {\n    matchpeaktib$datetime_little[i] &lt;- mytib_bf$datetime[events_little$which.max[events_little$srt == mypairs_com$srt[i]]]\n    matchpeaktib$datetime_big[i] &lt;- mytib_bf$datetime[events_big$which.max[events_big$srt == mypairs_com$matched.srt[i]]]\n    matchpeaktib$yield_little[i] &lt;- events_little$max[events_little$srt == mypairs_com$srt[i]]\n    matchpeaktib$yield_big[i] &lt;- events_big$max[events_big$srt == mypairs_com$matched.srt[i]]\n    }\n  matchpeaktib &lt;- matchpeaktib %&gt;% mutate(datetime_little = as_datetime(datetime_little),\n                                          datetime_big = as_datetime(datetime_big),\n                                          timediff_hrs = as.numeric(difftime(datetime_big, datetime_little), units = \"hours\"),\n                                          site_name = sites[j])\n  \n  # store output in list\n  outlist[[j]] &lt;- matchpeaktib\n}\nmatchpeaktib &lt;- do.call(rbind, outlist)\n(matchpeaktib)\n\n\n# A tibble: 515 × 6\n   datetime_little     datetime_big        yield_little yield_big timediff_hrs\n   &lt;dttm&gt;              &lt;dttm&gt;                     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n 1 2020-02-07 17:00:00 2020-02-07 23:00:00        0.150    0.155             6\n 2 2020-02-21 10:00:00 2020-02-21 18:00:00        0.111    0.0893            8\n 3 2020-02-27 09:00:00 2020-02-27 16:00:00        0.432    0.477             7\n 4 2020-03-13 13:00:00 2020-03-13 19:00:00        0.190    0.180             6\n 5 2020-03-19 10:00:00 2020-03-19 16:00:00        0.191    0.181             6\n 6 2020-03-29 23:00:00 2020-03-30 05:00:00        0.327    0.332             6\n 7 2020-04-09 17:00:00 2020-04-09 23:00:00        0.204    0.197             6\n 8 2020-04-13 19:00:00 2020-04-14 02:00:00        0.419    0.506             7\n 9 2020-04-30 15:00:00 2020-04-30 22:00:00        0.214    0.218             7\n10 2020-05-01 19:00:00 2020-05-02 00:00:00        0.811    1.28              5\n# ℹ 505 more rows\n# ℹ 1 more variable: site_name &lt;fct&gt;\n\n\n\n\n4.2.1.2 Plot output\n\nDistribution of lags\nConstrain lag times to realistic values (&gt;=0 and &lt;= 24) as event pairing is not perfect, and view histograms by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= 0 & timediff_hrs &lt;= 24) %&gt;% ggplot() + geom_histogram(aes(x = timediff_hrs)) + facet_wrap(~site_name)\n\n\n\n\n\n\n\n\n\nView distributions summarized as boxplots. Sites are ordered from closest to Big G (bottom) to furthest (top). Interestingly, there is not a strong pattern of longer lag times for further sites.\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= 0 & timediff_hrs &lt;= 24) %&gt;% ggplot() + geom_boxplot(aes(x = site_name, y = timediff_hrs)) + coord_flip()\n\n\n\n\n\n\n\n\n\n\n\nLag by yield\nDoes lag time depend on the magnitude of yield at big G? Under high flows when water is moving more quickly, we might expect the lag to be shorter (negative relationship).\nView global relationship\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= 0 & timediff_hrs &lt;= 24) %&gt;% ggplot(aes(x = yield_big, y = jitter(timediff_hrs))) + geom_point() + geom_smooth()\n\n\n\n\n\n\n\n\n\nView by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= 0 & timediff_hrs &lt;= 24) %&gt;% ggplot(aes(x = yield_big, y = jitter(timediff_hrs))) + geom_point() + geom_smooth() + facet_wrap(~ site_name)\n\n\n\n\n\n\n\n\n\nThere appears to be some evidence for shorter lag times with increasing flow, but this relationship is only evident for very low flows. What is more apparent is the overall attenuation in variability in lag time as flows increase: at very low flows, lags are highly variable, but less variable (and intermediate in magnitude) under high flows.\n\n\nLag by time\nDoes lag time change over time? Perhaps lag time is seasonal and changes with antecedant conditions. Note that this is not the best way to get at the question of importance of antecedant conditions.\nView global relationship\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= 0 & timediff_hrs &lt;= 24) %&gt;% mutate(doy = yday(datetime_little)) %&gt;% ggplot(aes(x = doy, y = jitter(timediff_hrs))) + geom_point() + geom_smooth()\n\n\n\n\n\n\n\n\n\nView by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= 0 & timediff_hrs &lt;= 24) %&gt;% mutate(doy = yday(datetime_little)) %&gt;% ggplot(aes(x = doy, y = jitter(timediff_hrs))) + geom_point() + geom_smooth() + facet_wrap(~ site_name)\n\n\n\n\n\n\n\n\n\nThere does not appear to be any consistent pattern (within or among sites) in how lag times change with time of year\n\n\n\n\n4.2.2 Daily data\n\n4.2.2.1 Conduct event pairing\n\n\nCode\n# baseflow separation and event delineation parameters\nalp &lt;- 0.925\nnumpass &lt;- 3\nthresh &lt;- 0.5\n\n# sites\nsites &lt;- unique(dat_1day$site_name)[1:9]\n\n# empty list to store output\noutlist &lt;- list()\n\nfor (j in 1:length(sites)) {\n  # grab big and little g data and combine into a single tibble\n  littleg &lt;- dat_1day %&gt;% filter(site_name == sites[j])\n  bigg &lt;- dat_1day %&gt;% filter(site_name == \"West Brook NWIS\")\n  mytib &lt;- bigg %&gt;% select(date, Yield_filled_mm) %&gt;% rename(yield_big = Yield_filled_mm) %&gt;% left_join(littleg %&gt;% select(date, Yield_filled_mm) %&gt;% rename(yield_little = Yield_filled_mm))\n  \n  # baseflow separation\n  mytib_bf &lt;- mytib %&gt;% \n  filter(!is.na(yield_big), !is.na(yield_little)) %&gt;% \n  mutate(bf_big = baseflowB(yield_big, alpha = alp, passes = numpass)$bf, \n         bfi_big = baseflowB(yield_big, alpha = alp, passes = numpass)$bfi,\n         bf_little = baseflowB(yield_little, alpha = alp, passes = numpass)$bf, \n         bfi_little = baseflowB(yield_little, alpha = alp, passes = numpass)$bfi)\n  \n  # delineate events\n  events_little &lt;- eventBaseflow(mytib_bf$yield_little, BFI_Th = thresh, bfi = mytib_bf$bfi_little)\n  events_big &lt;- eventBaseflow(mytib_bf$yield_big, BFI_Th = thresh, bfi = mytib_bf$bfi_big)\n  \n  # event matching\n  mypairs &lt;- pairEvents(events_little, events_big, lag = 5, type = 1)\n  mypairs_com &lt;- mypairs[complete.cases(mypairs),]\n  \n  # get matched event info\n  matchpeaktib &lt;- tibble(datetime_little = rep(NA, times = dim(mypairs_com)[1]), datetime_big = rep(NA, times = dim(mypairs_com)[1]),\n                         yield_little = rep(NA, times = dim(mypairs_com)[1]), yield_big = rep(NA, times = dim(mypairs_com)[1]))\n  for (i in 1:dim(mypairs_com)[1]) {\n    matchpeaktib$datetime_little[i] &lt;- mytib_bf$date[events_little$which.max[events_little$srt == mypairs_com$srt[i]]]\n    matchpeaktib$datetime_big[i] &lt;- mytib_bf$date[events_big$which.max[events_big$srt == mypairs_com$matched.srt[i]]]\n    matchpeaktib$yield_little[i] &lt;- events_little$max[events_little$srt == mypairs_com$srt[i]]\n    matchpeaktib$yield_big[i] &lt;- events_big$max[events_big$srt == mypairs_com$matched.srt[i]]\n    }\n  matchpeaktib &lt;- matchpeaktib %&gt;% mutate(datetime_little = as_date(datetime_little),\n                                          datetime_big = as_date(datetime_big),\n                                          timediff_dys = as.numeric(difftime(datetime_big, datetime_little), units = \"days\"),\n                                          site_name = sites[j])\n  \n  # store output in list\n  outlist[[j]] &lt;- matchpeaktib\n}\nmatchpeaktib &lt;- do.call(rbind, outlist)\n(matchpeaktib)\n\n\n# A tibble: 337 × 6\n   datetime_little datetime_big yield_little yield_big timediff_dys site_name  \n   &lt;date&gt;          &lt;date&gt;              &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt; &lt;fct&gt;      \n 1 2020-02-27      2020-02-27         10.5       6.35             0 Avery Brook\n 2 2020-03-29      2020-03-29          9.56      6.19             0 Avery Brook\n 3 2020-04-13      2020-04-13          8.76      6.24             0 Avery Brook\n 4 2020-05-01      2020-05-01         20.1      14.8              0 Avery Brook\n 5 2020-05-16      2020-05-16          2.68      1.93             0 Avery Brook\n 6 2020-07-03      2020-07-04          1.17      0.447            1 Avery Brook\n 7 2020-07-09      2020-07-10          3.05      0.763            1 Avery Brook\n 8 2020-07-17      2020-07-17          0.684     0.364            0 Avery Brook\n 9 2020-07-23      2020-07-23          0.630     0.904            0 Avery Brook\n10 2020-08-04      2020-08-05          0.615     0.229            1 Avery Brook\n# ℹ 327 more rows\n\n\n\n\n4.2.2.2 Plot output\n\nDistribution of lags\nConstrain lag times to realistic values (&gt;=0 and &lt;= 24) as event pairing is not perfect, and view histograms by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1) %&gt;% ggplot() + geom_histogram(aes(x = timediff_dys)) + facet_wrap(~site_name)\n\n\n\n\n\n\n\n\n\nView distributions summarized as means. Sites are ordered from closest to Big G (bottom) to furthest (top). There is general pattern of longer lag times for further sites.\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1) %&gt;% group_by(site_name) %&gt;% summarize(diffmean = mean(timediff_dys), diffsd = sd(timediff_dys)) %&gt;% ggplot() + \n  geom_point(aes(x = site_name, y = diffmean)) + \n  #geom_errorbar(aes(x = site_name, ymin = diffmean - diffsd, ymax = diffmean + diffsd)) + \n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\nLag by yield\nDoes lag time depend on the magnitude of yield at big G? Under high flows when water is moving more quickly, we might expect the lag to be shorter (negative relationship).\nView global relationship\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1) %&gt;% ggplot(aes(x = yield_big, y = jitter(timediff_dys))) + geom_point() + geom_smooth()\n\n\n\n\n\n\n\n\n\nView by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1)  %&gt;% ggplot(aes(x = yield_big, y = jitter(timediff_dys))) + geom_point() + geom_smooth() + facet_wrap(~ site_name)\n\n\n\n\n\n\n\n\n\nAs with the hourly data, there appears to be some evidence for shorter lag times with increasing flow, but this relationship is only evident for very low flows. Although we note that 1-day lags are very rare (16% of all observations)\n\n\nLag by time\nDoes lag time change over time? Perhaps lag time is seasonal and changes with antecedant conditions. Note that this is not the best way to get at the question of importance of antecedant conditions.\nView global relationship\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1) %&gt;% mutate(doy = yday(datetime_little)) %&gt;% ggplot(aes(x = doy, y = jitter(timediff_dys))) + geom_point() + geom_smooth()\n\n\n\n\n\n\n\n\n\nView by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1) %&gt;% mutate(doy = yday(datetime_little)) %&gt;% ggplot(aes(x = doy, y = (timediff_dys))) + geom_point() + geom_smooth() + facet_wrap(~ site_name)\n\n\n\n\n\n\n\n\n\nThe prevalence of 1-day lags in peak flow generally peaks in mid summer (July) when flows are low",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Explore Sub-Daily Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/TemporalResolution.html#dynamic-time-warping",
    "href": "Explore Data/TemporalResolution.html#dynamic-time-warping",
    "title": "4  Explore Sub-Daily Data",
    "section": "4.5 Dynamic time warping",
    "text": "4.5 Dynamic time warping\nExplore the use of dynamic time warping (Giorgino 2009) to align hourly time series data.\n\n4.5.1 Select data\nTrim to restricted period b/c DTW cannot handle very large datasets\n\n\nCode\nlittleg &lt;- dat_1hr %&gt;% filter(site_name == \"Avery Brook\", datetime &gt;= as_datetime(\"2020-03-01 00:00:00\") & datetime &lt;= as_datetime(\"2020-06-01 00:00:00\"))\nbigg &lt;- dat_1hr %&gt;% filter(site_name == \"West Brook NWIS\", datetime &gt;= as_datetime(\"2020-03-01 00:00:00\") & datetime &lt;= as_datetime(\"2020-06-01 00:00:00\"))\n\nmytib &lt;- bigg %&gt;% select(datetime, yield) %&gt;% rename(yield_big = yield) %&gt;% left_join(littleg %&gt;% select(datetime, yield) %&gt;% rename(yield_little = yield))\nmytib %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\")\n\n\n\n\n\n\n\n\n4.5.2 Align data\n\n\nCode\nalign1hr &lt;- dtw(x = unlist(littleg %&gt;% select(yield)), y = unlist(bigg %&gt;% select(yield)), step = asymmetric, keep = TRUE)\nstr(align1hr)\n\n\nList of 20\n $ costMatrix        : num [1:2209, 1:2209] 0.0076 0.0136 0.0195 0.0263 0.0328 ...\n $ directionMatrix   : int [1:2209, 1:2209] NA 1 1 1 1 1 1 1 1 1 ...\n $ stepPattern       : 'stepPattern' num [1:6, 1:4] 1 1 2 2 3 3 1 0 1 0 ...\n  ..- attr(*, \"npat\")= num 3\n  ..- attr(*, \"norm\")= chr \"N\"\n $ N                 : int 2209\n $ M                 : int 2209\n $ call              : language dtw(x = unlist(littleg %&gt;% select(yield)), y = unlist(bigg %&gt;% select(yield)),      step.pattern = asymmetric, ke| __truncated__\n $ openEnd           : logi FALSE\n $ openBegin         : logi FALSE\n $ windowFunction    :function (iw, jw, ...)  \n $ jmin              : int 2209\n $ distance          : num 35.6\n $ normalizedDistance: num 0.0161\n $ index1            : num [1:2209] 1 2 3 4 5 6 7 8 9 10 ...\n $ index2            : num [1:2209] 1 3 4 6 8 10 12 13 14 16 ...\n $ index1s           : num [1:2209] 1 2 3 4 5 6 7 8 9 10 ...\n $ index2s           : num [1:2209] 1 3 4 6 8 10 12 13 14 16 ...\n $ stepsTaken        : int [1:2208] 3 2 3 3 3 3 2 2 3 2 ...\n $ localCostMatrix   : 'crossdist' num [1:2209, 1:2209] 0.0076 0.006 0.00586 0.00683 0.00652 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:2209] \"yield1\" \"yield2\" \"yield3\" \"yield4\" ...\n  .. ..$ : chr [1:2209] \"yield1\" \"yield2\" \"yield3\" \"yield4\" ...\n  ..- attr(*, \"method\")= chr \"Euclidean\"\n  ..- attr(*, \"call\")= language proxy::dist(x = x, y = y, method = dist.method)\n $ query             : num [1:2209, 1] 0.096 0.0976 0.0977 0.0967 0.097 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:2209] \"yield1\" \"yield2\" \"yield3\" \"yield4\" ...\n  .. ..$ : NULL\n $ reference         : num [1:2209, 1] 0.1036 0.1012 0.1005 0.0982 0.096 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:2209] \"yield1\" \"yield2\" \"yield3\" \"yield4\" ...\n  .. ..$ : NULL\n - attr(*, \"class\")= chr \"dtw\"\n\n\nView index alignment\n\n\nCode\nplot(align1hr, type = \"threeway\")\n\n\n\n\n\n\n\n\n\nShow aligned values\n\n\nCode\nplot(align1hr, type = \"twoway\", offset = - 1)\n\n\n\n\n\n\n\n\n\nView aligned timeseries using dyGraphs. Clearly, this is not a great approach as it matches multiple query data points to the same reference index, i.e., the result is multiple little g flow readings at a single time point. As seen in the plots above, it also does not align the series correctly.\n\n\nCode\naligneddata &lt;- tibble(datetime = bigg$datetime[align1hr$index2], query = littleg$yield[align1hr$index1], reference = bigg$yield[align1hr$index2])\naligneddata %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Explore Sub-Daily Data</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgStoryPlots.html",
    "href": "Big G Little g/GgStoryPlots.html",
    "title": "5  G-g Story Plots",
    "section": "",
    "text": "5.1 Site info and daily data\nPurpose: build visual story plots for each basin and climate year\nNotes:\nView map of sites\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\nLoad and view data structure\nCode\n# flow/yield (and temp) data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\") %&gt;% filter(!site_name %in% c(\"Wounded Buck Creek\"))\n\n# add water/climate year variables\ndat &lt;- add_date_variables(dat, dates = date, water_year_start = 4)\n\n# calculate completeness by site and water year\ncomplete &lt;- dat %&gt;% group_by(site_name, designation, WaterYear) %&gt;% summarize(completeness = sum(!is.na(Yield_filled_mm_7))/365)\ndat &lt;- dat %&gt;% left_join(complete)\nstr(dat)\n\n\ntibble [231,881 × 33] (S3: tbl_df/tbl/data.frame)\n $ station_no          : chr [1:231881] NA NA NA NA ...\n $ site_name           : chr [1:231881] \"BigCreekLower\" \"BigCreekLower\" \"BigCreekLower\" \"BigCreekLower\" ...\n $ site_id             : chr [1:231881] \"BIG_001\" \"BIG_001\" \"BIG_001\" \"BIG_001\" ...\n $ basin               : chr [1:231881] \"Flathead\" \"Flathead\" \"Flathead\" \"Flathead\" ...\n $ subbasin            : chr [1:231881] \"Big Creek\" \"Big Creek\" \"Big Creek\" \"Big Creek\" ...\n $ region              : chr [1:231881] \"Flat\" \"Flat\" \"Flat\" \"Flat\" ...\n $ lat                 : num [1:231881] 48.6 48.6 48.6 48.6 48.6 ...\n $ long                : num [1:231881] -114 -114 -114 -114 -114 ...\n $ elev_ft             : num [1:231881] 3429 3429 3429 3429 3429 ...\n $ area_sqmi           : num [1:231881] 81.2 81.2 81.2 81.2 81.2 ...\n $ designation         : chr [1:231881] \"little\" \"little\" \"little\" \"little\" ...\n $ date                : Date[1:231881], format: \"2017-07-28\" \"2017-07-29\" ...\n $ disch_reli          : num [1:231881] 1 1 1 1 1 1 1 1 1 1 ...\n $ temp_reli           : num [1:231881] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean           : num [1:231881] 81.4 76.5 77.6 92.1 98.1 ...\n $ tempc_mean          : num [1:231881] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean_filled    : num [1:231881] 81.4 76.5 77.6 92.1 98.1 ...\n $ flow_mean_cms       : num [1:231881] 2.3 2.17 2.2 2.61 2.78 ...\n $ flow_mean_filled_cms: num [1:231881] 2.3 2.17 2.2 2.61 2.78 ...\n $ area_sqkm           : num [1:231881] 210 210 210 210 210 ...\n $ Yield_mm            : num [1:231881] 0.946 0.89 0.902 1.071 1.141 ...\n $ Yield_filled_mm     : num [1:231881] 0.946 0.89 0.902 1.071 1.141 ...\n $ flow_mean_7         : num [1:231881] NA NA NA 91.3 94.4 ...\n $ flow_mean_filled_7  : num [1:231881] NA NA NA 91.3 94.4 ...\n $ tempc_mean_7        : num [1:231881] NA NA NA NA NA NA NA NA NA NA ...\n $ Yield_mm_7          : num [1:231881] NA NA NA 1.06 1.1 ...\n $ Yield_filled_mm_7   : num [1:231881] NA NA NA 1.06 1.1 ...\n $ CalendarYear        : num [1:231881] 2017 2017 2017 2017 2017 ...\n $ Month               : num [1:231881] 7 7 7 7 8 8 8 8 8 8 ...\n $ MonthName           : Factor w/ 12 levels \"Apr\",\"May\",\"Jun\",..: 4 4 4 4 5 5 5 5 5 5 ...\n $ WaterYear           : num [1:231881] 2018 2018 2018 2018 2018 ...\n $ DayofYear           : num [1:231881] 119 120 121 122 123 124 125 126 127 128 ...\n $ completeness        : num [1:231881] 0.268 0.268 0.268 0.268 0.268 ...\nView little and medium g time series data (yield), by basin and site\nCode\nmysubbasins &lt;- unique(dat$subbasin)[-c(4,7,13)]\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  myplots[[i]] &lt;- dat %&gt;% filter(designation %in% c(\"little\", \"medium\"), subbasin == mysubbasins[i]) %&gt;% ggplot() + geom_line(aes(x = date, y = log(Yield_filled_mm_7))) + facet_wrap(~site_name)\n}\nView little and medium g time series data (yield), by basin. Use the handles below the x-axis to change the time frame.\nCode\nmysubbasins &lt;- unique(dat$subbasin)[-c(4,7,13)]\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  myplots[[i]] &lt;- dat %&gt;% filter(designation %in% c(\"little\", \"medium\"), subbasin == mysubbasins[i]) %&gt;% mutate(logYield = log(Yield_filled_mm_7)) %&gt;% select(date, site_name, logYield) %&gt;% spread(key = site_name, value = logYield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"ln(Yield, mm)\")\n}",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>G-g Story Plots</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgStoryPlots.html#site-info-and-daily-data",
    "href": "Big G Little g/GgStoryPlots.html#site-info-and-daily-data",
    "title": "5  G-g Story Plots",
    "section": "",
    "text": "Big CreekCoal CreekMcGee CreekWest BrookPaine RunStaunton RiverDuck CreekShields RiverSnake RiverDonner Blitzen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBig CreekCoal CreekMcGee CreekWest BrookPaine RunStaunton RiverDuck CreekShields RiverSnake RiverDonner Blitzen",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>G-g Story Plots</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgStoryPlots.html#create-plotting-functions",
    "href": "Big G Little g/GgStoryPlots.html#create-plotting-functions",
    "title": "5  G-g Story Plots",
    "section": "5.2 Create plotting functions",
    "text": "5.2 Create plotting functions\nWrite functions to generate residual time series/scatter plot\n\n\nCode\nresidualplots &lt;- function(mybasin, CY, little, big) {\n  # essential elements\n  dat_basin &lt;- dat %&gt;% filter(basin == mybasin)\n  \n  # create residual data frame\n  delta_dat &lt;- dat_basin %&gt;% select(site_name, site_id, basin, region, designation, date, WaterYear, Yield_mm_mean_7) %&gt;% filter(site_name %in% little, WaterYear == CY) %&gt;% \n    left_join(dat_basin %&gt;% select(basin, site_name, date, WaterYear, Yield_mm_mean_7) %&gt;% filter(site_name == big, WaterYear == CY) %&gt;% rename(bigyield = Yield_mm_mean_7) %&gt;% select(-site_name)) %&gt;% \n    mutate(delta_yield = log(Yield_mm_mean_7) - log(bigyield), site_name = factor(site_name, levels = little)) %&gt;% \n    group_by(site_name) %&gt;% mutate(cum_resid = cumsum(coalesce(delta_yield, 0)) + delta_yield*0) \n  \n  # base plot\n  p1 &lt;- delta_dat %&gt;% \n    filter(WaterYear == CY) %&gt;%\n    group_by(site_name) %&gt;%\n    mutate(month = month(date), doy = 1:n()) %&gt;% \n    ungroup() %&gt;%\n    ggplot(aes(x = log(bigyield), y = log(Yield_mm_mean_7), color = doy)) +\n    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +\n    geom_point(aes(group = doy)) +\n    geom_path() +\n    scale_color_gradient2(midpoint = 182, low = \"orange\", mid = \"purple3\", high = \"orange\") +\n    facet_wrap(~site_name) +\n    xlab(\"Big G ln(Yield)\") + ylab(\"Little G ln(Yield)\") + labs(color = \"Days from April 1\") +\n    theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) \n  \n  # animated \n  # p1_anim &lt;- p1 + transition_reveal(along = doy)\n  \n  # write out - static\n  jpeg(paste(\"Big G Little g/Compare Time Series/BigGLittleG_ScatterByTime\", mybasin, \"_\", CY, \".jpg\", sep = \"\"), height = 10, width = 12, units = \"in\", res = 500)\n  print(p1)\n  dev.off()\n  \n  # write out - animated\n  # animate(p1_anim, renderer = gifski_renderer(), height = 10, width = 12, units = \"in\", res = 500)\n  # anim_save(paste(\"Big G Little g/Compare Time Series/BigGLittleG_ScatterByTime_Animated_\", mybasin, \"_\", CY, \".gif\", sep = \"\"))\n  \n  # residual time series\n  jpeg(paste(\"Big G Little g/Compare Time Series/BigGLittleG_YieldResiduals_TimeSeries_\", mybasin, \"_\", CY, \".jpg\", sep = \"\"), height = 4, width = 6, units = \"in\", res = 500)\n  print(ggplot(data = delta_dat) + \n    geom_line(aes(x = date, y = delta_yield, group = site_name, color = site_name)) + \n    geom_hline(aes(yintercept = 0), linetype = \"dashed\") +\n    xlab(\"\") + ylab(\"ln(Yield) residuals (difference from Big G)\") + labs(color = \"Little g\") +\n    theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()))\n  dev.off()\n  \n  \n  # plot little g cumulative residuals - difference from Big G by site\n  jpeg(paste(\"Big G Little g/Compare Time Series/BigGLittleG_YieldResiduals_Cumulative_TimeSeries_\", mybasin, \"_\", CY, \".jpg\", sep = \"\"), height = 4, width = 6, units = \"in\", res = 500)\n  print(delta_dat %&gt;% \n    ggplot() + \n    geom_line(aes(x = date, y = cum_resid, group = site_name, color = site_name)) + \n    geom_hline(aes(yintercept = 0), linetype = \"dashed\") +\n    xlab(\"\") + ylab(\"ln(Yield) cumulative residuals \") + labs(color = \"Little g\") +\n    theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()))\n  dev.off()\n}\n\n\nWrite function to generate flow story plot\n\n\nCode\nbigplotfun &lt;- function(mybasin, mysubbasin, CY, little, big, super, supergyears, mymap, evalyears) {\n  #### essential elements\n  dat_basin &lt;- dat %&gt;% filter(basin == mybasin)\n  months &lt;- c(\"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\", \"Jan\", \"Feb\", \"Mar\")\n  fudge &lt;- 0.01 # add small value to deal with 0 flow on log scale\n\n  # clean data...drop all dates that have missing data at any site\n  dat_basin_cy_clean &lt;- dat %&gt;% \n    filter(site_name %in% c(little, big), WaterYear == CY) %&gt;% \n    select(date, site_name, Yield_filled_mm_7) %&gt;%\n    spread(key = site_name, value = Yield_filled_mm_7) %&gt;% \n    drop_na() %&gt;%\n    gather(key = site_name, value = Yield_filled_mm_7, 2:ncol(.))\n  dat_basin_cy_clean &lt;- fill_missing_dates(dat_basin_cy_clean, dates = \"date\", groups = \"site_name\", pad_ends = FALSE)\n  \n  # get among-year yield min/max for y-axis limits\n  dat_basin_sub &lt;- dat %&gt;% \n    filter(site_name %in% c(little, big), WaterYear %in% evalyears) %&gt;% \n    select(date, WaterYear, site_name, Yield_filled_mm_7) %&gt;%\n    spread(key = site_name, value = Yield_filled_mm_7) %&gt;% \n    drop_na() %&gt;%\n    gather(key = site_name, value = Yield_filled_mm_7, 3:ncol(.)) %&gt;%\n    filter(!is.na(Yield_filled_mm_7)) %&gt;% \n    mutate(Yield_filled_mm_7_log = log(Yield_filled_mm_7+fudge)) \n  yield_lim &lt;- range(dat_basin_sub$Yield_filled_mm_7_log)\n  \n  \n  # clean months\n  cleanmonths &lt;- unlist(dat_basin_cy_clean %&gt;% filter(site_name == little[1]) %&gt;% drop_na() %&gt;% left_join(dat_basin %&gt;% select(date, site_name, MonthName, Month)) %&gt;% group_by(MonthName) %&gt;% summarize(ndays = n()) %&gt;% filter(ndays &gt;= 20) %&gt;% select(MonthName))\n  \n  #### MAP\n  p1 &lt;- mymap\n  # print(\"p1\")\n  \n  #### HYDROGRAPHS IN YIELD\n  p2 &lt;- ggplot() + \n    geom_line(data = dat_basin_cy_clean %&gt;% filter(site_name %in% little) %&gt;% mutate(site_name = factor(site_name, levels = little)), aes(x = date, y = log(Yield_filled_mm_7+fudge), group = site_name, color = site_name)) +\n    geom_line(data = dat_basin_cy_clean %&gt;% filter(site_name == big), aes(x = date, y = log(Yield_filled_mm_7+fudge)), color = \"black\", size = 1.25) +\n    xlab(\"Date\") + ylab(\"ln(Yield, mm)\") + theme_bw() + ylim(yield_lim) + \n    scale_x_date(limits = as.Date(c(paste(CY-1, '-04-01', sep = \"\"), paste(CY, '-04-01', sep = \"\")))) +\n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n  # print(\"p2\")\n  \n  \n  #### TOTAL ANNUAL YIELD\n  # get total yield per year and convert to percentiles\n  yeartotals &lt;- dat_basin %&gt;% \n    filter(site_name == super, WaterYear %in% supergyears) %&gt;% \n    group_by(WaterYear) %&gt;% \n    summarize(totalyield = sum(Yield_filled_mm, na.rm = TRUE)) %&gt;%\n    filter(!is.na(totalyield)) %&gt;%\n    mutate(percentile = percent_rank(totalyield))\n  p3 &lt;- ggplot() + \n    geom_line(data = yeartotals, aes(x = WaterYear, y = totalyield), color = \"grey40\") + \n    geom_point(data = yeartotals %&gt;% filter(WaterYear == CY), aes(x = WaterYear, y = totalyield)) +\n    xlab(\"Climate year\") + ylab(\"Total annual yield (mm)\") + theme_bw() + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # print(\"p3\")\n  \n  \n  #### EXCEEDANCE PROBABILITY - SUPER G PERIOD OF RECORD\n  exceedance &lt;- dat_basin %&gt;% \n    filter(site_name %in% c(little, big, super)) %&gt;%\n    filter(!is.na(Yield_filled_mm_7)) %&gt;% \n    mutate(Yield_filled_mm_7_log = log(Yield_filled_mm_7)) %&gt;%\n    group_by(site_name, WaterYear) %&gt;% \n    arrange(desc(Yield_filled_mm_7_log), .by_group = TRUE) %&gt;% \n    mutate(exceedance = 100/length(Yield_filled_mm_7_log)*1:length(Yield_filled_mm_7_log)) %&gt;%\n    ungroup()\n  p4 &lt;- ggplot() + \n    geom_line(data = exceedance %&gt;% filter(site_name == super, WaterYear %in% supergyears), aes(x = exceedance, y = Yield_filled_mm_7_log, group = WaterYear, color = WaterYear), size = 0.25) +\n    geom_line(data = exceedance %&gt;% filter(site_name == super, WaterYear == CY), aes(x = exceedance, y = Yield_filled_mm_7_log), color = \"black\", size = 1.25) +\n    geom_text(aes(x = 50, y = Inf, label = paste(\"Super G: \", super, \" (\", min(supergyears), \"-\", max(supergyears), \")\", \"\\nCurrent year: \", CY, \" (\", round(yeartotals$percentile[yeartotals$WaterYear == CY]*100), \"th perc.)\", sep = \"\")), vjust = 1.2) +\n    scale_color_continuous(trans = \"reverse\") +\n    xlab(\"Exceedance probability\") + ylab(\"ln(Yield, mm)\") + labs(color = \"Climate year\") + theme_bw() + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.15,0.23), \n          legend.text = element_text(size = 9), legend.title = element_text(size = 9), legend.key.height = unit(0.4, \"cm\"))\n  # print(\"p4\")\n  \n  \n  #### CUMULATIVE YIELD RESIDUALS\n  # get range of residuals among years\n  dat_basin_res &lt;- dat_basin_sub %&gt;% \n    filter(site_name %in% little, WaterYear %in% evalyears) %&gt;% select(site_name, date, WaterYear, Yield_filled_mm_7) %&gt;%\n    left_join(dat %&gt;% filter(site_name == big) %&gt;% rename(bigyield = Yield_filled_mm_7) %&gt;% select(date, WaterYear, bigyield)) %&gt;% \n    mutate(delta_yield = log(Yield_filled_mm_7+fudge) - log(bigyield+fudge), site_name = factor(site_name, levels = little)) %&gt;% \n    group_by(site_name, WaterYear) %&gt;% mutate(cum_resid = cumsum(coalesce(delta_yield, 0)) + delta_yield*0) \n  res_lim &lt;- range(dat_basin_res$cum_resid, na.rm = TRUE)\n  p5 &lt;- dat_basin_cy_clean %&gt;% filter(site_name %in% little) %&gt;% \n    left_join(dat_basin_cy_clean %&gt;% filter(site_name == big) %&gt;% rename(bigyield = Yield_filled_mm_7) %&gt;% select(-site_name)) %&gt;% \n    mutate(delta_yield = log(Yield_filled_mm_7+fudge) - log(bigyield+fudge), site_name = factor(site_name, levels = little)) %&gt;% \n    group_by(site_name) %&gt;% mutate(cum_resid = cumsum(coalesce(delta_yield, 0)) + delta_yield*0) %&gt;%\n    ggplot() + \n    geom_line(aes(x = date, y = cum_resid, group = site_name, color = site_name)) + \n    geom_hline(aes(yintercept = 0), linetype = \"dashed\") +\n    xlab(\"Date\") + ylab(\"ln(Yield) cumulative residuals \") + ylim(res_lim) +\n    scale_x_date(limits = as.Date(c(paste(CY-1, '-04-01', sep = \"\"), paste(CY, '-04-01', sep = \"\")))) +\n    theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n  # print(\"p5\")\n\n  \n  #### EXCEEDANCE PROBABILITY - BIG G/LITTLE G CURRENT YEAR\n  exceedance &lt;- dat_basin_cy_clean %&gt;% \n    filter(site_name %in% c(little, big)) %&gt;%\n    filter(!is.na(Yield_filled_mm_7)) %&gt;% \n    mutate(Yield_filled_mm_7_log = log(Yield_filled_mm_7+fudge)) %&gt;%\n    group_by(site_name) %&gt;% \n    arrange(desc(Yield_filled_mm_7_log), .by_group = TRUE) %&gt;% \n    mutate(exceedance = 100/length(Yield_filled_mm_7_log)*1:length(Yield_filled_mm_7_log)) %&gt;%\n    ungroup()\n  p6 &lt;- ggplot() + \n    geom_line(data = exceedance %&gt;% filter(site_name %in% little) %&gt;% mutate(site_name = factor(site_name, levels = little)), aes(x = exceedance, y = Yield_filled_mm_7_log, group = site_name, color = site_name)) +\n    geom_line(data = exceedance %&gt;% filter(site_name == big), aes(x = exceedance, y = Yield_filled_mm_7_log), color = \"black\", size = 1.25) +\n    xlab(\"Exceedance probability\") + ylab(\"ln(Yield, mm)\") + labs(color = \"Little g\") + theme_bw() + ylim(yield_lim) + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n  # print(\"p6\")\n  \n  \n  #### EXCEEDANCE PROBABILITY MONTHLY\n  exceedance_monthly &lt;- dat_basin_cy_clean %&gt;% \n    filter(site_name %in% c(little, big)) %&gt;%\n    filter(!is.na(Yield_filled_mm_7)) %&gt;% \n    left_join(dat_basin %&gt;% select(date, site_name, MonthName, Month)) %&gt;%\n    mutate(Yield_filled_mm_7_log = log(Yield_filled_mm_7+fudge),\n           site_name = factor(site_name, levels = c(little, big)),\n           MonthName = factor(MonthName, levels = months)) %&gt;%\n    group_by(site_name, Month) %&gt;% \n    arrange(desc(Yield_filled_mm_7_log), .by_group = TRUE) %&gt;% \n    mutate(exceedance = 100/length(Yield_filled_mm_7_log)*1:length(Yield_filled_mm_7_log)) %&gt;%\n    ungroup()\n  exceedance_monthly2 &lt;- exceedance_monthly %&gt;% mutate(Yield_filled_mm_7_log = ifelse(MonthName %in% cleanmonths, Yield_filled_mm_7_log, NA))\n  p7 &lt;- ggplot() + \n    geom_line(data = exceedance_monthly2 %&gt;% filter(site_name %in% little), aes(x = exceedance, y = Yield_filled_mm_7_log, group = site_name, color = site_name)) +\n    geom_line(data = exceedance_monthly2 %&gt;% filter(site_name == big), aes(x = exceedance, y = Yield_filled_mm_7_log), color = \"black\", size = 1.25) +\n    facet_wrap(~ factor(MonthName), nrow = 2) + \n    xlab(\"Exceedance probability\") + ylab(\"ln(Yield, mm)\") + labs(color = \"Little g\") + theme_bw() +  ylim(yield_lim) + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n  # print(\"p7\")\n  \n  \n  #### ANNUAL BIG-LITTLE DIFFERENCE\n  mypvals &lt;- tibble(type =  rep(NA, times = length(little)), \n                    month = rep(NA, times = length(little)),\n                    site_name = rep(NA, times = length(little)), \n                    stat = rep(NA, times = length(little)),\n                    pval = rep(NA, times = length(little)))\n  for (i in 1:length(little)) {\n    mytest &lt;- ks.test(exceedance$Yield_filled_mm_7_log[exceedance$site_name == big],\n                      exceedance$Yield_filled_mm_7_log[exceedance$site_name == little[i]], exact = TRUE)\n    mypvals$type &lt;- \"annual\"\n    mypvals$month &lt;- 0\n    mypvals$site_name[i] &lt;- little[i]\n    mypvals$stat[i] &lt;- mytest$statistic\n    mypvals$pval[i] &lt;- mytest$p.value\n  }\n  p8 &lt;- mypvals %&gt;% \n    mutate(site_name = factor(site_name, levels = little)) %&gt;% \n    ggplot() + \n    geom_boxplot(aes(x = month, y = pval, group = month), fill = \"grey90\", outlier.shape = NA) +\n    geom_point(aes(x = jitter(month, factor = 10), y = pval, color = site_name), size = 2) +\n    ylim(0,1) + geom_hline(yintercept = 0.05, linetype = \"dashed\") +\n    xlab(\"\") + ylab(\"Kolmogorov-Smirnov test p-value\") + scale_x_continuous(labels = \"Annual\", breaks = 0) +\n    theme_bw() + theme(axis.title.x = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n  # print(\"p8\")\n  \n  \n  #### MONTHLY BIG-LITTLE DIFFERENCE\n  mypvals_monthly_list &lt;- list()\n  for (i in 1:length(little)) {\n    mypvals_monthly &lt;- tibble(type =  rep(NA, times = 12), \n                              month = rep(NA, times = 12),\n                              site_name = rep(NA, times = 12), \n                              stat = rep(NA, times = 12),\n                              pval = rep(NA, times = 12))\n    for (j in 1:12) {\n      big_exc &lt;- exceedance_monthly$Yield_filled_mm_7_log[exceedance_monthly$site_name == big & exceedance_monthly$MonthName == months[j]]\n      lit_exc &lt;- exceedance_monthly$Yield_filled_mm_7_log[exceedance_monthly$site_name == little[i] & exceedance_monthly$MonthName == months[j]]\n      if(length(lit_exc) &lt; 20) {\n        mypvals_monthly$site_name[j] &lt;- little[i]\n        mypvals_monthly$type &lt;- \"monthly\"\n        mypvals_monthly$month[j] &lt;- months[j]\n        mypvals_monthly$stat[j] &lt;- NA\n        mypvals_monthly$pval[j] &lt;- NA\n      } else {\n        mytest &lt;- ks.test(big_exc, lit_exc, exact = TRUE)\n        mypvals_monthly$site_name[j] &lt;- little[i]\n        mypvals_monthly$type &lt;- \"monthly\"\n        mypvals_monthly$month[j] &lt;- months[j]\n        mypvals_monthly$stat[j] &lt;- mytest$statistic\n        mypvals_monthly$pval[j] &lt;- mytest$p.value\n      }\n    }\n    mypvals_monthly_list[[i]] &lt;- mypvals_monthly\n  }\n  mypvals_monthly &lt;- do.call(rbind, mypvals_monthly_list) %&gt;% \n    mutate(site_name = factor(site_name, levels = little),\n           month = factor(month, levels = months), \n           month_num = as.numeric(month)) \n  # compute the loess\n  # dum &lt;- rbind(mypvals_monthly %&gt;% mutate(month_num = month_num-12),\n  #              mypvals_monthly,\n  #              mypvals_monthly %&gt;% mutate(month_num = month_num+12)) \n  # mylo &lt;- loess(pval ~ month_num, dum, span = 0.25)\n  # plot(pval ~ month_num, dum)\n  # j &lt;- order(dum$month_num)[(dim(mypvals_monthly)[1]+1):(dim(mypvals_monthly)[1]+dim(mypvals_monthly)[1])]\n  # lines(dum$month_num[j], mylo$fitted[j], col = \"red\")\n  # the plot\n  p9 &lt;- mypvals_monthly %&gt;% \n    ggplot() + \n    geom_boxplot(aes(x = month, y = pval, group = month), fill = \"grey90\", outlier.shape = NA) +\n    # geom_line(aes(x = dum$month_num[j], y = mylo$fitted[j]), linewidth = 1.25) +\n    geom_smooth(aes(x = month_num, y = pval), linewidth = 1.25, color = \"black\", se = FALSE) +\n    geom_point(aes(x = jitter(month_num), y = pval, color = site_name), size = 2) +\n    ylim(0,1) + geom_hline(yintercept = (0.05), linetype = \"dashed\") +\n    xlab(\"\") + ylab(\"\") + \n    labs(color = \"\") + theme_bw() + \n    theme(axis.title.x = element_blank(), axis.text.y = element_blank(), panel.grid.minor = element_blank())\n  # print(\"p9\")\n  \n  \n  #### BIG PLOT\n  bigp &lt;- ggarrange(ggarrange(mymap, ggarrange(NA, p2, nrow = 2, heights = c(0.2,1))),\n                    ggarrange(p3, p4), \n                    ggarrange(p5, p6),\n                    p7, \n                    ggarrange(p8, p9, widths = c(0.13, 0.85)), nrow = 5, heights = c(1.2,0.9,0.9,1.2,0.9))\n  # print(\"big plot!\")\n  # write out\n  # jpeg(paste(\"Big G Little g/Compare Distributions/BigGLittleG_BigPlot_\", mybasin, \"_\", mysubbasin, \"_\", CY, \".jpg\", sep = \"\"), height = 18, width = 10, units = \"in\", res = 500)\n  # annotate_figure(bigp, fig.lab = \"The West Brook, CY 2021\", fig.lab.pos = \"top.right\", fig.lab.size = 24)\n  print(annotate_figure(bigp, top = text_grob(paste(mybasin, \", CY \", CY, sep = \"\"), x = 0.75, y = -0.5, just = \"centre\", size = 24)))\n  # dev.off()\n}",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>G-g Story Plots</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgStoryPlots.html#create-map-objects",
    "href": "Big G Little g/GgStoryPlots.html#create-map-objects",
    "title": "5  G-g Story Plots",
    "section": "5.3 Create map objects",
    "text": "5.3 Create map objects\n\nWest BrookStaunton RiverPaine RunBig CreekSpread CreekShields RiverDonner-Blitzen",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>G-g Story Plots</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgStoryPlots.html#flow-story-plots",
    "href": "Big G Little g/GgStoryPlots.html#flow-story-plots",
    "title": "5  G-g Story Plots",
    "section": "5.4 Flow story plots",
    "text": "5.4 Flow story plots\nGenerate streamflow story plots by basin and climate year\n\n5.4.1 West Brook\n\n20212022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.2 Staunton River\n\n202120222023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.3 Paine Run\n\n20212022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.4 Big Creek, Flathead\n\n201920202021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.5 Spread Creek, Snake\n\n20222023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.6 Shields River\n\n20202023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.7 Donner-Blitzen\n\n2020202120222023",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>G-g Story Plots</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html",
    "href": "Event Delineation/HydroEvents.html",
    "title": "6  Hydro Event Delineation",
    "section": "",
    "text": "6.1 Data\nPurpose: Conduct baseflow separation and delineate hydrologic events to model in Gg framework",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#data",
    "href": "Event Delineation/HydroEvents.html#data",
    "title": "6  Hydro Event Delineation",
    "section": "",
    "text": "6.1.1 Site info and daily data\n\n\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# flow/yield (and temp) data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\") %&gt;%\n  filter(!site_name %in% c(\"WoundedBuckCreek\", \"Brackett Creek\"))\n\n# add water/climate year variables\ndat &lt;- add_date_variables(dat, dates = date, water_year_start = 4)\nstr(dat)\n\n\ntibble [229,559 × 32] (S3: tbl_df/tbl/data.frame)\n $ station_no          : chr [1:229559] NA NA NA NA ...\n $ site_name           : chr [1:229559] \"BigCreekLower\" \"BigCreekLower\" \"BigCreekLower\" \"BigCreekLower\" ...\n $ site_id             : chr [1:229559] \"BIG_001\" \"BIG_001\" \"BIG_001\" \"BIG_001\" ...\n $ basin               : chr [1:229559] \"Flathead\" \"Flathead\" \"Flathead\" \"Flathead\" ...\n $ subbasin            : chr [1:229559] \"Big Creek\" \"Big Creek\" \"Big Creek\" \"Big Creek\" ...\n $ region              : chr [1:229559] \"Flat\" \"Flat\" \"Flat\" \"Flat\" ...\n $ lat                 : num [1:229559] 48.6 48.6 48.6 48.6 48.6 ...\n $ long                : num [1:229559] -114 -114 -114 -114 -114 ...\n $ elev_ft             : num [1:229559] 3429 3429 3429 3429 3429 ...\n $ area_sqmi           : num [1:229559] 81.2 81.2 81.2 81.2 81.2 ...\n $ designation         : chr [1:229559] \"little\" \"little\" \"little\" \"little\" ...\n $ date                : Date[1:229559], format: \"2017-07-28\" \"2017-07-29\" ...\n $ disch_reli          : num [1:229559] 1 1 1 1 1 1 1 1 1 1 ...\n $ temp_reli           : num [1:229559] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean           : num [1:229559] 81.4 76.5 77.6 92.1 98.1 ...\n $ tempc_mean          : num [1:229559] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean_filled    : num [1:229559] 81.4 76.5 77.6 92.1 98.1 ...\n $ flow_mean_cms       : num [1:229559] 2.3 2.17 2.2 2.61 2.78 ...\n $ flow_mean_filled_cms: num [1:229559] 2.3 2.17 2.2 2.61 2.78 ...\n $ area_sqkm           : num [1:229559] 210 210 210 210 210 ...\n $ Yield_mm            : num [1:229559] 0.946 0.89 0.902 1.071 1.141 ...\n $ Yield_filled_mm     : num [1:229559] 0.946 0.89 0.902 1.071 1.141 ...\n $ flow_mean_7         : num [1:229559] NA NA NA 91.3 94.4 ...\n $ flow_mean_filled_7  : num [1:229559] NA NA NA 91.3 94.4 ...\n $ tempc_mean_7        : num [1:229559] NA NA NA NA NA NA NA NA NA NA ...\n $ Yield_mm_7          : num [1:229559] NA NA NA 1.06 1.1 ...\n $ Yield_filled_mm_7   : num [1:229559] NA NA NA 1.06 1.1 ...\n $ CalendarYear        : num [1:229559] 2017 2017 2017 2017 2017 ...\n $ Month               : num [1:229559] 7 7 7 7 8 8 8 8 8 8 ...\n $ MonthName           : Factor w/ 12 levels \"Apr\",\"May\",\"Jun\",..: 4 4 4 4 5 5 5 5 5 5 ...\n $ WaterYear           : num [1:229559] 2018 2018 2018 2018 2018 ...\n $ DayofYear           : num [1:229559] 119 120 121 122 123 124 125 126 127 128 ...",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#sensitivity-analyses",
    "href": "Event Delineation/HydroEvents.html#sensitivity-analyses",
    "title": "6  Hydro Event Delineation",
    "section": "6.5 Sensitivity analyses",
    "text": "6.5 Sensitivity analyses\n\n6.5.1 Missing data\nMany of the EcoDrought time series data are incomplete. At some sites, discharge data is available only during the summer and/or fall periods, and at other sites, time series data are interrupted due to malfunctioning sensors and/or ice formation (“ice spikes”). So how does the length of the time series affect baseflow separation (and subsequent event identification)? Wasko and Guo (2022) use a 67 day time series of flow to demonstrate the utility of the hydroEvents packages, suggesting digital baseflow separation techniques may be valid for relatively short time series.\nHere, I perform a simple sensitivity analysis to explore the effect of time series length on the results of baseflow separation. Essentially, perform baseflow separation on increasingly smaller subsets of the data. With the default parameters, the minimum number of days/observations needed is 31. This is because the default number of points reflected at start and end of data (r) is 30. Reflection allows bf/bfi to be calculated over the entire period of record as the underlying baseflow separation equations result in “issues of”Warm-up” and “cool-down” as the recursive filter is moved forward and backward over the dataset” (Ladson et al. 2013, Australian Journal of Water Resources). baseflowB() uses a default reflection period of 30, which Ladson et al. (2013) found to “provide a realistic baselfow response for the start and end of the actual flow data”.\n\n6.5.1.1 Compare baseflow\nDivergence in baseflow among datasets is a result of the reflected data of the shorter dataset not matching the actual data of the longer dataset. As a result, divergence really only occurs at the end of each time series and is generally small in magnitude.\n\n\n6.5.1.2 Compare baseflow index\nThe story here is essentially the same as above: divergence is ~minimal and restricted to the end of each time series. However, we note that divergence in BFI appears to increase as absolute flow/baseflow decreases, because small differences in absolute space become much larger in relative space when absolute values are small.\nView relationship between Big G and among-site/event-specific standard deviation in little g.",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#baseflow-separation-1",
    "href": "Event Delineation/HydroEvents.html#baseflow-separation-1",
    "title": "6  Hydro Event Delineation",
    "section": "6.3 Baseflow separation",
    "text": "6.3 Baseflow separation\nPerform baseflow separation. See Wasko and Guo (2022, Hydrological Processes) for recommendations on parameterization, as different algorithms and alpha values can produce different results. Section 4.1: “…users should not simply use recommended filter parameter values from literature in combination with any baseflow filter code without verification of their choice of filter parameter. As the digital baseflow filter is not tied to any physical realism (Nathan and McMahon, 1990) and a larger fractional baseflow may aid identification of events—even if this is not strictly baseflow as per its definition (Linsley et al., 1958)…”.\nIt is not actually necessary to do this separately, as baseflow separation is conducted in the event delineation function internally. But it is helpful to view the results and explore how different parameterizations yield different baseflow contributions.\n\n6.3.1 West Brook\n\n\nCode\ndat_wb &lt;- dat %&gt;% filter(site_name %in% c(\"West Brook NWIS\", \"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\"))\ndat_wb_bf &lt;- dat_wb %&gt;% \n  filter(!is.na(Yield_filled_mm)) %&gt;% \n  select(site_name, basin, subbasin, WaterYear, date, Yield_filled_mm, flow_mean_filled_cms, area_sqkm) %&gt;%\n  group_by(site_name) %&gt;%\n  mutate(bf = baseflowB(Yield_filled_mm)$bf, bfi = baseflowB(Yield_filled_mm)$bfi) %&gt;%\n  ungroup()\nhead(dat_wb_bf)\n\n\n# A tibble: 6 × 10\n  site_name   basin      subbasin   WaterYear date       Yield_filled_mm\n  &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;date&gt;               &lt;dbl&gt;\n1 Avery Brook West Brook West Brook      2020 2020-02-20            1.43\n2 Avery Brook West Brook West Brook      2020 2020-02-21            1.42\n3 Avery Brook West Brook West Brook      2020 2020-02-22            1.22\n4 Avery Brook West Brook West Brook      2020 2020-02-23            1.28\n5 Avery Brook West Brook West Brook      2020 2020-02-24            1.40\n6 Avery Brook West Brook West Brook      2020 2020-02-25            1.76\n# ℹ 4 more variables: flow_mean_filled_cms &lt;dbl&gt;, area_sqkm &lt;dbl&gt;, bf &lt;dbl&gt;,\n#   bfi &lt;dbl&gt;\n\n\n\n\nCode\ndat_wb_bf %&gt;% filter(site_name == \"West Brook NWIS\") %&gt;% select(date, Yield_filled_mm, bf, bfi) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTotal daily streamflow in yield (mm), baseflow in yield, and fractional baseflow index over the period of record for site West Brook NWIS\n\n\n\n\n6.3.2 Spread Creek\nPerform baseflow separation for spread creek, an example of a snowmelt dominated stream. Note that with the default parameters, the ~entire summer/fall period could potentially be classified as a single event\n\n\nCode\nalp &lt;- 0.925\ndat_sh &lt;- dat %&gt;% \n  filter(site_name %in% c(\"SF Spread Creek Lower NWIS\")) %&gt;% \n  filter(!is.na(Yield_filled_mm)) %&gt;% \n  select(site_name, basin, subbasin, WaterYear, date, Yield_filled_mm) %&gt;%\n  group_by(site_name) %&gt;%\n  mutate(bf = baseflowB(Yield_filled_mm, alpha = alp)$bf, bfi = baseflowB(Yield_filled_mm, alpha = alp)$bfi) %&gt;%\n  ungroup()\ndat_sh %&gt;% filter(site_name == \"SF Spread Creek Lower NWIS\") %&gt;% select(date, Yield_filled_mm, bf, bfi) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTotal daily streamflow in yield (mm), baseflow in yield, and fractional baseflow index over the period of record for site SF Spread Creek Lower NWIS",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#event-identification",
    "href": "Event Delineation/HydroEvents.html#event-identification",
    "title": "6  Hydro Event Delineation",
    "section": "6.4 Event identification",
    "text": "6.4 Event identification\nThere are multiple options for methods of event identification. Section 4.2 in Wasko and Guo (2022): It can be generalized that, if the aim of the analysis is to identify independent streamflow maxima then eventMaxima() and eventMinima() work well and indeed have been traditionally employed for this task. If identifying independent small events becomes difficult, or the aim is to identify wet spells, eventBaseflow() may be preferred.” In our case, small events are likely important, so we use eventBaseflow() with a ~large values for BFI_Th to capture those small events.\nThe aim is to understand how water availability affects differences in yield between Big G and Little g during hydrologic events and the intervening periods (non-event baseflow periods). Therefore, we identify events from the Big G data, apply event/non-event time periods to the little g data, then explore G-g deviations during both events and non-events as a function of\nSeparate Big G and Little G data\n\n\nCode\ndat_big &lt;- dat_wb_bf %&gt;% filter(site_name == \"West Brook NWIS\")\ndat_little &lt;- dat_wb_bf %&gt;% filter(site_name != \"West Brook NWIS\")\n\n\nIdentify events at Big G:\n\n\nCode\nevents &lt;- eventBaseflow(dat_big$Yield_filled_mm, BFI_Th = 0.75)\nevents &lt;- events %&gt;% mutate(len = end - srt + 1)\nhead(events)\n\n\n  srt end which.max      max       sum len\n1   6   9         7 2.528865  7.652927   4\n2  12  15        13 2.006509  6.881830   4\n3  26  31        27 6.351183 19.045257   6\n4  31  35        33 3.026347 11.881521   5\n5  41  44        42 3.125843 10.115461   4\n6  47  50        48 3.125843 10.156918   4\n\n\nPlot Big G events using the default function\n\n\nCode\nplotEvents(dat_big$Yield_filled_mm, events = events)\n\n\n\n\n\nTime series of hydrologic events at Big G, identified using eventBaseflow().\n\n\n\n\nNow add variables to the Big G time series data specifying events and non-events\n\n\nCode\n# define positions of non-events\nsrt &lt;- c(1)\nend &lt;- c(events$srt[1]-1)\nfor (i in 2:(dim(events)[1])) {\n  srt[i] &lt;- events$end[i-1]+1\n  end[i] &lt;- events$srt[i]-1\n}\nnonevents &lt;- data.frame(tibble(srt, end) %&gt;% mutate(len = end - srt) %&gt;% filter(len &gt;= 0) %&gt;% select(-len) %&gt;% add_row(srt = events$end[dim(events)[1]]+1, end = dim(dat_big)[1]))\n\n# create vectors of binary event/non-event and event IDs\nisevent_vec &lt;- rep(2, times = dim(dat_big)[1])\neventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(events)[1]) { \n  isevent_vec[c(events[i,1]:events[i,2])] &lt;- 1 \n  eventid_vec[c(events[i,1]:events[i,2])] &lt;- i\n}\n\n# create vector of non-event IDs\nnoneventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n\n# create vector of \"agnostic events\": combined hydro events and non-events\nagnevents &lt;- rbind(events %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\nagneventid_vec &lt;- c()\nfor (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n# add event/non-event vectors to Big G data\ndat_big &lt;- dat_big %&gt;% \n  mutate(isevent = isevent_vec, \n         eventid = eventid_vec,\n         noneventid = noneventid_vec,\n         agneventid = agneventid_vec,\n         big_event_yield = ifelse(isevent_vec == 1, Yield_filled_mm, NA),\n         big_nonevent_yield = ifelse(isevent_vec == 2, Yield_filled_mm, NA),\n         big_event_quick = big_event_yield - bf) %&gt;%\n  rename(big_yield = Yield_filled_mm, big_bf = bf, big_bfi = bfi, big_flow = flow_mean_filled_cms, big_area_sqkm = area_sqkm)\n(dat_big)\n\n\n# A tibble: 1,780 × 17\n   site_name       basin      subbasin   WaterYear date       big_yield big_flow\n   &lt;chr&gt;           &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n 1 West Brook NWIS West Brook West Brook      2020 2020-02-01      1.57    0.535\n 2 West Brook NWIS West Brook West Brook      2020 2020-02-02      1.52    0.518\n 3 West Brook NWIS West Brook West Brook      2020 2020-02-03      1.45    0.496\n 4 West Brook NWIS West Brook West Brook      2020 2020-02-04      1.41    0.481\n 5 West Brook NWIS West Brook West Brook      2020 2020-02-05      1.42    0.484\n 6 West Brook NWIS West Brook West Brook      2020 2020-02-06      1.51    0.515\n 7 West Brook NWIS West Brook West Brook      2020 2020-02-07      2.53    0.864\n 8 West Brook NWIS West Brook West Brook      2020 2020-02-08      2.04    0.697\n 9 West Brook NWIS West Brook West Brook      2020 2020-02-09      1.58    0.538\n10 West Brook NWIS West Brook West Brook      2020 2020-02-10      1.47    0.501\n# ℹ 1,770 more rows\n# ℹ 10 more variables: big_area_sqkm &lt;dbl&gt;, big_bf &lt;dbl&gt;, big_bfi &lt;dbl&gt;,\n#   isevent &lt;dbl&gt;, eventid &lt;int&gt;, noneventid &lt;int&gt;, agneventid &lt;int&gt;,\n#   big_event_yield &lt;dbl&gt;, big_nonevent_yield &lt;dbl&gt;, big_event_quick &lt;dbl&gt;\n\n\n\n\nCode\ndat_big %&gt;% select(date, big_yield, big_bf, big_event_yield, big_nonevent_yield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTime series of hydrologic events at Big G, identified using eventBaseflow().\n\n\nApplying Big G event/non-event periods to little g time series data inherently assumes that event/non-event periods would be similarly delineated for little g. If this assumption does not hold, then non-event little g flow would be included in event periods, and vice-versa. How well does this assumption hold?\nAt the hourly time-scale, how aligned are the time series data? Typically, Big G lags behind Little G by 2-4 hours, but this depends on the site.\n\n\nCode\ndat_little %&gt;% select(date, site_name, Yield_filled_mm) %&gt;% spread(key = site_name, value = Yield_filled_mm) %&gt;% left_join(dat_big %&gt;% select(date, big_flow)) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(colors = c(hcl.colors(9, \"Zissou 1\"), \"black\")) \n\n\n\n\n\n\nHow does event delineation change?\n\n\nCode\nsites &lt;- c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")\n\ndat_little2 &lt;- dat_little %&gt;% filter(site_name == \"Jimmy Brook\")\nevents_little &lt;- eventBaseflow(dat_little2$Yield_filled_mm, BFI_Th = 0.75)\n\n# define positions of non-events\nsrt &lt;- c(1)\nend &lt;- c(events_little$srt[1]-1)\nfor (i in 2:(dim(events_little)[1])) {\n  srt[i] &lt;- events_little$end[i-1]+1\n  end[i] &lt;- events_little$srt[i]-1\n}\nnonevents &lt;- data.frame(tibble(srt, end) %&gt;% mutate(len = end - srt) %&gt;% filter(len &gt;= 0) %&gt;% select(-len) %&gt;% add_row(srt = events_little$end[dim(events_little)[1]]+1, end = dim(dat_little2)[1]))\n\n# create vectors of binary event/non-event and event IDs\nisevent_vec &lt;- rep(2, times = dim(dat_little2)[1])\neventid_vec &lt;- rep(NA, times = dim(dat_little2)[1])\nfor (i in 1:dim(events_little)[1]) { \n  isevent_vec[c(events_little[i,1]:events_little[i,2])] &lt;- 1 \n  eventid_vec[c(events_little[i,1]:events_little[i,2])] &lt;- i\n}\n\n# create vector of non-event IDs\nnoneventid_vec &lt;- rep(NA, times = dim(dat_little2)[1])\nfor (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n\n# create vector of \"agnostic events\": combined hydro events and non-events\nagnevents &lt;- rbind(events_little %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\nagneventid_vec &lt;- c()\nfor (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n# add event/non-event vectors to Big G data\ndat_little2 &lt;- dat_little2 %&gt;% \n  mutate(isevent = isevent_vec, \n         eventid = eventid_vec,\n         noneventid = noneventid_vec,\n         agneventid = agneventid_vec,\n         little_event_yield = ifelse(isevent_vec == 1, Yield_filled_mm, NA),\n         little_nonevent_yield = ifelse(isevent_vec == 2, Yield_filled_mm, NA),\n         little_event_quick = little_event_yield - bf) %&gt;%\n  rename(little_yield = Yield_filled_mm, little_bf = bf, little_bfi = bfi)\n\n\ndat_big %&gt;% select(date, big_event_yield) %&gt;% left_join(dat_little2 %&gt;% select(date, little_event_yield)) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTime series of yield for Big G (West Brook NWIS) and one little g site (Jimmy Brook) during hydrologic events as delineated for Big G and little g, respectively.\n\n\nWhether or not events alight between G and g is highly variable. In some cases, g events begin/end prior to G events, and in other cases g events begin/end later G events. In some cases g events are shorter than G events, and in other cases they are longer. In many cases, events are perfectly matched. Importantly, peaks in yield are almost always synchronous.\nUltimately, does this matter given that we are simply using this as a method to break up our data? Furthermore, the framing of the ~entire project is that Big G is the reference by which to compare all little g’s. In this sense, applying event/non-event periods derived from G to g matches this persepctive.",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#join-events-to-little-g",
    "href": "Event Delineation/HydroEvents.html#join-events-to-little-g",
    "title": "6  Hydro Event Delineation",
    "section": "6.5 Join events to Little g",
    "text": "6.5 Join events to Little g\n\n\nCode\n# wide\ndat_wb2 &lt;- dat_little %&gt;% \n  filter(date &gt;= min(dat_big$date) & date &lt;= max(dat_big$date)) %&gt;%\n  left_join(dat_big %&gt;% select(-site_name)) %&gt;% \n  group_by(site_name, basin, subbasin, agneventid) %&gt;% \n  summarise(eventlen = n(),\n            mindate = min(date),\n            isevent = unique(isevent), \n            yield_little_cum = sum(Yield_filled_mm+0.01),\n            yield_big_cum = sum(big_yield+0.01),\n            yield_little_cum_log = log(yield_little_cum),\n            yield_big_cum_log = log(yield_big_cum),\n            xxx_little = sum(flow_mean_filled_cms * 86400 * (1/unique(area_sqkm)) * (1/1000000) * 1000),\n            yyy_little = sum(flow_mean_filled_cms * 86400) * (1/unique(area_sqkm)) * (1/1000000) * 1000,\n            yield_little_mean_log = mean(log(Yield_filled_mm+0.01)),\n            yield_big_mean_log = mean(log(big_yield+0.01)),\n            yield_little_q25_log = quantile(log(Yield_filled_mm+0.01), probs = 0.25),\n            yield_little_q50_log = quantile(log(Yield_filled_mm+0.01), probs = 0.50),\n            yield_little_q75_log = quantile(log(Yield_filled_mm+0.01), probs = 0.75),\n            yield_big_q25_log = quantile(log(big_yield+0.01), probs = 0.25),\n            yield_big_q50_log = quantile(log(big_yield+0.01), probs = 0.50),\n            yield_big_q75_log = quantile(log(big_yield+0.01), probs = 0.75)) %&gt;%\n  ungroup() %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")),\n         site_name_cd = as.numeric(site_name),\n         z_yield_big_cum_log = as.numeric(scale(yield_big_cum_log, center = TRUE, scale = TRUE)),\n         z_yield_big_mean_log = as.numeric(scale(yield_big_mean_log, center = TRUE, scale = TRUE)))\n\n# plot(yield_little_cum ~ xxx_little, dat_wb2, main = \"cumulative yield derived using fasstr ~ by-hand\")\n# abline(a = 0, b = 1, col = \"red\")\n# plot(yyy_little ~ xxx_little, dat_wb2, main = \"cumulative yield derived from cumulative flow ~ summed daily yield\")\n# abline(a = 0, b = 1, col = \"red\")\n# plot(yield_little_mean_log ~ yield_little_cum_log, dat_wb2, main = \"mean log yield ~ cumulative log yield\")\n# abline(a = 0, b = 1, col = \"red\")\n\n# write to file\nwrite_csv(dat_wb2, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Event Delineation/EcoDrought_Data_EventNonEvent_WestBrookonly.csv\")\n\n\nView relationship between Big G and little g, color by site, facet by event/non-event.\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, group = site_name, color = site_name)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~isevent)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods.\n\n\n\n\nWhat does this look like if we use mean yield per event/non-event period?\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~isevent)\n\n\n\n\n\nEffect of mean (log) yield at Big G on mean (log) yield at little g during baseflow and event periods.\n\n\n\n\nWhat does this look like if we use different quantiles? Generally the relationships appear the be the same, just shifted up along the axes to reflect slightly higher flows. Although, note that because we do this on daily data, we are missing a certain about of within-day variability\n\n\nCode\np1 &lt;- dat_wb2 %&gt;% \n  ggplot(aes(x = yield_big_q25_log, y = yield_little_q25_log, group = site_name, color = site_name)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + xlim(-4,2) + ylim(-5,2.75) + theme(legend.position=\"none\")\np2 &lt;- dat_wb2 %&gt;% \n  ggplot(aes(x = yield_big_q50_log, y = yield_little_q50_log, group = site_name, color = site_name)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + xlim(-4,2) + ylim(-5,2.75) + theme(legend.position=\"none\")\np3 &lt;- dat_wb2 %&gt;% \n  ggplot(aes(x = yield_big_q75_log, y = yield_little_q75_log, group = site_name, color = site_name)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + xlim(-4,2) + ylim(-5,2.75) + theme(legend.position=\"none\")\nggarrange(p1, p2, p3, nrow = 1)\n\n\n\n\n\nEffect of mean (log) yield at Big G on mean (log) yield at little g during baseflow and event periods.\n\n\n\n\nView relationship between Big G and little g, color by event/non-event, facet by site. For most sites (except may Obear Brook), G-g relationships are identical between events and non-event.\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, group = isevent, color = isevent)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods.\n\n\n\n\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = isevent, color = isevent)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\n\n\nEffect of mean (log) yield at Big G on mean (log) yield at little g during baseflow and event periods.\n\n\n\n\nView relationship between Big G and little g, color by site, all together\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, group = site_name, color = site_name)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = T)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g.\n\n\n\n\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = T)\n\n\n\n\n\nEffect of mean (log) yield at Big G on mean (log) yield at little g.\n\n\n\n\nView relationship between Big G and among-site/event-specific standard deviation in little g.\n\n\nCode\ndat_wb2 %&gt;% \n  select(agneventid, yield_big_cum_log, yield_little_cum_log) %&gt;% \n  group_by(agneventid) %&gt;% \n  summarize(unq_big = unique(yield_big_cum_log),\n            sd_little = sd(yield_little_cum_log)) %&gt;% \n  ggplot(aes(x = unq_big, y = sd_little)) + geom_point() + geom_smooth() + ylim(0,1.5)\n\n\n\n\n\nDerived from log cumulative yield\n\n\n\n\n\n\nCode\ndat_wb2 %&gt;% \n  select(agneventid, yield_big_mean_log, yield_little_mean_log) %&gt;% \n  group_by(agneventid) %&gt;% \n  summarize(unq_big = unique(yield_big_mean_log),\n            sd_little = sd(yield_little_mean_log)) %&gt;% \n  ggplot(aes(x = unq_big, y = sd_little)) + geom_point() + geom_smooth() + ylim(0,1.5)\n\n\n\n\n\nDerived from mean log yield",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html",
    "href": "Big G Little g/WedgeModel.html",
    "title": "7  The Wedge Model",
    "section": "",
    "text": "7.1 Q, H, A\nPurpose: Define the Wedge hypothesis and model in JAGS.\nQuestions:\nThe Wedge Hypothesis: Among- and within-site diversity in g response to G drive spatiotemporal variation in flow across river networks\nApproach",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#q-h-a",
    "href": "Big G Little g/WedgeModel.html#q-h-a",
    "title": "7  The Wedge Model",
    "section": "",
    "text": "How does water availability (G) affect upstream diversity in streamflow regimes (g)?\n\nHow does streamflow diversity manifest as heterogeneity within and among locations in the upstream river network?\n\nWhat are the relative contributions of within- and among-site diversity to the total streamflow diversity across the river network and does this change with water availability?\n\n\n\nAmong-site wedge: heterogeneity in physical characteristics among sites diversify little g response during low flows, but diversity in little g response attenuates (decreases) during high flows\nWithin-site wedge: within sites, variation in little g response to G is greater at low flows than at high flows\nAdditive diversity in the response of little g to Big G among and within sites drives total streamflow diversity across river networks\n\n\n\nBreak up data into manageable chunks using event/non-event delineation\n\nUsing Big G flow time series data, perform baseflow separation and event delineation to break up data into event and intervening non-event (baseflow) periods.\nApply Big G event/non-event periods to corresponding little g time series data and calculate (log) volumetric yield during each period for both G and g.\n\nUsing a Bayesian hierarchical model to account for site-level variation, model g ~ G, where g is (log) volumetric yield at little g and G is (log) volumetric yield at Big G during successive event/non-event periods.\n\nFit site-aware and site-agnostic models to describe within- and among-site diversity in g response to G, respectively.\nDerive measures of observed and expected g variance dampening with increasing G under different assumptions regarding among- and within-site streamflow diversity\n\n\n\n7.1.1 Conceptual diagram\nThe Wedge Hypothesis states that among- and within-site diversity in g response to G drive spatiotemporal variation in streamflow across entire river networks:\n\n\n\nThe Wedge Hypothesis - general\n\n\nThe hypothesis can be represented with a relatively simple hierarchical model:\n\n\n\nThe Wedge Hypothesis - parameters\n\n\nFrom the fitted model, we can assess the relative contributions of within- and among-site diversity to total streamflow diversity across the river network and explore the extent to which this changes with water availability:\n\n\n\nThe Wedge Hypothesis - portfolio strength",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#data",
    "href": "Big G Little g/WedgeModel.html#data",
    "title": "7  The Wedge Model",
    "section": "7.2 Data",
    "text": "7.2 Data\n\n7.2.1 Site info and event data\n\n\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# delineated event/non-event volumetric yield data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Event Delineation/EcoDrought_Data_EventNonEvent_WestBrookonly.csv\") %&gt;% mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")))\nstr(dat)\n\n\ntibble [689 × 18] (S3: tbl_df/tbl/data.frame)\n $ site_name            : Factor w/ 9 levels \"West Brook Lower\",..: 8 8 8 8 8 8 8 8 8 8 ...\n $ basin                : chr [1:689] \"West Brook\" \"West Brook\" \"West Brook\" \"West Brook\" ...\n $ subbasin             : chr [1:689] \"West Brook\" \"West Brook\" \"West Brook\" \"West Brook\" ...\n $ agneventid           : num [1:689] 5 6 7 8 9 10 11 12 13 14 ...\n $ eventlen             : num [1:689] 6 5 5 5 4 2 4 4 11 6 ...\n $ mindate              : Date[1:689], format: \"2020-02-20\" \"2020-02-26\" ...\n $ isevent              : num [1:689] 2 1 1 2 1 2 1 2 1 2 ...\n $ yield_little_cum     : num [1:689] 8.57 23.21 18.74 15.54 14.08 ...\n $ yield_big_cum        : num [1:689] 7.04 17.14 11.93 9.41 10.16 ...\n $ yield_little_cum_log : num [1:689] 2.15 3.14 2.93 2.74 2.64 ...\n $ yield_big_cum_log    : num [1:689] 1.95 2.84 2.48 2.24 2.32 ...\n $ xxx_little           : num [1:689] 8.51 23.16 18.69 15.49 14.04 ...\n $ yyy_little           : num [1:689] 8.51 23.16 18.69 15.49 14.04 ...\n $ yield_little_mean_log: num [1:689] 0.35 1.37 1.3 1.13 1.23 ...\n $ yield_big_mean_log   : num [1:689] 0.154 1.124 0.859 0.632 0.909 ...\n $ site_name_cd         : num [1:689] 8 8 8 8 8 8 8 8 8 8 ...\n $ z_yield_big_cum_log  : num [1:689] 0.284 0.868 0.63 0.475 0.525 ...\n $ z_yield_big_mean_log : num [1:689] 0.434 1.24 1.019 0.831 1.061 ...\n\n\n\n\n7.2.2 Visualize g~G relationships\nView relationship between Big G and little g, color by site, facet by event/non-event.\n\n\nCode\ndat %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, group = site_name, color = site_name)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~isevent)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods.\n\n\n\n\nView relationship between Big G and little g, color by event/non-event, facet by site. For most sites (except may Obear Brook), G-g relationships are identical between events and non-event.\n\n\nCode\ndat %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, group = isevent, color = isevent)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods.\n\n\n\n\n\n\n7.2.3 Examine hysteresis\nDoes the g~G relationship change over time?\n\n\nCode\ndat %&gt;% \n  mutate(doy = yday(mindate)) %&gt;%\n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, color = doy)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  scale_color_gradient2(midpoint = 182, low = \"orange\", mid = \"purple3\", high = \"orange\") +\n  facet_wrap(~site_name)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods. Points colored by day of year.\n\n\n\n\n\n\nCode\ndat %&gt;% \n  mutate(season = ifelse(month(mindate) %in% c(12,1,2), \"winter\",\n                         ifelse(month(mindate) %in% c(3,4,5), \"spring\",\n                                ifelse(month(mindate) %in% c(6,7,8), \"summer\", \"autumn\")))) %&gt;%\n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, group = season, color = season)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods, by season.\n\n\n\n\nYes, it does appear that the relationship between g and G changes is time-dependent, potentially motivating some inclusion of time as a covariate (and interaction with big G effect…circular regression?). However, this also likely drives the shape/existence of the little wedges. So, is it necessary to account for?",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#declare-model",
    "href": "Big G Little g/WedgeModel.html#declare-model",
    "title": "7  The Wedge Model",
    "section": "7.3 Declare model",
    "text": "7.3 Declare model\nBased on results above, there does not appear to be any significant difference in the G-g relationship for event and non-event periods. Therefore, do not include random intercepts/slopes (by event/non-event) in the model. Previously, I tried to estimate the G-g differences using an intercept model, with the magnitude of difference a function of water availability. However, when Q = Qg, this simplified to a linear regression between Qg (dependent var.) and QG (independent var.), which is ultimately what is of interest. I estimate this regression model below:\nCorrelation between site-level slopes and site-level intercepts is modeled as specified on pgs. 362 and 376 in Gelman and Hill (2007).\n\nData\n\nQg: log volumetric yield at little g\nsites: numeric site id\nQG: log volumetric yield at Big G\nnObs: number of observations\nnSites: number of sites (little g sites)\n\nParameters\n\nalpha: site-level intercept\nbeta: site-level effect of Big G on little g (slope)\nalpha.mu: global intercept\nbeta.mu: global effect of Big G on little g (slope)\nalpha.sigma: site-level variability in the intercept\nbeta.sigma: site-level variability in the slope\nsig.alpha: site-level intercept for process error\nsig.beta: site-level effect of Big G on process error (slope)\nsig.alpha.mu: global process error intercept\nsig.beta.mu: global process error slope\nsig.alpha.sigma: site-level variability in process error intercept\nsig.beta.sigma: site-level variability in process error slope\nrho: correlation between site-leve intercepts (alpha) and slopes (beta)\n\nDerived values\n\npredlg: predicted little g\ndiff: difference between predicted little g and Big G\nVpObs: observed population variance, conditional on x\nVpScen1: expected population variance, no within or among-site diversity\nVpScen2: expected population variance, no within-site diversity\nVpScen3: expected population variance, no among-size diversity\nport1, port2, port3: predicted portfolio strength (over a range of G) compared to 3 alternative hypotheses\nattenObs, atten1, atten2, atten3: attentuation strength (“wedginess”) of observed data and expected under 3 alternative hypotheses\n\n\n\n\nCode\ncat(\"model {\n\n##--- LIKELIHOOD ---------------------------------------------------##\n\nfor (i in 1:nObs) {\n\n  Qg[i] ~ dnorm(mu[i], pow(sigma[i], -2))\n  mu[i] &lt;- alpha[sites[i]] + beta[sites[i]] * QG[i]\n  log(sigma[i]) &lt;- sig.alpha[sites[i]] + sig.beta[sites[i]] * QG[i]\n  \n  # Log-likelihood\n  loglik[i] &lt;- logdensity.norm(Qg[i], mu[i], pow(sigma[i], -2))\n  \n  ## SITE AGNOSTIC\n  Qg2[i] ~ dnorm(ag.mu[i], pow(ag.sigma[i], -2))\n  ag.mu[i] &lt;- ag.alpha + ag.beta * QG[i]\n  log(ag.sigma[i]) &lt;- ag.sig.alpha + ag.sig.beta * QG[i]  \n  }\n\n\n##--- PRIORS --------------------------------------------------------##\n\n# Site-specific parameters\nfor (j in 1:nSites) {\n    alpha[j] &lt;- B[j,1]\n    beta[j] &lt;- B[j,2]\n    B[j,1:2] ~ dmnorm(B.hat[j,], Tau.B[,])\n    B.hat[j,1] &lt;- alpha.mu\n    B.hat[j,2] &lt;- beta.mu\n    \n    sig.alpha[j] ~ dnorm(sig.alpha.mu, pow(sig.alpha.sigma, -2))\n    sig.beta[j] ~ dnorm(sig.beta.mu, pow(sig.beta.sigma, -2))\n    }\n    \n# global parameters\nalpha.mu ~ dnorm(0, pow(10, -2))\nbeta.mu ~ dnorm(0, pow(10, -2))\nsig.alpha.mu ~ dnorm(0, pow(10, -2))\nsig.beta.mu ~ dnorm(0, pow(10, -2))\n\n# variance-covariance matrix components\nTau.B[1:2,1:2] &lt;- inverse(Sigma.B[,])\nSigma.B[1,1] &lt;- pow(alpha.sigma, 2)\nSigma.B[2,2] &lt;- pow(beta.sigma, 2)\nSigma.B[1,2] &lt;- rho * alpha.sigma * beta.sigma\nSigma.B[2,1] &lt;- Sigma.B[1,2]\n\nalpha.sigma ~ dunif(0.001, 100)\nbeta.sigma ~ dunif(0.001, 100)\nrho ~ dunif(-1,1)\n\n# among-site variation in sigma parameters\nsig.alpha.sigma ~ dunif(0.001, 100)\nsig.beta.sigma ~ dunif(0.001, 100)\n\n\n## SITE AGNOSTIC\nag.alpha ~ dnorm(0, pow(10, -2))\nag.beta ~ dnorm(0, pow(10, -2))\nag.sig.alpha ~ dnorm(0, pow(10, -2))\nag.sig.beta ~ dnorm(0, pow(10, -2))\n\n\n##--- DERIVED VALUES ------------------------------------------------##\n\n# expected deviation from Big G\nfor (j in 1:nSites) { \n  for (i in 1:nDiff) {\n    predlg[j,i] &lt;- alpha[j] + beta[j] * QGvec[i]\n    diff[j,i] &lt;- (alpha[j] + beta[j] * QGvec[i]) - QGvec[i]\n  }}\n\n\n# variance decomposition and standardization\nfor (i in 1:nDiff) {\n\n  # observed population variance, conditional on x\n  VpObs[i] &lt;- ((beta.mu^2) * varx) + ((alpha.sigma^2) + ((QGvec[i]^2) * (beta.sigma^2)) + (2 * QGvec[i] * (rho * alpha.sigma * beta.sigma))) + ((exp(sig.alpha.mu + sig.beta.mu * QGvec[i]))^2)\n  \n  # expected population variance, no within or among-site diversity\n  VpScen1[i] &lt;- ((beta.mu^2) * varx) + ((exp(sig.alpha.mu))^2)\n  \n  # expected population variance, no within-site diversity\n  VpScen2[i] &lt;- ((beta.mu^2) * varx) + ((alpha.sigma^2) + ((QGvec[i]^2) * (beta.sigma^2)) + (2 * QGvec[i] * (rho * alpha.sigma * beta.sigma))) + ((exp(sig.alpha.mu))^2)\n  \n  # expected population variance, no among-size diversity\n  VpScen3[i] &lt;- ((beta.mu^2) * varx) + ((exp(sig.alpha.mu + sig.beta.mu * QGvec[i]))^2)\n  \n  # portfolio strength: how much more diversity in streamflow do we observe at the little g gages than expected under alternative (null) hypotheses?\n  port1[i] &lt;- VpObs[i] / VpScen1[i]\n  port2[i] &lt;- VpObs[i] / VpScen2[i]\n  port3[i] &lt;- VpObs[i] / VpScen3[i]\n  \n  # variance in raw response values, agnostic to site (i.e., variance in the sample)\n  VarAg[i] &lt;- (exp(ag.sig.alpha + ag.sig.beta * QGvec[i]))^2\n  \n  Vf[i] &lt;- (beta.mu^2) * varx\n  Vix[i] &lt;- (alpha.sigma^2) + ((QGvec[i]^2) * (beta.sigma^2)) + (2 * QGvec[i] * (rho * alpha.sigma * beta.sigma))\n  Vr[i] &lt;- (exp(sig.alpha.mu + sig.beta.mu * QGvec[i]))^2\n}\n\n\n\n# attenuation strength: how much more diversity in streamflow (among little g gages) do we observe at low vs. high flows?\nattenObs &lt;- VpObs[1] / VpObs[nDiff]\natten1 &lt;- VpScen1[1] / VpScen1[nDiff]\natten2 &lt;- VpScen2[1] / VpScen2[nDiff]\natten3 &lt;- VpScen3[1] / VpScen3[nDiff]\n\n}\", file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod_Events_2_corr.txt\")",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#fit-the-model",
    "href": "Big G Little g/WedgeModel.html#fit-the-model",
    "title": "7  The Wedge Model",
    "section": "7.4 Fit the model",
    "text": "7.4 Fit the model\n\n\nCode\n# vector of QG for prediction\nndiff &lt;- 100\nQGvec &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = ndiff)\n\n# gather data for JAGS\njags.data &lt;- list(\"nObs\" = dim(dat)[1], \"nSites\" = length(unique(dat$site_name_cd)), \n                  \"sites\" = dat$site_name_cd, #\"indev\" = dat_wb2$isevent,\n                  \"Qg\" = dat$yield_little_cum_log, \"QG\" = dat$yield_big_cum_log, \"Qg2\" = dat$yield_little_cum_log, \n                  \"QGvec\" = QGvec, \"nDiff\" = ndiff, \"varx\" = var(dat$yield_big_cum_log))\n\n# parameters to monitor\njags.params &lt;- c(\"alpha\", \"beta\", \"alpha.mu\", \"beta.mu\", \"alpha.sigma\", \"beta.sigma\", \n                 \"sig.alpha\", \"sig.beta\", \"sig.alpha.mu\", \"sig.beta.mu\", \"sig.alpha.sigma\", \"sig.beta.sigma\", \n                 \"rho\", \"diff\", \"predlg\", \"loglik\", \"mu\", \"Qg\", \n                 \"VpObs\", \"VpScen1\", \"VpScen2\", \"VpScen3\", \"port1\", \"port2\", \"port3\", \"attenObs\", \"atten1\", \"atten2\", \"atten3\",\n                 \"VarAg\", \"Vf\", \"Vix\", \"Vr\")\n\n# initial values\nmyinits &lt;- function() {\n  list(alpha.mu = 0, beta.mu = 1, alpha.sigma = 1, beta.sigma = 0.1, \n       sig.alpha.mu = -0.5, sig.beta.mu = -0.2, sig.alpha.sigma = 0.4, sig.beta.sigma = 0.05, \n       ag.alpha = 0.3, ag.beta = 1, ag.sig.alpha = 0, ag.sig.beta = -0.2, rho = -0.8)\n}\n\n# run in jags\nmod_0 &lt;- jags.parallel(data = jags.data, inits = myinits, parameters.to.save = jags.params,\n                       model.file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod_Events_2_corr.txt\",\n                       n.chains = 10, n.thin = 50, n.burnin = 4000, n.iter = 14000, DIC = FALSE)\n# saveRDS(mod_0, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/Fitted models/GgMod_Events.rds\")\n\n\nGet MCMC samples and summary\n\n\nCode\ntop_mod &lt;- mod_0\n# generate MCMC samples and store as an array\nmodelout &lt;- top_mod$BUGSoutput\nMcmcList &lt;- vector(\"list\", length = dim(modelout$sims.array)[2])\nfor(i in 1:length(McmcList)) { McmcList[[i]] = as.mcmc(modelout$sims.array[,i,]) }\n# rbind MCMC samples from 10 chains \nMcmcdat_0 &lt;- rbind(McmcList[[1]], McmcList[[2]], McmcList[[3]], McmcList[[4]], McmcList[[5]], McmcList[[6]], McmcList[[7]], McmcList[[8]], McmcList[[9]], McmcList[[10]])\nparam.summary_0 &lt;- modelout$summary\nhead(param.summary_0)\n\n\n          mean sd     2.5%      25%      50%      75%    97.5% Rhat n.eff\nQg[1] 2.148762  0 2.148762 2.148762 2.148762 2.148762 2.148762    1     1\nQg[2] 3.144685  0 3.144685 3.144685 3.144685 3.144685 3.144685    1     1\nQg[3] 2.930699  0 2.930699 2.930699 2.930699 2.930699 2.930699    1     1\nQg[4] 2.743658  0 2.743658 2.743658 2.743658 2.743658 2.743658    1     1\nQg[5] 2.644678  0 2.644678 2.644678 2.644678 2.644678 2.644678    1     1\nQg[6] 1.624893  0 1.624893 1.624893 1.624893 1.624893 1.624893    1     1",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#model-diagnostics",
    "href": "Big G Little g/WedgeModel.html#model-diagnostics",
    "title": "7  The Wedge Model",
    "section": "7.5 Model diagnostics",
    "text": "7.5 Model diagnostics\n\n7.5.1 View R-hat\nAny problematic R-hat values (&gt;1.01)?\n\n\nCode\nmod_0$BUGSoutput$summary[,8][mod_0$BUGSoutput$summary[,8] &gt; 1.01]\n\n\n loglik[452]    port1[65]    port1[66]    port1[67]    port1[68]    port1[69] \n    1.010080     1.010151     1.010424     1.010663     1.010867     1.011032 \n   port1[70]    port1[71]    port1[72]    port1[73]    port1[74]    port1[75] \n    1.011159     1.011246     1.011293     1.011301     1.011272     1.011207 \n   port1[76]    port1[77]    port1[78]    port1[79]    port1[80]    port1[81] \n    1.011109     1.010981     1.010826     1.010648     1.010450     1.010234 \n   port1[82]    port3[61]    port3[62]    port3[63]    port3[64]    port3[65] \n    1.010006     1.010254     1.010789     1.011316     1.011829     1.012322 \n   port3[66]    port3[67]    port3[68]    port3[69]    port3[70]    port3[71] \n    1.012787     1.013219     1.013611     1.013956     1.014251     1.014489 \n   port3[72]    port3[73]    port3[74]    port3[75]    port3[76]    port3[77] \n    1.014668     1.014785     1.014839     1.014830     1.014760     1.014629 \n   port3[78]    port3[79]    port3[80]    port3[81]    port3[82]    port3[83] \n    1.014444     1.014207     1.013924     1.013600     1.013243     1.012857 \n   port3[84]    port3[85]    port3[86]    port3[87]    port3[88]    port3[89] \n    1.012449     1.012026     1.011591     1.011152     1.010712     1.010275 \npredlg[1,33] \n    1.026732 \n\n\n\n\n7.5.2 View traceplots\nFor global parameters and hyperparameters only…\n\n\nCode\nMCMCtrace(mod_0, ind = TRUE, params = c(\"alpha.mu\", \"beta.mu\", \"alpha.sigma\", \"beta.sigma\", \"sig.alpha.mu\", \"sig.beta.mu\", \"sig.alpha.sigma\", \"sig.beta.sigma\", \"rho\"), pdf = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.5.3 PP check\nGet observed and expected values\n\n\nCode\nppdat_obs &lt;- as.matrix(Mcmcdat_0[,startsWith(colnames(Mcmcdat_0), \"Qg\")])\nppdat_exp &lt;- as.matrix(Mcmcdat_0[,startsWith(colnames(Mcmcdat_0), \"mu\")])\n\n\nBayesian p-value: values approaching 0.5 indicate lack of bias in model estimates\n\n\nCode\nsum(ppdat_exp &gt; ppdat_obs) / (dim(ppdat_obs)[1]*dim(ppdat_obs)[2])\n\n\n[1] 0.4930435\n\n\nPosterior predictive check: ensure linearity and ~1:1 relationship between expected and observed (log) volumetric Qg yield\n\n\nCode\npar(mar = c(4.5,4.5,1,1))\nplot(apply(ppdat_exp, 2, median) ~ apply(ppdat_obs, 2, median), xlab = \"Observed Qg\", ylab = \"Expected Qg\")\nabline(a = 0, b = 1, col = \"red\", lwd = 2)\nlegend(\"topleft\", legend = \"1:1\", lwd = 2, col = \"red\", bty = \"n\")\n\n\n\n\n\n\n\n\n\nSite-specific posterior predictive check: does the model fit some sites better than others?\n\n\nCode\ntibble(obs = apply(ppdat_obs, 2, median), exp = apply(ppdat_exp, 2, median), sitecd = dat$site_name) %&gt;% ggplot(aes(x = obs, y = exp)) + geom_point() + geom_smooth(method = \"lm\") + geom_abline(intercept = 0, slope = 1, color = \"red\") + facet_wrap(~sitecd)\n\n\n\n\n\n\n\n\n\n\n\n7.5.4 Model selection\nPerform model selection using leave-one-out cross-validation (LOO-CV). Does the site-aware (random slopes/random intercepts) model perform better than the site-agnostic model?\nNote: this will need to be updated once we add other random effects specifications. For now, use LOO-CV as an additional check on model fitting…i.e., examine Pareto k estimates.\nAgain, model is well specified for all but 1 data point (k &gt; 1)\n\n\nCode\n# get log-likelihoods\nloglik1 &lt;- mod_0$BUGSoutput$sims.list$loglik\n\n# get relative effective sample size\nreff1 &lt;- relative_eff(exp(loglik1), chain_id = c(rep(1,200), rep(2,200), rep(3,200), rep(4,200), rep(5,200), \n                                                 rep(6,200), rep(7,200), rep(8,200), rep(9,200), rep(10,200)))\n\n# calculate loo\nloo1 &lt;- loo(loglik1, r_eff = reff1)\n\n# compare\nprint(loo1)\n\n\n\nComputed from 2000 by 689 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -426.8 26.6\np_loo        35.6  4.6\nlooic       853.7 53.2\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.8, 1.1]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     687   99.7%   238     \n   (0.7, 1]   (bad)        2    0.3%   &lt;NA&gt;    \n   (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;    \nSee help('pareto-k-diagnostic') for details.\n\n\nCode\nplot(loo1)",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#plot-model-output",
    "href": "Big G Little g/WedgeModel.html#plot-model-output",
    "title": "7  The Wedge Model",
    "section": "7.6 Plot model output",
    "text": "7.6 Plot model output\n\n7.6.1 Slope-int. correlation\nSlopes and intercepts are negatively correlated (this is not unexpected, and explains the attenuation/wedge shape of the data). As noted in Gelman and Hill, the strength of the correlation between slopes and intercepts is sensitive to how the data is centered (or not). Currently, data span 0 (in log space), so this isn’t really an artifact of the issues mentioned in Gelman and Hill (although if we mean centered the data this relationship does weaken slightly). It may actually make the most sense to force the intercept to be at the lowest value of log(G) (i.e., add min(log(G)) to all data, G and g). Intercepts would then represent the maximum expected variation in g during periods of lowest water availability. Alternatively, we could force the intercept to be at the highest valyes of log(G) (i.e., subtract max log(G) from all data) and test for random vs. fixed intercept (as suggested by Ben). Random intercepts would suggest that we still do see site-level variation in g when overall flows are high, whereas a fixed intercept would suggest minimal/no site-level variation in g at high flows. However, we do ultimately need to the slope/intercept correlation structure to do the variance decomposition.\n\n\nCode\nsitib &lt;- tibble(site_name = levels(dat$site_name),\n                slopes = param.summary_0[str_subset(rownames(param.summary_0), pattern = \"^beta\")[1:9],5],\n                intercepts = param.summary_0[str_subset(rownames(param.summary_0), pattern = \"^alpha\")[1:9],5]) \n\n# slope-intercept scatterplot\np1 &lt;- sitib %&gt;% ggplot(aes(x = slopes, y = intercepts, color = site_name)) + geom_point(size = 3) + theme_bw() + xlab(\"Site-level slope\") + ylab(\"Site-level intercept\")\n\n# \"rho\" posterior density\np2 &lt;- tibble(Mcmcdat_0[,\"rho\"]) %&gt;% ggplot(aes(x = Mcmcdat_0[, \"rho\"])) + geom_density(color = \"black\", fill = \"grey\") + theme_bw() + xlab(\"rho\") + ylab(\"Posterior density\") + xlim(-1,0)\n\n# arrange plots\nggarrange(p2, p1, ncol = 2, widths = c(0.35, 0.65))\n\n\n\n\n\n\n\n\n\nCode\n# correlation\n# cor.test(sitib$intercepts, sitib$slopes)\n\n\n\n\nCode\nsitib &lt;- tibble(site_name = levels(dat$site_name),\n                slopes = param.summary_0[str_subset(rownames(param.summary_0), pattern = \"^sig.beta\")[1:9],5],\n                intercepts = param.summary_0[str_subset(rownames(param.summary_0), pattern = \"^sig.alpha\")[1:9],5]) \n\n# slope-intercept scatterplot\np1 &lt;- sitib %&gt;% ggplot(aes(x = slopes, y = intercepts, color = site_name)) + geom_point(size = 3) + theme_bw() + xlab(\"Site-level slope\") + ylab(\"Site-level intercept\")\n\n# \"rho\" posterior density\n# p2 &lt;- tibble(Mcmcdat_0[,\"rho\"]) %&gt;% ggplot(aes(x = Mcmcdat_0[, \"rho\"])) + geom_density(color = \"black\", fill = \"grey\") + theme_bw() + xlab(\"rho\") + ylab(\"Posterior density\") + xlim(-1,0)\n\n# arrange plots\n# ggarrange(p2, p1, ncol = 2, widths = c(0.35, 0.65))\np1\n\n\n\n\n\n\n\n\n\nCode\n# correlation\ncor.test(sitib$intercepts, sitib$slopes)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  sitib$intercepts and sitib$slopes\nt = 1.1218, df = 7, p-value = 0.2989\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.3695613  0.8373947\nsample estimates:\n      cor \n0.3903705 \n\n\n\n\n7.6.2 Effect of G on g\nHere, I plot the results of the fitted model: site-specific effects of Big G yield on little g yield.\n\n\nCode\n# control panel\nnvals &lt;- 100\nnsim &lt;- dim(Mcmcdat_0)[1]\nnsites &lt;- length(unique(dat$site_name_cd))\nx_seq &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = nvals)\n\n# predict from model\npred_arr &lt;- array(NA, dim = c(nsim, nvals, nsites))\npred_arr_summ &lt;- array(NA, dim = c(nvals, 3, nsites))\nfor (k in 1:nsites) {\n  for (j in 1:nsim) {\n    pred_arr[j,,k] &lt;- Mcmcdat_0[j,paste(\"alpha[\", k, \"]\", sep = \"\")] + Mcmcdat_0[j,paste(\"beta[\", k, \"]\", sep = \"\")] * x_seq\n  }\n  pred_arr_summ[,1,k] &lt;- apply(pred_arr[,,k], 2, quantile, probs = 0.025)\n  pred_arr_summ[,2,k] &lt;- apply(pred_arr[,,k], 2, quantile, probs = 0.5)\n  pred_arr_summ[,3,k] &lt;- apply(pred_arr[,,k], 2, quantile, probs = 0.975)\n}\n\n\n\n\nCode\npar(mar = c(5,5,1,11), mfrow = c(1,1))\ngg_color_hue &lt;- function(n) { \n  hues = seq(15, 375, length = n + 1) \n  hcl(h = hues, l = 65, c = 100)[1:n] }\nmycols &lt;- gg_color_hue(9)\n\n# combined\nplot(seq(from = range(pred_arr)[1], to = range(pred_arr)[2], length.out = nvals) ~ x_seq, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"(log) volumetric yield at little g\")\nfor (k in 1:nsites) { \n  polygon(x = c(x_seq, rev(x_seq)), y = c(pred_arr_summ[,1,k], rev(pred_arr_summ[,3,k])), col = alpha(mycols[k], 0.2), border = NA)\n  lines(pred_arr_summ[,2,k] ~ x_seq, lwd = 2, col = mycols[k])\n  points(yield_little_cum_log ~ yield_big_cum_log, data = dat %&gt;% filter(site_name_cd == k), col = mycols[k])\n  }\nabline(a = 0, b = 1, lty = 2)\nlegend(\"topleft\", legend = \"1:1\", lty = 2, bty = \"n\")\npar(xpd = TRUE)\nlegend(\"topright\", inset = c(-0.55, 0), legend = levels(dat$site_name), fill = alpha(mycols, 0.5), bty = \"n\")\n\n\n\n\n\nEffect of (log) volumetric yield at Big G on (log) cumulative yield at little g.\n\n\n\n\n\n\n7.6.3 Within-site variation\nHere, I plot the effect of Big G yield on site-level variation in little g (i.e., sigma). How does site-specific variation in little g response to big G attenuate with increasing Big G?\n\n\nCode\n# control panel\nnvals &lt;- 100\nnsim &lt;- dim(Mcmcdat_0)[1]\nnsites &lt;- length(unique(dat$site_name_cd))\nx_seq &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = nvals)\n\npred_arr &lt;- array(NA, dim = c(nsim, nvals, nsites))\npred_arr_summ &lt;- array(NA, dim = c(3, nvals, nsites))\nfor (k in 1:nsites) {\n  for (j in 1:nsim) {\n    pred_arr[j,,k] &lt;- (exp(Mcmcdat_0[j,paste(\"sig.alpha[\", k, \"]\", sep = \"\")] + Mcmcdat_0[j,paste(\"sig.beta[\", k, \"]\", sep = \"\")] * x_seq))\n  }\n  for (i in 1:nvals) {\n    pred_arr_summ[1,i,k] &lt;- quantile(pred_arr[,i,k], probs = 0.025)\n    pred_arr_summ[2,i,k] &lt;- quantile(pred_arr[,i,k], probs = 0.5)\n    pred_arr_summ[3,i,k] &lt;- quantile(pred_arr[,i,k], probs = 0.975)\n  }\n}\n\npar(mar = c(5,5,1,11), mfrow = c(1,1))\ngg_color_hue &lt;- function(n) { \n  hues = seq(15, 375, length = n + 1) \n  hcl(h = hues, l = 65, c = 100)[1:n] }\nmycols &lt;- gg_color_hue(9)\n\n# polygons as 95% CIs\nplot(seq(from = 0, to = range(pred_arr_summ)[2], length.out = nvals) ~ x_seq, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Within-site variation in little g, sigma\")\nfor (k in 1:nsites) { \n  polygon(x = c(x_seq, rev(x_seq)), y = c(pred_arr_summ[1,,k], rev(pred_arr_summ[3,,k])), col = alpha(mycols[k], 0.2), border = NA)\n  lines(pred_arr_summ[2,,k] ~ x_seq, col = mycols[k], lwd = 2)\n}\npar(xpd = TRUE)\nlegend(\"topright\", inset = c(-0.55, 0), legend = levels(dat$site_name), fill = alpha(mycols, 0.5), bty = \"n\")\n\n\n\n\n\nIncreasing water availability decreases site-level heterogeneity in little g response to Big G. Lines and polygons represent the median and 95% credible interval of the relationship for each site (color).\n\n\n\n\n\n\n7.6.4 Among-site variation\nHere, I plot the effect of Big G yield on global (i.e., among-site) variation in little g. How does among-site variation in little g response to big G attenuate with increasing Big G? This is a derived parameter: the square root of the “phenotypic variance” (conditional on x) as defined in Shielzeth and Nakagawa (2022).\nFrom S&N: “We note that the phenotypic variance VP as we calculate it here as the sum of additive variance components might differ slightly from the variance in response values as estimated from the raw data (Rights & Sterba, 2020). The difference is that the sum of the variance components aims to estimate the population variance while the variance in raw response values represents to variance in the sample. Since the population variance is what is relevant to biological interpretation (de Villemereuil et al., 2018), the sum of additive components is usually preferable.”\n\n\nCode\n# control panel\nnsim &lt;- dim(Mcmcdat_0)[1]\n\n# get derived values\npred_arr &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\nfor (j in 1:nsim) { pred_arr[j,] &lt;- (Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"VpObs\")]) }\nfor (j in 1:ndiff) { pred_arr_summ[j,] &lt;- quantile(pred_arr[,j], probs = c(0.025, 0.5, 0.95)) }\n\n\n\n\nCode\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0))\nplot(seq(from = 0, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Global variance, VpObs\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_summ[,1], rev(pred_arr_summ[,3])), col = alpha(\"black\", 0.2), border = NA)\nlines(pred_arr_summ[,2] ~ QGvec, col = \"black\", lwd = 2)\n\n\n\n\n\nIncreasing water availability decreases among-site heterogeneity in little g response to Big G. Line and polygon represent the median and 95% credible interval of the relationship.\n\n\n\n\nVisually comparing the figure above with the data/regression fits figure, it seems like there is not as much variation in VpObs with x in the plot above as there “should” be. In the plot below, I directly compare the population variance (VpObs) with the sample variance (VarAg), derived from the site-agnostic model). While Schielzeth and Nakagawa (2022) state that the population and sample standard deviations (variances) may “differ slightly” (pg. 1216), the difference as plotted below seems quite large, which leads me to wonder if the variance decomposition model is specified correctly…\n\n\nCode\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0))\nnsim &lt;- 100\nplot(seq(from = 0, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"\")\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"VpObs\")]) ~ QGvec, col = alpha(\"black\", 0.3), lwd = 0.5) }\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"VarAg\")]) ~ QGvec, col = alpha(\"blue\", 0.3), lwd = 0.5) }\nlegend(\"topright\", legend = c(\"VpObs\", \"VarAg\"), lty = 1, col = c(\"black\", \"blue\"), bty = \"n\")\n\n\n\n\n\n\n\n\n\nSo what drives this difference? Below I plot the three components of Vp: Vf, Vix, and Vr, and the sum of Vix and Vr. The difference in VpObs and VarAg in the plot of above is driven in large part by the constant Vf, the variance explained by the fixed effects. Note that VarAg is the residual variance from the site-agnostic model, and thus does not include variance explained by fixed effects. For the site-aware model, the best approximation of VarAg is Vix + Vr, the between/amomg-site variance plus the residual variance (within site).\n\n\nCode\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0), mfrow = c(2,2))\nnsim &lt;- 100\n\n# Vf\nplot(seq(from = 0, to = 4, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Vf\")\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"Vf\")]) ~ QGvec, col = alpha(\"black\", 0.3), lwd = 0.5) }\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"VarAg\")]) ~ QGvec, col = alpha(\"blue\", 0.3), lwd = 0.5) }\nlegend(\"topright\", legend = c(\"Vf\", \"VarAg\"), lty = 1, col = c(\"black\", \"blue\"), bty = \"n\")\n\n# Vix\nplot(seq(from = 0, to = 4, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Vix\")\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"Vix\")]) ~ QGvec, col = alpha(\"black\", 0.3), lwd = 0.5) }\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"VarAg\")]) ~ QGvec, col = alpha(\"blue\", 0.3), lwd = 0.5) }\nlegend(\"topright\", legend = c(\"Vix\", \"VarAg\"), lty = 1, col = c(\"black\", \"blue\"), bty = \"n\")\n\n# Vr\nplot(seq(from = 0, to = 4, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Vr\")\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"Vr\")]) ~ QGvec, col = alpha(\"black\", 0.3), lwd = 0.5) }\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"VarAg\")]) ~ QGvec, col = alpha(\"blue\", 0.3), lwd = 0.5) }\nlegend(\"topright\", legend = c(\"Vr\", \"VarAg\"), lty = 1, col = c(\"black\", \"blue\"), bty = \"n\")\n\n# Vix + Vr\nplot(seq(from = 0, to = 4, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Vix + Vr\")\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"Vix\")]) + (Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"Vr\")]) ~ QGvec, col = alpha(\"black\", 0.3), lwd = 0.5) }\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"VarAg\")]) ~ QGvec, col = alpha(\"blue\", 0.3), lwd = 0.5) }\nlegend(\"topright\", legend = c(\"Vix + Vr\", \"VarAg\"), lty = 1, col = c(\"black\", \"blue\"), bty = \"n\")\n\n\n\n\n\n\n\n\n\nWhy does this matter?\n\nThe best way to compare the plot of within-site variation in little g (sigma ~ G) and among-site variation in little g is probably to use the sum of Vix and Vr, ignoring Vf, as within-site variation (sigma) also effectively ignores fixed effect variance.\nFor calculation of portfolio effects, it likely does not matter as all variance scenarios contain the constant and thus the constant is divided out\nBut for calculation of attenuation strength, it appears to lead to substantial underestimates of attenuation, i.e., “wedginess”. Attenuation strength is a ratio between variation at low vs high levels of G, so when a constant is added to both the numerator and denominator, the absolute difference is the same but the relative difference can be quite different\n\nConsider the following. 4 / 2 = 2 and 3 / 1 = 3. In both cases the absolute difference is the same (1) but the relative difference changes (2 vs. 3).\n\n\n\n\n7.6.5 Portfolio strength\nFirst plot population/phenotypic variances, conditional on QG\n\n\nCode\n# control panel\nnsim &lt;- dim(Mcmcdat_0)[1]\nx_seq &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = ndiff)\n\n# get derived values\npred_arr_VpObs &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_VpScen1 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_VpScen2 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_VpScen3 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\n\npred_arr_VpObs_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_VpScen1_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_VpScen2_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_VpScen3_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\n\nfor (j in 1:nsim) { \n  pred_arr_VpObs[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"VpObs\")] \n  pred_arr_VpScen1[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"VpScen1\")] \n  pred_arr_VpScen2[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"VpScen2\")] \n  pred_arr_VpScen3[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"VpScen3\")] \n  }\nfor (j in 1:ndiff) { \n  pred_arr_VpObs_summ[j,] &lt;- quantile(pred_arr_VpObs[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_VpScen1_summ[j,] &lt;- quantile(pred_arr_VpScen1[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_VpScen2_summ[j,] &lt;- quantile(pred_arr_VpScen2[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_VpScen3_summ[j,] &lt;- quantile(pred_arr_VpScen3[,j], probs = c(0.025, 0.5, 0.95))\n  }\n\n\n\n\nCode\n# plot\nmycols &lt;- c(brewer.pal(3, \"Dark2\"), \"black\")\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0), mfrow = c(2,2))\n\n# VpScen1\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpScen1_summ[,1], rev(pred_arr_VpScen1_summ[,3])), col = alpha(mycols[1], 0.2), border = NA)\nlines(pred_arr_VpScen1_summ[,2] ~ QGvec, col = mycols[1], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 1\", bty = \"n\")\n# VpScen2\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpScen2_summ[,1], rev(pred_arr_VpScen2_summ[,3])), col = alpha(mycols[2], 0.2), border = NA)\nlines(pred_arr_VpScen2_summ[,2] ~ QGvec, col = mycols[2], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 2\", bty = \"n\")\n# VpScen3\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpScen3_summ[,1], rev(pred_arr_VpScen3_summ[,3])), col = alpha(mycols[3], 0.2), border = NA)\nlines(pred_arr_VpScen3_summ[,2] ~ QGvec, col = mycols[3], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 3\", bty = \"n\")\n# VpObs\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpObs_summ[,1], rev(pred_arr_VpObs_summ[,3])), col = alpha(mycols[4], 0.2), border = NA)\nlines(pred_arr_VpObs_summ[,2] ~ QGvec, col = mycols[4], lwd = 2)\nlegend(\"topright\", legend = \"Observed\", bty = \"n\")\n\n\n\n\n\nEffect of water availability (log cumulative yield at Big G) on population variance in little g expected under three alternative (null) hypotheses and for observed data.\n\n\n\n\nNow to show portfolio strength: How much more variable is the observed data than what is expected under three (null) alternative hypotheses?\nNote: subtracted 1 from ratios so values &gt;0 indicate the observed data is more variable than expected and values &lt;0 indicate the observed data is less variable than expected\n\n\nCode\n# control panel\nnsim &lt;- dim(Mcmcdat_0)[1]\nx_seq &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = ndiff)\n\n# get derived values\npred_arr_Port1 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_Port2 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_Port3 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\n\npred_arr_Port1_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_Port2_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_Port3_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\n\nfor (j in 1:nsim) { \n  pred_arr_Port1[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"port1\")] - 1\n  pred_arr_Port2[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"port2\")] - 1\n  pred_arr_Port3[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"port3\")] - 1\n  }\nfor (j in 1:ndiff) { \n  pred_arr_Port1_summ[j,] &lt;- quantile(pred_arr_Port1[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_Port2_summ[j,] &lt;- quantile(pred_arr_Port2[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_Port3_summ[j,] &lt;- quantile(pred_arr_Port3[,j], probs = c(0.025, 0.5, 0.95))\n  }\n\n\n\n\nCode\n# plot\nmycols &lt;- c(brewer.pal(3, \"Dark2\"), \"black\")\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0), mfrow = c(2,2))\nylim1 &lt;- -0.25\nylim2 &lt;- 1.25\n\n# VpScen1\nplot(seq(from = ylim1, to = ylim2, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Portfolio strength\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_Port1_summ[,1], rev(pred_arr_Port1_summ[,3])), col = alpha(mycols[1], 0.2), border = NA)\nlines(pred_arr_Port1_summ[,2] ~ QGvec, col = mycols[1], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 1\", bty = \"n\")\nabline(h = 0, lty = 2)\n# VpScen2\nplot(seq(from = ylim1, to = ylim2, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Portfolio strength\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_Port2_summ[,1], rev(pred_arr_Port2_summ[,3])), col = alpha(mycols[2], 0.2), border = NA)\nlines(pred_arr_Port2_summ[,2] ~ QGvec, col = mycols[2], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 2\", bty = \"n\")\nabline(h = 0, lty = 2)\n# VpScen3\nplot(seq(from = ylim1, to = ylim2, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Portfolio strength\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_Port3_summ[,1], rev(pred_arr_Port3_summ[,3])), col = alpha(mycols[3], 0.2), border = NA)\nlines(pred_arr_Port3_summ[,2] ~ QGvec, col = mycols[3], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 3\", bty = \"n\")\nabline(h = 0, lty = 2)\n\n\n\n\n\n\n\n\n\n\n\n7.6.6 Attenuation Strength\nTo what degree does diversity in streamflow regimes attenuate with increasing Big G? Attenuation strength is calculated as the variance at min G divided by variance at max G four our observed data and three alternative hypotheses. Note that for scenario 1, variance is constant over G and thus would equal 1. Therefore, a value of 1 represents no attenuation. These figures may provide a standardized approach to comparing “wedginess” across basins.\n\n\nCode\nmycols &lt;- c(brewer.pal(3, \"Dark2\"), \"black\")\npar(mar = c(5,5,1,1), mfrow = c(1,1))\nplot(seq(from = 0, to = 1, length.out = 100) ~ seq(from = 0.5, to = 3, length.out = 100), type = \"n\", xlab = \"Attenuation strength\", ylab = \"Density\")\n\n# observed\nobs_den &lt;- density(Mcmcdat_0[,\"attenObs\"])\nobs_den$y2 &lt;- obs_den$y / max(obs_den$y)\nobs_l &lt;- min(which(obs_den$x &gt;= hdi(obs_den, credMass = 0.95)[1]))\nobs_h &lt;- max(which(obs_den$x &lt; hdi(obs_den, credMass = 0.95)[2]))\npolygon(x = c(obs_den$x[c(obs_l,obs_l:obs_h,obs_h)]), y = c(0,obs_den$y2[obs_l:obs_h],0), col = alpha(mycols[4], 0.3), lty = 0)\nlines(obs_den$y2 ~ obs_den$x, col = mycols[4], lwd = 2)\n\n# scenario 2\nexp_den &lt;- density(Mcmcdat_0[,\"atten2\"])\nexp_den$y2 &lt;- exp_den$y / max(exp_den$y)\nexp_l &lt;- min(which(exp_den$x &gt;= hdi(exp_den, credMass = 0.95)[1]))\nexp_h &lt;- max(which(exp_den$x &lt; hdi(exp_den, credMass = 0.95)[2]))\npolygon(x = c(exp_den$x[c(exp_l,exp_l:exp_h,exp_h)]), y = c(0,exp_den$y2[exp_l:exp_h],0), col = alpha(mycols[2], 0.3), lty = 0)\nlines(exp_den$y2 ~ exp_den$x, col = mycols[2], lwd = 2)\n\n# scenario 3\nexp_den &lt;- density(Mcmcdat_0[,\"atten3\"])\nexp_den$y2 &lt;- exp_den$y / max(exp_den$y)\nexp_l &lt;- min(which(exp_den$x &gt;= hdi(exp_den, credMass = 0.95)[1]))\nexp_h &lt;- max(which(exp_den$x &lt; hdi(exp_den, credMass = 0.95)[2]))\npolygon(x = c(exp_den$x[c(exp_l,exp_l:exp_h,exp_h)]), y = c(0,exp_den$y2[exp_l:exp_h],0), col = alpha(mycols[3], 0.3), lty = 0)\nlines(exp_den$y2 ~ exp_den$x, col = mycols[3], lwd = 2)\n\nlegend(\"topright\", legend = c(\"Scenario 1\", \"Scenario 2\", \"Scenario 3\", \"Observed\"), fill = alpha(mycols, 0.3), bty = \"n\")\nabline(v = 1, lty = 1, lwd = 2, col = mycols[1])",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#deprecated",
    "href": "Big G Little g/WedgeModel.html#deprecated",
    "title": "7  The Wedge Model",
    "section": "7.7 DEPRECATED",
    "text": "7.7 DEPRECATED\n\n\nCode\n# vector of QG for prediction\nndiff &lt;- 100\nQGvec &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = ndiff)\n\n# gather data for JAGS\njags.data &lt;- list(\"nObs\" = dim(dat)[1], \"nSites\" = length(unique(dat$site_name_cd)), \n                  \"sites\" = dat$site_name_cd, #\"indev\" = dat_wb2$isevent,\n                  \"Qg\" = dat$yield_little_cum_log, \"Qg2\" = dat$yield_little_cum_log, \"QG\" = dat$yield_big_cum_log, \n                  \"QGvec\" = QGvec, \"nDiff\" = ndiff)\n\n# parameters to monitor\njags.params &lt;- c(\"alpha\", \"beta\", \"alpha.mu\", \"beta.mu\", \"alpha.sigma\", \"beta.sigma\", \n                 \"sig.alpha\", \"sig.beta\", \"sig.alpha.mu\", \"sig.beta.mu\", \"sig.alpha.sigma\", \"sig.beta.sigma\", \n                 \"ag.alpha\", \"ag.beta\", \"ag.sig.alpha\", \"ag.sig.beta\",\n                 \"diff\", \"predlg\", \"loglik\", \"loglik2\", \"mu\", \"Qg\", \"portfolio1\", \"portfolio3\", \"atten3\", \"attenObs\")\n\n# run in jags\nmod_0 &lt;- jags.parallel(data = jags.data, inits = NULL, parameters.to.save = jags.params,\n                       model.file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod_Events_2.txt\",\n                       n.chains = 10, n.thin = 20, n.burnin = 1000, n.iter = 5000, DIC = FALSE)\n# saveRDS(mod_0, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/Fitted models/GgMod_Events.rds\")\n\n\nHere, I plot the effect of Big G yield on global (i.e., among-site) variation in little g from the site-agnostic model. How does among-site variation in little g response to big G attenuate with increasing Big G? Note that this only considers the sites we have data for, not all possible locations in the river network. This could potentially be achieved by simulating data for new sites (see pg. 362 in Gelman and Hill, 2007), but would likely need to add slope-intercept correlation structure to the model to ensure that attenuation in preserved (see pg. 376 in Gelman and Hill).\nWe can visualize this another way, as site-specific differences between little g and Big G at different levels of water availability/Big G flow. This is ~equivalent to the plot above, but provides a site-level examination of Qg variation around QG and how those change over the range of Big G flow.\n\n7.7.0.1 Null model simulations\nHow much among-site variation in little G response to Big G might we expect assuming homogeneity in flow regimes? This is the null hypotheses. Although I’m not sure this is the proper way to do this…for each of n sites, I randomly sample from the posterior distributions of alpha.mu and beta.mu to generate site-specific relationships that all follow the global parameters/relationships.\nHere’s an example of an individual simulation…\n\nPortfolio strength\nThere are probably better ways to do this, but here I’m quantifying/visualizing what I’m calling “portfolio strength”, or the degree of heterogeneity in streamflow regimes across the network, as a function of water availability (big G flow). Portfolio strength is calculated as the (median) observed among-site variation in little G divided by the (median) expected/simulated among site variation in little g assuming flow homogeneity. Thus, values &gt;1 and &lt;1 indicate greater and less heterogeneity in streamflow than expected under the assumption of homogeneity, respectively. I think this would be a good way to compare/standardize among basins.\nAlternatively, portfolio strength can be defined as the ratio between among-site variation in little g at low vs. high values of Big G (sensu Chezik et al. 2017)…so we get distributions for observed and expected values, where a value of 1 indicates no portfolio behavior (no streamflow diversity at different levels of Big G). I don’t think this makes sense because the whole point is the evaluation how diversity in flow regimes (i.e., portfolio strength) changes with water availability.\n\n\n\n7.7.1 Agnostic to sites\nThis model evaluates the G-g relationship and the effect of G on sigma, but ignores site groupings. With respect to the sigma~G relationship, this is essentially what I am trying to reconstruct above using derived values.\n\n7.7.1.1 Fit the JAGS model\nGet MCMC samples and summary\n\n\n7.7.1.2 View traceplots\n\n\n7.7.1.3 Effect of G on sigma\nHere, I plot the effects of Big G yield on among-site variation in little g (i.e., sigma). This describes the effect of water availability on network-wide heterogeneity in streamflow.\n\n\n\n7.7.2 Porfolio strength\nHow much more heterogeneous is observed little g streamflow at different levels of water availability (Big G) relative to our expectations if among- and within-site streamflow diversity is eroded? What does this tell us about the relative contributions of within- and among-site diversity to the total streamflow diversity across the river network?\nPortfolio strength is calculated as the observed variance divided by expected variance under different scenarios in which diversity is eroded. These relationships may provide a standardized approach to comparing “wedginess” across basins\n\n\n7.7.3 Attenuation strength\nTo what degree does diversity in streamflow regimes attenuate with increasing Big G? Attenuation strength is calculated as the variance at min G divided by variance at max G four our observed data and relevant scenarios. Note that for scenario 1, variance is constant over G and thus would equal 1. Therfore, a value of 1 represents no attenuation. These figures may provide a standardized approach to comparing “wedginess” across basins.",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffKS.html",
    "href": "Big G Little g/GgDiffKS.html",
    "title": "8  G-g Difference (KS)",
    "section": "",
    "text": "8.1 Site info and daily data\nPurpose: Explore effects of monthly/annual water availability on Big-little difference using non-parametric Kolmogorov-Smirnov tests\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# flow/yield (and temp) data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\") %&gt;%\n  filter(!site_name %in% c(\"WoundedBuckCreek\", \"Brackett Creek\"))\n\n# add water/climate year variables\ndat &lt;- add_date_variables(dat, dates = date, water_year_start = 4)",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>G-g Difference (KS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffKS.html#separate-and-join-g-g",
    "href": "Big G Little g/GgDiffKS.html#separate-and-join-g-g",
    "title": "8  G-g Difference (KS)",
    "section": "8.2 Separate and join G-g",
    "text": "8.2 Separate and join G-g\n\n\nCode\n# pull out big G data\ndat_big &lt;- dat %&gt;% filter(site_name %in% c(\"West Brook NWIS\", \"Paine Run 10\", \"Piney River 10\", \"Staunton River 10\", \"Spread Creek Dam\", \"BigCreekLower\", \"Shields River ab Smith NWIS\", \"Donner Blitzen River nr Frenchglen NWIS\")) \n\n# pull out little G data, assign big G site name\ndat_little &lt;- dat %&gt;% \n  filter(designation %in% c(\"little\", \"medium\"), !subbasin %in% c(\"Coal Creek\", \"McGee Creek\", \"Duck Creek\", \"Flathead\"),\n         !site_name %in% c(\"West Brook NWIS\", \"West Brook 0\", \"Paine Run 10\", \"Piney River 10\", \"Staunton River 10\", \"Spread Creek Dam\", \"Shields River ab Smith NWIS\", \"BigCreekLower\")) %&gt;%\n  mutate(site_name_big = ifelse(subbasin == \"Big Creek\", \"BigCreekLower\",\n                                ifelse(subbasin == \"West Brook\", \"West Brook NWIS\", \n                                       ifelse(subbasin == \"Paine Run\", \"Paine Run 10\", \n                                              ifelse(subbasin == \"Piney River\", \"Piney River 10\",\n                                                     ifelse(subbasin == \"Staunton River\", \"Staunton River 10\",\n                                                            ifelse(subbasin == \"Shields River\", \"Shields River ab Smith NWIS\",\n                                                                   ifelse(subbasin == \"Snake River\", \"Spread Creek Dam\", \"Donner Blitzen River nr Frenchglen NWIS\"))))))))\n\n# Join big-little discharge data\ndat_Gg &lt;- dat_little %&gt;%\n  select(site_name, site_name_big, basin, subbasin, date, Month, MonthName, WaterYear, Yield_filled_mm_7) %&gt;% rename(yield_little = Yield_filled_mm_7) %&gt;%\n  left_join(dat_big %&gt;% select(site_name, date, Yield_filled_mm_7) %&gt;% rename(site_name_big = site_name, yield_big = Yield_filled_mm_7)) %&gt;%\n  drop_na() %&gt;% mutate(MonthName = as.character(MonthName))\n\n# table\ndat_Gg %&gt;% group_by(subbasin) %&gt;% summarize(site_name_big = unique(site_name_big)) %&gt;% kable(caption = \"Big G gage names for each focal sub-basin.\")\n\n\n\nBig G gage names for each focal sub-basin.\n\n\nsubbasin\nsite_name_big\n\n\n\n\nBig Creek\nBigCreekLower\n\n\nDonner Blitzen\nDonner Blitzen River nr Frenchglen NWIS\n\n\nPaine Run\nPaine Run 10\n\n\nShields River\nShields River ab Smith NWIS\n\n\nSnake River\nSpread Creek Dam\n\n\nStaunton River\nStaunton River 10\n\n\nWest Brook\nWest Brook NWIS\n\n\n\n\n\nView unique little g site names\n\n\nCode\nsort(unique(dat_Gg$site_name))\n\n\n [1] \"Avery Brook\"                      \"Avery Broook NWIS\"               \n [3] \"Big Creek NWIS\"                   \"BigCreekMiddle\"                  \n [5] \"BigCreekUpper\"                    \"Buck Creek\"                      \n [7] \"Crandall Creek\"                   \"Deep Creek\"                      \n [9] \"Donner Blitzen ab Fish NWIS\"      \"Donner Blitzen ab Indian NWIS\"   \n[11] \"Donner Blitzen nr Burnt Car NWIS\" \"Dugout Creek\"                    \n[13] \"Dugout Creek NWIS\"                \"Fish Creek\"                      \n[15] \"Grizzly Creek\"                    \"Grouse Creek\"                    \n[17] \"Hallowat Creek NWIS\"              \"HallowattCreekLower\"             \n[19] \"Jimmy Brook\"                      \"LangfordCreekLower\"              \n[21] \"LangfordCreekUpper\"               \"Leidy Creek Mouth\"               \n[23] \"Leidy Creek Mouth NWIS\"           \"Leidy Creek Upper\"               \n[25] \"Lodgepole Creek\"                  \"Mitchell Brook\"                  \n[27] \"NF Spread Creek Lower\"            \"NF Spread Creek Upper\"           \n[29] \"NicolaCreek\"                      \"Obear Brook Lower\"               \n[31] \"Paine Run 01\"                     \"Paine Run 02\"                    \n[33] \"Paine Run 06\"                     \"Paine Run 07\"                    \n[35] \"Paine Run 08\"                     \"Rock Creek\"                      \n[37] \"Sanderson Brook\"                  \"SF Spread Creek Lower\"           \n[39] \"SF Spread Creek Lower NWIS\"       \"SF Spread Creek Upper\"           \n[41] \"Shields River ab Dugout\"          \"SkookoleelCreek\"                 \n[43] \"Staunton River 02\"                \"Staunton River 03\"               \n[45] \"Staunton River 06\"                \"Staunton River 07\"               \n[47] \"Staunton River 09\"                \"WernerCreek\"                     \n[49] \"West Brook Lower\"                 \"West Brook Reservoir\"            \n[51] \"West Brook Upper\"                 \"West Whately Brook\"",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>G-g Difference (KS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffKS.html#compute-gg-difference",
    "href": "Big G Little g/GgDiffKS.html#compute-gg-difference",
    "title": "8  G-g Difference (KS)",
    "section": "8.3 Compute Gg Difference",
    "text": "8.3 Compute Gg Difference\n\n\nCode\nmysites &lt;- unique(dat_Gg$site_name)\nkscompare_list &lt;- list()\nfor (i in 1:length(mysites)) {\n  d &lt;- dat_Gg %&gt;% filter(site_name == mysites[i])\n  yrs &lt;- unique(d$WaterYear)\n  kscompare_list_yr &lt;- list()\n  for(j in 1:length(yrs)) {\n    dy &lt;- d %&gt;% filter(WaterYear == yrs[j])\n    mypvals_monthly &lt;- tibble(site_name = rep(NA, times = 12), \n                              site_name_big = rep(NA, times = 12), \n                              WaterYear = rep(NA, times = 12),\n                              Month = rep(NA, times = 12),\n                              MonthName = rep(NA, times = 12),\n                              days = rep(NA, times = 12),\n                              stat = rep(NA, times = 12),\n                              pval = rep(NA, times = 12))\n    for(k in 1:12) {\n      dym &lt;- dy %&gt;% filter(Month == k)\n      if(dim(dym)[1] &lt; 25) next\n      mytest &lt;- ks.test(dym$yield_little, dym$yield_big, exact = TRUE)\n      mypvals_monthly$site_name[k] &lt;- mysites[i]\n      mypvals_monthly$site_name_big[k] &lt;- unique(dym$site_name_big)\n      mypvals_monthly$WaterYear[k] &lt;- yrs[j]\n      mypvals_monthly$Month[k] &lt;- k\n      mypvals_monthly$MonthName[k] &lt;- unique(dym$MonthName)\n      mypvals_monthly$days[k] &lt;- dim(dym)[1]\n      mypvals_monthly$stat[k] &lt;- mytest$statistic\n      mypvals_monthly$pval[k] &lt;- mytest$p.value\n      }\n    kscompare_list_yr[[j]] &lt;- mypvals_monthly\n    }\n  kscompare_list[[i]] &lt;- do.call(rbind, kscompare_list_yr)\n}\nkscompare &lt;- do.call(rbind, kscompare_list) %&gt;% drop_na()\n\n\nView relationship between KS test statistic and p-value\n\n\nCode\nplot(pval ~ stat, kscompare, xlab = \"KS test statistic\", ylab = \"p-value\")\n\n\n\n\n\n\n\n\n\nView distribution of KS test statistics and p-values\n\n\nCode\nhist(kscompare$stat)\n\n\n\n\n\n\n\n\n\nCode\nhist(kscompare$pval)",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>G-g Difference (KS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffKS.html#calculate-total-yield",
    "href": "Big G Little g/GgDiffKS.html#calculate-total-yield",
    "title": "8  G-g Difference (KS)",
    "section": "8.4 Calculate total yield",
    "text": "8.4 Calculate total yield\n\n\nCode\n# Get total annual and monthly Big G yield and join to KS diffs\n\n# get total annual yield by big G site\ntotyield_annual &lt;- dat_big %&gt;% \n  group_by(site_name, WaterYear, basin, subbasin) %&gt;% \n  summarize(days = n(), yield_annual = sum(Yield_filled_mm, na.rm = TRUE)) %&gt;%\n  filter(!is.na(yield_annual), days &gt;= 360) %&gt;%\n  ungroup() %&gt;%\n  rename(site_name_big = site_name) %&gt;%\n  select(site_name_big, WaterYear, yield_annual) %&gt;%\n  ungroup()\n\n# get total monthly yield by big G site\ntotyield_monthly &lt;- dat_big %&gt;% \n  group_by(site_name, WaterYear, basin, subbasin, Month) %&gt;% \n  summarize(days = n(), yield_monthly = sum(Yield_filled_mm, na.rm = TRUE)) %&gt;%\n  filter(!is.na(yield_monthly), days &gt;= 28) %&gt;%\n  ungroup() %&gt;%\n  rename(site_name_big = site_name) %&gt;%\n  select(site_name_big, WaterYear, Month, yield_monthly) %&gt;%\n  ungroup()",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>G-g Difference (KS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffKS.html#explore-gg-diff-by-water-availability",
    "href": "Big G Little g/GgDiffKS.html#explore-gg-diff-by-water-availability",
    "title": "8  G-g Difference (KS)",
    "section": "8.5 Explore Gg diff by water availability",
    "text": "8.5 Explore Gg diff by water availability\nHypothesis: during wetter periods (months/years) flow regimes become more similar among locations within stream networks (i.e., positive relationship between monthly/annual total yield and KS-test p-value)\nHow might this vary among basins that differ in primary water source (rain vs. snow) and among sites within basins (due to surface vs. subsurface controls on flow)?\n\n\nCode\n# join KS comparison df with annual/monthly water availability\nkscompare &lt;- kscompare %&gt;% left_join(totyield_annual) %&gt;% left_join(totyield_monthly) %&gt;%\n  mutate(MonthName = factor(MonthName, levels = c(\"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\", \"Jan\", \"Feb\", \"Mar\"))) %&gt;%\n  left_join(siteinfo %&gt;% select(site_name, basin))\n\n\n\n8.5.1 Global relationship\nPlot relationship between log(monthly total yield) and log(KS p-value) for all basins, sites, and months combined\n\n\nCode\nkscompare %&gt;% ggplot(aes(x = log(yield_monthly), y = log(pval))) + \n  geom_point(aes(group = MonthName, color = MonthName)) + \n  geom_smooth(method = \"lm\") + geom_abline(slope = 0, intercept = log(0.05), linetype = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\n8.5.2 Basin-level effects\n\n\nCode\n# Plot all sites, facet by basin\nkscompare %&gt;% ggplot(aes(x = log(yield_monthly), y = log(pval))) + \n  geom_point(aes(group = MonthName, color = MonthName)) + facet_wrap(~ basin) + \n  geom_smooth(method = \"lm\") + geom_abline(slope = 0, intercept = log(0.05), linetype = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\n8.5.3 Basin and site effects\n\n\nCode\nmybasins &lt;- unique(kscompare$basin)\nmyplots &lt;- list()\nfor (i in 1:length(mybasins)) {\n  myplots[[i]] &lt;- kscompare %&gt;% \n    filter(basin == mybasins[i]) %&gt;%\n    ggplot(aes(x = log(yield_monthly), y = log(pval))) + \n    geom_point(aes(group = MonthName, color = MonthName)) + \n    facet_wrap(~ site_name) + \n    geom_smooth(method = \"lm\") + \n    geom_abline(slope = 0, intercept = log(0.05), linetype = \"dashed\")\n}\n\n\n\nBig CreekWest BrookPaine RunStaunton RiverShields RiverSnake RiverDonner Blitzen",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>G-g Difference (KS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffJAGS.html",
    "href": "Big G Little g/GgDiffJAGS.html",
    "title": "9  G-g Difference (JAGS)",
    "section": "",
    "text": "9.1 Data\nPurpose: Model effects of monthly/annual water availability on Big-little difference using JAGS",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>G-g Difference (JAGS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffJAGS.html#data",
    "href": "Big G Little g/GgDiffJAGS.html#data",
    "title": "9  G-g Difference (JAGS)",
    "section": "",
    "text": "9.1.1 Site info and daily data\n\n\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# flow/yield (and temp) data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\") %&gt;%\n  filter(!site_name %in% c(\"WoundedBuckCreek\", \"Brackett Creek\"))\n\n# add water/climate year variables\ndat &lt;- add_date_variables(dat, dates = date, water_year_start = 4)\n\n\n\n\n9.1.2 Separate and join G-g\n\n\nCode\n# pull out big G data\ndat_big &lt;- dat %&gt;% filter(site_name %in% c(\"West Brook NWIS\", \"Paine Run 10\", \"Piney River 10\", \"Staunton River 10\", \"Spread Creek Dam\", \"BigCreekLower\", \"Shields River ab Smith NWIS\", \"Donner Blitzen River nr Frenchglen NWIS\")) \n\n# pull out little G data, assign big G site name\ndat_little &lt;- dat %&gt;% \n  filter(designation %in% c(\"little\", \"medium\"), !subbasin %in% c(\"Coal Creek\", \"McGee Creek\", \"Duck Creek\", \"Flathead\"),\n         !site_name %in% c(\"West Brook NWIS\", \"West Brook 0\", \"Paine Run 10\", \"Piney River 10\", \"Staunton River 10\", \"Spread Creek Dam\", \"Shields River ab Smith NWIS\", \"BigCreekLower\")) %&gt;%\n  mutate(site_name_big = ifelse(subbasin == \"Big Creek\", \"BigCreekLower\",\n                                ifelse(subbasin == \"West Brook\", \"West Brook NWIS\", \n                                       ifelse(subbasin == \"Paine Run\", \"Paine Run 10\", \n                                              ifelse(subbasin == \"Piney River\", \"Piney River 10\",\n                                                     ifelse(subbasin == \"Staunton River\", \"Staunton River 10\",\n                                                            ifelse(subbasin == \"Shields River\", \"Shields River ab Smith NWIS\",\n                                                                   ifelse(subbasin == \"Snake River\", \"Spread Creek Dam\", \"Donner Blitzen River nr Frenchglen NWIS\"))))))))\n\n# Join big-little discharge data\ndat_Gg &lt;- dat_little %&gt;%\n  select(site_name, site_name_big, basin, subbasin, date, Month, MonthName, WaterYear, Yield_filled_mm_7) %&gt;% rename(yield_little = Yield_filled_mm_7) %&gt;%\n  left_join(dat_big %&gt;% select(site_name, date, Yield_filled_mm_7) %&gt;% rename(site_name_big = site_name, yield_big = Yield_filled_mm_7)) %&gt;%\n  drop_na() %&gt;% mutate(MonthName = as.character(MonthName))\n\n# table\ndat_Gg %&gt;% group_by(subbasin) %&gt;% summarise(site_name_big = unique(site_name_big)) %&gt;% kable(caption = \"Big G gage names for each focal sub-basin.\")\n\n\n\nBig G gage names for each focal sub-basin.\n\n\nsubbasin\nsite_name_big\n\n\n\n\nBig Creek\nBigCreekLower\n\n\nDonner Blitzen\nDonner Blitzen River nr Frenchglen NWIS\n\n\nPaine Run\nPaine Run 10\n\n\nShields River\nShields River ab Smith NWIS\n\n\nSnake River\nSpread Creek Dam\n\n\nStaunton River\nStaunton River 10\n\n\nWest Brook\nWest Brook NWIS\n\n\n\n\n\n\n\n9.1.3 Calculate total yield\n\n\nCode\n# Get total annual and monthly Big G yield and join to KS diffs\n\n# get total annual yield by big G site\ntotyield_annual &lt;- dat_big %&gt;% \n  group_by(site_name, WaterYear, basin, subbasin) %&gt;% \n  summarise(days = n(), yield_annual = sum(Yield_filled_mm, na.rm = TRUE)) %&gt;%\n  filter(!is.na(yield_annual), days &gt;= 360) %&gt;%\n  ungroup() %&gt;%\n  rename(site_name_big = site_name) %&gt;%\n  select(site_name_big, WaterYear, yield_annual) %&gt;%\n  ungroup()\n\n# get total monthly yield by big G site\ntotyield_monthly &lt;- dat_big %&gt;% \n  group_by(site_name, WaterYear, basin, subbasin, Month) %&gt;% \n  summarise(days = n(), yield_monthly = sum(Yield_filled_mm, na.rm = TRUE)) %&gt;%\n  filter(!is.na(yield_monthly), days &gt;= 28) %&gt;%\n  ungroup() %&gt;%\n  rename(site_name_big = site_name) %&gt;%\n  select(site_name_big, WaterYear, Month, yield_monthly) %&gt;%\n  ungroup()\n\n\n\n\n9.1.4 Final dataset\nJoin and filter G-g data to relevant basin(s) and years: currently, West Brook CY 2021 only!\n\n\nCode\n# wide format to enable direct difference calculation (Attempt 1)\ndat_Gg2 &lt;- dat_Gg %&gt;% left_join(totyield_annual) %&gt;% left_join(totyield_monthly) %&gt;% \n  filter(basin == \"West Brook\", site_name != \"Avery Broook NWIS\", WaterYear == 2021) %&gt;% \n  mutate(site_name_cd = as.numeric(as.factor(site_name)),\n         z_log_yield_monthly = as.numeric(scale(log(yield_monthly), center = TRUE, scale = TRUE)),\n         month_radian = as_radians((Month/12)*360))\n\n# long format for more standard intercept model (Attempt 2)\ndat_Gg3 &lt;- dat_Gg2 %&gt;% select(site_name, site_name_cd, Month, month_radian, WaterYear, yield_little, yield_big, z_log_yield_monthly) %&gt;%\n  gather(key = \"ind\", value = \"yield\", yield_little, yield_big) %&gt;% mutate(indnum = as.numeric(as.factor(ind))-1)\nhead(dat_Gg3)\n\n\n# A tibble: 6 × 9\n  site_name  site_name_cd Month month_radian WaterYear z_log_yield_monthly ind  \n  &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;               &lt;dbl&gt; &lt;chr&gt;\n1 Avery Bro…            1     4         2.09      2021                1.20 yiel…\n2 Avery Bro…            1     4         2.09      2021                1.20 yiel…\n3 Avery Bro…            1     4         2.09      2021                1.20 yiel…\n4 Avery Bro…            1     4         2.09      2021                1.20 yiel…\n5 Avery Bro…            1     4         2.09      2021                1.20 yiel…\n6 Avery Bro…            1     4         2.09      2021                1.20 yiel…\n# ℹ 2 more variables: yield &lt;dbl&gt;, indnum &lt;dbl&gt;\n\n\nExplore G-g data\n\n\nCode\ndat_Gg2 %&gt;% group_by(WaterYear, Month) %&gt;% summarise(z_log_yield_monthly = unique(z_log_yield_monthly)) %&gt;% \n  ggplot(aes(x = Month, y = z_log_yield_monthly)) + geom_point() + geom_smooth()\n\n\n\n\n\nStandardized (log) total monthly yield at Big G during CY 2021\n\n\n\n\n\n\nCode\ndat_Gg3 %&gt;% ggplot() + geom_boxplot(aes(x = as.factor(Month), y = log(yield), fill = ind)) + facet_wrap(~site_name)\n\n\n\n\n\nDistribution of (log) yield at G-g over time, by site\n\n\n\n\n\n\nCode\ndat_Gg2 %&gt;% \n  group_by(site_name, Month) %&gt;% \n  summarise(yield_little = mean(log(yield_little), na.rm = TRUE), \n            yield_big = mean(log(yield_big), na.rm = TRUE),\n            z_log_yield_monthly = unique(z_log_yield_monthly)) %&gt;%\n  mutate(Qd = yield_little - yield_big) %&gt;% \n  ggplot(aes(x = Month, y = Qd)) + geom_point() + geom_smooth() + ylab(\"mean[log(g) - log(G)]\") + \n  facet_wrap(~site_name) + geom_abline(intercept = 0, slope = 0, linetype = \"dashed\")\n\n\n\n\n\nG-g difference in (log) monthly mean yield over time\n\n\n\n\n\n\nCode\ndat_Gg2 %&gt;% \n  group_by(site_name, Month) %&gt;% \n  summarise(yield_little = mean(log(yield_little), na.rm = TRUE), \n            yield_big = mean(log(yield_big), na.rm = TRUE),\n            z_log_yield_monthly = unique(z_log_yield_monthly)) %&gt;%\n  mutate(Qd = yield_little - yield_big) %&gt;% \n  ggplot(aes(x = z_log_yield_monthly, y = Qd)) + geom_point() + geom_smooth(method = \"lm\") + \n  ylab(\"mean[log(g) - log(G)]\") + facet_wrap(~site_name) + geom_abline(intercept = 0, slope = 0, linetype = \"dashed\")\n\n\n\n\n\nG-g difference in (log) monthly mean yield as a function of (log) total monthly yield at G",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>G-g Difference (JAGS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffJAGS.html#declare-the-jags-model",
    "href": "Big G Little g/GgDiffJAGS.html#declare-the-jags-model",
    "title": "9  G-g Difference (JAGS)",
    "section": "9.2 Declare the JAGS model",
    "text": "9.2 Declare the JAGS model\nFirst attempt tries to model the difference as a derived parameter (like the growth model), but this maintains the temporal structure of the data, and we are primarily interested in the difference in the distributions\n\n\nCode\ncat(\"model {\n\n##--- LIKELIHOOD ---------------------------------------------------##\n\nfor (i in 1:nObs) {\n  Qg[i] ~ dnorm(mu[i], pow(sigma, -2))\n  mu[i] &lt;- QG[i] - Qd[i]\n  Qd[i] &lt;- alpha[sites[i]] + beta[sites[i]] * yield[i]\n  \n  # Log-likelihood\n  loglik[i] &lt;- logdensity.norm(Qg[i], mu[i], pow(sigma, -2))\n  }\n\n\n##--- PRIORS --------------------------------------------------------##\n\n# Process error is shared among sites\nsigma ~ dunif(0.001, 100)\n\n# Site-specific parameters\nfor (k in 1:nSites) {\n  alpha[k] ~ dnorm(alpha.mu, pow(sigma.alpha, -2))\n  beta[k] ~ dnorm(beta.mu, pow(sigma.beta, -2))\n  }\n\n# Global parameters\nalpha.mu ~ dnorm(0, pow(10, -2))\nbeta.mu ~ dnorm(0, pow(10, -2))\n\n# Site-level variation in alpha and beta\nsigma.alpha ~ dunif(0.001, 100)\nsigma.beta ~ dunif(0.001, 100)\n\n}\", file = \"./Big G Little g/JAGS Models/GgMod.txt\")\n\n\nSecond attempt is a more standard intercept model.\n\n“alpha” is the mean monthly yield at Big-G, which is shared among sites\n“beta1” is a Little-g offset to the intercept, which describes the site-level mean G-g difference\n“beta2” describes the effect of water availability (log total monthly yield at Big G) on the site-level mean G-g difference.\n\nNote that this is only “turned on” for little-g (ind[i] = 1)\n\nShould add covariates on sigma to deal with unequal variance among groups\n\n\n\nCode\ncat(\"model {\n\n##--- LIKELIHOOD ---------------------------------------------------##\n\nfor (i in 1:nObs) {\n  Q[i] ~ dnorm(mu[i], pow(sigma, -2))\n  mu[i] &lt;- alpha[months[i]] + beta1[sites[i]] * ind[i] + beta2[sites[i]] * ind[i] * yieldtot[i]\n  \n  # Log-likelihood\n  loglik[i] &lt;- logdensity.norm(Q[i], mu[i], pow(sigma, -2))\n  }\n\n\n##--- PRIORS --------------------------------------------------------##\n\n# Process error is shared among sites\nsigma ~ dunif(0.001, 100)\n\n# Site-specific parameters\nfor (j in 1:nSites) {\n  beta1[j] ~ dnorm(0, pow(10, -2))\n  beta2[j] ~ dnorm(0, pow(10, -2))\n  }\n\nfor(k in 1:nMonths) {\n  alpha[k] ~ dnorm(0, pow(10, -2))\n  }\n\n}\", file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod.txt\")",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>G-g Difference (JAGS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffJAGS.html#fit-the-jags-model",
    "href": "Big G Little g/GgDiffJAGS.html#fit-the-jags-model",
    "title": "9  G-g Difference (JAGS)",
    "section": "9.3 Fit the JAGS model",
    "text": "9.3 Fit the JAGS model\n\n\nCode\n# gather data for JAGS\n# jags.data &lt;- list(\"nObs\" = dim(dat_Gg2)[1], \"nSites\" = length(unique(dat_Gg2$site_name_cd)), \"sites\" = dat_Gg2$site_name_cd, \n#                   \"Qg\" = dat_Gg2$yield_little, \"QG\" = dat_Gg2$yield_big, \"yield\" = dat_Gg2$z_yield_monthly)\njags.data &lt;- list(\"nObs\" = dim(dat_Gg3)[1], \"nSites\" = length(unique(dat_Gg3$site_name_cd)), \"nMonths\" = length(unique(dat_Gg3$Month)), \n                  \"sites\" = dat_Gg3$site_name_cd, \"months\" = dat_Gg3$Month,\n                  \"Q\" = log(dat_Gg3$yield+0.01), \"ind\" = dat_Gg3$indnum, \"yieldtot\" = dat_Gg3$z_log_yield_monthly)\n\n# parameters to monitor\n# jags.params &lt;- c(\"alpha\", \"alpha.mu\", \"sigma.alpha\", \"beta\", \"beta.mu\", \"sigma.beta\", \"sigma\", \"loglik\")\njags.params &lt;- c(\"alpha\", \"beta1\", \"beta2\", \"sigma\", \"loglik\")\n\n# run in jags\nmod_0 &lt;- jags.parallel(data = jags.data, inits = NULL, parameters.to.save = jags.params,\n                       model.file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod.txt\",\n                       n.chains = 6, n.thin = 20, n.burnin = 1000, n.iter = 5000, DIC = TRUE)\n# saveRDS(mod_0, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod.RDS\")\n\n\nAny problematic R-hat values?\n\n\nCode\nmod_0$BUGSoutput$summary[,8][mod_0$BUGSoutput$summary[,8] &gt; 1.01]\n\n\nloglik[2211] \n    1.011407 \n\n\n\n9.3.1 View traceplots\n\n\nCode\nMCMCtrace(mod_0, ind = TRUE, params = c(\"alpha\", \"beta1\", \"beta2\", \"sigma\"), pdf = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.3.2 Get MCMC samples and summary\n\n\nCode\ntop_mod &lt;- mod_0\n# generate MCMC samples and store as an array\nmodelout &lt;- top_mod$BUGSoutput\nMcmcList &lt;- vector(\"list\", length = dim(modelout$sims.array)[2])\nfor(i in 1:length(McmcList)) { McmcList[[i]] = as.mcmc(modelout$sims.array[,i,]) }\n# rbind MCMC samples from 10 chains \nMcmcdat &lt;- rbind(McmcList[[1]], McmcList[[2]], McmcList[[3]], McmcList[[4]], McmcList[[5]], McmcList[[6]])\nparam.summary &lt;- modelout$summary\nhead(param.summary)\n\n\n               mean         sd       2.5%        25%        50%        75%\nalpha[1]  0.5462529 0.02781862  0.4936378  0.5270035  0.5462240  0.5655740\nalpha[2] -0.1422659 0.02915204 -0.1999043 -0.1625639 -0.1424827 -0.1225840\nalpha[3]  0.4374197 0.02802609  0.3807040  0.4192080  0.4371426  0.4555607\nalpha[4]  1.2530323 0.02901345  1.1953046  1.2329734  1.2536734  1.2737716\nalpha[5]  0.5094628 0.02926410  0.4531626  0.4896552  0.5098029  0.5290679\nalpha[6] -1.5593645 0.02751962 -1.6113834 -1.5774984 -1.5599359 -1.5417936\n               97.5%     Rhat n.eff\nalpha[1]  0.60321864 1.002291   920\nalpha[2] -0.08210678 1.004733   560\nalpha[3]  0.49472750 1.001976  1000\nalpha[4]  1.30751424 1.003528   700\nalpha[5]  0.56547757 1.000548  1200\nalpha[6] -1.50406241 1.000014  1200",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>G-g Difference (JAGS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffJAGS.html#plot-model-output",
    "href": "Big G Little g/GgDiffJAGS.html#plot-model-output",
    "title": "9  G-g Difference (JAGS)",
    "section": "9.4 Plot model output",
    "text": "9.4 Plot model output\n\n\nCode\n# control panel\nnvals &lt;- 100\nnsim &lt;- 50\nnsites &lt;- length(unique(dat_Gg3$site_name_cd))\nx_seq &lt;- seq(from = min(dat_Gg2$z_log_yield_monthly), to = max(dat_Gg2$z_log_yield_monthly), length.out = nvals)\n\n# predict from model\npred_arr &lt;- array(NA, dim = c(nsim, nvals, nsites))\nfor (k in 1:nsites) {\n  for (j in 1:nsim) {\n    pred_arr[j,,k] &lt;- Mcmcdat[j,paste(\"beta1[\", k, \"]\", sep = \"\")] + Mcmcdat[j,paste(\"beta2[\", k, \"]\", sep = \"\")] * x_seq\n  }\n}\n# pred_dist_lin &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nrgs)\n# for (i in 1:nrow(pred_dist_lin)) { pred_dist_lin[i,] &lt;- exp(Mcmcdat[i,\"alpha\"] + Mcmcdat[i,\"beta1\"]*pdist) }\n# pred_dist_tran &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nrgs)\n# for (i in 1:nrow(pred_dist_tran)) { pred_dist_tran[i,] &lt;-  pred_dist_lin[i,] / rowSums(pred_dist_lin)[i] }\n# pred_lower &lt;- apply(pred_dist_tran, MARGIN = 2, quantile, prob = 0.025)\n# pred_upper &lt;- apply(pred_dist_tran, MARGIN = 2, quantile, prob = 0.975)\n# pred_median &lt;- apply(pred_dist_tran, MARGIN = 2, quantile, prob = 0.5)\n\n\n\n\nCode\npar(mar = c(5,5,2,12))\nmycols &lt;- brewer.pal(9, \"Set1\")\nplot(seq(from = range(pred_arr)[1], to = range(pred_arr)[2], length.out = nvals) ~ x_seq, type = \"n\", xlab = \"(log) Monthly total yield at Big G (z-score)\", ylab = \"Little g deviation from Big G\")\nfor (k in 1:nsites) {\n  for (j in 1:nsim) {\n    lines(pred_arr[j,,k] ~ x_seq, col = alpha(mycols[k], 0.3))\n  }\n}\nabline(h = 0, lty = 2)\npar(xpd = TRUE)\nlegend(\"right\", inset = c(-0.4,0), legend = unlist(dat_Gg3 %&gt;% group_by(site_name) %&gt;% summarise(stcd = unique(site_name_cd)) %&gt;% select(site_name)), fill = mycols, bty = \"n\")\n\n\n\n\n\nG-g mean difference in (log) yield as a function of (log) total monthly yield at G",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>G-g Difference (JAGS)</span>"
    ]
  },
  {
    "objectID": "Explore Data/TemporalResolution.html#hourly-data",
    "href": "Explore Data/TemporalResolution.html#hourly-data",
    "title": "4  Explore Sub-Daily Data",
    "section": "4.2 Hourly data",
    "text": "4.2 Hourly data\nset baseflow separation (for the Lyne-Hollick one-parameter digital recursive filter) and event delineation paramters (as in Wasko and Guo, 2022)\n\nalp: alpha filter parameter, higher values “lower” the estimated baseflow (thus making it difficult to delineate events)\nnumpass: number of passes. Ladson et al. (2013) recommend 3 passes for daily data (default in baseflowB() function) and 9 passes for hourly data\nthresh: baseflow index threshold for event delineation, higher threshold values make it “easier” to delineate events\n\n\n4.2.1 Event pairing\nConduct event pairing using hydroEvents package to understand lag time between peak flows at big and little g’s\n\n4.2.1.1 Conduct event pairing\n\n\nCode\n# baseflow separation and event delineation parameters\nalp &lt;- 0.925\nnumpass &lt;- 9\nthresh &lt;- 0.5\n\n# sites\nsites &lt;- unique(dat_1hr$site_name)[1:9]\n\n# empty list to store output\noutlist &lt;- list()\n\nfor (j in 1:length(sites)) {\n  # grab big and little g data and combine into a single tibble\n  littleg &lt;- dat_1hr %&gt;% filter(site_name == sites[j])\n  bigg &lt;- dat_1hr %&gt;% filter(site_name == \"West Brook NWIS\")\n  mytib &lt;- bigg %&gt;% select(datetime, yield) %&gt;% rename(yield_big = yield) %&gt;% left_join(littleg %&gt;% select(datetime, yield) %&gt;% rename(yield_little = yield))\n  \n  # baseflow separation\n  mytib_bf &lt;- mytib %&gt;% \n  filter(!is.na(yield_big), !is.na(yield_little)) %&gt;% \n  mutate(bf_big = baseflowB(yield_big, alpha = alp, passes = numpass)$bf, \n         bfi_big = baseflowB(yield_big, alpha = alp, passes = numpass)$bfi,\n         bf_little = baseflowB(yield_little, alpha = alp, passes = numpass)$bf, \n         bfi_little = baseflowB(yield_little, alpha = alp, passes = numpass)$bfi)\n  \n  # delineate events\n  events_little &lt;- eventBaseflow(mytib_bf$yield_little, BFI_Th = thresh, bfi = mytib_bf$bfi_little)\n  events_big &lt;- eventBaseflow(mytib_bf$yield_big, BFI_Th = thresh, bfi = mytib_bf$bfi_big)\n  \n  # event matching\n  mypairs &lt;- pairEvents(events_little, events_big, lag = 5, type = 1)\n  mypairs_com &lt;- mypairs[complete.cases(mypairs),]\n  \n  # get matched event info\n  matchpeaktib &lt;- tibble(datetime_little = rep(NA, times = dim(mypairs_com)[1]), datetime_big = rep(NA, times = dim(mypairs_com)[1]),\n                         yield_little = rep(NA, times = dim(mypairs_com)[1]), yield_big = rep(NA, times = dim(mypairs_com)[1]))\n  for (i in 1:dim(mypairs_com)[1]) {\n    matchpeaktib$datetime_little[i] &lt;- mytib_bf$datetime[events_little$which.max[events_little$srt == mypairs_com$srt[i]]]\n    matchpeaktib$datetime_big[i] &lt;- mytib_bf$datetime[events_big$which.max[events_big$srt == mypairs_com$matched.srt[i]]]\n    matchpeaktib$yield_little[i] &lt;- events_little$max[events_little$srt == mypairs_com$srt[i]]\n    matchpeaktib$yield_big[i] &lt;- events_big$max[events_big$srt == mypairs_com$matched.srt[i]]\n    }\n  matchpeaktib &lt;- matchpeaktib %&gt;% mutate(datetime_little = as_datetime(datetime_little),\n                                          datetime_big = as_datetime(datetime_big),\n                                          timediff_hrs = as.numeric(difftime(datetime_big, datetime_little), units = \"hours\"),\n                                          site_name = sites[j])\n  \n  # store output in list\n  outlist[[j]] &lt;- matchpeaktib\n}\nmatchpeaktib &lt;- do.call(rbind, outlist)\n(matchpeaktib)\n\n\n# A tibble: 515 × 6\n   datetime_little     datetime_big        yield_little yield_big timediff_hrs\n   &lt;dttm&gt;              &lt;dttm&gt;                     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n 1 2020-02-07 17:00:00 2020-02-07 23:00:00        0.150    0.155             6\n 2 2020-02-21 10:00:00 2020-02-21 18:00:00        0.111    0.0893            8\n 3 2020-02-27 09:00:00 2020-02-27 16:00:00        0.432    0.477             7\n 4 2020-03-13 13:00:00 2020-03-13 19:00:00        0.190    0.180             6\n 5 2020-03-19 10:00:00 2020-03-19 16:00:00        0.191    0.181             6\n 6 2020-03-29 23:00:00 2020-03-30 05:00:00        0.327    0.332             6\n 7 2020-04-09 17:00:00 2020-04-09 23:00:00        0.204    0.197             6\n 8 2020-04-13 19:00:00 2020-04-14 02:00:00        0.419    0.506             7\n 9 2020-04-30 15:00:00 2020-04-30 22:00:00        0.214    0.218             7\n10 2020-05-01 19:00:00 2020-05-02 00:00:00        0.811    1.28              5\n# ℹ 505 more rows\n# ℹ 1 more variable: site_name &lt;fct&gt;\n\n\n\n\n4.2.1.2 Plot output\n\nDistribution of lags\nConstrain lag times to realistic values (&gt;=0 and &lt;= 24) as event pairing is not perfect, and view histograms by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= 0 & timediff_hrs &lt;= 24) %&gt;% ggplot() + geom_histogram(aes(x = timediff_hrs)) + facet_wrap(~site_name)\n\n\n\n\n\n\n\n\n\nView distributions summarized as boxplots. Sites are ordered from closest to Big G (bottom) to furthest (top). Interestingly, there is not a strong pattern of longer lag times for further sites.\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= 0 & timediff_hrs &lt;= 24) %&gt;% ggplot() + geom_boxplot(aes(x = site_name, y = timediff_hrs)) + coord_flip()\n\n\n\n\n\n\n\n\n\n\n\nLag by yield\nDoes lag time depend on the magnitude of yield at big G? Under high flows when water is moving more quickly, we might expect the lag to be shorter (negative relationship).\nView global relationship\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= 0 & timediff_hrs &lt;= 24) %&gt;% ggplot(aes(x = yield_big, y = jitter(timediff_hrs))) + geom_point() + geom_smooth()\n\n\n\n\n\n\n\n\n\nView by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= 0 & timediff_hrs &lt;= 24) %&gt;% ggplot(aes(x = yield_big, y = jitter(timediff_hrs))) + geom_point() + geom_smooth() + facet_wrap(~ site_name)\n\n\n\n\n\n\n\n\n\nThere appears to be some evidence for shorter lag times with increasing flow, but this relationship is only evident for very low flows. What is more apparent is the overall attenuation in variability in lag time as flows increase: at very low flows, lags are highly variable, but less variable (and intermediate in magnitude) under high flows.\n\n\nLag by time\nDoes lag time change over time? Perhaps lag time is seasonal and changes with antecedant conditions. Note that this is not the best way to get at the question of importance of antecedant conditions.\nView global relationship\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= 0 & timediff_hrs &lt;= 24) %&gt;% mutate(doy = yday(datetime_little)) %&gt;% ggplot(aes(x = doy, y = jitter(timediff_hrs))) + geom_point() + geom_smooth()\n\n\n\n\n\n\n\n\n\nView by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= 0 & timediff_hrs &lt;= 24) %&gt;% mutate(doy = yday(datetime_little)) %&gt;% ggplot(aes(x = doy, y = jitter(timediff_hrs))) + geom_point() + geom_smooth() + facet_wrap(~ site_name)\n\n\n\n\n\n\n\n\n\nThere does not appear to be any consistent pattern (within or among sites) in how lag times change with time of year\n\n\n\n\n4.2.2 Gg pseudo-analysis\n\n4.2.2.1 Prepare data\nSpecify big and little g data\n\n\nCode\ndat_big &lt;- dat_1hr %&gt;% filter(site_name %in% c(\"West Brook NWIS\"))\ndat_little &lt;- dat_1hr %&gt;% filter(site_name %in% c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\"))\n\n\nConduct baseflow separation and event delineation on big g data\n\n\nCode\n# baseflow separation\ndat_big &lt;- dat_big %&gt;% \n  filter(!is.na(yield)) %&gt;% \n  mutate(bf = baseflowB(yield, alpha = 0.925, passes = 9)$bf, \n         bfi = baseflowB(yield, alpha = 0.925, passes = 9)$bfi)\n\n# event delineation\nevents &lt;- eventBaseflow(dat_big$yield, BFI_Th = 0.75, bfi = dat_big$bfi)\nevents &lt;- events %&gt;% mutate(len = end - srt + 1)\n\n# define positions of non-events\nsrt &lt;- c(1)\nend &lt;- c(events$srt[1]-1)\nfor (i in 2:(dim(events)[1])) {\n  srt[i] &lt;- events$end[i-1]+1\n  end[i] &lt;- events$srt[i]-1\n}\nnonevents &lt;- data.frame(tibble(srt, end) %&gt;% mutate(len = end - srt) %&gt;% filter(len &gt;= 0) %&gt;% select(-len) %&gt;% add_row(srt = events$end[dim(events)[1]]+1, end = dim(dat_big)[1]))\n\n# create vectors of binary event/non-event and event IDs\nisevent_vec &lt;- rep(2, times = dim(dat_big)[1])\neventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(events)[1]) { \n  isevent_vec[c(events[i,1]:events[i,2])] &lt;- 1 \n  eventid_vec[c(events[i,1]:events[i,2])] &lt;- i\n}\n\n# create vector of non-event IDs\nnoneventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n\n# create vector of \"agnostic events\": combined hydro events and non-events\nagnevents &lt;- rbind(events %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\nagneventid_vec &lt;- c()\nfor (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n# add event/non-event vectors to Big G data\ndat_big &lt;- dat_big %&gt;% \n  mutate(isevent = isevent_vec, \n         eventid = eventid_vec,\n         noneventid = noneventid_vec,\n         agneventid = agneventid_vec,\n         big_event_yield = ifelse(isevent_vec == 1, yield, NA),\n         big_nonevent_yield = ifelse(isevent_vec == 2, yield, NA),\n         big_event_quick = big_event_yield - bf) %&gt;%\n  rename(big_yield = yield, big_bf = bf, big_bfi = bfi)\ndat_big\n\n\n# A tibble: 42,233 × 16\n   site_name    datetime             flow area_sqmi flow_cms area_sqkm big_yield\n   &lt;fct&gt;        &lt;dttm&gt;              &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 West Brook … 2020-01-31 15:00:00  23.2      11.4    0.657      29.5    0.0801\n 2 West Brook … 2020-01-31 16:00:00  26.8      11.4    0.759      29.5    0.0926\n 3 West Brook … 2020-01-31 17:00:00  23.3      11.4    0.660      29.5    0.0805\n 4 West Brook … 2020-01-31 18:00:00  18.9      11.4    0.534      29.5    0.0652\n 5 West Brook … 2020-01-31 19:00:00  18.7      11.4    0.530      29.5    0.0647\n 6 West Brook … 2020-01-31 20:00:00  19.0      11.4    0.539      29.5    0.0658\n 7 West Brook … 2020-01-31 21:00:00  18.9      11.4    0.534      29.5    0.0652\n 8 West Brook … 2020-01-31 22:00:00  19.0      11.4    0.539      29.5    0.0658\n 9 West Brook … 2020-01-31 23:00:00  19.4      11.4    0.549      29.5    0.0669\n10 West Brook … 2020-02-01 00:00:00  19.0      11.4    0.539      29.5    0.0658\n# ℹ 42,223 more rows\n# ℹ 9 more variables: big_bf &lt;dbl&gt;, big_bfi &lt;dbl&gt;, isevent &lt;dbl&gt;,\n#   eventid &lt;int&gt;, noneventid &lt;int&gt;, agneventid &lt;int&gt;, big_event_yield &lt;dbl&gt;,\n#   big_nonevent_yield &lt;dbl&gt;, big_event_quick &lt;dbl&gt;\n\n\nCode\n# plot\ndat_big %&gt;% select(datetime, big_yield, big_bf, big_event_yield, big_nonevent_yield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Hourly yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\n\n\nA few things to note:\n\nMany delineated events are &lt;24 hours in length\nMuch of the natural diel variation in streamflow (“stream breathing” due to diel cycle of ET) ends up being delineated as individual events\n\nWhen viewed at this time-scale, there also seems to be variation in terms of whether or not the “stream breathing” exists, which could be due to changes in how the data were processed and subsequently smoothed (or not)\n\nWMA interpolataion becomes an issue at the sub-daily time scale. I.e., the time scale of the data changes during observed (15-min) and interpolated (4-hour) periods\n\nCombine big and little g data\n\n\nCode\ndat_wb2 &lt;- dat_little %&gt;% \n  filter(datetime &gt;= min(dat_big$datetime) & datetime &lt;= max(dat_big$datetime)) %&gt;%\n  left_join(dat_big %&gt;% select(datetime, big_yield, big_bf, big_bfi, agneventid, isevent)) %&gt;%\n  group_by(site_name, agneventid) %&gt;% \n  summarise(eventlen = n(),\n            mindate = min(datetime),\n            isevent = unique(isevent), \n            yield_little_cumul = sum(yield+0.01),\n            yield_big_cumul = sum(big_yield+0.01),\n            yield_little_cumul_log = log(yield_little_cumul),\n            yield_big_cumul_log = log(yield_big_cumul),\n            yield_little_mean_log = mean(log(yield+0.01)),\n            yield_big_mean_log = mean(log(big_yield+0.01))) %&gt;%\n  ungroup() %&gt;%\n  filter(!is.na(isevent)) %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")),\n         site_name_cd = as.numeric(site_name))\ndat_wb2\n\n\n# A tibble: 3,242 × 12\n   site_name  agneventid eventlen mindate             isevent yield_little_cumul\n   &lt;fct&gt;           &lt;int&gt;    &lt;int&gt; &lt;dttm&gt;                &lt;dbl&gt;              &lt;dbl&gt;\n 1 West Broo…          1      168 2020-01-31 15:00:00       2            12.6   \n 2 West Broo…          2       29 2020-02-07 15:00:00       1             3.18  \n 3 West Broo…          3       19 2020-02-08 20:00:00       2             1.42  \n 4 West Broo…          4        6 2020-02-09 15:00:00       1             0.402 \n 5 West Broo…          5       90 2020-02-09 21:00:00       2             7.12  \n 6 West Broo…          6       25 2020-02-13 15:00:00       1             2.68  \n 7 West Broo…          7      104 2020-02-14 16:00:00       2             9.14  \n 8 West Broo…          8       36 2020-02-19 00:00:00       1             3.01  \n 9 West Broo…          9        1 2020-02-20 12:00:00       2             0.0624\n10 West Broo…         10        5 2020-02-20 13:00:00       1             0.312 \n# ℹ 3,232 more rows\n# ℹ 6 more variables: yield_big_cumul &lt;dbl&gt;, yield_little_cumul_log &lt;dbl&gt;,\n#   yield_big_cumul_log &lt;dbl&gt;, yield_little_mean_log &lt;dbl&gt;,\n#   yield_big_mean_log &lt;dbl&gt;, site_name_cd &lt;dbl&gt;\n\n\n\n\n4.2.2.2 Plot output\ngG relationship with data summarized as cumulative yield per event/non-event:\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~isevent)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods.\n\n\n\n\nFacet by site\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~site_name) +\n  theme(legend.position = \"none\")\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods, faceted by site.\n\n\n\n\nGg relationship with data summarized as mean yield per event/non-event\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~isevent)\n\n\n\n\n\nEffect of (log) mean yield at Big G on (log) mean yield at little g during baseflow and event periods.\n\n\n\n\nFacet by site\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~site_name) +\n  theme(legend.position = \"none\")\n\n\n\n\n\nEffect of (log) mean yield at Big G on (log) mean yield at little g during baseflow and event periods, faceted by site.",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Explore Sub-Daily Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/TemporalResolution.html#daily-data",
    "href": "Explore Data/TemporalResolution.html#daily-data",
    "title": "4  Explore Sub-Daily Data",
    "section": "4.3 Daily data",
    "text": "4.3 Daily data\n\n4.3.1 Event pairing\n\n4.3.1.1 Conduct event pairing\n\n\nCode\n# baseflow separation and event delineation parameters\nalp &lt;- 0.925\nnumpass &lt;- 3\nthresh &lt;- 0.5\n\n# sites\nsites &lt;- unique(dat_1day$site_name)[1:9]\n\n# empty list to store output\noutlist &lt;- list()\n\nfor (j in 1:length(sites)) {\n  # grab big and little g data and combine into a single tibble\n  littleg &lt;- dat_1day %&gt;% filter(site_name == sites[j])\n  bigg &lt;- dat_1day %&gt;% filter(site_name == \"West Brook NWIS\")\n  mytib &lt;- bigg %&gt;% select(date, Yield_filled_mm) %&gt;% rename(yield_big = Yield_filled_mm) %&gt;% left_join(littleg %&gt;% select(date, Yield_filled_mm) %&gt;% rename(yield_little = Yield_filled_mm))\n  \n  # baseflow separation\n  mytib_bf &lt;- mytib %&gt;% \n  filter(!is.na(yield_big), !is.na(yield_little)) %&gt;% \n  mutate(bf_big = baseflowB(yield_big, alpha = alp, passes = numpass)$bf, \n         bfi_big = baseflowB(yield_big, alpha = alp, passes = numpass)$bfi,\n         bf_little = baseflowB(yield_little, alpha = alp, passes = numpass)$bf, \n         bfi_little = baseflowB(yield_little, alpha = alp, passes = numpass)$bfi)\n  \n  # delineate events\n  events_little &lt;- eventBaseflow(mytib_bf$yield_little, BFI_Th = thresh, bfi = mytib_bf$bfi_little)\n  events_big &lt;- eventBaseflow(mytib_bf$yield_big, BFI_Th = thresh, bfi = mytib_bf$bfi_big)\n  \n  # event matching\n  mypairs &lt;- pairEvents(events_little, events_big, lag = 5, type = 1)\n  mypairs_com &lt;- mypairs[complete.cases(mypairs),]\n  \n  # get matched event info\n  matchpeaktib &lt;- tibble(datetime_little = rep(NA, times = dim(mypairs_com)[1]), datetime_big = rep(NA, times = dim(mypairs_com)[1]),\n                         yield_little = rep(NA, times = dim(mypairs_com)[1]), yield_big = rep(NA, times = dim(mypairs_com)[1]))\n  for (i in 1:dim(mypairs_com)[1]) {\n    matchpeaktib$datetime_little[i] &lt;- mytib_bf$date[events_little$which.max[events_little$srt == mypairs_com$srt[i]]]\n    matchpeaktib$datetime_big[i] &lt;- mytib_bf$date[events_big$which.max[events_big$srt == mypairs_com$matched.srt[i]]]\n    matchpeaktib$yield_little[i] &lt;- events_little$max[events_little$srt == mypairs_com$srt[i]]\n    matchpeaktib$yield_big[i] &lt;- events_big$max[events_big$srt == mypairs_com$matched.srt[i]]\n    }\n  matchpeaktib &lt;- matchpeaktib %&gt;% mutate(datetime_little = as_date(datetime_little),\n                                          datetime_big = as_date(datetime_big),\n                                          timediff_dys = as.numeric(difftime(datetime_big, datetime_little), units = \"days\"),\n                                          site_name = sites[j])\n  \n  # store output in list\n  outlist[[j]] &lt;- matchpeaktib\n}\nmatchpeaktib &lt;- do.call(rbind, outlist)\n(matchpeaktib)\n\n\n# A tibble: 337 × 6\n   datetime_little datetime_big yield_little yield_big timediff_dys site_name  \n   &lt;date&gt;          &lt;date&gt;              &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt; &lt;fct&gt;      \n 1 2020-02-27      2020-02-27         10.5       6.35             0 Avery Brook\n 2 2020-03-29      2020-03-29          9.56      6.19             0 Avery Brook\n 3 2020-04-13      2020-04-13          8.76      6.24             0 Avery Brook\n 4 2020-05-01      2020-05-01         20.1      14.8              0 Avery Brook\n 5 2020-05-16      2020-05-16          2.68      1.93             0 Avery Brook\n 6 2020-07-03      2020-07-04          1.17      0.447            1 Avery Brook\n 7 2020-07-09      2020-07-10          3.05      0.763            1 Avery Brook\n 8 2020-07-17      2020-07-17          0.684     0.364            0 Avery Brook\n 9 2020-07-23      2020-07-23          0.630     0.904            0 Avery Brook\n10 2020-08-04      2020-08-05          0.615     0.229            1 Avery Brook\n# ℹ 327 more rows\n\n\n\n\n4.3.1.2 Plot output\n\nDistribution of lags\nConstrain lag times to realistic values (&gt;=0 and &lt;= 24) as event pairing is not perfect, and view histograms by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1) %&gt;% ggplot() + geom_histogram(aes(x = timediff_dys)) + facet_wrap(~site_name)\n\n\n\n\n\n\n\n\n\nView distributions summarized as means. Sites are ordered from closest to Big G (bottom) to furthest (top). There is general pattern of longer lag times for further sites.\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1) %&gt;% group_by(site_name) %&gt;% summarize(diffmean = mean(timediff_dys), diffsd = sd(timediff_dys)) %&gt;% ggplot() + \n  geom_point(aes(x = site_name, y = diffmean)) + \n  #geom_errorbar(aes(x = site_name, ymin = diffmean - diffsd, ymax = diffmean + diffsd)) + \n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\nLag by yield\nDoes lag time depend on the magnitude of yield at big G? Under high flows when water is moving more quickly, we might expect the lag to be shorter (negative relationship).\nView global relationship\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1) %&gt;% ggplot(aes(x = yield_big, y = jitter(timediff_dys))) + geom_point() + geom_smooth()\n\n\n\n\n\n\n\n\n\nView by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1)  %&gt;% ggplot(aes(x = yield_big, y = jitter(timediff_dys))) + geom_point() + geom_smooth() + facet_wrap(~ site_name)\n\n\n\n\n\n\n\n\n\nAs with the hourly data, there appears to be some evidence for shorter lag times with increasing flow, but this relationship is only evident for very low flows. Although we note that 1-day lags are very rare (16% of all observations)\n\n\nLag by time\nDoes lag time change over time? Perhaps lag time is seasonal and changes with antecedant conditions. Note that this is not the best way to get at the question of importance of antecedant conditions.\nView global relationship\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1) %&gt;% mutate(doy = yday(datetime_little)) %&gt;% ggplot(aes(x = doy, y = jitter(timediff_dys))) + geom_point() + geom_smooth()\n\n\n\n\n\n\n\n\n\nView by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1) %&gt;% mutate(doy = yday(datetime_little)) %&gt;% ggplot(aes(x = doy, y = (timediff_dys))) + geom_point() + geom_smooth() + facet_wrap(~ site_name)\n\n\n\n\n\n\n\n\n\nThe prevalence of 1-day lags in peak flow generally peaks in mid summer (July) when flows are low\n\n\n\n\n4.3.2 Gg pseudo-analysis\n\n4.3.2.1 Prepare data\nSpecify big and little g data\n\n\nCode\ndat_big &lt;- dat_1day %&gt;% filter(site_name %in% c(\"West Brook NWIS\")) %&gt;% rename(yield = Yield_filled_mm)\ndat_little &lt;- dat_1day %&gt;% filter(site_name %in% c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")) %&gt;% rename(yield = Yield_filled_mm)\n\n\nConduct baseflow separation and event delineation on big g data\n\n\nCode\n# baseflow separation\ndat_big &lt;- dat_big %&gt;% \n  filter(!is.na(yield)) %&gt;% \n  mutate(bf = baseflowB(yield, alpha = 0.925, passes = 3)$bf, \n         bfi = baseflowB(yield, alpha = 0.925, passes = 3)$bfi)\n\n# event delineation\nevents &lt;- eventBaseflow(dat_big$yield, BFI_Th = 0.75, bfi = dat_big$bfi)\nevents &lt;- events %&gt;% mutate(len = end - srt + 1)\n\n# define positions of non-events\nsrt &lt;- c(1)\nend &lt;- c(events$srt[1]-1)\nfor (i in 2:(dim(events)[1])) {\n  srt[i] &lt;- events$end[i-1]+1\n  end[i] &lt;- events$srt[i]-1\n}\nnonevents &lt;- data.frame(tibble(srt, end) %&gt;% mutate(len = end - srt) %&gt;% filter(len &gt;= 0) %&gt;% select(-len) %&gt;% add_row(srt = events$end[dim(events)[1]]+1, end = dim(dat_big)[1]))\n\n# create vectors of binary event/non-event and event IDs\nisevent_vec &lt;- rep(2, times = dim(dat_big)[1])\neventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(events)[1]) { \n  isevent_vec[c(events[i,1]:events[i,2])] &lt;- 1 \n  eventid_vec[c(events[i,1]:events[i,2])] &lt;- i\n}\n\n# create vector of non-event IDs\nnoneventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n\n# create vector of \"agnostic events\": combined hydro events and non-events\nagnevents &lt;- rbind(events %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\nagneventid_vec &lt;- c()\nfor (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n# add event/non-event vectors to Big G data\ndat_big &lt;- dat_big %&gt;% \n  mutate(isevent = isevent_vec, \n         eventid = eventid_vec,\n         noneventid = noneventid_vec,\n         agneventid = agneventid_vec,\n         big_event_yield = ifelse(isevent_vec == 1, yield, NA),\n         big_nonevent_yield = ifelse(isevent_vec == 2, yield, NA),\n         big_event_quick = big_event_yield - bf) %&gt;%\n  rename(big_yield = yield, big_bf = bf, big_bfi = bfi)\ndat_big\n\n\n# A tibble: 1,780 × 36\n   station_no site_name       site_id basin  subbasin region   lat  long elev_ft\n   &lt;chr&gt;      &lt;fct&gt;           &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 2 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 3 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 4 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 5 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 6 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 7 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 8 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 9 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n10 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n# ℹ 1,770 more rows\n# ℹ 27 more variables: area_sqmi &lt;dbl&gt;, designation &lt;chr&gt;, date &lt;date&gt;,\n#   disch_reli &lt;dbl&gt;, temp_reli &lt;dbl&gt;, flow_mean &lt;dbl&gt;, tempc_mean &lt;dbl&gt;,\n#   flow_mean_filled &lt;dbl&gt;, flow_mean_cms &lt;dbl&gt;, flow_mean_filled_cms &lt;dbl&gt;,\n#   area_sqkm &lt;dbl&gt;, Yield_mm &lt;dbl&gt;, big_yield &lt;dbl&gt;, flow_mean_7 &lt;dbl&gt;,\n#   flow_mean_filled_7 &lt;dbl&gt;, tempc_mean_7 &lt;dbl&gt;, Yield_mm_7 &lt;dbl&gt;,\n#   Yield_filled_mm_7 &lt;dbl&gt;, big_bf &lt;dbl&gt;, big_bfi &lt;dbl&gt;, isevent &lt;dbl&gt;, …\n\n\nCode\n# plot\ndat_big %&gt;% select(date, big_yield, big_bf, big_event_yield, big_nonevent_yield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Hourly yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\n\n\nCombine big and little g data\n\n\nCode\ndat_wb2 &lt;- dat_little %&gt;% \n  filter(date &gt;= min(dat_big$date) & date &lt;= max(dat_big$date)) %&gt;%\n  left_join(dat_big %&gt;% select(date, big_yield, big_bf, big_bfi, agneventid, isevent)) %&gt;%\n  group_by(site_name, agneventid) %&gt;% \n  summarise(eventlen = n(),\n            mindate = min(date),\n            isevent = unique(isevent), \n            yield_little_cumul = sum(yield+0.01),\n            yield_big_cumul = sum(big_yield+0.01),\n            yield_little_cumul_log = log(yield_little_cumul),\n            yield_big_cumul_log = log(yield_big_cumul),\n            yield_little_mean_log = mean(log(yield+0.01)),\n            yield_big_mean_log = mean(log(big_yield+0.01))) %&gt;%\n  ungroup() %&gt;%\n  filter(!is.na(isevent)) %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")),\n         site_name_cd = as.numeric(site_name))\ndat_wb2\n\n\n# A tibble: 695 × 12\n   site_name        agneventid eventlen mindate    isevent yield_little_cumul\n   &lt;fct&gt;                 &lt;int&gt;    &lt;int&gt; &lt;date&gt;       &lt;dbl&gt;              &lt;dbl&gt;\n 1 West Brook Lower          1        5 2020-02-01       2               7.57\n 2 West Brook Lower          2        4 2020-02-06       1               7.49\n 3 West Brook Lower          3        2 2020-02-10       2               3.17\n 4 West Brook Lower          4        4 2020-02-12       1               8.61\n 5 West Brook Lower          5       10 2020-02-16       2              15.3 \n 6 West Brook Lower          6        5 2020-02-26       1              16.7 \n 7 West Brook Lower          7        5 2020-03-02       1              12.6 \n 8 West Brook Lower          8        5 2020-03-07       2              10.4 \n 9 West Brook Lower          9        4 2020-03-12       1              11.4 \n10 West Brook Lower         10        2 2020-03-16       2               4.62\n# ℹ 685 more rows\n# ℹ 6 more variables: yield_big_cumul &lt;dbl&gt;, yield_little_cumul_log &lt;dbl&gt;,\n#   yield_big_cumul_log &lt;dbl&gt;, yield_little_mean_log &lt;dbl&gt;,\n#   yield_big_mean_log &lt;dbl&gt;, site_name_cd &lt;dbl&gt;\n\n\n\n\n4.3.2.2 Plot output\ngG relationship with data summarized as cumulative yield per event/non-event:\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~isevent)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods.\n\n\n\n\nFacet by site\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~site_name) +\n  theme(legend.position = \"none\")\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods, faceted by site.\n\n\n\n\nGg relationship with data summarized as mean yield per event/non-event\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~isevent)\n\n\n\n\n\nEffect of (log) mean yield at Big G on (log) mean yield at little g during baseflow and event periods.\n\n\n\n\nFacet by site\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~site_name) +\n  theme(legend.position = \"none\")\n\n\n\n\n\nEffect of (log) mean yield at Big G on (log) mean yield at little g during baseflow and event periods, faceted by site.",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Explore Sub-Daily Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/TemporalResolution.html#summary",
    "href": "Explore Data/TemporalResolution.html#summary",
    "title": "4  Explore Sub-Daily Data",
    "section": "4.4 Summary",
    "text": "4.4 Summary\n\nEvent delineation at sub-daily (i.e., hourly) time scale is strongly affected by data processing steps (e.g., smoothing and interpolation by WMA) and landscape processes that are not the focus of this study (i.e., diel fluctuations in flow due to ET)\n\nIn some cases, changes in how WMA treats diel fluctuations may introduce further inconsistencies into downstream analyses\n\nAt the hourly timescale, temporal mismatches between big and little g time series data due to routing time are evident, typically in the 4-8 hour range for the West Brook.\n\nThere does not appear to be any predictable relationship between lag time and flow magnitude or time of year.\nBecause many of the event/non-event periods are very short, these mismatches may have a large effect on how reasonable it is to apply Big G events to little g data, and whether Big G events/non-events adequately encompass similar flow conditions at little g sites.\nTemporal mismatches are less prevalent and more predictable for the daily data.\n\nInferences regarding the g~G relationship derived from hourly data generally do not match those derived from daily data.\n\nthe g~G relationship is more strongly affected by assumptions of temporal alignment for hourly data relative to daily data.",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Explore Sub-Daily Data</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#west-brook",
    "href": "Event Delineation/HydroEvents.html#west-brook",
    "title": "6  Hydro Event Delineation",
    "section": "6.2 West Brook",
    "text": "6.2 West Brook\n\n6.2.1 Trim to focal sites\n\n\nCode\ndat_wb &lt;- dat %&gt;% filter(site_name %in% c(\"West Brook NWIS\", \"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\"))\n\n\nView daily yield at Big G\n\n\nCode\ndat_wb %&gt;% filter(site_name == \"West Brook NWIS\") %&gt;% select(date, Yield_filled_mm) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTotal daily streamflow in yield (mm), over the period of record\n\n\nView daily yield at all sites\n\n\nCode\ndat_wb %&gt;% filter(site_name != \"West Brook NWIS\") %&gt;% select(date, site_name, Yield_filled_mm) %&gt;% spread(key = site_name, value = Yield_filled_mm) %&gt;% left_join(dat_wb %&gt;% filter(site_name == \"West Brook NWIS\") %&gt;% select(date, Yield_filled_mm) %&gt;% rename(West_Brook_NWIS = Yield_filled_mm)) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(colors = c(hcl.colors(9, \"Zissou 1\"), \"black\")) \n\n\n\n\n\n\n\n\n6.2.2 Set parameters\nSet baseflow separation (for the Lyne-Hollick one-parameter digital recursive filter) and event delineation paramters (as in Wasko and Guo, 2022)\n\nalp: alpha filter parameter, higher values “lower” the estimated baseflow (thus making it difficult to delineate events)\nnumpass: number of passes. Ladson et al. (2013) recommend 3 passes for daily data (default in baseflowB() function)\nthresh: baseflow index threshold for event delineation, higher threshold values make it “easier” to delineate events\n\n\n\nCode\nalp &lt;- 0.925\nnumpass &lt;- 3\nthresh &lt;- 0.75\n\n\n\n\n6.2.3 Baseflow separation\nPerform baseflow separation. See Wasko and Guo (2022, Hydrological Processes) for recommendations on parameterization, as different algorithms and alpha values can produce different results. Section 4.1: “…users should not simply use recommended filter parameter values from literature in combination with any baseflow filter code without verification of their choice of filter parameter. As the digital baseflow filter is not tied to any physical realism (Nathan and McMahon, 1990) and a larger fractional baseflow may aid identification of events—even if this is not strictly baseflow as per its definition (Linsley et al., 1958)…”.\nIt is not actually necessary to do this separately, as baseflow separation is conducted in the event delineation function internally. But it is helpful to view the results and explore how different parameterizations yield different baseflow contributions.\n\n\nCode\ndat_wb_bf &lt;- dat_wb %&gt;% \n  filter(!is.na(Yield_filled_mm)) %&gt;% \n  select(site_name, basin, subbasin, WaterYear, date, Yield_filled_mm, flow_mean_filled_cms, area_sqkm) %&gt;%\n  group_by(site_name) %&gt;%\n  mutate(bf = baseflowB(Yield_filled_mm, alpha = alp, passes = numpass)$bf, \n         bfi = baseflowB(Yield_filled_mm, alpha = alp, passes = numpass)$bfi) %&gt;%\n  ungroup()\nhead(dat_wb_bf)\n\n\n# A tibble: 6 × 10\n  site_name   basin      subbasin   WaterYear date       Yield_filled_mm\n  &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;date&gt;               &lt;dbl&gt;\n1 Avery Brook West Brook West Brook      2020 2020-02-20            1.43\n2 Avery Brook West Brook West Brook      2020 2020-02-21            1.42\n3 Avery Brook West Brook West Brook      2020 2020-02-22            1.22\n4 Avery Brook West Brook West Brook      2020 2020-02-23            1.28\n5 Avery Brook West Brook West Brook      2020 2020-02-24            1.40\n6 Avery Brook West Brook West Brook      2020 2020-02-25            1.76\n# ℹ 4 more variables: flow_mean_filled_cms &lt;dbl&gt;, area_sqkm &lt;dbl&gt;, bf &lt;dbl&gt;,\n#   bfi &lt;dbl&gt;\n\n\n\n\nCode\ndat_wb_bf %&gt;% filter(site_name == \"West Brook NWIS\") %&gt;% select(date, Yield_filled_mm, bf, bfi) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTotal daily streamflow in yield (mm), baseflow in yield, and fractional baseflow index over the period of record for site West Brook NWIS\n\n\n\n\n6.2.4 Event identification\nThere are multiple options for methods of event identification. Section 4.2 in Wasko and Guo (2022): It can be generalized that, if the aim of the analysis is to identify independent streamflow maxima then eventMaxima() and eventMinima() work well and indeed have been traditionally employed for this task. If identifying independent small events becomes difficult, or the aim is to identify wet spells, eventBaseflow() may be preferred.” In our case, small events are likely important, so we use eventBaseflow() with a ~large values for BFI_Th to capture those small events.\nThe aim is to understand how water availability affects differences in yield between Big G and Little g during hydrologic events and the intervening periods (non-event baseflow periods). Therefore, we identify events from the Big G data, apply event/non-event time periods to the little g data, then explore G-g deviations during both events and non-events as a function of\n\n6.2.4.1 Identify events\nSeparate Big G and Little G data\n\n\nCode\ndat_big &lt;- dat_wb_bf %&gt;% filter(site_name == \"West Brook NWIS\")\ndat_little &lt;- dat_wb_bf %&gt;% filter(site_name != \"West Brook NWIS\")\n\n\nIdentify events at Big G\n\n\nCode\nevents &lt;- eventBaseflow(dat_big$Yield_filled_mm, BFI_Th = thresh, bfi = dat_big$bfi)\nevents &lt;- events %&gt;% mutate(len = end - srt + 1)\n(events)\n\n\n     srt  end which.max         max          sum len\n1      6    9         7  2.52886521   7.65292654   4\n2     12   15        13  2.00650945   6.88182993   4\n3     26   31        27  6.35118280  19.04525705   6\n4     31   35        33  3.02634690  11.88152083   5\n5     41   44        42  3.12584323  10.11546086   4\n6     47   50        48  3.12584323  10.15691767   4\n7     55   65        58  6.19364694  41.32414502  11\n8     72   76        73  6.23510374  20.86106518   5\n9     77   79        78  3.44091496   9.33607289   3\n10    89  122        91 14.75862322  82.94097510  34\n11   130  134       132  0.40296016   1.59359965   5\n12   149  153       150  0.33248359   1.38216994   5\n13   153  156       155  0.44690438   1.34983363   4\n14   159  164       161  0.76280525   2.38459553   6\n15   167  170       168  0.36399076   1.00740041   4\n16   172  182       174  0.90375839   3.08024075  11\n17   185  192       187  0.22884157   0.87556776   8\n18   208  213       211  0.14509882   0.51821009   6\n19   214  219       216  0.32585050   0.77855883   6\n20   222  226       224  0.21225885   0.57542048   5\n21   241  248       243  0.87888430   1.78595924   8\n22   255  264       260  1.04471153   3.23694748  10\n23   270  280       273  0.83742750   3.99146136  11\n24   289  293       290  0.87888430   2.13668382   5\n25   296  299       297  0.41456807   1.33905486   4\n26   299  314       304  8.62301582  35.03183088  16\n27   328  343       329 30.76095065  86.39349797  16\n28   350  357       351  4.11251523  15.97745334   8\n29   375  377       376  1.25199557   3.16730004   3\n30   381  384       382  1.79093405   4.86205430   4\n31   394  396       395  1.35978326   3.12335582   3\n32   404  410       406  1.94017856  10.05742133   7\n33   411  427       423  4.23688566  34.16870017  17\n34   439  449       441  6.99790899  33.24006769  11\n35   453  475       460 12.02247397  92.49013598  23\n36   483  491       486  3.04292962  13.30017276   9\n37   516  522       519  1.94017856   7.22426315   7\n38   523  542       534 15.91941381  81.91947938  20\n39   542  550       546  3.97156209  20.12313402   9\n40   565  567       566  2.06454898   3.66146518   3\n41   568  575       570 10.94459700  30.87702971   8\n42   578  586       580 14.50988238  30.35467394   9\n43   586  589       587  1.89043039   5.99465426   4\n44   601  603       602  1.84068222   3.54787353   3\n45   611  617       613  6.36776552  19.63643111   7\n46   624  626       625  1.70802044   4.27005110   3\n47   632  637       634  2.97659873  11.69081952   6\n48   637  643       639  4.94994273  16.81488084   7\n49   650  657       651  5.85370112  24.40147648   8\n50   684  686       685  1.65827227   3.93839665   3\n51   687  689       688  2.62836155   5.53862939   3\n52   690  692       691  1.98992673   4.99969090   3\n53   694  697       695  2.31328982   7.29639800   4\n54   700  704       702  1.97334400   8.06749460   5\n55   705  708       706  1.27686965   4.76753278   4\n56   734  740       735 12.85161011  21.43897307   7\n57   742  745       743  1.42611415   4.76753278   4\n58   748  752       749  4.01301890  10.57148573   5\n59   752  759       754  5.42255033  20.48795392   8\n60   765  773       767  3.73111261  22.51933746   9\n61   774  776       775  2.78589742   7.35443753   3\n62   777  781       779  4.06276707  14.35234652   5\n63   782  787       784  4.52708330  19.00380024   6\n64   790  792       791  4.20372021   9.05416661   3\n65   797  803       798  8.70592943  26.75622311   7\n66   808  815       809  6.59992364  23.44796993   8\n67   815  832       817  2.23037621  28.36225981  18\n68   835  844       837  1.06129425   7.09740532  10\n69   847  851       848  0.73378548   2.56700548   5\n70   851  853       852  0.44607524   1.29179410   3\n71   858  866       860  1.23541284   4.23522738   9\n72   867  871       868  0.33911668   1.31003509   5\n73   872  891       874  0.24542430   3.17890795  20\n74   894  908       900  0.16333982   1.12513774  15\n75   909  911       910  0.03316545   0.09037584   3\n76   920  922       921  0.04560249   0.08540102   3\n77   934  937       935  0.03896940   0.11027511   4\n78   947  960       949  0.67242941   1.88545557  14\n79   961  971       965  0.39135226   1.71050785  11\n80   977  981       978  0.36564904   0.89546703   5\n81   986  995       987  1.16908195   3.27260033  10\n82   996 1002       998  0.43115079   2.04962453   7\n83  1014 1025      1016  1.34320054   7.00537121  12\n84  1030 1048      1041  3.34141863  18.64312602  19\n85  1049 1054      1051  2.22208484   8.28887395   6\n86  1056 1063      1057 14.34405515  29.25855597   8\n87  1066 1074      1070  3.07609506  20.51282801   9\n88  1077 1081      1078  4.77582414  14.03727478   5\n89  1084 1087      1085  4.02960162  11.47524412   4\n90  1087 1090      1088  3.63990764  11.39233051   4\n91  1090 1099      1091  9.36923834  36.84680989  10\n92  1134 1163      1152  5.45571578 105.77289688  30\n93  1177 1184      1178 20.39674895  50.19590168   8\n94  1184 1201      1186 10.86168338  65.75878695  18\n95  1204 1211      1206  4.23688566  14.80008003   8\n96  1230 1232      1231  0.92034111   2.16570359   3\n97  1242 1247      1245  1.26857829   5.26086878   6\n98  1247 1278      1256 39.63270730 218.95412513  32\n99  1284 1286      1285  1.55048457   3.85548303   3\n100 1291 1298      1292  3.42433224  13.20482210   8\n101 1301 1304      1302  1.28516101   3.68302272   4\n102 1306 1308      1307  1.10275106   2.45009728   3\n103 1316 1323      1319  1.79093405  10.18013348   8\n104 1326 1328      1327  1.07787698   2.62255760   3\n105 1332 1336      1333  2.13917123   6.19530521   5\n106 1336 1343      1338  4.87532048  17.62743425   8\n107 1344 1349      1346  3.05951234  10.90314019   6\n108 1358 1364      1359  4.83386367  16.13498921   7\n109 1367 1372      1368  3.10096915  13.16668184   6\n110 1390 1394      1391  1.94017856   7.23587106   5\n111 1395 1398      1396  2.93514192   7.39589433   4\n112 1401 1406      1403  2.98489009  11.54157501   6\n113 1408 1415      1410  7.26323255  22.90074008   8\n114 1415 1425      1417 37.55986696  80.31841750  11\n115 1426 1429      1427  3.84719167  12.81015330   4\n116 1439 1447      1440 17.08020440  59.67292771   9\n117 1450 1454      1453  3.86097453  16.13990126   5\n118 1454 1465      1456  7.27152391  42.41031336  12\n119 1488 1491      1490  1.99821809   5.39353057   4\n120 1492 1506      1497 13.51491902  67.35901969  15\n121 1512 1520      1513  9.70089279  42.92437776   9\n122 1523 1530      1525  5.21526630  31.95490668   8\n123 1531 1548      1533 27.94188779  94.65418129  18\n124 1548 1551      1549  2.00650945   7.45393386   4\n125 1551 1553      1552  1.74947725   5.04114771   3\n126 1555 1560      1557  2.15575395   9.57652237   6\n127 1566 1571      1567  1.62510683   7.48709931   6\n128 1577 1586      1581  3.02634690  15.39208323  10\n129 1600 1609      1604  1.60023274   8.64623163  10\n130 1616 1621      1619  0.72632326   2.84227867   6\n131 1628 1632      1630  0.80592032   2.45175555   5\n132 1634 1636      1635  0.37145299   0.81421169   3\n133 1646 1648      1647  0.30097642   0.70974053   3\n134 1649 1658      1653  2.78589742   9.10806045  10\n135 1660 1676      1663  0.97008928   5.26418533  17\n136 1680 1684      1682  0.20396749   0.67077113   5\n137 1699 1703      1701  0.18075168   0.62765605   5\n138 1717 1721      1718  0.28190629   0.74622252   5\n139 1755 1768      1764  0.58371184   3.13579287  14\n140 1768 1770      1769  0.14426969   0.40544757   3\n\n\nPlot Big G events using the default function\n\n\nCode\npar(mar = c(3,3,1,1))\nplotEvents(dat_big$Yield_filled_mm, events = events, main = NA, xlab = \"Time-step\", ylab = \"Yield\")\n\n\n\n\n\nTime series of hydrologic events at Big G, identified using eventBaseflow().\n\n\n\n\n\n\n6.2.4.2 Tidy events\nNow add variables to the Big G time series data specifying events and non-events\n\n\nCode\n# define positions of non-events\nsrt &lt;- c(1)\nend &lt;- c(events$srt[1]-1)\nfor (i in 2:(dim(events)[1])) {\n  srt[i] &lt;- events$end[i-1]+1\n  end[i] &lt;- events$srt[i]-1\n}\nnonevents &lt;- data.frame(tibble(srt, end) %&gt;% mutate(len = end - srt) %&gt;% filter(len &gt;= 0) %&gt;% select(-len) %&gt;% add_row(srt = events$end[dim(events)[1]]+1, end = dim(dat_big)[1]))\n\n# create vectors of binary event/non-event and event IDs\nisevent_vec &lt;- rep(2, times = dim(dat_big)[1])\neventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(events)[1]) { \n  isevent_vec[c(events[i,1]:events[i,2])] &lt;- 1 \n  eventid_vec[c(events[i,1]:events[i,2])] &lt;- i\n}\n\n# create vector of non-event IDs\nnoneventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n\n# create vector of \"agnostic events\": combined hydro events and non-events\nagnevents &lt;- rbind(events %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\nagneventid_vec &lt;- c()\nfor (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n# add event/non-event vectors to Big G data\ndat_big &lt;- dat_big %&gt;% \n  mutate(isevent = isevent_vec, \n         eventid = eventid_vec,\n         noneventid = noneventid_vec,\n         agneventid = agneventid_vec,\n         big_event_yield = ifelse(isevent_vec == 1, Yield_filled_mm, NA),\n         big_nonevent_yield = ifelse(isevent_vec == 2, Yield_filled_mm, NA),\n         big_event_quick = big_event_yield - bf) %&gt;%\n  rename(big_yield = Yield_filled_mm, big_bf = bf, big_bfi = bfi, big_flow = flow_mean_filled_cms, big_area_sqkm = area_sqkm)\n(dat_big)\n\n\n# A tibble: 1,780 × 17\n   site_name       basin      subbasin   WaterYear date       big_yield big_flow\n   &lt;chr&gt;           &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n 1 West Brook NWIS West Brook West Brook      2020 2020-02-01      1.57    0.535\n 2 West Brook NWIS West Brook West Brook      2020 2020-02-02      1.52    0.518\n 3 West Brook NWIS West Brook West Brook      2020 2020-02-03      1.45    0.496\n 4 West Brook NWIS West Brook West Brook      2020 2020-02-04      1.41    0.481\n 5 West Brook NWIS West Brook West Brook      2020 2020-02-05      1.42    0.484\n 6 West Brook NWIS West Brook West Brook      2020 2020-02-06      1.51    0.515\n 7 West Brook NWIS West Brook West Brook      2020 2020-02-07      2.53    0.864\n 8 West Brook NWIS West Brook West Brook      2020 2020-02-08      2.04    0.697\n 9 West Brook NWIS West Brook West Brook      2020 2020-02-09      1.58    0.538\n10 West Brook NWIS West Brook West Brook      2020 2020-02-10      1.47    0.501\n# ℹ 1,770 more rows\n# ℹ 10 more variables: big_area_sqkm &lt;dbl&gt;, big_bf &lt;dbl&gt;, big_bfi &lt;dbl&gt;,\n#   isevent &lt;dbl&gt;, eventid &lt;int&gt;, noneventid &lt;int&gt;, agneventid &lt;int&gt;,\n#   big_event_yield &lt;dbl&gt;, big_nonevent_yield &lt;dbl&gt;, big_event_quick &lt;dbl&gt;\n\n\n\n\nCode\ndat_big %&gt;% select(date, big_yield, big_bf, big_event_yield, big_nonevent_yield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTime series of hydrologic events at Big G, identified using eventBaseflow().\n\n\n\n\n6.2.4.3 Check congruency\nApplying Big G event/non-event periods to little g time series data inherently assumes that event/non-event periods would be similarly delineated for little g. If this assumption does not hold, then non-event little g flow would be included in event periods, and vice-versa. How well does this assumption hold?\n\n\nCode\nsites &lt;- c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")\n\ndat_little2 &lt;- dat_little %&gt;% filter(site_name == \"Jimmy Brook\")\nevents_little &lt;- eventBaseflow(dat_little2$Yield_filled_mm, BFI_Th = 0.75)\n\n# define positions of non-events\nsrt &lt;- c(1)\nend &lt;- c(events_little$srt[1]-1)\nfor (i in 2:(dim(events_little)[1])) {\n  srt[i] &lt;- events_little$end[i-1]+1\n  end[i] &lt;- events_little$srt[i]-1\n}\nnonevents &lt;- data.frame(tibble(srt, end) %&gt;% mutate(len = end - srt) %&gt;% filter(len &gt;= 0) %&gt;% select(-len) %&gt;% add_row(srt = events_little$end[dim(events_little)[1]]+1, end = dim(dat_little2)[1]))\n\n# create vectors of binary event/non-event and event IDs\nisevent_vec &lt;- rep(2, times = dim(dat_little2)[1])\neventid_vec &lt;- rep(NA, times = dim(dat_little2)[1])\nfor (i in 1:dim(events_little)[1]) { \n  isevent_vec[c(events_little[i,1]:events_little[i,2])] &lt;- 1 \n  eventid_vec[c(events_little[i,1]:events_little[i,2])] &lt;- i\n}\n\n# create vector of non-event IDs\nnoneventid_vec &lt;- rep(NA, times = dim(dat_little2)[1])\nfor (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n\n# create vector of \"agnostic events\": combined hydro events and non-events\nagnevents &lt;- rbind(events_little %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\nagneventid_vec &lt;- c()\nfor (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n# add event/non-event vectors to Big G data\ndat_little2 &lt;- dat_little2 %&gt;% \n  mutate(isevent = isevent_vec, \n         eventid = eventid_vec,\n         noneventid = noneventid_vec,\n         agneventid = agneventid_vec,\n         little_event_yield = ifelse(isevent_vec == 1, Yield_filled_mm, NA),\n         little_nonevent_yield = ifelse(isevent_vec == 2, Yield_filled_mm, NA),\n         little_event_quick = little_event_yield - bf) %&gt;%\n  rename(little_yield = Yield_filled_mm, little_bf = bf, little_bfi = bfi)\n\n\ndat_big %&gt;% select(date, big_event_yield) %&gt;% left_join(dat_little2 %&gt;% select(date, little_event_yield)) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTime series of yield for Big G (West Brook NWIS) and one little g site (Jimmy Brook) during hydrologic events as delineated for Big G and little g, respectively.\n\n\nWhether or not events alighn between G and g is highly variable. In some cases, g events begin/end prior to G events, and in other cases g events begin/end later G events. In some cases g events are shorter than G events, and in other cases they are longer. In many cases, events are perfectly matched. Importantly, peaks in yield are almost always synchronous.\nUltimately, does this matter given that we are simply using this as a method to break up our data? Furthermore, the framing of the ~entire project is that Big G is the reference by which to compare all little g’s. In this sense, applying event/non-event periods derived from G to g matches this persepctive.\n\n\n\n6.2.5 Join events to Little g\n\n\nCode\n# fudge factor to deal with 0 flow, when logged\nfudge &lt;- 0.01\n\n# join big g events to little g and summarize by event (cumulative, mean, and quantiles)\ndat_wb2 &lt;- dat_little %&gt;% \n  filter(date &gt;= min(dat_big$date) & date &lt;= max(dat_big$date)) %&gt;%\n  left_join(dat_big %&gt;% select(-site_name)) %&gt;% \n  group_by(site_name, basin, subbasin, agneventid) %&gt;% \n  summarise(eventlen = n(),\n            mindate = min(date),\n            isevent = unique(isevent), \n            # cumulative\n            yield_little_cumul = sum(Yield_filled_mm+fudge),\n            yield_big_cumul = sum(big_yield+fudge),\n            yield_little_cumul_log = log(yield_little_cumul),\n            yield_big_cumul_log = log(yield_big_cumul),\n            # mean\n            yield_little_mean = mean(Yield_filled_mm+fudge),\n            yield_big_mean = mean(big_yield+fudge),\n            yield_little_mean_log = mean(log(Yield_filled_mm+fudge)),\n            yield_big_mean_log = mean(log(big_yield+fudge)),\n            # quantiles\n            yield_little_q10_log = quantile(log(Yield_filled_mm+fudge), probs = 0.10),\n            yield_little_q50_log = quantile(log(Yield_filled_mm+fudge), probs = 0.50),\n            yield_little_q90_log = quantile(log(Yield_filled_mm+fudge), probs = 0.90),\n            yield_big_q10_log = quantile(log(big_yield+fudge), probs = 0.10),\n            yield_big_q50_log = quantile(log(big_yield+fudge), probs = 0.50),\n            yield_big_q90_log = quantile(log(big_yield+fudge), probs = 0.90)) %&gt;%\n  ungroup() %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")),\n         site_name_cd = as.numeric(site_name)\n         # z_yield_big_cumul_log = as.numeric(scale(yield_big_cum_log, center = TRUE, scale = TRUE)),\n         # z_yield_big_mean_log = as.numeric(scale(yield_big_mean_log, center = TRUE, scale = TRUE))\n         )\ndat_wb2\n\n\n# A tibble: 689 × 22\n   site_name   basin      subbasin   agneventid eventlen mindate    isevent\n   &lt;fct&gt;       &lt;chr&gt;      &lt;chr&gt;           &lt;int&gt;    &lt;int&gt; &lt;date&gt;       &lt;dbl&gt;\n 1 Avery Brook West Brook West Brook          5        6 2020-02-20       2\n 2 Avery Brook West Brook West Brook          6        5 2020-02-26       1\n 3 Avery Brook West Brook West Brook          7        5 2020-03-02       1\n 4 Avery Brook West Brook West Brook          8        5 2020-03-07       2\n 5 Avery Brook West Brook West Brook          9        4 2020-03-12       1\n 6 Avery Brook West Brook West Brook         10        2 2020-03-16       2\n 7 Avery Brook West Brook West Brook         11        4 2020-03-18       1\n 8 Avery Brook West Brook West Brook         12        4 2020-03-22       2\n 9 Avery Brook West Brook West Brook         13       11 2020-03-26       1\n10 Avery Brook West Brook West Brook         14        6 2020-04-06       2\n# ℹ 679 more rows\n# ℹ 15 more variables: yield_little_cumul &lt;dbl&gt;, yield_big_cumul &lt;dbl&gt;,\n#   yield_little_cumul_log &lt;dbl&gt;, yield_big_cumul_log &lt;dbl&gt;,\n#   yield_little_mean &lt;dbl&gt;, yield_big_mean &lt;dbl&gt;, yield_little_mean_log &lt;dbl&gt;,\n#   yield_big_mean_log &lt;dbl&gt;, yield_little_q10_log &lt;dbl&gt;,\n#   yield_little_q50_log &lt;dbl&gt;, yield_little_q90_log &lt;dbl&gt;,\n#   yield_big_q10_log &lt;dbl&gt;, yield_big_q50_log &lt;dbl&gt;, …\n\n\nCode\n# write to file\nwrite_csv(dat_wb2, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Event Delineation/Basin files/EcoDrought_Data_EventNonEvent_WestBrookonly.csv\")\n\n\nView pairs plot of summary statistics, for Big G only (limit to one little g site to avoid pseudo replication):\n\n\nCode\nmyplot &lt;- ggpairs(dat_wb2 %&gt;% filter(site_name == \"Avery Brook\") %&gt;% select(mindate, yield_big_cumul_log, yield_big_mean_log, yield_big_q10_log, yield_big_q50_log, yield_big_q90_log))\nrctib &lt;- tibble(r = c(3,4,4,5,5,5,6,6,6,6),\n                c = c(2,2,3,2,3,4,2,3,4,5))\nfor (i in 1:nrow(rctib)) {\n  myplot[rctib$r[i], rctib$c[i]] &lt;- myplot[rctib$r[i], rctib$c[i]] + geom_abline(intercept = 0, slope = 1, color = \"red\")\n}\nmyplot\n\n\n\n\n\n\n\n\n\n\n\n6.2.6 Plot gG relationships\n\n\nCode\np1 &lt;- dat_wb2 %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np2 &lt;- dat_wb2 %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np3 &lt;- dat_wb2 %&gt;% \n  ggplot(aes(x = yield_big_q10_log, y = yield_little_q10_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np4 &lt;- dat_wb2 %&gt;% \n  ggplot(aes(x = yield_big_q50_log, y = yield_little_q50_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np5 &lt;- dat_wb2 %&gt;% \n  ggplot(aes(x = yield_big_q90_log, y = yield_little_q90_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\nggarrange(p1, p2, p3, p4, p5, nrow = 2, ncol = 3)\n\n\n\n\n\nRelationship between yield at Big G and yield at little g, summarized during event/non-event periods with five different metrics.\n\n\n\n\nView relationship between Big G and little g, color by event/non-event, facet by site. For most sites (except may Obear Brook), G-g relationships are identical between events and non-event.\n\n\nCode\nmyplotlist &lt;- list()\n# cumulative \nmyplotlist[[1]] &lt;- dat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# mean\nmyplotlist[[2]] &lt;- dat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# 10% quantile\nmyplotlist[[3]] &lt;- dat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_q10_log, y = yield_little_q10_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# 50% quantile\nmyplotlist[[4]] &lt;- dat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_q50_log, y = yield_little_q50_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# 90% quantile\nmyplotlist[[5]] &lt;- dat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_q90_log, y = yield_little_q90_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\nCumul.MeanQ10Q50Q90\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.2.6.1 To log or not to log?\nDoes using log-transformed data fundamentally change nature of the relationship? What does the g~G relationship look like if we use data on the original scale? Means, for example:\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean, y = yield_little_mean, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#spread-creek",
    "href": "Event Delineation/HydroEvents.html#spread-creek",
    "title": "6  Hydro Event Delineation",
    "section": "6.3 Spread Creek",
    "text": "6.3 Spread Creek\n\n6.3.1 Trim to focal sites\n\n\nCode\ndat_sp &lt;- dat %&gt;% filter(basin == \"Snake River\", site_name != \"Pacific Creek at Moran NWIS\") %&gt;%\n  mutate(site_name = recode(site_name, \"Leidy Creek Mouth NWIS\" = \"Leidy Creek Mouth\", \"SF Spread Creek Lower NWIS\" = \"SF Spread Creek Lower\")) %&gt;% \n  group_by(site_name, date) %&gt;% summarise(Yield_filled_mm = mean(Yield_filled_mm), flow_mean_filled_cms = mean(flow_mean_filled_cms), area_sqkm = mean(area_sqkm), WaterYear = unique(WaterYear)) %&gt;% ungroup()\nunique(dat_sp$site_name)\n\n\n [1] \"Grizzly Creek\"         \"Grouse Creek\"          \"Leidy Creek Mouth\"    \n [4] \"Leidy Creek Upper\"     \"NF Spread Creek Lower\" \"NF Spread Creek Upper\"\n [7] \"Rock Creek\"            \"SF Spread Creek Lower\" \"SF Spread Creek Upper\"\n[10] \"Spread Creek Dam\"     \n\n\nView daily yield at Big G\n\n\nCode\ntemp &lt;- dat_sp %&gt;% filter(site_name == \"Spread Creek Dam\")\ntemp &lt;- fill_missing_dates(temp, dates = date)\ntemp %&gt;% select(date, Yield_filled_mm) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTotal daily streamflow in yield (mm), over the period of record\n\n\nView daily yield at all sites\n\n\nCode\ndat_sp %&gt;% filter(site_name != \"Spread Creek Dam\") %&gt;% select(date, site_name, Yield_filled_mm) %&gt;% spread(key = site_name, value = Yield_filled_mm) %&gt;% left_join(dat_sp %&gt;% filter(site_name == \"Spread Creek Dam\") %&gt;% select(date, Yield_filled_mm) %&gt;% rename(Spread_Creek_Dam = Yield_filled_mm)) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(colors = c(hcl.colors(9, \"Zissou 1\"), \"black\")) \n\n\n\n\n\n\n\n\n6.3.2 Set parameters\nSet baseflow separation (for the Lyne-Hollick one-parameter digital recursive filter) and event delineation paramters (as in Wasko and Guo, 2022)\n\nalp: alpha filter parameter, higher values “lower” the estimated baseflow (thus making it difficult to delineate events)\nnumpass: number of passes. Ladson et al. (2013) recommend 3 passes for daily data (default in baseflowB() function)\nthresh: baseflow index threshold for event delineation, higher threshold values make it “easier” to delineate events\n\n\n\nCode\nalp &lt;- 0.925\nnumpass &lt;- 3\nthresh &lt;- 0.85\n\n\n\n\n6.3.3 Baseflow separation\nPerform baseflow separation. See Wasko and Guo (2022, Hydrological Processes) for recommendations on parameterization, as different algorithms and alpha values can produce different results. Section 4.1: “…users should not simply use recommended filter parameter values from literature in combination with any baseflow filter code without verification of their choice of filter parameter. As the digital baseflow filter is not tied to any physical realism (Nathan and McMahon, 1990) and a larger fractional baseflow may aid identification of events—even if this is not strictly baseflow as per its definition (Linsley et al., 1958)…”.\nIt is not actually necessary to do this separately, as baseflow separation is conducted in the event delineation function internally. But it is helpful to view the results and explore how different parameterizations yield different baseflow contributions.\n\n\nCode\nyrs &lt;- unlist(unique(dat_sp %&gt;% filter(site_name == \"Spread Creek Dam\", !is.na(Yield_filled_mm)) %&gt;% select(WaterYear)))\ndatlist &lt;- list()\nfor(i in 1:length(yrs)) {\n  datlist[[i]] &lt;- dat_sp %&gt;% \n    filter(site_name == \"Spread Creek Dam\", WaterYear == yrs[i], !is.na(Yield_filled_mm)) %&gt;%\n    mutate(bf = baseflowB(Yield_filled_mm, alpha = alp, passes = numpass)$bf, \n           bfi = baseflowB(Yield_filled_mm, alpha = alp, passes = numpass)$bfi)\n}\ndat_sp_bf &lt;- do.call(rbind, datlist)\n\n\n\n\nCode\nfill_missing_dates(dat_sp_bf, dates = date) %&gt;% select(date, Yield_filled_mm, bf, bfi) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTotal daily streamflow in yield (mm), baseflow in yield, and fractional baseflow index over the period of record for site Spread Creek Dam (Big G)\n\n\n\n\n6.3.4 Event identification\n\n6.3.4.1 Identify events\nSeparate Big G and Little G data\n\n\nCode\ndat_big &lt;- dat_sp_bf %&gt;% filter(site_name == \"Spread Creek Dam\")\ndat_little &lt;- dat_sp %&gt;% filter(site_name != \"Spread Creek Dam\")\n\n\nIdentify events at Big G and tidy…loop over years, i.e., chunks of data\n\n\nCode\nyrs &lt;- unlist(unique(dat_sp %&gt;% filter(site_name == \"Spread Creek Dam\", !is.na(Yield_filled_mm)) %&gt;% select(WaterYear)))\nbiglist &lt;- list()\nfor (k in 1:length(yrs)) {\n  ddd &lt;- dat_sp_bf %&gt;% filter(WaterYear == yrs[k])\n  events &lt;- eventBaseflow(ddd$Yield_filled_mm, BFI_Th = thresh, bfi = ddd$bfi)\n  events &lt;- events %&gt;% mutate(len = end - srt + 1)\n  \n  # define positions of non-events\n  srt &lt;- c(1)\n  end &lt;- c(events$srt[1]-1)\n  for (i in 2:(dim(events)[1])) {\n    srt[i] &lt;- events$end[i-1]+1\n    end[i] &lt;- events$srt[i]-1\n    }\n  nonevents &lt;- tibble(srt, end) %&gt;% mutate(len = end - srt) %&gt;% filter(len &gt;= 0) %&gt;% select(-len)\n  if(events$end[dim(events)[1]] != dim(ddd)[1]) { nonevents &lt;- nonevents %&gt;% add_row(srt = events$end[dim(events)[1]]+1, end = dim(ddd)[1]) }\n  nonevents &lt;- data.frame(nonevents)\n  \n  # create vectors of binary event/non-event and event IDs\n  isevent_vec &lt;- rep(2, times = dim(ddd)[1])\n  eventid_vec &lt;- rep(NA, times = dim(ddd)[1])\n  for (i in 1:dim(events)[1]) { \n    isevent_vec[c(events[i,1]:events[i,2])] &lt;- 1 \n    eventid_vec[c(events[i,1]:events[i,2])] &lt;- i\n  }\n\n  # create vector of non-event IDs\n  noneventid_vec &lt;- rep(NA, times = dim(ddd)[1])\n  for (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n\n  # create vector of \"agnostic events\": combined hydro events and non-events\n  agnevents &lt;- rbind(events %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\n  agneventid_vec &lt;- c()\n  for (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n  # add event/non-event vectors to Big G data\n  biglist[[k]] &lt;- ddd %&gt;% \n    mutate(isevent = isevent_vec, \n           eventid = eventid_vec,\n           noneventid = noneventid_vec,\n           agneventid = agneventid_vec,\n           big_event_yield = ifelse(isevent_vec == 1, Yield_filled_mm, NA),\n           big_nonevent_yield = ifelse(isevent_vec == 2, Yield_filled_mm, NA),\n           big_event_quick = big_event_yield - bf) %&gt;% \n    mutate(agneventid = paste(yrs[k], \"_\", agneventid, sep = \"\")) %&gt;%\n    rename(big_yield = Yield_filled_mm, big_bf = bf, big_bfi = bfi, big_flow = flow_mean_filled_cms, big_area_sqkm = area_sqkm)\n}\ndat_big &lt;- do.call(rbind, biglist)\ndat_big\n\n\n# A tibble: 1,059 × 15\n   site_name        date       big_yield big_flow big_area_sqkm WaterYear big_bf\n   &lt;chr&gt;            &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n 1 Spread Creek Dam 2012-06-24      1.77     5.16          253.      2013  0.884\n 2 Spread Creek Dam 2012-06-25      1.72     5.03          253.      2013  0.914\n 3 Spread Creek Dam 2012-06-26      1.69     4.93          253.      2013  0.941\n 4 Spread Creek Dam 2012-06-27      1.67     4.89          253.      2013  0.966\n 5 Spread Creek Dam 2012-06-28      1.63     4.75          253.      2013  0.988\n 6 Spread Creek Dam 2012-06-29      1.55     4.52          253.      2013  1.01 \n 7 Spread Creek Dam 2012-06-30      1.51     4.41          253.      2013  1.02 \n 8 Spread Creek Dam 2012-07-01      1.44     4.21          253.      2013  1.04 \n 9 Spread Creek Dam 2012-07-02      1.40     4.08          253.      2013  1.05 \n10 Spread Creek Dam 2012-07-03      1.42     4.14          253.      2013  1.06 \n# ℹ 1,049 more rows\n# ℹ 8 more variables: big_bfi &lt;dbl&gt;, isevent &lt;dbl&gt;, eventid &lt;int&gt;,\n#   noneventid &lt;int&gt;, agneventid &lt;chr&gt;, big_event_yield &lt;dbl&gt;,\n#   big_nonevent_yield &lt;dbl&gt;, big_event_quick &lt;dbl&gt;\n\n\n\n\nCode\nfill_missing_dates(dat_big, dates = date) %&gt;% select(date, big_yield, big_bf, big_event_yield, big_nonevent_yield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTime series of hydrologic events at Big G, identified using eventBaseflow().\n\n\n\n\n\n6.3.5 Join events to Little g\n\n\nCode\n# fudge factor to deal with 0 flow, when logged\nfudge &lt;- 0.01\n\n# join big g events to little g and summarize by event (cumulative, mean, and quantiles)\ndat_sp2 &lt;- dat_little %&gt;% \n  filter(date &gt;= min(dat_big$date) & date &lt;= max(dat_big$date)) %&gt;%\n  left_join(dat_big %&gt;% select(-site_name)) %&gt;% \n  group_by(site_name, agneventid) %&gt;% \n  summarise(eventlen = n(),\n            mindate = min(date),\n            isevent = unique(isevent), \n            n_little = sum(!is.na(Yield_filled_mm)),\n            n_big = sum(!is.na(big_yield)),\n            # cumulative\n            yield_little_cumul = sum(Yield_filled_mm+fudge, na.rm = TRUE),\n            yield_big_cumul = sum(big_yield+fudge, na.rm = TRUE),\n            yield_little_cumul_log = log(yield_little_cumul),\n            yield_big_cumul_log = log(yield_big_cumul),\n            # mean\n            yield_little_mean = mean(Yield_filled_mm+fudge),\n            yield_big_mean = mean(big_yield+fudge),\n            yield_little_mean_log = mean(log(Yield_filled_mm+fudge), na.rm = TRUE),\n            yield_big_mean_log = mean(log(big_yield+fudge), na.rm = TRUE),\n            # quantiles\n            yield_little_q10_log = quantile(log(Yield_filled_mm+fudge), probs = 0.10, na.rm = TRUE),\n            yield_little_q50_log = quantile(log(Yield_filled_mm+fudge), probs = 0.50, na.rm = TRUE),\n            yield_little_q90_log = quantile(log(Yield_filled_mm+fudge), probs = 0.90, na.rm = TRUE),\n            yield_big_q10_log = quantile(log(big_yield+fudge), probs = 0.10, na.rm = TRUE),\n            yield_big_q50_log = quantile(log(big_yield+fudge), probs = 0.50, na.rm = TRUE),\n            yield_big_q90_log = quantile(log(big_yield+fudge), probs = 0.90, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"Rock Creek\", \"SF Spread Creek Lower\", \"Grouse Creek\", \"SF Spread Creek Upper\", \"Leidy Creek Mouth\", \"Leidy Creek Upper\", \"NF Spread Creek Lower\", \"NF Spread Creek Upper\", \"Grizzly Creek\")),\n         site_name_cd = as.numeric(site_name)\n         # z_yield_big_cumul_log = as.numeric(scale(yield_big_cum_log, center = TRUE, scale = TRUE)),\n         # z_yield_big_mean_log = as.numeric(scale(yield_big_mean_log, center = TRUE, scale = TRUE))\n         ) %&gt;%\n  filter(!is.na(agneventid))\ndat_sp2 &lt;- dat_sp2[dat_sp2$n_little == dat_sp2$n_big,]\n\ndat_sp2\n\n\n# A tibble: 610 × 22\n   site_name     agneventid eventlen mindate    isevent n_little n_big\n   &lt;fct&gt;         &lt;chr&gt;         &lt;int&gt; &lt;date&gt;       &lt;dbl&gt;    &lt;int&gt; &lt;int&gt;\n 1 Grizzly Creek 2019_1           13 2018-07-03       2       13    13\n 2 Grizzly Creek 2019_2           27 2018-07-16       1       27    27\n 3 Grizzly Creek 2019_3           14 2018-08-12       2       14    14\n 4 Grizzly Creek 2019_4            6 2018-08-26       1        6     6\n 5 Grizzly Creek 2019_5           33 2018-09-01       2       33    33\n 6 Grizzly Creek 2019_6            3 2018-10-04       1        3     3\n 7 Grizzly Creek 2019_7            8 2018-10-07       2        8     8\n 8 Grizzly Creek 2022_1           45 2021-06-15       2       45    45\n 9 Grizzly Creek 2022_10           5 2021-10-08       1        5     5\n10 Grizzly Creek 2022_11           2 2021-10-13       2        2     2\n# ℹ 600 more rows\n# ℹ 15 more variables: yield_little_cumul &lt;dbl&gt;, yield_big_cumul &lt;dbl&gt;,\n#   yield_little_cumul_log &lt;dbl&gt;, yield_big_cumul_log &lt;dbl&gt;,\n#   yield_little_mean &lt;dbl&gt;, yield_big_mean &lt;dbl&gt;, yield_little_mean_log &lt;dbl&gt;,\n#   yield_big_mean_log &lt;dbl&gt;, yield_little_q10_log &lt;dbl&gt;,\n#   yield_little_q50_log &lt;dbl&gt;, yield_little_q90_log &lt;dbl&gt;,\n#   yield_big_q10_log &lt;dbl&gt;, yield_big_q50_log &lt;dbl&gt;, …\n\n\nCode\n# write to file\nwrite_csv(dat_sp2, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Event Delineation/Basin files/EcoDrought_Data_EventNonEvent_SpreadCreekonly.csv\")\n\n\nView pairs plot of summary statistics, for Big G only (limit to one little g site to avoid pseudo replication):\n\n\nCode\nmyplot &lt;- ggpairs(dat_sp2 %&gt;% select(mindate, yield_big_cumul_log, yield_big_mean_log, yield_big_q10_log, yield_big_q50_log, yield_big_q90_log))\nrctib &lt;- tibble(r = c(3,4,4,5,5,5,6,6,6,6),\n                c = c(2,2,3,2,3,4,2,3,4,5))\nfor (i in 1:nrow(rctib)) {\n  myplot[rctib$r[i], rctib$c[i]] &lt;- myplot[rctib$r[i], rctib$c[i]] + geom_abline(intercept = 0, slope = 1, color = \"red\")\n}\nmyplot\n\n\n\n\n\n\n\n\n\n\n\n6.3.6 Plot gG relationships\n\n\nCode\np1 &lt;- dat_sp2 %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np2 &lt;- dat_sp2 %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np3 &lt;- dat_sp2 %&gt;% \n  ggplot(aes(x = yield_big_q10_log, y = yield_little_q10_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np4 &lt;- dat_sp2 %&gt;% \n  ggplot(aes(x = yield_big_q50_log, y = yield_little_q50_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np5 &lt;- dat_sp2 %&gt;% \n  ggplot(aes(x = yield_big_q90_log, y = yield_little_q90_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\nggarrange(p1, p2, p3, p4, p5, nrow = 2, ncol = 3)\n\n\n\n\n\nRelationship between yield at Big G and yield at little g, summarized during event/non-event periods with five different metrics.\n\n\n\n\nView relationship between Big G and little g, color by event/non-event, facet by site. For most sites (except may Obear Brook), G-g relationships are identical between events and non-event.\n\n\nCode\nmyplotlist &lt;- list()\n# cumulative \nmyplotlist[[1]] &lt;- dat_sp2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# mean\nmyplotlist[[2]] &lt;- dat_sp2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# 10% quantile\nmyplotlist[[3]] &lt;- dat_sp2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_q10_log, y = yield_little_q10_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# 50% quantile\nmyplotlist[[4]] &lt;- dat_sp2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_q50_log, y = yield_little_q50_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# 90% quantile\nmyplotlist[[5]] &lt;- dat_sp2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_q90_log, y = yield_little_q90_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\nCumul.MeanQ10Q50Q90\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.3.6.1 To log or not to log?\nDoes using log-transformed data fundamentally change nature of the relationship? What does the g~G relationship look like if we use data on the original scale? Means, for example:\n\n\nCode\ndat_sp2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean, y = yield_little_mean, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#deprecated",
    "href": "Event Delineation/HydroEvents.html#deprecated",
    "title": "6  Hydro Event Delineation",
    "section": "6.4 DEPRECATED",
    "text": "6.4 DEPRECATED",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  }
]