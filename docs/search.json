[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EcoDrought Capstone",
    "section": "",
    "text": "1 Introduction\nThis book provides a visual story of the USGS Eco-Drought Capstone Project. Our goals are to (1) quantify fine-scale spatial heterogeneity in flow regimes in headwater stream networks, (2) demonstrate the limitations of existing tools that model flow in headwater streams, and (3) assess the subsequent effects of streamflow heterogeneity on fish population dynamics and vulnerability to climatic variation, particularly drought.\nProject team: Jeff Baldock, Jenn Fair, Ben Letcher, Robert Al-Chokhachy, Clint Muhlfeld, and Jason Dunham\n\n\nSession Information\n\n\n\n\n\nCode\nsessionInfo()\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 22631)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Denver\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.1    fastmap_1.2.0     cli_3.6.3        \n [5] tools_4.4.1       htmltools_0.5.8.1 rstudioapi_0.17.1 rmarkdown_2.29   \n [9] knitr_1.48        jsonlite_1.8.9    xfun_0.49         digest_0.6.37    \n[13] rlang_1.1.4       evaluate_1.0.1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html",
    "href": "Data Availability/CollateData.html",
    "title": "2  Collate Data",
    "section": "",
    "text": "2.0.1 Load libraries\nPurpose: Collate EcoDrought streamflow and temperature data, povided by EcoD PIs/partners and NWIS\nNotes: - need to figure out how to embed shiny/interactive plots. Tried ‘shinylive’ but this does not work\nCode\nlibrary(tidyverse)\nlibrary(mapview)\nlibrary(sf)\nlibrary(zoo)\nlibrary(dataRetrieval)\nlibrary(nhdplusTools)\nlibrary(ggpubr)\nlibrary(fasstr)\nlibrary(dygraphs)\nlibrary(ggforce)\nlibrary(smwrBase)\nlibrary(shiny)\nlibrary(rmarkdown)\nlibrary(shiny)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#gather-site-information",
    "href": "Data Availability/CollateData.html#gather-site-information",
    "title": "2  Collate Data",
    "section": "2.1 Gather site information",
    "text": "2.1 Gather site information\n\n\nCode\n# West Brook\nsiteinfo_wb &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Mass/MA_site_info.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_Name = factor(Site_Name)) %&gt;%\n  rename(site_id = Site_ID, station_no = Station_No, site_name = Site_Name, lat = Latitude_dec_deg, long = Longitude_dec_deg, elev_ft = Elevation_ft, area_sqmi = Drainage_Area_sqmi) %&gt;%\n  mutate(designation = \"little\", basin = \"West Brook\", region = \"Mass\") #%&gt;% select(-c(elev_ft, area_sqmi)) \n\n# Shenandoah\nsiteinfo_shen &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/VA_site_info.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_Name = factor(Site_Name)) %&gt;%\n  rename(site_id = Site_ID, station_no = Station_No, site_name = Site_Name, lat = Latitude_dec_deg, long = Longitude_dec_deg, elev_ft = Elevation_ft, area_sqmi = Drainage_Area_sqmi) %&gt;%\n  mutate(designation = ifelse(str_detect(site_id, \"10FL\"), \"big\", \"little\"), \n         basin = str_sub(site_name, 1, str_length(site_name)-3), region = \"Shen\") #%&gt;% select(-c(elev_ft, area_sqmi))\n\n# Flathead/Muhlfeld\nsiteinfo_flat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Flathead/Flathead_SiteInfo_UpdateOct25.csv\") %&gt;% \n  select(basin, site_name, site_id, region, designation, lat, long) %&gt;%\n  rename(subbasin = basin) %&gt;%\n  mutate(basin = \"Flathead\", region = \"Flat\") %&gt;%\n  select(site_id, site_name, lat, long, designation, basin, subbasin, region) %&gt;%\n  filter(designation == \"little\")\n  \n# GYA/Al-Chokhachy\nsiteinfo_gya &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/Al-Chokhachy_sites.csv\") %&gt;%\n  mutate(region = ifelse(basin == \"Snake River\", \"Snake\", \"Shields\"), \n         designation = \"little\") %&gt;%\n  select(site_id, site_name, latitude, longitude, designation, basin, region) %&gt;% \n  rename(lat = latitude, long = longitude)\n  \n\n# NWIS Medium/Big/Super G\nsites &lt;- c(\"01169900\", # South River at Conway, Massachusetts\n           \"13011500\", # Pacific Creek, Snake River, Wyoming\n           \"06195600\", # Shields River at Livingston, Montana\n           \"12355500\", # North Fork Flathead River, Montana\n           \"10396000\", # Donner Blitzen River near Frenchglen, Oregon\n           # Medium G\n           \"12355347\", # Big Creek (Flathead)\n           \"12355342\", # Hallowat Creek (Flathead)\n           \"06192980\", # Shields Rivera above Smith Creek (GYA)\n           \"06192900\", # Dugout Creek Mouth (GYA)\n           \"13012475\", # South Fork Spread Creek (GYA)\n           \"13012465\", # Leidy Creek, lower (GYA)\n           \"01171100\", # West Brook (Mass)\n           \"01171000\",  # Avery Brook (Mass)\n           \"424551118503200\", # Fish Creek at DB confluence (Oreg)\n           \"424547118503500\", # DB above Fish Creek (Oreg)\n           \"424325118495900\", # DB near Burnt Car Spring (Oreg)\n           \"424003118453700\", # Little Blitzen River (Oreg)\n           \"423830118453200\", # Indian Creek (Oreg)\n           \"423815118453900\" # DB above Indian Creek (Oreg)\n           )\nsiteinfo_nwis &lt;- tibble(readNWISsite(sites)[,c(2:3,7,8,20,30)]) # get site info\nnames(siteinfo_nwis) &lt;- c(\"station_no\", \"site_name\", \"lat\", \"long\", \"elev_ft\", \"area_sqmi\") # rename columns\nsiteinfo_nwis &lt;- siteinfo_nwis %&gt;% mutate(site_name = c(\"South River Conway NWIS\", \n                                                        \"Avery Broook NWIS\", \n                                                        \"West Brook NWIS\", \n                                                        \"Dugout Creek NWIS\", \n                                                        \"Shields River ab Smith NWIS\", \n                                                        \"Shields River nr Livingston NWIS\", \n                                                        \"Donner Blitzen River nr Frenchglen NWIS\", \n                                                        \"Hallowat Creek NWIS\", \n                                                        \"Big Creek NWIS\", \n                                                        \"North Fork Flathead River NWIS\", \n                                                        \"Pacific Creek at Moran NWIS\", \n                                                        \"Leidy Creek Mouth NWIS\", \n                                                        \"SF Spread Creek Lower NWIS\",\n                                                        \"Donner Blitzen ab Indian NWIS\",\n                                                        \"Indian Creek NWIS\",\n                                                        \"Little Blizten River NWIS\",\n                                                        \"Donner Blitzen nr Burnt Car NWIS\",\n                                                        \"Donner Blitzen ab Fish NWIS\",\n                                                        \"Fish Creek\"),\n                                          site_id = c(\"SRC\", \"AVB\", \"WBR\", \"DUG\", \"SRS\", \"SRL\", \"DBF\", \"HAL\", \"BIG\", \"NFF\", \"PCM\", \"LEI\", \"SFS\", \"DBI\", \"IND\", \"LBL\", \"DBB\", \"DBA\", \"FSH\"),\n                                          designation = c(\"big\", \"medium\", \"medium\", \"medium\", \"medium\", \"big\", \"big\", \"medium\", \"medium\", \"big\", \"big\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\"),\n                                          basin = c(\"West Brook\", \"West Brook\", \"West Brook\", \"Shields River\", \"Shields River\", \"Shields River\", \"Donner Blitzen\", \"Flathead\", \"Flathead\", \"Flathead\", \"Snake River\", \"Snake River\", \"Snake River\", \"Donner Blitzen\", \"Donner Blitzen\", \"Donner Blitzen\", \"Donner Blitzen\", \"Donner Blitzen\", \"Donner Blitzen\"),\n                                          region = c(\"Mass\", \"Mass\", \"Mass\", \"Shields\", \"Shields\", \"Shields\", \"Oreg\", \"Flat\", \"Flat\", \"Flat\", \"Snake\", \"Snake\", \"Snake\",\"Oreg\", \"Oreg\", \"Oreg\", \"Oreg\", \"Oreg\", \"Oreg\")) %&gt;% \n  select(site_id, site_name, lat, long, station_no, designation, basin, region, elev_ft, area_sqmi)\n#mapview(st_as_sf(siteinfo_nwis, coords = c(\"long\", \"lat\"), crs = 4326))\n\n\n# bind together, fill in ragged subbasin\nsiteinfo &lt;- bind_rows(siteinfo_wb, siteinfo_shen, siteinfo_flat, siteinfo_gya, siteinfo_nwis)\nsiteinfo$subbasin[siteinfo$site_name == \"Hallowat Creek NWIS\"] &lt;- \"Big Creek\"\nsiteinfo$subbasin[siteinfo$site_name == \"Big Creek NWIS\"] &lt;- \"Big Creek\"\nsiteinfo &lt;- siteinfo %&gt;% mutate(subbasin = ifelse(is.na(subbasin), basin, subbasin))\n\n\n# fix Shields River Valley Ranch site locations\nsiteinfo$lat[siteinfo$site_id == \"SH07\"] &lt;- siteinfo$lat[siteinfo$site_id == \"SRS\"]\nsiteinfo$long[siteinfo$site_id == \"SH07\"] &lt;- siteinfo$long[siteinfo$site_id == \"SRS\"]\n\n\n# add elevation and area variables (from watershed delineation)\nareafiles &lt;- list.files(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Area and Elevation\")\narealist &lt;- list()\nfor (i in 1:length(areafiles)) { arealist[[i]] &lt;- read_csv(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Area and Elevation/\", areafiles[i], sep = \"\"))}\nareaelev &lt;- do.call(rbind, arealist)\n# how well do provided and delineation area/elevation match?\n# test &lt;- siteinfo %&gt;% left_join(areaelev, by = \"site_id\")\n# test %&gt;% ggplot() + geom_point(aes(x = area_sqmi.x, y = area_sqmi.y)) + geom_abline(intercept = 0, slope = 1) + facet_wrap(~basin, scales = \"free\")\n# test %&gt;% ggplot() + geom_point(aes(x = elev_ft.x, y = elev_ft.y)) + geom_abline(intercept = 0, slope = 1) + facet_wrap(~basin, scales = \"free\")\n# add delineated variables\nsiteinfo &lt;- siteinfo %&gt;% select(-c(area_sqmi, elev_ft)) %&gt;% left_join(areaelev)\n# fix NF Flathead (no dem from Canada)\nsiteinfo$area_sqmi[siteinfo$site_id == \"NFF\"] &lt;- 1556\n\n\nWrite and re-load site information\n\n\nCode\nwrite_csv(siteinfo, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\n\n\nView unique basin names\n\n\nCode\nunique(siteinfo$basin)\n\n\n[1] \"West Brook\"     \"Paine Run\"      \"Piney River\"    \"Staunton River\"\n[5] \"Flathead\"       \"Duck Creek\"     \"Shields River\"  \"Snake River\"   \n[9] \"Donner Blitzen\"\n\n\nView unique site names\n\n\nCode\nunique(siteinfo$site_name)\n\n\n  [1] \"Avery Brook\"                            \n  [2] \"Jimmy Brook\"                            \n  [3] \"Mitchell Brook\"                         \n  [4] \"Obear Brook Lower\"                      \n  [5] \"Sanderson Brook\"                        \n  [6] \"West Brook Lower\"                       \n  [7] \"West Brook Upper\"                       \n  [8] \"West Brook Reservoir\"                   \n  [9] \"West Whately Brook\"                     \n [10] \"West Brook 0\"                           \n [11] \"Paine Run 01\"                           \n [12] \"Paine Run 02\"                           \n [13] \"Paine Run 03\"                           \n [14] \"Paine Run 04\"                           \n [15] \"Paine Run 05\"                           \n [16] \"Paine Run 06\"                           \n [17] \"Paine Run 07\"                           \n [18] \"Paine Run 08\"                           \n [19] \"Paine Run 09\"                           \n [20] \"Paine Run 10\"                           \n [21] \"Piney River 01\"                         \n [22] \"Piney River 02\"                         \n [23] \"Piney River 03\"                         \n [24] \"Piney River 04\"                         \n [25] \"Piney River 05\"                         \n [26] \"Piney River 06\"                         \n [27] \"Piney River 08\"                         \n [28] \"Piney River 09\"                         \n [29] \"Piney River 10\"                         \n [30] \"Staunton River 01\"                      \n [31] \"Staunton River 02\"                      \n [32] \"Staunton River 03\"                      \n [33] \"Staunton River 04\"                      \n [34] \"Staunton River 05\"                      \n [35] \"Staunton River 06\"                      \n [36] \"Staunton River 07\"                      \n [37] \"Staunton River 08\"                      \n [38] \"Staunton River 09\"                      \n [39] \"Staunton River 10\"                      \n [40] \"BigCreekLower\"                          \n [41] \"BigCreekMiddle\"                         \n [42] \"BigCreekUpper\"                          \n [43] \"CoalCreekHeadwaters\"                    \n [44] \"CoalCreekLower\"                         \n [45] \"CoalCreekMiddle\"                        \n [46] \"CycloneCreekLower\"                      \n [47] \"CycloneCreekMiddle\"                     \n [48] \"CycloneCreekUpper\"                      \n [49] \"HallowattCreekLower\"                    \n [50] \"LangfordCreekLower\"                     \n [51] \"LangfordCreekUpper\"                     \n [52] \"McGeeCreekLower\"                        \n [53] \"McGeeCreekTrib\"                         \n [54] \"McGeeCreekUpper\"                        \n [55] \"MeadowCreek\"                            \n [56] \"NicolaCreek\"                            \n [57] \"CoalCreekNorth\"                         \n [58] \"SkookoleelCreek\"                        \n [59] \"WernerCreek\"                            \n [60] \"WoundedBuckCreek\"                       \n [61] \"EF Duck Creek be HF\"                    \n [62] \"EF Duck Creek ab HF\"                    \n [63] \"Henrys Fork\"                            \n [64] \"Brackett Creek\"                         \n [65] \"Buck Creek\"                             \n [66] \"Crandall Creek\"                         \n [67] \"Deep Creek\"                             \n [68] \"Dugout Creek\"                           \n [69] \"Lodgepole Creek\"                        \n [70] \"Shields River Valley Ranch\"             \n [71] \"Shields River ab Dugout\"                \n [72] \"Grizzly Creek\"                          \n [73] \"Grouse Creek\"                           \n [74] \"Leidy Creek Lower\"                      \n [75] \"Leidy Creek Upper\"                      \n [76] \"Leidy Creek Mouth\"                      \n [77] \"NF Spread Creek Lower\"                  \n [78] \"NF Spread Creek Upper\"                  \n [79] \"Rock Creek\"                             \n [80] \"SF Spread Creek Lower\"                  \n [81] \"SF Spread Creek Upper\"                  \n [82] \"Spread Creek Dam\"                       \n [83] \"South River Conway NWIS\"                \n [84] \"Avery Broook NWIS\"                      \n [85] \"West Brook NWIS\"                        \n [86] \"Dugout Creek NWIS\"                      \n [87] \"Shields River ab Smith NWIS\"            \n [88] \"Shields River nr Livingston NWIS\"       \n [89] \"Donner Blitzen River nr Frenchglen NWIS\"\n [90] \"Hallowat Creek NWIS\"                    \n [91] \"Big Creek NWIS\"                         \n [92] \"North Fork Flathead River NWIS\"         \n [93] \"Pacific Creek at Moran NWIS\"            \n [94] \"Leidy Creek Mouth NWIS\"                 \n [95] \"SF Spread Creek Lower NWIS\"             \n [96] \"Donner Blitzen ab Indian NWIS\"          \n [97] \"Indian Creek NWIS\"                      \n [98] \"Little Blizten River NWIS\"              \n [99] \"Donner Blitzen nr Burnt Car NWIS\"       \n[100] \"Donner Blitzen ab Fish NWIS\"            \n[101] \"Fish Creek\"                             \n\n\nMap sites\n\n\nCode\n# convert to spatial object and view on map\n#| fig-cap: \"Map of EcoDrought project locations\"\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#load-ecod-data",
    "href": "Data Availability/CollateData.html#load-ecod-data",
    "title": "2  Collate Data",
    "section": "2.2 Load EcoD data",
    "text": "2.2 Load EcoD data\n\n\nCode\n# West Brook\ndat_wb &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Mass/EcoDrought Continuous_MA.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_Name = factor(Site_Name)) %&gt;%\n  rename(station_no = Station_No, site_name = Site_Name, datetime = DateTime_EST, height = GageHeight_Hobo_ft, flow = Discharge_Hobo_cfs, tempf = WaterTemperature_HOBO_DegF) %&gt;%\n  mutate(tempc = (tempf - 32)*(5/9)) %&gt;% select(station_no, site_name, datetime, height, flow, tempc) %&gt;%\n  left_join(siteinfo %&gt;% select(-station_no))\n\n\n# Shenandoah\ndat_shen &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/EcoDrought_Continuous_VA.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_ID = factor(Site_ID), Discharge_Hobo_cfs = as.numeric(Discharge_Hobo_cfs)) %&gt;%\n  rename(station_no = Station_No, site_id = Site_ID, datetime = DateTime_EST, height = GageHeight_Hobo_ft, flow = Discharge_Hobo_cfs, tempf = WaterTemperature_HOBO_DegF) %&gt;%\n  mutate(tempc = (tempf - 32)*(5/9)) %&gt;% select(station_no, site_id, datetime, height, flow, tempc) %&gt;%\n  left_join(siteinfo)\n# pull in Big G data separately (UVA long-term gage sites)\ndat_shen_uva_q &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/Shen_BigG_Discharge_hourly_UVA.csv\") %&gt;%\n  rename(flow = cfs)\ndat_shen_uva_t &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/Shen_BigG_TempEtc_hourly_UVA.csv\") %&gt;%\n  select(site_id, datetime, tempc_mean) %&gt;% rename(tempc = tempc_mean)\ndat_shen_uva &lt;- dat_shen_uva_q %&gt;% left_join(dat_shen_uva_t) %&gt;% left_join(siteinfo)\n# bind usgs and uva data\ndat_shen &lt;- bind_rows(dat_shen, dat_shen_uva)\n\n\n# Flathead/Muhlfeld\nflatfiles &lt;- list.files(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Flathead/Export2/EMA/Continuous Data\")\nflatlist &lt;- list()\nfor (i in 1:length(flatfiles)) { \n  #print(flatfiles[i])\n  flatlist[[i]] &lt;- read_csv(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Flathead/Export2/EMA/Continuous Data/\", flatfiles[i], sep = \"\")) %&gt;%\n    mutate(DateTime = mdy_hm(DateTime, tz = \"MST\"),\n           site_name = gsub(\"EMA.csv\", \"\", flatfiles[i]))\n  }\ndat_flat &lt;- bind_rows(flatlist) %&gt;% select(DateTime, GageHeightFT, DischargeCFS, TempF, TempC, site_name, DischargeReliability, TempReliability) %&gt;% \n  rename(datetime = DateTime, height = GageHeightFT, flow = DischargeCFS, tempf = TempF, tempc = TempC) %&gt;%\n  mutate(DischargeReliability = as_factor(DischargeReliability),\n         TempReliability = as_factor(TempReliability)) %&gt;%\n  mutate(tempf = ifelse(is.na(tempf), (tempc * (9/5)) + 32, tempf),\n         tempc = ifelse(is.na(tempc), (tempf - 32) * (5/9), tempc)) %&gt;%\n  left_join(siteinfo) %&gt;% select(-tempf)\n\n\n# Greater Yellowstone/Al-Chokhachy\ngyafiles &lt;- list.files(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/Al-Chokhachy data files\")\ngyalist &lt;- list()\nfor (i in 1:length(gyafiles)) { \n  #print(gyafiles[i])\n  gyalist[[i]] &lt;- read_csv(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/Al-Chokhachy data files/\", gyafiles[i], sep = \"\")) %&gt;%\n    mutate(date = mdy(date), DateTime = ymd_hms(paste(date, time, sep = \" \"), tz = \"MST\"), discharge = as.numeric(discharge))\n}\ndat_gya &lt;- bind_rows(gyalist) %&gt;% select(DateTime, depth, discharge, temperature, location) %&gt;% \n  rename(datetime = DateTime, height = depth, flow = discharge, tempc = temperature, site_name = location) %&gt;%\n  filter(site_name != \"EF Henrys\") %&gt;% # drop weird duplicate site/year?\n  mutate(site_name = dplyr::recode(site_name,\n                            \"EF Above Confluence\" = \"EF Duck Creek ab HF\",\n                            \"EF Below Confluence\" = \"EF Duck Creek be HF\",\n                            \"NF Spread Creek\" = \"NF Spread Creek Lower\",\n                            \"Upper NF Spread Creek\" = \"NF Spread Creek Upper\",\n                            \"SF Spread Creek\" = \"SF Spread Creek Lower\",\n                            \"Upper SF Spread Creek\" = \"SF Spread Creek Upper\",\n                            \"Shields River above Dugout Creek\" = \"Shields River ab Dugout\",\n                            \"Upper Leidy Creek\" = \"Leidy Creek Upper\", \n                            \"Leidy Creek\" = \"Leidy Creek Mouth\",\n                            \"Spread Creek\" = \"Spread Creek Dam\",\n                            \"Shields River above Smith Creek\" = \"Shields River Valley Ranch\")) %&gt;%\n  left_join(siteinfo) %&gt;% filter(tempc &lt;= 100)\n\n\nBind EcoD hourly flow/temp data with siteinfo and write to file\n\n\nCode\n# bind together\ndat &lt;- bind_rows(dat_wb, dat_shen, dat_flat, dat_gya)\n# unique(dat$site_name)\nwrite_csv(dat, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_Raw.csv\")\ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_Raw.csv\")\n\n\nCheck unique designations\n\n\nCode\nunique(dat$designation)\n\n\n[1] \"little\" \"big\"   \n\n\nCheck unique regions\n\n\nCode\nunique(dat$region)\n\n\n[1] \"Mass\"    \"Shen\"    \"Flat\"    \"Shields\" \"Snake\"  \n\n\nCheck unique basins\n\n\nCode\nunique(dat$basin)\n\n\n[1] \"West Brook\"     \"Paine Run\"      \"Staunton River\" \"Piney River\"   \n[5] \"Flathead\"       \"Shields River\"  \"Duck Creek\"     \"Snake River\"   \n\n\nCheck unique subbasins\n\n\nCode\nunique(dat$subbasin)\n\n\n [1] \"West Brook\"         \"Paine Run\"          \"Staunton River\"    \n [4] \"Piney River\"        \"Big Creek\"          \"Coal Creek\"        \n [7] \"McGee Creek\"        \"Wounded Buck Creek\" \"Shields River\"     \n[10] \"Duck Creek\"         \"Snake River\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#load-nwis-data",
    "href": "Data Availability/CollateData.html#load-nwis-data",
    "title": "2  Collate Data",
    "section": "2.3 Load NWIS data",
    "text": "2.3 Load NWIS data\n\n\nCode\n# extract daily mean discharge and temp data from USGS NWIS website\ndat_superg_nwis &lt;- tibble(readNWISdv(siteNumbers = sites, parameterCd = c(\"00010\", \"00060\"), startDate = \"1980-01-01\", endDate = Sys.Date(), statCd = c(\"00003\", \"00001\", \"00002\")))[,-c(1,5,7,9,11)]\nnames(dat_superg_nwis) &lt;- c(\"station_no\", \"date\", \"tempc_max\", \"tempc_min\", \"tempc_mean\", \"flow_mean\")\ndat_superg_nwis &lt;- dat_superg_nwis %&gt;% left_join(siteinfo)\n\n\n\n\nCode\ndat_superg_nwis %&gt;% filter(designation == \"big\") %&gt;% ggplot() + geom_line(aes(x = date, y = log(flow_mean))) + facet_wrap(~site_name)\n\n\n\n\n\n(log) Stream flow (cfs) for Big G NWIS gages\n\n\n\n\n\n\nCode\ndat_superg_nwis %&gt;% filter(designation == \"medium\") %&gt;% ggplot() + geom_line(aes(x = date, y = log(flow_mean))) + facet_wrap(~site_name)\n\n\n\n\n\n(log) Stream flow (cfs) for Medium G NWIS gages",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#bind-data-and-calc.-daily-means",
    "href": "Data Availability/CollateData.html#bind-data-and-calc.-daily-means",
    "title": "2  Collate Data",
    "section": "2.4 Bind data and calc. daily means",
    "text": "2.4 Bind data and calc. daily means\n\n\nCode\n# daily flow/temp summaries\ndat_daily &lt;- dat %&gt;% mutate(date = as_date(datetime)) %&gt;% \n  group_by(station_no, site_name, site_id, basin, subbasin, region, lat, long, elev_ft, area_sqmi, designation, date) %&gt;% \n  summarize(disch_reli = max(DischargeReliability),\n            temp_reli = max(TempReliability),\n            flow_mean = mean(flow), flow_min = min(flow), flow_max = max(flow),\n            tempc_mean = mean(tempc), tempc_min = min(tempc), tempc_max = max(tempc)) %&gt;%\n  arrange(region, basin, site_name, date) %&gt;%\n  ungroup()\n\n# cbind EcoD and NWIS datasets\ndat_daily &lt;- bind_rows(dat_daily %&gt;% select(-flow_min, -flow_max, -tempc_min, -tempc_max), \n                       dat_superg_nwis %&gt;% select(-tempc_max, -tempc_min),\n                       dat_superg_nwis %&gt;% filter(site_id == \"SRL\") %&gt;% mutate(subbasin = \"Duck Creek\") %&gt;% select(-tempc_max, -tempc_min))\n\n# add missing dates\ndat_daily &lt;- fill_missing_dates(dat_daily, dates = date, groups = site_name)\n\n\nView daily mean time series data\n\n\nCode\nlibrary(shiny)\nui &lt;- shiny::fluidPage(\n  shiny::selectInput(inputId = \"mysite\", label = \"site_name\", choices = unique(dat_daily$site_name)),\n  dygraphs::dygraphOutput(\"plotDy\")\n)\nserver &lt;- function(input, output) {\n  flow_data &lt;- reactive({\n    dat_daily %&gt;% filter(site_name == input$mysite) %&gt;% select(date, flow_mean)\n  })\n  output$plotDy &lt;- renderDygraph({\n    dygraph(flow_data()) %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Mean daily flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n  })\n}\nshiny::shinyApp(ui = ui, server = server)\n\n\nShiny applications not supported in static R Markdown documents\nMean daily stream flow (cfs) by site",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#interpolate-missing-data",
    "href": "Data Availability/CollateData.html#interpolate-missing-data",
    "title": "2  Collate Data",
    "section": "2.5 Interpolate missing data",
    "text": "2.5 Interpolate missing data\nSmall periods of missing data (&lt;24 hours) become a problem when aggregating at the daily and weekly time scales. *Note that currently this discovers and fills missing data at the daily time scale, but should be changed to interpolate at the original timescale of the raw data (e.g., hourly).\n\n\nCode\n# explore data gaps\nmysites &lt;- unique(dat_daily$site_name)\nmynas &lt;- list()\nfor (i in 1:length(mysites)) {\n  mydisch &lt;- unlist(dat_daily$flow_mean[dat_daily$site_name == mysites[i]])\n  runsna &lt;- rle(is.na(mydisch))\n  mynas[[i]] &lt;- tibble(site_name = mysites[i], run = runsna$lengths[runsna$values == TRUE])\n}\nmynas &lt;- do.call(rbind, mynas)\n# mynas %&gt;% filter(run &lt; 100) %&gt;% ggplot() + geom_histogram(aes(x = run)) + facet_wrap_paginate(~site_name, nrow = 4, ncol = 4, page = 1)\n# mynas %&gt;% filter(run &lt; 100) %&gt;% ggplot() + geom_histogram(aes(x = run)) + facet_wrap_paginate(~site_name, nrow = 4, ncol = 4, page = 2)\n# mynas %&gt;% filter(run &lt; 100) %&gt;% ggplot() + geom_histogram(aes(x = run)) + facet_wrap_paginate(~site_name, nrow = 4, ncol = 4, page = 3)\n# mynas %&gt;% filter(run &lt; 100) %&gt;% ggplot() + geom_histogram(aes(x = run)) + facet_wrap_paginate(~site_name, nrow = 4, ncol = 4, page = 4)\n\n\nMost gaps are relatively short\n\n\nCode\nmynas %&gt;% ggplot() + geom_histogram(aes(x = run)) + xlab(\"Days\") + ylab(\"Fresquency\")\n\n\n\n\n\nDistributiion of lengths of missing data (days)\n\n\n\n\nZoomed in…\n\n\nCode\nmynas %&gt;% filter(run &lt; 30) %&gt;% ggplot() + geom_histogram(aes(x = run))  + xlab(\"Days\") + ylab(\"Fresquency\")\n\n\n\n\n\nDistributiion of lengths of missing data (days)\n\n\n\n\nConsidering just the short gaps, which are likely a function of logger malfunction or Aquarius export issues, which sites are problematic? Answer: Flathead\n\n\nCode\nmynas %&gt;% filter(run &lt; 30) %&gt;% ggplot() + geom_bar(aes(site_name))+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\nFrequency of short (&lt;40 days) data gaps by site\n\n\n\n\nFill short gaps (&lt;=14 days…2x smoothing period) using time series interpolation\n\n\nCode\n# fill short gaps (&lt;=14 days...2x smoothing period) using time series interpolation\ndatalist &lt;- list()\nfor (i in 1:length(mysites)) { datalist[[i]] &lt;- dat_daily %&gt;% filter(site_name == mysites[i]) %&gt;% mutate(flow_mean_filled = fillMissing(flow_mean, max.fill = 14, span = 100)) }\n# bind and check 1:1\ndat_daily_fill &lt;- do.call(rbind, datalist)\n# dat_daily_fill %&gt;% ggplot() + geom_point(aes(x = flow_mean, y = flow_mean_filled)) + facet_wrap(~site_name, scales = \"free\")\n\n\nExplore interpolated/filled time series relative to original (daily) data\n\n\nCode\n# explore individual sites\n#| fig-cap: \"Mean daily observed and interpolated stream flow (cfs) by site\"\nlibrary(shiny)\nui &lt;- shiny::fluidPage(\n  shiny::selectInput(inputId = \"mysite\", label = \"site_name\", choices = unique(dat_daily_fill$site_name)),\n  dygraphs::dygraphOutput(\"plotDy\")\n)\nserver &lt;- function(input, output) {\n  flow_data &lt;- reactive({\n    dat_daily_fill %&gt;% filter(site_name == input$mysite) %&gt;% select(date, flow_mean, flow_mean_filled)\n  })\n  output$plotDy &lt;- renderDygraph({\n    dygraph(flow_data()) %&gt;% dyRangeSelector() %&gt;% dySeries(\"flow_mean\", strokeWidth = 5, color = \"black\") %&gt;% dySeries(\"flow_mean_filled\", strokeWidth = 1, color = \"red\") %&gt;% dyAxis(\"y\", label = \"Mean daily flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n  })\n}\nshiny::shinyApp(ui = ui, server = server)\n\n\nShiny applications not supported in static R Markdown documents",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#calculate-yield",
    "href": "Data Availability/CollateData.html#calculate-yield",
    "title": "2  Collate Data",
    "section": "2.6 Calculate yield",
    "text": "2.6 Calculate yield\n\n\nCode\n# convert cfs and basin area to metric\ndat_daily_fill &lt;- dat_daily_fill %&gt;% mutate(flow_mean_cms = flow_mean*0.02831683199881, \n                                            flow_mean_filled_cms = flow_mean_filled*0.02831683199881, \n                                            area_sqkm = area_sqmi*2.58999)\n\n# sites\nsites &lt;- unique(dat_daily_fill$site_name)\n\n# site-specific basin area in square km\nbasinarea &lt;- dat_daily_fill %&gt;% filter(!is.na(site_id)) %&gt;% group_by(site_name) %&gt;% summarize(area_sqkm = unique(area_sqkm))\n\n# calculate yield\nyield_list &lt;- list()\nfor (i in 1:length(sites)) {\n  d &lt;- dat_daily_fill %&gt;% filter(site_name == sites[i])\n  ba &lt;- unlist(basinarea %&gt;% filter(site_name == sites[i]) %&gt;% select(area_sqkm))\n  yield_list[[i]] &lt;-  add_daily_yield(data = d, values = flow_mean_cms, basin_area = as.numeric(ba)) %&gt;% left_join(add_daily_yield(data = d, values = flow_mean_filled_cms, basin_area = as.numeric(ba)) %&gt;% rename(Yield_filled_mm = Yield_mm))\n}\ndat_daily_fill_wyield &lt;- do.call(rbind, yield_list)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#calculate-7-day-means",
    "href": "Data Availability/CollateData.html#calculate-7-day-means",
    "title": "2  Collate Data",
    "section": "2.7 Calculate 7-day means",
    "text": "2.7 Calculate 7-day means\n\n\nCode\ndat_daily_fill_wyield &lt;- dat_daily_fill_wyield %&gt;%\n  group_by(site_name) %&gt;%\n  mutate(flow_mean_7 = rollapply(flow_mean, FUN = mean, width = 7, align = \"center\", fill = NA),\n         flow_mean_filled_7 = rollapply(flow_mean_filled, FUN = mean, width = 7, align = \"center\", fill = NA),\n         tempc_mean_7 = rollapply(tempc_mean, FUN = mean, width = 7, align = \"center\", fill = NA),\n         Yield_mm_7 = rollapply(Yield_mm, FUN = mean, width = 7, align = \"center\", fill = NA),\n         Yield_filled_mm_7 = rollapply(Yield_filled_mm, FUN = mean, width = 7, align = \"center\", fill = NA)) %&gt;%\n  ungroup() %&gt;% filter(!is.na(site_id))\n\n# # view flow\n# dat_daily_fill_wyield %&gt;% filter(site_name == \"Avery Brook\") %&gt;% select(date, flow_mean_filled, flow_mean_filled_7) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% \n#   dySeries(\"flow_mean_filled\", strokeWidth = 5, color = \"black\") %&gt;% dySeries(\"flow_mean_filled_7\", strokeWidth = 1, color = \"red\")\n# \n# # view yield\n# dat_daily_fill_wyield %&gt;% filter(site_name == \"Avery Brook\") %&gt;% select(date, Yield_filled_mm, Yield_filled_mm_7) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% \n#   dySeries(\"Yield_filled_mm\", strokeWidth = 5, color = \"black\") %&gt;% dySeries(\"Yield_filled_mm_7\", strokeWidth = 1, color = \"red\")\n\n# unique(dat_daily_fill_wyield$basin)\n# unique(dat_daily_fill_wyield$subbasin)\n# unique(dat_daily_fill_wyield$region)\n# unique(dat_daily_fill_wyield$disch_reli)\n# unique(dat_daily_fill_wyield$temp_reli)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#write-out-and-read-data",
    "href": "Data Availability/CollateData.html#write-out-and-read-data",
    "title": "2  Collate Data",
    "section": "2.8 Write out and read data",
    "text": "2.8 Write out and read data\n\n\nCode\n# write out\nwrite_csv(dat_daily_fill_wyield, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\")\ndat_daily &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#view-data-availability",
    "href": "Data Availability/CollateData.html#view-data-availability",
    "title": "2  Collate Data",
    "section": "2.9 View data availability",
    "text": "2.9 View data availability\n\n\nCode\n# summarize data availability\ndat_summ &lt;- dat_daily %&gt;% filter(site_id != \"MRN\") %&gt;%\n  group_by(basin, date, designation) %&gt;% summarize(numflow = sum(!is.na(flow_mean)), numtemp = sum(!is.na(tempc_mean))) %&gt;% \n  gather(type, avail, numflow:numtemp) %&gt;% mutate(type2 = as.factor(paste(designation, type, sep = \"_\"))) %&gt;% \n  mutate(type3 = as.numeric(type2), avail = na_if(avail, 0)) %&gt;% ungroup() %&gt;% filter(!is.na(avail))\n# levels(dat_summ$type2)\n# unique(dat_summ$basin)\n\n\n\n\nCode\n# plot all years\n#| fig-cap: \"Data availability by basin, all years\"\nmyplot &lt;- dat_summ %&gt;% ggplot(aes(x = date, y = type3)) + \n  geom_errorbarh(aes(xmax = date, xmin = date, color = avail), size = 0.001) +\n  scale_color_continuous(trans = \"reverse\", na.value = \"grey60\") +\n  scale_y_discrete(limits = c(\"Big G flow\", \"Big G temp\", \"Medium g flow\", \"Medium g temp\", \"Little g flow\", \"Little g temp\")) + \n  labs(colour = \"Number \\nof sites\") + ylab(\"\") + xlab(\"Date\") + \n  facet_wrap(~ basin, nrow = 4,\n             labeller = as_labeller(c(`West Brook` = \"West Brook: G = South River Conway (NWIS)\", \n                                      `Staunton River` = \"Staunton River: G = Staunton River 10 (UVA)\",\n                                      `Paine Run` = \"Paine Run: G = Paine Run 10 (UVA)\",\n                                      `Piney River` = \"Piney River: G = Piney River 10 (UVA)\",\n                                      `Snake River` = \"Snake River: G = Pacific Creek Moran (NWIS)\",\n                                      `Shields River` = \"Shields River: G = Shields River Livingston (NWIS)\",\n                                      `Flathead` = \"NF Flathead River: G = NF Flathead (NWIS)\",\n                                      `Donner Blitzen` = \"Donner Blitzen River: G = DB Frenchglen (NWIS)\",\n                                      `Duck Creek` = \"Duck Creek: G = Shields River Livingston (NWIS)\")))\nmyplot\n\n\n\n\n\n\n\n\n\nCode\n# jpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Data Availability/DataAvailability_byBasin.jpg\", height = 6, width = 12, units = \"in\", res = 500)\n# myplot\n# dev.off()\n\n\n\n\nCode\n# plot recent years\n#| fig-cap: \"Data availability by basin, recent years\"\n# jpeg(\"./Data Availability/DataAvailability_byBasin_recent.jpg\", height = 6, width = 12, units = \"in\", res = 500)\nmyplot &lt;- dat_summ %&gt;% filter(date &gt;= \"2018-10-01\") %&gt;% ggplot(aes(x = date, y = type3)) + \n  geom_errorbarh(aes(xmax = date, xmin = date, color = avail), size = 0.001) +\n  scale_color_continuous(trans = \"reverse\", na.value = \"grey60\") +\n  scale_y_discrete(limits = c(\"Big G flow\", \"Big G temp\", \"Medium g flow\", \"Medium g temp\", \"Little g flow\", \"Little g temp\")) + \n  labs(colour = \"Number \\nof sites\") + ylab(\"\") + xlab(\"Date\") + \n  facet_wrap(~ basin, nrow = 4,\n             labeller = as_labeller(c(`West Brook` = \"West Brook: G = South River Conway (NWIS)\", \n                                      `Staunton River` = \"Staunton River: G = Staunton River 10 (UVA)\",\n                                      `Paine Run` = \"Paine Run: G = Paine Run 10 (UVA)\",\n                                      `Piney River` = \"Piney River: G = Piney River 10 (UVA)\",\n                                      `Snake River` = \"Snake River: G = Pacific Creek Moran (NWIS)\",\n                                      `Shields River` = \"Shields River: G = Shields River Livingston (NWIS)\",\n                                      `Flathead` = \"NF Flathead River: G = NF Flathead (NWIS)\",\n                                      `Donner Blitzen` = \"Donner Blitzen River: G = DB Frenchglen (NWIS)\",\n                                      `Duck Creek` = \"Duck Creek: G = Shields River Livingston (NWIS)\")))\nmyplot",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#compare-co-located-gages",
    "href": "Data Availability/CollateData.html#compare-co-located-gages",
    "title": "2  Collate Data",
    "section": "2.10 Compare co-located gages",
    "text": "2.10 Compare co-located gages\nCompare streamflow data from co-located EcoDrought and NWIS gages\n\n\nCode\n# WEST BROOK\np1 &lt;- dat_daily %&gt;% filter(site_name == \"West Brook 0\") %&gt;% select(date, flow_mean_7) %&gt;% rename(little = flow_mean_7) %&gt;% \n  left_join(dat_daily %&gt;% filter(site_name == \"West Brook NWIS\") %&gt;% select(date, flow_mean_7) %&gt;% rename(medium = flow_mean_7)) %&gt;%\n  ggplot() + geom_point(aes(x = log(medium), y = log(little))) + geom_abline(intercept = 0, slope = 1, color = \"red\")\n\np2 &lt;- dat_daily %&gt;% filter(site_name == \"Avery Brook\") %&gt;% select(date, flow_mean_7) %&gt;% rename(little = flow_mean_7) %&gt;% \n  left_join(dat_daily %&gt;% filter(site_name == \"Avery Broook NWIS\") %&gt;% select(date, flow_mean_7) %&gt;% rename(medium = flow_mean_7)) %&gt;%\n  ggplot() + geom_point(aes(x = log(medium), y = log(little))) + geom_abline(intercept = 0, slope = 1, color = \"red\")\n\n# FLATHEAD\np3 &lt;- dat_daily %&gt;% filter(site_name == \"BigCreekMiddle\") %&gt;% select(date, flow_mean_7) %&gt;% rename(little = flow_mean_7) %&gt;% \n  left_join(dat_daily %&gt;% filter(site_name == \"Big Creek NWIS\") %&gt;% select(date, flow_mean_7) %&gt;% rename(medium = flow_mean_7)) %&gt;%\n  ggplot() + geom_point(aes(x = log(medium), y = log(little))) + geom_abline(intercept = 0, slope = 1, color = \"red\")\n\n# jpeg(\"./Data Availability/LittleMedium_Co-Located_Gages.jpg\", height = 6, width = 6, units = \"in\", res = 500)\nggarrange(p1, p2, p3, ncol = 2, nrow = 2, labels = c(\"West Brook 0\", \"Avery Brook\", \"Big Creek (Flathead)\"))\n\n\n\n\n\nStreamflow measured at little g gages (EcoDrought) as a function of streamflow measured at medium g gages (NWIS), on a log-scale. Red line denotes 1:1\n\n\n\n\nCode\n# dev.off()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  }
]