[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EcoDrought Capstone",
    "section": "",
    "text": "1 Introduction\nThis book provides a visual story of the USGS Eco-Drought Capstone Project. Our goals are to (1) quantify fine-scale spatial heterogeneity in flow regimes in headwater stream networks, (2) demonstrate the limitations of existing tools that model flow in headwater streams, and (3) assess the subsequent effects of streamflow heterogeneity on fish population dynamics and vulnerability to climatic variation, particularly drought.\nThis information is preliminary or provisional and is subject to revision. It is being provided to meet the need for timely best science. The information has not received final approval by the U.S. Geological Survey (USGS) and is provided on the condition that neither the USGS nor the U.S. Government shall be held liable for any damages resulting from the authorized or unauthorized use of the information.\nProject team: Jeff Baldock, Jenn Fair, Ben Letcher, Robert Al-Chokhachy, Clint Muhlfeld, and Jason Dunham\n\n\nSession Information\n\n\n\n\n\nCode\nsessionInfo()\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 22631)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Denver\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.1    fastmap_1.2.0     cli_3.6.3        \n [5] tools_4.4.1       htmltools_0.5.8.1 rstudioapi_0.17.1 rmarkdown_2.29   \n [9] knitr_1.48        jsonlite_1.8.9    xfun_0.49         digest_0.6.37    \n[13] rlang_1.1.4       evaluate_1.0.1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html",
    "href": "Data Availability/CollateData.html",
    "title": "2  Collate Data",
    "section": "",
    "text": "2.1 Gather site information\nPurpose: Collate EcoDrought streamflow and temperature data, povided by EcoD PIs/partners and NWIS\nNotes:\nCode\n# West Brook\nsiteinfo_wb &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Mass/MA_site_info.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_Name = factor(Site_Name)) %&gt;%\n  rename(site_id = Site_ID, station_no = Station_No, site_name = Site_Name, lat = Latitude_dec_deg, long = Longitude_dec_deg, elev_ft = Elevation_ft, area_sqmi = Drainage_Area_sqmi) %&gt;%\n  mutate(designation = \"little\", basin = \"West Brook\", region = \"Mass\") #%&gt;% select(-c(elev_ft, area_sqmi)) \n\n# Shenandoah\nsiteinfo_shen &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/VA_site_info.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_Name = factor(Site_Name)) %&gt;%\n  rename(site_id = Site_ID, station_no = Station_No, site_name = Site_Name, lat = Latitude_dec_deg, long = Longitude_dec_deg, elev_ft = Elevation_ft, area_sqmi = Drainage_Area_sqmi) %&gt;%\n  mutate(designation = ifelse(str_detect(site_id, \"10FL\"), \"big\", \"little\"), \n         basin = str_sub(site_name, 1, str_length(site_name)-3), region = \"Shen\") #%&gt;% select(-c(elev_ft, area_sqmi))\n\n# Flathead/Muhlfeld\nsiteinfo_flat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Flathead/Flathead_SiteInfo_UpdateOct25.csv\") %&gt;% \n  select(basin, site_name, site_id, region, designation, lat, long) %&gt;%\n  rename(subbasin = basin) %&gt;%\n  mutate(basin = \"Flathead\", region = \"Flat\") %&gt;%\n  select(site_id, site_name, lat, long, designation, basin, subbasin, region) %&gt;%\n  filter(designation == \"little\")\n  \n# GYA/Al-Chokhachy\nsiteinfo_gya &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/Al-Chokhachy_sites.csv\") %&gt;%\n  mutate(region = ifelse(basin == \"Snake River\", \"Snake\", \"Shields\"), \n         designation = \"little\") %&gt;%\n  select(site_id, site_name, latitude, longitude, designation, basin, region) %&gt;% \n  rename(lat = latitude, long = longitude)\n  \n\n# NWIS Medium/Big/Super G\nsites &lt;- c(\"01169900\", # South River at Conway, Massachusetts\n           \"13011500\", # Pacific Creek, Snake River, Wyoming\n           \"06195600\", # Shields River at Livingston, Montana\n           \"12355500\", # North Fork Flathead River, Montana\n           \"10396000\", # Donner Blitzen River near Frenchglen, Oregon\n           # Medium G\n           \"12355347\", # Big Creek (Flathead)\n           \"12355342\", # Hallowat Creek (Flathead)\n           \"06192980\", # Shields Rivera above Smith Creek (GYA)\n           \"06192900\", # Dugout Creek Mouth (GYA)\n           \"13012475\", # South Fork Spread Creek (GYA)\n           \"13012465\", # Leidy Creek, lower (GYA)\n           \"01171100\", # West Brook (Mass)\n           \"01171000\",  # Avery Brook (Mass)\n           \"424551118503200\", # Fish Creek at DB confluence (Oreg)\n           \"424547118503500\", # DB above Fish Creek (Oreg)\n           \"424325118495900\", # DB near Burnt Car Spring (Oreg)\n           \"424003118453700\", # Little Blitzen River (Oreg)\n           \"423830118453200\", # Indian Creek (Oreg)\n           \"423815118453900\" # DB above Indian Creek (Oreg)\n           )\nsiteinfo_nwis &lt;- tibble(readNWISsite(sites)[,c(2:3,7,8,20,30)]) # get site info\nnames(siteinfo_nwis) &lt;- c(\"station_no\", \"site_name\", \"lat\", \"long\", \"elev_ft\", \"area_sqmi\") # rename columns\nsiteinfo_nwis &lt;- siteinfo_nwis %&gt;% mutate(site_name = c(\"South River Conway NWIS\", \n                                                        \"Avery Broook NWIS\", \n                                                        \"West Brook NWIS\", \n                                                        \"Dugout Creek NWIS\", \n                                                        \"Shields River ab Smith NWIS\", \n                                                        \"Shields River nr Livingston NWIS\", \n                                                        \"Donner Blitzen River nr Frenchglen NWIS\", \n                                                        \"Hallowat Creek NWIS\", \n                                                        \"Big Creek NWIS\", \n                                                        \"North Fork Flathead River NWIS\", \n                                                        \"Pacific Creek at Moran NWIS\", \n                                                        \"Leidy Creek Mouth NWIS\", \n                                                        \"SF Spread Creek Lower NWIS\",\n                                                        \"Donner Blitzen ab Indian NWIS\",\n                                                        \"Indian Creek NWIS\",\n                                                        \"Little Blizten River NWIS\",\n                                                        \"Donner Blitzen nr Burnt Car NWIS\",\n                                                        \"Donner Blitzen ab Fish NWIS\",\n                                                        \"Fish Creek\"),\n                                          site_id = c(\"SRC\", \"AVB\", \"WBR\", \"DUG\", \"SRS\", \"SRL\", \"DBF\", \"HAL\", \"BIG\", \"NFF\", \"PCM\", \"LEI\", \"SFS\", \"DBI\", \"IND\", \"LBL\", \"DBB\", \"DBA\", \"FSH\"),\n                                          designation = c(\"big\", \"medium\", \"medium\", \"medium\", \"medium\", \"big\", \"big\", \"medium\", \"medium\", \"big\", \"big\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\"),\n                                          basin = c(\"West Brook\", \"West Brook\", \"West Brook\", \"Shields River\", \"Shields River\", \"Shields River\", \"Donner Blitzen\", \"Flathead\", \"Flathead\", \"Flathead\", \"Snake River\", \"Snake River\", \"Snake River\", \"Donner Blitzen\", \"Donner Blitzen\", \"Donner Blitzen\", \"Donner Blitzen\", \"Donner Blitzen\", \"Donner Blitzen\"),\n                                          region = c(\"Mass\", \"Mass\", \"Mass\", \"Shields\", \"Shields\", \"Shields\", \"Oreg\", \"Flat\", \"Flat\", \"Flat\", \"Snake\", \"Snake\", \"Snake\",\"Oreg\", \"Oreg\", \"Oreg\", \"Oreg\", \"Oreg\", \"Oreg\")) %&gt;% \n  select(site_id, site_name, lat, long, station_no, designation, basin, region, elev_ft, area_sqmi)\n#mapview(st_as_sf(siteinfo_nwis, coords = c(\"long\", \"lat\"), crs = 4326))\n\n\n# bind together, fill in ragged subbasin\nsiteinfo &lt;- bind_rows(siteinfo_wb, siteinfo_shen, siteinfo_flat, siteinfo_gya, siteinfo_nwis)\nsiteinfo$subbasin[siteinfo$site_name == \"Hallowat Creek NWIS\"] &lt;- \"Big Creek\"\nsiteinfo$subbasin[siteinfo$site_name == \"Big Creek NWIS\"] &lt;- \"Big Creek\"\nsiteinfo &lt;- siteinfo %&gt;% mutate(subbasin = ifelse(is.na(subbasin), basin, subbasin))\n\n\n# fix Shields River Valley Ranch site locations\nsiteinfo$lat[siteinfo$site_id == \"SH07\"] &lt;- siteinfo$lat[siteinfo$site_id == \"SRS\"]\nsiteinfo$long[siteinfo$site_id == \"SH07\"] &lt;- siteinfo$long[siteinfo$site_id == \"SRS\"]\n\n\n# add elevation and area variables (from watershed delineation)\nareafiles &lt;- list.files(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Area and Elevation\")\narealist &lt;- list()\nfor (i in 1:length(areafiles)) { arealist[[i]] &lt;- read_csv(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Area and Elevation/\", areafiles[i], sep = \"\"))}\nareaelev &lt;- do.call(rbind, arealist)\n# how well do provided and delineation area/elevation match?\n# siteinfo %&gt;% left_join(areaelev, by = \"site_id\") %&gt;% ggplot() + geom_point(aes(x = area_sqmi.x, y = area_sqmi.y)) + geom_abline(intercept = 0, slope = 1) + facet_wrap(~basin, scales = \"free\")\n# test %&gt;% ggplot() + geom_point(aes(x = elev_ft.x, y = elev_ft.y)) + geom_abline(intercept = 0, slope = 1) + facet_wrap(~basin, scales = \"free\")\n# add delineated variables\nsiteinfo &lt;- siteinfo %&gt;% select(-c(area_sqmi, elev_ft)) %&gt;% left_join(areaelev)\n# fix NF Flathead (no dem from Canada)\nsiteinfo$area_sqmi[siteinfo$site_id == \"NFF\"] &lt;- 1556\nWrite and re-load site information\nCode\nwrite_csv(siteinfo, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nView unique basin names\nCode\nunique(siteinfo$basin)\n\n\n[1] \"West Brook\"     \"Paine Run\"      \"Piney River\"    \"Staunton River\"\n[5] \"Flathead\"       \"Duck Creek\"     \"Shields River\"  \"Snake River\"   \n[9] \"Donner Blitzen\"\nView unique site names\nCode\nunique(siteinfo$site_name)\n\n\n  [1] \"Avery Brook\"                            \n  [2] \"Jimmy Brook\"                            \n  [3] \"Mitchell Brook\"                         \n  [4] \"Obear Brook Lower\"                      \n  [5] \"Sanderson Brook\"                        \n  [6] \"West Brook Lower\"                       \n  [7] \"West Brook Upper\"                       \n  [8] \"West Brook Reservoir\"                   \n  [9] \"West Whately Brook\"                     \n [10] \"West Brook 0\"                           \n [11] \"Paine Run 01\"                           \n [12] \"Paine Run 02\"                           \n [13] \"Paine Run 03\"                           \n [14] \"Paine Run 04\"                           \n [15] \"Paine Run 05\"                           \n [16] \"Paine Run 06\"                           \n [17] \"Paine Run 07\"                           \n [18] \"Paine Run 08\"                           \n [19] \"Paine Run 09\"                           \n [20] \"Paine Run 10\"                           \n [21] \"Piney River 01\"                         \n [22] \"Piney River 02\"                         \n [23] \"Piney River 03\"                         \n [24] \"Piney River 04\"                         \n [25] \"Piney River 05\"                         \n [26] \"Piney River 06\"                         \n [27] \"Piney River 08\"                         \n [28] \"Piney River 09\"                         \n [29] \"Piney River 10\"                         \n [30] \"Staunton River 01\"                      \n [31] \"Staunton River 02\"                      \n [32] \"Staunton River 03\"                      \n [33] \"Staunton River 04\"                      \n [34] \"Staunton River 05\"                      \n [35] \"Staunton River 06\"                      \n [36] \"Staunton River 07\"                      \n [37] \"Staunton River 08\"                      \n [38] \"Staunton River 09\"                      \n [39] \"Staunton River 10\"                      \n [40] \"BigCreekLower\"                          \n [41] \"BigCreekMiddle\"                         \n [42] \"BigCreekUpper\"                          \n [43] \"CoalCreekHeadwaters\"                    \n [44] \"CoalCreekLower\"                         \n [45] \"CoalCreekMiddle\"                        \n [46] \"CycloneCreekLower\"                      \n [47] \"CycloneCreekMiddle\"                     \n [48] \"CycloneCreekUpper\"                      \n [49] \"HallowattCreekLower\"                    \n [50] \"LangfordCreekLower\"                     \n [51] \"LangfordCreekUpper\"                     \n [52] \"McGeeCreekLower\"                        \n [53] \"McGeeCreekTrib\"                         \n [54] \"McGeeCreekUpper\"                        \n [55] \"MeadowCreek\"                            \n [56] \"NicolaCreek\"                            \n [57] \"CoalCreekNorth\"                         \n [58] \"SkookoleelCreek\"                        \n [59] \"WernerCreek\"                            \n [60] \"WoundedBuckCreek\"                       \n [61] \"EF Duck Creek be HF\"                    \n [62] \"EF Duck Creek ab HF\"                    \n [63] \"Henrys Fork\"                            \n [64] \"Brackett Creek\"                         \n [65] \"Buck Creek\"                             \n [66] \"Crandall Creek\"                         \n [67] \"Deep Creek\"                             \n [68] \"Dugout Creek\"                           \n [69] \"Lodgepole Creek\"                        \n [70] \"Shields River Valley Ranch\"             \n [71] \"Shields River ab Dugout\"                \n [72] \"Grizzly Creek\"                          \n [73] \"Grouse Creek\"                           \n [74] \"Leidy Creek Lower\"                      \n [75] \"Leidy Creek Upper\"                      \n [76] \"Leidy Creek Mouth\"                      \n [77] \"NF Spread Creek Lower\"                  \n [78] \"NF Spread Creek Upper\"                  \n [79] \"Rock Creek\"                             \n [80] \"SF Spread Creek Lower\"                  \n [81] \"SF Spread Creek Upper\"                  \n [82] \"Spread Creek Dam\"                       \n [83] \"South River Conway NWIS\"                \n [84] \"Avery Broook NWIS\"                      \n [85] \"West Brook NWIS\"                        \n [86] \"Dugout Creek NWIS\"                      \n [87] \"Shields River ab Smith NWIS\"            \n [88] \"Shields River nr Livingston NWIS\"       \n [89] \"Donner Blitzen River nr Frenchglen NWIS\"\n [90] \"Hallowat Creek NWIS\"                    \n [91] \"Big Creek NWIS\"                         \n [92] \"North Fork Flathead River NWIS\"         \n [93] \"Pacific Creek at Moran NWIS\"            \n [94] \"Leidy Creek Mouth NWIS\"                 \n [95] \"SF Spread Creek Lower NWIS\"             \n [96] \"Donner Blitzen ab Indian NWIS\"          \n [97] \"Indian Creek NWIS\"                      \n [98] \"Little Blizten River NWIS\"              \n [99] \"Donner Blitzen nr Burnt Car NWIS\"       \n[100] \"Donner Blitzen ab Fish NWIS\"            \n[101] \"Fish Creek\"\nMap sites\nCode\n# convert to spatial object and view on map\n#| fig-cap: \"Map of EcoDrought project locations\"\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#load-ecod-data",
    "href": "Data Availability/CollateData.html#load-ecod-data",
    "title": "2  Collate Data",
    "section": "2.2 Load EcoD data",
    "text": "2.2 Load EcoD data\n\n\nCode\n# West Brook\ndat_wb &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Mass/EcoDrought Continuous_MA.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_Name = factor(Site_Name)) %&gt;%\n  rename(station_no = Station_No, site_name = Site_Name, datetime = DateTime_EST, height = GageHeight_Hobo_ft, flow = Discharge_Hobo_cfs, tempf = WaterTemperature_HOBO_DegF) %&gt;%\n  mutate(tempc = (tempf - 32)*(5/9)) %&gt;% select(station_no, site_name, datetime, height, flow, tempc) %&gt;%\n  left_join(siteinfo %&gt;% select(-station_no)) \n\n\n# Shenandoah\ndat_shen &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/EcoDrought_Continuous_VA.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_ID = factor(Site_ID), Discharge_Hobo_cfs = as.numeric(Discharge_Hobo_cfs)) %&gt;%\n  rename(station_no = Station_No, site_id = Site_ID, datetime = DateTime_EST, height = GageHeight_Hobo_ft, flow = Discharge_Hobo_cfs, tempf = WaterTemperature_HOBO_DegF) %&gt;%\n  mutate(tempc = (tempf - 32)*(5/9)) %&gt;% select(station_no, site_id, datetime, height, flow, tempc) %&gt;%\n  left_join(siteinfo)\n# pull in Big G data separately (UVA long-term gage sites)\ndat_shen_uva_q &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/Shen_BigG_Discharge_hourly_UVA.csv\") %&gt;%\n  rename(flow = cfs)\ndat_shen_uva_t &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/Shen_BigG_TempEtc_hourly_UVA.csv\") %&gt;%\n  select(site_id, datetime, tempc_mean) %&gt;% rename(tempc = tempc_mean)\ndat_shen_uva &lt;- dat_shen_uva_q %&gt;% left_join(dat_shen_uva_t) %&gt;% left_join(siteinfo)\n# bind usgs and uva data\ndat_shen &lt;- bind_rows(dat_shen, dat_shen_uva)\n\n\n# Flathead/Muhlfeld\nflatfiles &lt;- list.files(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Flathead/Export2/EMA/Continuous Data\")\nflatlist &lt;- list()\nfor (i in 1:length(flatfiles)) { \n  #print(flatfiles[i])\n  flatlist[[i]] &lt;- read_csv(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Flathead/Export2/EMA/Continuous Data/\", flatfiles[i], sep = \"\")) %&gt;%\n    mutate(DateTime = mdy_hm(DateTime, tz = \"MST\"),\n           site_name = gsub(\"EMA.csv\", \"\", flatfiles[i]))\n  }\ndat_flat &lt;- bind_rows(flatlist) %&gt;% select(DateTime, GageHeightFT, DischargeCFS, TempF, TempC, site_name, DischargeReliability, TempReliability) %&gt;% \n  rename(datetime = DateTime, height = GageHeightFT, flow = DischargeCFS, tempf = TempF, tempc = TempC) %&gt;%\n  mutate(DischargeReliability = as_factor(DischargeReliability),\n         TempReliability = as_factor(TempReliability)) %&gt;%\n  mutate(tempf = ifelse(is.na(tempf), (tempc * (9/5)) + 32, tempf),\n         tempc = ifelse(is.na(tempc), (tempf - 32) * (5/9), tempc)) %&gt;%\n  left_join(siteinfo) %&gt;% select(-tempf)\n\n\n# Greater Yellowstone/Al-Chokhachy\ngyafiles &lt;- list.files(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/Al-Chokhachy data files\")\ngyalist &lt;- list()\nfor (i in 1:length(gyafiles)) { \n  #print(gyafiles[i])\n  gyalist[[i]] &lt;- read_csv(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/Al-Chokhachy data files/\", gyafiles[i], sep = \"\")) %&gt;%\n    mutate(date = mdy(date), DateTime = ymd_hms(paste(date, time, sep = \" \"), tz = \"MST\"), discharge = as.numeric(discharge)*35.314666212661)\n}\ndat_gya &lt;- bind_rows(gyalist) %&gt;% select(DateTime, depth, discharge, temperature, location) %&gt;% \n  rename(datetime = DateTime, height = depth, flow = discharge, tempc = temperature, site_name = location) %&gt;%\n  filter(site_name != \"EF Henrys\") %&gt;% # drop weird duplicate site/year?\n  mutate(site_name = dplyr::recode(site_name,\n                            \"EF Above Confluence\" = \"EF Duck Creek ab HF\",\n                            \"EF Below Confluence\" = \"EF Duck Creek be HF\",\n                            \"NF Spread Creek\" = \"NF Spread Creek Lower\",\n                            \"Upper NF Spread Creek\" = \"NF Spread Creek Upper\",\n                            \"SF Spread Creek\" = \"SF Spread Creek Lower\",\n                            \"Upper SF Spread Creek\" = \"SF Spread Creek Upper\",\n                            \"Shields River above Dugout Creek\" = \"Shields River ab Dugout\",\n                            \"Upper Leidy Creek\" = \"Leidy Creek Upper\", \n                            \"Leidy Creek\" = \"Leidy Creek Mouth\",\n                            \"Spread Creek\" = \"Spread Creek Dam\",\n                            \"Shields River above Smith Creek\" = \"Shields River Valley Ranch\")) %&gt;%\n  left_join(siteinfo) %&gt;% filter(tempc &lt;= 100)\n\n\nBind EcoD hourly flow/temp data with siteinfo and write to file\n\n\nCode\n# bind together\ndat &lt;- bind_rows(dat_wb, dat_shen, dat_flat, dat_gya)\n# unique(dat$site_name)\nwrite_csv(dat, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_Raw.csv\")\ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_Raw.csv\")\n\n\nCheck unique designations\n\n\nCode\nunique(dat$designation)\n\n\n[1] \"little\" \"big\"   \n\n\nCheck unique regions\n\n\nCode\nunique(dat$region)\n\n\n[1] \"Mass\"    \"Shen\"    \"Flat\"    \"Shields\" \"Snake\"  \n\n\nCheck unique basins\n\n\nCode\nunique(dat$basin)\n\n\n[1] \"West Brook\"     \"Paine Run\"      \"Staunton River\" \"Piney River\"   \n[5] \"Flathead\"       \"Shields River\"  \"Duck Creek\"     \"Snake River\"   \n\n\nCheck unique subbasins\n\n\nCode\nunique(dat$subbasin)\n\n\n [1] \"West Brook\"         \"Paine Run\"          \"Staunton River\"    \n [4] \"Piney River\"        \"Big Creek\"          \"Coal Creek\"        \n [7] \"McGee Creek\"        \"Wounded Buck Creek\" \"Shields River\"     \n[10] \"Duck Creek\"         \"Snake River\"       \n\n\n\n2.2.1 Inspect hourly data\n\n2.2.1.1 West Brook\nJoin data update\n\n\nCode\ndat_wb_new &lt;- dat_wb %&gt;%\n  bind_rows(read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Mass/EcoDrought Continuous_MA_updateDec2024.csv\") %&gt;% \n            rename(datetime = TimeStamp) %&gt;%\n            gather(key = \"station_no\", value = \"flow\", 2:9) %&gt;% \n            mutate(datetime = as_datetime(datetime),\n                   station_no = factor(sub(\".*Discharge@\", \"\", station_no))) %&gt;% \n            left_join(siteinfo %&gt;% mutate(station_no = factor(station_no))))\n\n\n\nAveryJimmyMitchellObearSandersonWB0WB LowerWB ReservoirWB UpperWest Whateley\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"Avery Brook\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"Jimmy Brook\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"Mitchell Brook\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"Obear Brook Lower\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"Sanderson Brook\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"West Brook 0\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"West Brook Lower\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"West Brook Reservoir\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"West Brook Upper\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndat_wb_new %&gt;% filter(site_name == \"West Whately Brook\") %&gt;% select(datetime, flow) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5) %&gt;% dyEvent(x = as_datetime(\"2021/10/01 00:00:00\"))\n\n\n\n\n\n\n\n\n\n\n\n2.2.1.2 Flathead\n\n\nCode\nmysites &lt;- unlist(unique(dat %&gt;% filter(basin == \"Flathead\") %&gt;% select(site_name)))\nmyplots &lt;- list()\nfor (i in 1:length(mysites)) {\n  test &lt;- dat %&gt;% filter(site_name == mysites[i]) %&gt;% select(datetime, flow, DischargeReliability) %&gt;% spread(key = DischargeReliability, value = flow) %&gt;% arrange(datetime) %&gt;% mutate(mindiff = as.numeric(lead(datetime) - (datetime)))\nna_index &lt;- which(test$mindiff &gt; 60)\n  ds_blank &lt;- tibble(index = na_index + 0.5, datetime = NA, \"0\" = NA, \"1\" = NA)\n  myplots[[i]] &lt;- test %&gt;% select(-mindiff) %&gt;% rowid_to_column(\"index\") %&gt;% union(ds_blank) %&gt;% arrange(index) %&gt;% select(-index) %&gt;% mutate(datetime = if_else(is.na(datetime), lag(datetime) + hours(1), datetime)) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n}\n\n\n\nBigCreekLowerBigCreekMiddleBigCreekUpperCoalCreekHeadwatersCoalCreekLowerCoalCreekMiddleCoalCreekNorthCycloneCreekLowerCycloneCreekMidddleCycloneCreekUpperHallowattCreekLowerLangfordCreekLowerLangfordCreekUpperMcGeeCreekLowerMcGeeCreekTribMcGeeCreekUpperMeadowCreekNicolaCreekSkookoleelCreekWernerCreekWoundedBuckCreek",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#load-nwis-data",
    "href": "Data Availability/CollateData.html#load-nwis-data",
    "title": "2  Collate Data",
    "section": "2.3 Load NWIS data",
    "text": "2.3 Load NWIS data\n\n\nCode\n# extract daily mean discharge and temp data from USGS NWIS website\ndat_superg_nwis &lt;- tibble(readNWISdv(siteNumbers = sites, parameterCd = c(\"00010\", \"00060\"), startDate = \"1980-01-01\", endDate = Sys.Date(), statCd = c(\"00003\", \"00001\", \"00002\")))[,-c(1,5,7,9,11)]\nnames(dat_superg_nwis) &lt;- c(\"station_no\", \"date\", \"tempc_max\", \"tempc_min\", \"tempc_mean\", \"flow_mean\")\ndat_superg_nwis &lt;- dat_superg_nwis %&gt;% left_join(siteinfo %&gt;% filter(designation %in% c(\"big\", \"medium\")))\n\n# Manually grab Donner Blitzen above Indian Creek at the original timescale\n# daily mean flow dropped from above query, perhaps b/c in 2020 flow measurements were made every minute\ndbabind &lt;- tibble(readNWISdata(sites = \"423815118453900\", service = \"uv\", startDate = \"1980-01-01\", endDate = Sys.Date()))[,c(2,3,6)] \ndbabind_daily &lt;- dbabind %&gt;% group_by(site_no, date(dateTime)) %&gt;% summarize(nobs = n(), flow_mean = mean(X_00060_00000)) %&gt;% filter(nobs %in% c(96, 1440)) %&gt;% select(c(1,2,4))\nnames(dbabind_daily) &lt;- c(\"station_no\", \"date\", \"flow_mean\") \ndbabind_daily &lt;- dat_superg_nwis %&gt;% filter(station_no == \"423815118453900\") %&gt;% select(-flow_mean) %&gt;% left_join(dbabind_daily)\n\n# bind DBabInd to reset of data\ndat_superg_nwis &lt;- rbind(dat_superg_nwis %&gt;% filter(station_no != \"423815118453900\"), dbabind_daily)\n\n\n\n\nCode\ndat_superg_nwis %&gt;% filter(designation == \"big\") %&gt;% ggplot() + geom_line(aes(x = date, y = log(flow_mean))) + facet_wrap(~site_name)\n\n\n\n\n\n(log) Stream flow (cfs) for Big G NWIS gages\n\n\n\n\n\n\nCode\ndat_superg_nwis %&gt;% filter(designation == \"medium\") %&gt;% ggplot() + geom_line(aes(x = date, y = log(flow_mean))) + facet_wrap(~site_name)\n\n\n\n\n\n(log) Stream flow (cfs) for Medium G NWIS gages",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#bind-data-and-calc.-daily-means",
    "href": "Data Availability/CollateData.html#bind-data-and-calc.-daily-means",
    "title": "2  Collate Data",
    "section": "2.4 Bind data and calc. daily means",
    "text": "2.4 Bind data and calc. daily means\n\n\nCode\n# daily flow/temp summaries\ndat_daily &lt;- dat %&gt;% mutate(date = as_date(datetime)) %&gt;% \n  group_by(station_no, site_name, site_id, basin, subbasin, region, lat, long, elev_ft, area_sqmi, designation, date) %&gt;% \n  summarize(disch_reli = max(DischargeReliability),\n            temp_reli = max(TempReliability),\n            flow_mean = mean(flow), flow_min = min(flow), flow_max = max(flow),\n            tempc_mean = mean(tempc), tempc_min = min(tempc), tempc_max = max(tempc)) %&gt;%\n  arrange(region, basin, site_name, date) %&gt;%\n  ungroup()\n\n# cbind EcoD and NWIS datasets\ndat_daily &lt;- bind_rows(dat_daily %&gt;% select(-flow_min, -flow_max, -tempc_min, -tempc_max), \n                       dat_superg_nwis %&gt;% select(-tempc_max, -tempc_min),\n                       dat_superg_nwis %&gt;% filter(site_id == \"SRL\") %&gt;% mutate(subbasin = \"Duck Creek\") %&gt;% select(-tempc_max, -tempc_min))\n\n# add missing dates\ndat_daily &lt;- fill_missing_dates(dat_daily, dates = date, groups = site_name)\n\n\nView daily mean time series data, for example, site_name = CoalCreekLower. Notice the many shorts gaps in the daily data.\n\n\nCode\nlibrary(dygraphs)\ndat_daily %&gt;% filter(site_name == \"CoalCreekLower\") %&gt;% select(date, flow_mean) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Mean daily flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#interpolate-missing-data",
    "href": "Data Availability/CollateData.html#interpolate-missing-data",
    "title": "2  Collate Data",
    "section": "2.5 Interpolate missing data",
    "text": "2.5 Interpolate missing data\nSmall periods of missing data (&lt;24 hours) become a problem when aggregating at the daily and weekly time scales. *Note that currently this discovers and fills missing data at the daily time scale, but should be changed to interpolate at the original timescale of the raw data (e.g., hourly).\n\n\nCode\n# explore data gaps\nmysites &lt;- unique(dat_daily$site_name)\nmynas &lt;- list()\nfor (i in 1:length(mysites)) {\n  mydisch &lt;- unlist(dat_daily$flow_mean[dat_daily$site_name == mysites[i]])\n  runsna &lt;- rle(is.na(mydisch))\n  mynas[[i]] &lt;- tibble(site_name = mysites[i], run = runsna$lengths[runsna$values == TRUE])\n}\nmynas &lt;- do.call(rbind, mynas)\n# mynas %&gt;% filter(run &lt; 100) %&gt;% ggplot() + geom_histogram(aes(x = run)) + facet_wrap_paginate(~site_name, nrow = 4, ncol = 4, page = 1)\n# mynas %&gt;% filter(run &lt; 100) %&gt;% ggplot() + geom_histogram(aes(x = run)) + facet_wrap_paginate(~site_name, nrow = 4, ncol = 4, page = 2)\n# mynas %&gt;% filter(run &lt; 100) %&gt;% ggplot() + geom_histogram(aes(x = run)) + facet_wrap_paginate(~site_name, nrow = 4, ncol = 4, page = 3)\n# mynas %&gt;% filter(run &lt; 100) %&gt;% ggplot() + geom_histogram(aes(x = run)) + facet_wrap_paginate(~site_name, nrow = 4, ncol = 4, page = 4)\n\n\nMost gaps are relatively short\n\n\nCode\nmynas %&gt;% ggplot() + geom_histogram(aes(x = run)) + xlab(\"Days\") + ylab(\"Frequency\")\n\n\n\n\n\nDistributiion of lengths of missing data (days)\n\n\n\n\nZoomed in…\n\n\nCode\nmynas %&gt;% filter(run &lt; 30) %&gt;% ggplot() + geom_histogram(aes(x = run))  + xlab(\"Days\") + ylab(\"Frequency\")\n\n\n\n\n\nDistributiion of lengths of missing data (days)\n\n\n\n\nConsidering just the short gaps, which are likely a function of logger malfunction or Aquarius export issues, which sites are problematic? Answer: Flathead\n\n\nCode\nmynas %&gt;% filter(run &lt; 30) %&gt;% ggplot() + geom_bar(aes(site_name))+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\nFrequency of short (&lt;40 days) data gaps by site\n\n\n\n\nFill short gaps (&lt;=14 days…2x smoothing period) using time series interpolation\n\n\nCode\n# fill short gaps (&lt;=14 days...2x smoothing period) using time series interpolation\ndatalist &lt;- list()\nfor (i in 1:length(mysites)) { datalist[[i]] &lt;- dat_daily %&gt;% filter(site_name == mysites[i]) %&gt;% mutate(flow_mean_filled = fillMissing(flow_mean, max.fill = 14, span = 100)) }\n# bind and check 1:1\ndat_daily_fill &lt;- do.call(rbind, datalist)\n# dat_daily_fill %&gt;% ggplot() + geom_point(aes(x = flow_mean, y = flow_mean_filled)) + facet_wrap(~site_name, scales = \"free\")\n\n\nExplore interpolated/filled time series relative to original (daily) data Again, CoalCreekLower as an example. Would like to replace with shiny/interactive app\n\n\nCode\nlibrary(dygraphs)\ndat_daily_fill %&gt;% filter(site_name == \"CoalCreekLower\") %&gt;% select(date, flow_mean, flow_mean_filled) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dySeries(\"flow_mean\", strokeWidth = 5, color = \"black\") %&gt;% dySeries(\"flow_mean_filled\", strokeWidth = 1, color = \"red\") %&gt;% dyAxis(\"y\", label = \"Mean daily flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#calculate-yield",
    "href": "Data Availability/CollateData.html#calculate-yield",
    "title": "2  Collate Data",
    "section": "2.6 Calculate yield",
    "text": "2.6 Calculate yield\n\n\nCode\n# convert cfs and basin area to metric\ndat_daily_fill &lt;- dat_daily_fill %&gt;% mutate(flow_mean_cms = flow_mean*0.02831683199881, \n                                            flow_mean_filled_cms = flow_mean_filled*0.02831683199881, \n                                            area_sqkm = area_sqmi*2.58999)\n\n# sites\nsites &lt;- unique(dat_daily_fill$site_name)\n\n# site-specific basin area in square km\nbasinarea &lt;- dat_daily_fill %&gt;% filter(!is.na(site_id)) %&gt;% group_by(site_name) %&gt;% summarize(area_sqkm = unique(area_sqkm))\n\n# calculate yield\nyield_list &lt;- list()\nfor (i in 1:length(sites)) {\n  d &lt;- dat_daily_fill %&gt;% filter(site_name == sites[i])\n  ba &lt;- unlist(basinarea %&gt;% filter(site_name == sites[i]) %&gt;% select(area_sqkm))\n  yield_list[[i]] &lt;-  add_daily_yield(data = d, values = flow_mean_cms, basin_area = as.numeric(ba)) %&gt;% left_join(add_daily_yield(data = d, values = flow_mean_filled_cms, basin_area = as.numeric(ba)) %&gt;% rename(Yield_filled_mm = Yield_mm))\n}\ndat_daily_fill_wyield &lt;- do.call(rbind, yield_list)",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#calculate-7-day-means",
    "href": "Data Availability/CollateData.html#calculate-7-day-means",
    "title": "2  Collate Data",
    "section": "2.7 Calculate 7-day means",
    "text": "2.7 Calculate 7-day means\n\n\nCode\ndat_daily_fill_wyield &lt;- dat_daily_fill_wyield %&gt;%\n  group_by(site_name) %&gt;%\n  mutate(flow_mean_7 = rollapply(flow_mean, FUN = mean, width = 7, align = \"center\", fill = NA),\n         flow_mean_filled_7 = rollapply(flow_mean_filled, FUN = mean, width = 7, align = \"center\", fill = NA),\n         tempc_mean_7 = rollapply(tempc_mean, FUN = mean, width = 7, align = \"center\", fill = NA),\n         Yield_mm_7 = rollapply(Yield_mm, FUN = mean, width = 7, align = \"center\", fill = NA),\n         Yield_filled_mm_7 = rollapply(Yield_filled_mm, FUN = mean, width = 7, align = \"center\", fill = NA)) %&gt;%\n  ungroup() %&gt;% filter(!is.na(site_id))\n\n# # view flow\n# dat_daily_fill_wyield %&gt;% filter(site_name == \"Avery Brook\") %&gt;% select(date, flow_mean_filled, flow_mean_filled_7) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% \n#   dySeries(\"flow_mean_filled\", strokeWidth = 5, color = \"black\") %&gt;% dySeries(\"flow_mean_filled_7\", strokeWidth = 1, color = \"red\")\n# \n# # view yield\n# dat_daily_fill_wyield %&gt;% filter(site_name == \"Avery Brook\") %&gt;% select(date, Yield_filled_mm, Yield_filled_mm_7) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% \n#   dySeries(\"Yield_filled_mm\", strokeWidth = 5, color = \"black\") %&gt;% dySeries(\"Yield_filled_mm_7\", strokeWidth = 1, color = \"red\")\n\n# unique(dat_daily_fill_wyield$basin)\n# unique(dat_daily_fill_wyield$subbasin)\n# unique(dat_daily_fill_wyield$region)\n# unique(dat_daily_fill_wyield$disch_reli)\n# unique(dat_daily_fill_wyield$temp_reli)\n\n\nView little and medium g time series data (7-day mean yield), by sub-basin. Use the handles below the x-axis to adjust the time frame.\n\n\nCode\nmysubbasins &lt;- unique(dat_daily_fill_wyield$subbasin)[-c(4,7,13)]\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  myplots[[i]] &lt;- dat_daily_fill_wyield %&gt;% filter(designation %in% c(\"little\", \"medium\"), subbasin == mysubbasins[i]) %&gt;% mutate(logYield = log(Yield_filled_mm_7)) %&gt;% select(date, site_name, logYield) %&gt;% spread(key = site_name, value = logYield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"ln(Yield, mm)\")\n}\n\n\n\nBig CreekCoal CreekMcGee CreekWest BrookPaine RunStaunton RiverDuck CreekShields RiverSnake RiverDonner Blitzen",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#write-out-and-read-data",
    "href": "Data Availability/CollateData.html#write-out-and-read-data",
    "title": "2  Collate Data",
    "section": "2.8 Write out and read data",
    "text": "2.8 Write out and read data\n\n\nCode\n# write out\nwrite_csv(dat_daily_fill_wyield, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\")\ndat_daily &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#view-data-availability",
    "href": "Data Availability/CollateData.html#view-data-availability",
    "title": "2  Collate Data",
    "section": "2.9 View data availability",
    "text": "2.9 View data availability\n\n\nCode\n# summarize data availability\ndat_summ &lt;- dat_daily %&gt;% filter(site_id != \"MRN\") %&gt;%\n  group_by(basin, date, designation) %&gt;% summarize(numflow = sum(!is.na(flow_mean)), numtemp = sum(!is.na(tempc_mean))) %&gt;% \n  gather(type, avail, numflow:numtemp) %&gt;% mutate(type2 = as.factor(paste(designation, type, sep = \"_\"))) %&gt;% \n  mutate(type3 = as.numeric(type2), avail = na_if(avail, 0)) %&gt;% ungroup() %&gt;% filter(!is.na(avail))\n# levels(dat_summ$type2)\n# unique(dat_summ$basin)\n\n\n\n\nCode\n# plot all years\n#| fig-cap: \"Data availability by basin, all years\"\nmyplot &lt;- dat_summ %&gt;% ggplot(aes(x = date, y = type3)) + \n  geom_errorbarh(aes(xmax = date, xmin = date, color = avail), size = 0.001) +\n  scale_color_continuous(trans = \"reverse\", na.value = \"grey60\") +\n  scale_y_discrete(limits = c(\"Big G flow\", \"Big G temp\", \"Medium g flow\", \"Medium g temp\", \"Little g flow\", \"Little g temp\")) + \n  labs(colour = \"Number \\nof sites\") + ylab(\"\") + xlab(\"Date\") + \n  facet_wrap(~ basin, nrow = 4,\n             labeller = as_labeller(c(`West Brook` = \"West Brook: G = South River Conway (NWIS)\", \n                                      `Staunton River` = \"Staunton River: G = Staunton River 10 (UVA)\",\n                                      `Paine Run` = \"Paine Run: G = Paine Run 10 (UVA)\",\n                                      `Piney River` = \"Piney River: G = Piney River 10 (UVA)\",\n                                      `Snake River` = \"Snake River: G = Pacific Creek Moran (NWIS)\",\n                                      `Shields River` = \"Shields River: G = Shields River Livingston (NWIS)\",\n                                      `Flathead` = \"NF Flathead River: G = NF Flathead (NWIS)\",\n                                      `Donner Blitzen` = \"Donner Blitzen River: G = DB Frenchglen (NWIS)\",\n                                      `Duck Creek` = \"Duck Creek: G = Shields River Livingston (NWIS)\")))\nmyplot\n\n\n\n\n\n\n\n\n\nCode\n# jpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Data Availability/DataAvailability_byBasin.jpg\", height = 6, width = 12, units = \"in\", res = 500)\n# myplot\n# dev.off()\n\n\n\n\nCode\n# plot recent years\n#| fig-cap: \"Data availability by basin, recent years\"\n# jpeg(\"./Data Availability/DataAvailability_byBasin_recent.jpg\", height = 6, width = 12, units = \"in\", res = 500)\nmyplot &lt;- dat_summ %&gt;% filter(date &gt;= \"2018-10-01\") %&gt;% ggplot(aes(x = date, y = type3)) + \n  geom_errorbarh(aes(xmax = date, xmin = date, color = avail), size = 0.001) +\n  scale_color_continuous(trans = \"reverse\", na.value = \"grey60\") +\n  scale_y_discrete(limits = c(\"Big G flow\", \"Big G temp\", \"Medium g flow\", \"Medium g temp\", \"Little g flow\", \"Little g temp\")) + \n  labs(colour = \"Number \\nof sites\") + ylab(\"\") + xlab(\"Date\") + \n  facet_wrap(~ basin, nrow = 4,\n             labeller = as_labeller(c(`West Brook` = \"West Brook: G = South River Conway (NWIS)\", \n                                      `Staunton River` = \"Staunton River: G = Staunton River 10 (UVA)\",\n                                      `Paine Run` = \"Paine Run: G = Paine Run 10 (UVA)\",\n                                      `Piney River` = \"Piney River: G = Piney River 10 (UVA)\",\n                                      `Snake River` = \"Snake River: G = Pacific Creek Moran (NWIS)\",\n                                      `Shields River` = \"Shields River: G = Shields River Livingston (NWIS)\",\n                                      `Flathead` = \"NF Flathead River: G = NF Flathead (NWIS)\",\n                                      `Donner Blitzen` = \"Donner Blitzen River: G = DB Frenchglen (NWIS)\",\n                                      `Duck Creek` = \"Duck Creek: G = Shields River Livingston (NWIS)\")))\nmyplot",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#compare-co-located-gages",
    "href": "Data Availability/CollateData.html#compare-co-located-gages",
    "title": "2  Collate Data",
    "section": "2.10 Compare co-located gages",
    "text": "2.10 Compare co-located gages\n\n2.10.1 Compare synchronous gages\nCompare streamflow data from co-located EcoDrought and NWIS gages with overlapping periods of record\n\n\nCode\n# WEST BROOK\np1 &lt;- dat_daily %&gt;% filter(site_name == \"West Brook 0\") %&gt;% select(date, flow_mean_7) %&gt;% rename(little = flow_mean_7) %&gt;% \n  left_join(dat_daily %&gt;% filter(site_name == \"West Brook NWIS\") %&gt;% select(date, flow_mean_7) %&gt;% rename(medium = flow_mean_7)) %&gt;%\n  ggplot() + geom_point(aes(x = log(medium), y = log(little))) + geom_abline(intercept = 0, slope = 1, color = \"red\")\n\np2 &lt;- dat_daily %&gt;% filter(site_name == \"Avery Brook\") %&gt;% select(date, flow_mean_7) %&gt;% rename(little = flow_mean_7) %&gt;% \n  left_join(dat_daily %&gt;% filter(site_name == \"Avery Broook NWIS\") %&gt;% select(date, flow_mean_7) %&gt;% rename(medium = flow_mean_7)) %&gt;%\n  ggplot() + geom_point(aes(x = log(medium), y = log(little))) + geom_abline(intercept = 0, slope = 1, color = \"red\")\n\n# FLATHEAD\np3 &lt;- dat_daily %&gt;% filter(site_name == \"BigCreekMiddle\") %&gt;% select(date, flow_mean_7) %&gt;% rename(little = flow_mean_7) %&gt;% \n  left_join(dat_daily %&gt;% filter(site_name == \"Big Creek NWIS\") %&gt;% select(date, flow_mean_7) %&gt;% rename(medium = flow_mean_7)) %&gt;%\n  ggplot() + geom_point(aes(x = log(medium), y = log(little))) + geom_abline(intercept = 0, slope = 1, color = \"red\")\n\n# jpeg(\"./Data Availability/LittleMedium_Co-Located_Gages.jpg\", height = 6, width = 6, units = \"in\", res = 500)\nggarrange(p1, p2, p3, ncol = 2, nrow = 2, labels = c(\"West Brook 0\", \"Avery Brook\", \"Big Creek (Flathead)\"))\n\n\n\n\n\nStreamflow measured at little g gages (EcoDrought) as a function of streamflow measured at medium g gages (NWIS), on a log-scale. Red line denotes 1:1\n\n\n\n\nCode\n# dev.off()\n\n\n\n\n2.10.2 Compare asynchronous gages\nFor Spread Creek and Shields River, compare data from co-located EcoDrought and NWIS gages, with NON-overlapping periods of record. Note that streamflow from NWIS gages is about ~1 order of magnitude greater than what is measured at EcoD gages.\n\nLeidy CreekSF Spread Creek LowerDugout CreekSheilds Valley Ranch",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html",
    "href": "Explore Data/ExploreData.html",
    "title": "3  Explore Long-Term Data",
    "section": "",
    "text": "3.1 Site info and daily data\nPurpose: Explore (long-term) data and (recent) climatic context of EcoD years\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# flow (and temp) data\ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html#daymet-air-temp-and-precip",
    "href": "Explore Data/ExploreData.html#daymet-air-temp-and-precip",
    "title": "3  Explore Long-Term Data",
    "section": "3.2 Daymet air temp and precip",
    "text": "3.2 Daymet air temp and precip\n\n\nCode\nmycols &lt;- brewer.pal(6, \"Dark2\")\nsiteinfo_big &lt;- siteinfo %&gt;% filter(designation == \"big\")\n\n# download point location Daymet data\nclimlist &lt;- vector(\"list\", length = dim(siteinfo_big)[1])\nfor (i in 1:dim(siteinfo_big)[1]) {\n  clim &lt;- download_daymet(site = siteinfo_big$site_name[i], lat = siteinfo_big$lat[i], lon = siteinfo_big$long[i], start = 1980, end = 2023, internal = T)\n  climlist[[i]] &lt;- tibble(clim$data) %&gt;% \n    mutate(air_temp_mean = (tmax..deg.c. + tmin..deg.c.)/2, \n           date = as.Date(paste(year, yday, sep = \"-\"), \"%Y-%j\"),\n           site_name = siteinfo_big$site_name[i]) %&gt;%\n    select(12,2,11,10,4,6) %&gt;% rename(precip_mmday = 5, swe_kgm2 = 6)\n  #print(i)\n}\n\n# combine and calculate 7-day moving averages\nclimdf &lt;- do.call(rbind, climlist) %&gt;% left_join(siteinfo_big) %&gt;% mutate(year = year(date)) %&gt;% \n  group_by(station_no, site_name, site_id, basin, region, lat, long, elev_ft, area_sqmi, designation) %&gt;%\n  mutate(air_mean_7 = rollapply(air_temp_mean, FUN = mean, width = 7, align = \"center\", fill = NA),\n         precip_mean_7 = rollapply(precip_mmday, FUN = mean, width = 7, align = \"center\", fill = NA),\n         swe_mean_7 = rollapply(swe_kgm2, FUN = mean, width = 7, align = \"center\", fill = NA)) %&gt;%\n  ungroup() \n\n# trim to Big G sites\nclimdf_big &lt;- climdf %&gt;% filter(designation == \"big\")\n\n\nView long-term trends in mean annual air temperature, by basin\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Daymet_AirTemp_AnnualTrend_BigG.jpg\", height = 8, width = 8, units = \"in\", res = 500)\nclimdf_big_summ &lt;- climdf_big %&gt;% group_by(site_name, year) %&gt;% summarize(anntemp = mean(air_temp_mean)) %&gt;% ungroup()\nclimdf_big_summ %&gt;% \n  ggplot(aes(x = year, y = anntemp)) + geom_point() + facet_wrap(~site_name) + \n  geom_smooth(method = \"lm\", se = TRUE) + xlab(\"Year\") + ylab(\"Mean annual air temperature (deg C)\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nView long-term trends in total annual precipitation, by basin\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Daymet_AirTemp_AnnualTrend_BigG.jpg\", height = 8, width = 8, units = \"in\", res = 500)\nclimdf_big_summ &lt;- climdf_big %&gt;% group_by(site_name, year) %&gt;% summarize(annprec = sum(precip_mmday)) %&gt;% ungroup()\nclimdf_big_summ %&gt;% \n  ggplot(aes(x = year, y = annprec)) + geom_point() + facet_wrap(~site_name) + \n  geom_smooth(method = \"lm\", se = TRUE) + xlab(\"Year\") + ylab(\"Total annual precipitaion (mm)\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nView annual air temperature time series\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Daymet_AirTemp_Regime_BigG.jpg\", height = 8, width = 8, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = climdf_big, aes(x = yday, y = air_mean_7, group = year, color = year), size = 0.2) +\n  facet_wrap(~ site_name) + xlab(\"Day of year\") + ylab(\"7-day mean air temperature (deg C)\") + \n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nView annual air temperature time series, highlight recent years\n\n\nCode\nclimdf_big_recent &lt;- climdf_big %&gt;% filter(year %in% c(2018:2023))\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Daymet_AirTemp_Regime_BigG_Recent.jpg\", height = 8, width = 8, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = climdf_big, aes(x = yday, y = air_mean_7, group = year), color = \"grey70\", size = 0.25) +\n  geom_line(data = climdf_big_recent, aes(x = yday, y = air_mean_7, group = as.factor(year), color = as.factor(year))) +\n  scale_colour_manual(values = mycols) + facet_wrap(~ site_name) +\n  xlab(\"Day of year\") + ylab(\"7-day mean air temperature\") + \n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html#big-g-temp-flow-and-yield",
    "href": "Explore Data/ExploreData.html#big-g-temp-flow-and-yield",
    "title": "3  Explore Long-Term Data",
    "section": "3.3 Big G temp, flow, and yield",
    "text": "3.3 Big G temp, flow, and yield\n\n\nCode\ndat_daily_G &lt;- dat %&gt;% filter(designation == \"big\", site_name != \"West Brook 0\") %&gt;% mutate(yday = yday(date), year = year(date))\ndat_daily_G_recent &lt;- dat_daily_G %&gt;% filter(year %in% c(2018:2023))\nyear_range &lt;- dat_daily_G %&gt;% group_by(site_name) %&gt;% summarize(minyear = min(year), maxyear = max(year)) %&gt;% mutate(yearrange = paste(minyear, maxyear, sep = \"-\"))\nmycols &lt;- brewer.pal(6, \"Dark2\")\ndat_daily_G %&gt;% group_by(site_name) %&gt;% summarize(mindate = min(date), maxdate = max(date)) %&gt;% kable(caption = \"Date range of Big G streamflow data\")\n\n\n\nDate range of Big G streamflow data\n\n\nsite_name\nmindate\nmaxdate\n\n\n\n\nDonner Blitzen River nr Frenchglen NWIS\n1980-01-01\n2024-11-17\n\n\nNorth Fork Flathead River NWIS\n1980-01-01\n2024-11-17\n\n\nPacific Creek at Moran NWIS\n1980-01-01\n2024-11-17\n\n\nPaine Run 10\n1992-10-01\n2023-12-31\n\n\nPiney River 10\n1992-10-01\n2023-12-31\n\n\nShields River nr Livingston NWIS\n1980-01-01\n2024-11-17\n\n\nSouth River Conway NWIS\n1980-01-01\n2024-11-17\n\n\nStaunton River 10\n1992-09-02\n2023-12-31\n\n\n\n\n\nIn-situ stream temperature\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_StreamTemp_BigG_Recent.jpg\", height = 8, width = 9, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = dat_daily_G, aes(x = yday, y = tempc_mean_7, group = year), color = \"grey70\", size = 0.25) +\n  geom_line(data = dat_daily_G_recent, aes(x = yday, y = tempc_mean_7, group = as.factor(year), color = as.factor(year))) +\n  scale_colour_manual(values = mycols) + facet_wrap(~ site_name, nrow = 3) + xlab(\"Day of calendar year\") + ylab(\"7-day mean temperature (deg C)\") + ylim(0,22) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.9,0.05), legend.justification = c(1,0)) + labs(color = \"Year\")\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nIn-situ streamflow\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_StreamFlow_BigG_Recent.jpg\", height = 8, width = 9, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = dat_daily_G, aes(x = yday, y = log(flow_mean_7), group = year), color = \"grey70\", size = 0.25) +\n  geom_line(data = dat_daily_G_recent, aes(x = yday, y = log(flow_mean_7), group = as.factor(year), color = as.factor(year))) +\n  scale_colour_manual(values = mycols) + \n  geom_text(data = year_range, aes(x = -Inf, y = -Inf, label = yearrange), hjust = -0.1, vjust = -1) +\n  facet_wrap(~ site_name, nrow = 3, scales = \"free_y\") + \n  xlab(\"Day of calendar year\") + ylab(\"ln 7-day mean streamflow (cfs)\") + labs(color = \"Year\") + theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.9,0.05), legend.justification = c(1,0))\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nStreamflow in Yield. Note same y-axis limits\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Yield_BigG_Recent.jpg\", height = 8, width = 9, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = dat_daily_G, aes(x = yday, y = log(Yield_filled_mm_7), group = year), color = \"grey70\", size = 0.25) +\n  geom_line(data = dat_daily_G_recent, aes(x = yday, y = log(Yield_filled_mm_7), group = as.factor(year), color = as.factor(year))) +\n  scale_colour_manual(values = mycols) + \n  geom_text(data = year_range, aes(x = -Inf, y = -Inf, label = yearrange), hjust = -0.1, vjust = -1) +\n  facet_wrap(~ site_name, nrow = 3) + \n  xlab(\"Day of year\") + ylab(\"ln 7-day mean yield\") + labs(color = \"Year\") + theme_bw() + ylim(-5,3.5) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.9,0.05), legend.justification = c(1,0))\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html#exceedance-probability",
    "href": "Explore Data/ExploreData.html#exceedance-probability",
    "title": "3  Explore Long-Term Data",
    "section": "3.4 Exceedance probability",
    "text": "3.4 Exceedance probability\n\n\nCode\nexceedance &lt;- dat_daily_G %&gt;% filter(!is.na(Yield_filled_mm)) %&gt;% \n  mutate(Yield_filled_mm_log = log(Yield_filled_mm)) %&gt;%\n  group_by(station_no, site_name, site_id, basin, region, lat, long, elev_ft, area_sqmi, designation, year) %&gt;% \n  arrange(desc(Yield_filled_mm_log), .by_group = TRUE) %&gt;% \n  mutate(exceedance = 100/length(Yield_filled_mm_log)*1:length(Yield_filled_mm_log)) %&gt;%\n  ungroup()\nexceedance_recent &lt;- exceedance %&gt;% filter(year %in% c(2018:2023))\n\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Yield_Recent_Exceedance.jpg\", height = 8, width = 9, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = exceedance, aes(x = exceedance, y = Yield_filled_mm_log, group = year), color = \"grey70\", size = 0.25) +\n  geom_line(data = exceedance_recent, aes(x = exceedance, y = Yield_filled_mm_log, group = as.factor(year), color = as.factor(year))) +\n  scale_colour_manual(values = mycols) + \n  geom_text(data = year_range, aes(x = -Inf, y = -Inf, label = yearrange), hjust = -0.1, vjust = -1) +\n  facet_wrap(~ site_name, nrow = 3) + \n  xlab(\"Exceedance probability\") + ylab(\"ln daily mean yield (mm)\") + labs(color = \"Year\") + theme_bw() + ylim(-5,5) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.9,0.05), legend.justification = c(1,0))\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html#dsci",
    "href": "Explore Data/ExploreData.html#dsci",
    "title": "3  Explore Long-Term Data",
    "section": "3.5 DSCI",
    "text": "3.5 DSCI\nView time series of drought severity and coverage index (DSCI), summarized over HUC08 basins. Accessed https://droughtmonitor.unl.edu/DmData/TimeSeries.aspx\n\n\nCode\n# get huc 8 codes\nhuctib &lt;- tibble(site_name = siteinfo$site_name, basin = siteinfo$basin, huc08 = NA)\nfor (i in 1:dim(siteinfo)[1]) {\n  huctib$huc08[i] &lt;- unlist(tibble(get_huc(siteinfo_sp[i,], type = \"huc08\"))[,11])\n  #print(i)\n}\nhuctib &lt;- huctib %&gt;% group_by(basin) %&gt;% summarize(huc08 = unique(huc08)) #%&gt;% filter(basin != \"Piney River\")\n# unique(huctib$huc08)\n\n# bring in drought indices\ndsci &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/dm_export_19800101_20241004.csv\") %&gt;%\n rename(huc08 = HUCID, name = Name, date = MapDate, dsci = DSCI) %&gt;% mutate(date = ymd(date)) %&gt;% left_join(huctib)\n\n# print table\ndsci %&gt;% group_by(basin) %&gt;% summarize(dsci_name = unique(name), huc08 = unique(huc08)) %&gt;% kable(caption = \"HUC08 basin codes for primary EcoDrought basins\")\n\n\n\nHUC08 basin codes for primary EcoDrought basins\n\n\nbasin\ndsci_name\nhuc08\n\n\n\n\nDonner Blitzen\nDonner und Blitzen\n17120003\n\n\nFlathead\nNorth Fork Flathead\n17010206\n\n\nPaine Run\nSouth Fork Shenandoah\n02070005\n\n\nPiney River\nRapidan-Upper Rappahannock\n02080103\n\n\nShields River\nShields\n10070003\n\n\nSnake River\nSnake Headwaters\n17040101\n\n\nStaunton River\nRapidan-Upper Rappahannock\n02080103\n\n\nWest Brook\nMiddle Connecticut\n01080201\n\n\n\n\n\n\n\nCode\n# calculate monthly means\ndsci_monthly &lt;- dsci %&gt;% \n  mutate(monthyear = as_date(paste(format_ISO8601(date, precision = \"ym\"), \"-01\", sep = \"\"))) %&gt;% \n  mutate(year = year(monthyear), month = month(monthyear)) %&gt;%\n  group_by(huc08, basin, year, month, monthyear) %&gt;% \n  summarize(dsci_monthly_1 = mean(dsci)) %&gt;% \n  ungroup() %&gt;%\n  group_by(huc08, basin) %&gt;%\n  mutate(dsci_monthly_2 = rollapply(dsci_monthly_1, FUN = mean, width = 2, align = \"right\", fill = NA),\n         dsci_monthly_3 = rollapply(dsci_monthly_1, FUN = mean, width = 3, align = \"right\", fill = NA),\n         dsci_monthly_4 = rollapply(dsci_monthly_1, FUN = mean, width = 4, align = \"right\", fill = NA),\n         dsci_monthly_5 = rollapply(dsci_monthly_1, FUN = mean, width = 5, align = \"right\", fill = NA),\n         dsci_monthly_6 = rollapply(dsci_monthly_1, FUN = mean, width = 6, align = \"right\", fill = NA),\n         dsci_monthly_7 = rollapply(dsci_monthly_1, FUN = mean, width = 7, align = \"right\", fill = NA),\n         dsci_monthly_8 = rollapply(dsci_monthly_1, FUN = mean, width = 8, align = \"right\", fill = NA),\n         dsci_monthly_9 = rollapply(dsci_monthly_1, FUN = mean, width = 9, align = \"right\", fill = NA),\n         dsci_monthly_10 = rollapply(dsci_monthly_1, FUN = mean, width = 10, align = \"right\", fill = NA),\n         dsci_monthly_11 = rollapply(dsci_monthly_1, FUN = mean, width = 11, align = \"right\", fill = NA),\n         dsci_monthly_12 = rollapply(dsci_monthly_1, FUN = mean, width = 12, align = \"right\", fill = NA),\n         dsci_monthly_13 = rollapply(dsci_monthly_1, FUN = mean, width = 13, align = \"right\", fill = NA),\n         dsci_monthly_14 = rollapply(dsci_monthly_1, FUN = mean, width = 14, align = \"right\", fill = NA),\n         dsci_monthly_15 = rollapply(dsci_monthly_1, FUN = mean, width = 15, align = \"right\", fill = NA),\n         dsci_monthly_16 = rollapply(dsci_monthly_1, FUN = mean, width = 16, align = \"right\", fill = NA),\n         dsci_monthly_17 = rollapply(dsci_monthly_1, FUN = mean, width = 17, align = \"right\", fill = NA),\n         dsci_monthly_18 = rollapply(dsci_monthly_1, FUN = mean, width = 18, align = \"right\", fill = NA),\n         dsci_monthly_19 = rollapply(dsci_monthly_1, FUN = mean, width = 19, align = \"right\", fill = NA),\n         dsci_monthly_20 = rollapply(dsci_monthly_1, FUN = mean, width = 20, align = \"right\", fill = NA),\n         dsci_monthly_21 = rollapply(dsci_monthly_1, FUN = mean, width = 21, align = \"right\", fill = NA),\n         dsci_monthly_22 = rollapply(dsci_monthly_1, FUN = mean, width = 22, align = \"right\", fill = NA),\n         dsci_monthly_23 = rollapply(dsci_monthly_1, FUN = mean, width = 23, align = \"right\", fill = NA),\n         dsci_monthly_24 = rollapply(dsci_monthly_1, FUN = mean, width = 24, align = \"right\", fill = NA),) %&gt;%\n  ungroup()\n\n# plot time series\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_DSCI_1-6-12.jpg\", height = 8, width = 9, units = \"in\", res = 500)\ndsci_monthly %&gt;% ggplot() + \n  geom_line(aes(x = monthyear, y = dsci_monthly_1), color = \"grey50\") + \n  geom_line(aes(x = monthyear, y = dsci_monthly_6), color = mycols[1]) + \n  geom_line(aes(x = monthyear, y = dsci_monthly_12), color = mycols[2]) + \n  facet_wrap(~ basin) + \n  xlab(\"\") + ylab(\"Drought severity and coverage index (DSCI): 1-, 6-, and 12-month\") + theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html#spi",
    "href": "Explore Data/ExploreData.html#spi",
    "title": "3  Explore Long-Term Data",
    "section": "3.6 SPI",
    "text": "3.6 SPI\nCalculate standardized precipiation index (SPI) for EcoDrought basins at multiple time scales (1-24 months). View time series data.\n\n\nCode\n# combine and calculate monthly totals\nclimdf_monthly &lt;- do.call(rbind, climlist) %&gt;% left_join(siteinfo_big) %&gt;% mutate(year = year(date), month = month(date)) %&gt;%\n  group_by(station_no, site_name, site_id, basin, region, lat, long, elev_ft, area_sqmi, designation, year, month) %&gt;%\n  summarize(precip_mmmonth = sum(precip_mmday)) %&gt;%\n  ungroup() %&gt;%\n  mutate(date = date(paste(year, month, \"01\", sep = \"-\")))\n\n# calculate SPI at various time scales\nspi_list &lt;- list()\nfor (i in 1:dim(siteinfo_big)[1]) {\n  d &lt;- climdf_monthly %&gt;% filter(site_name == siteinfo_big$site_name[i])\n  for (j in 1:24) {\n    myspi &lt;- spi(unlist(d %&gt;% select(precip_mmmonth)), scale = j)\n    myspi &lt;- myspi$fitted\n    myspi[is.infinite(myspi)] &lt;- NA\n    d[,paste(\"spi\", j, sep = \"_\")] &lt;- myspi\n  }\n  spi_list[[i]] &lt;- d\n  #print(i)\n}\n\n\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n\n\nCode\nspi_monthly &lt;- do.call(rbind, spi_list)\n# view(spi_monthly)\n\n# spi_monthly %&gt;% filter(site_id == \"SRL\") %&gt;% ggplot() + geom_line(aes(x = date, y = spi_1))\n# spi_monthly %&gt;% filter(site_id == \"SRL\") %&gt;% ggplot() + geom_line(aes(x = date, y = spi_3))\n# spi_monthly %&gt;% filter(site_id == \"SRL\") %&gt;% ggplot() + geom_line(aes(x = date, y = spi_6))\n# spi_monthly %&gt;% filter(site_id == \"SRL\") %&gt;% ggplot() + geom_line(aes(x = date, y = spi_12))\n# spi_monthly %&gt;% filter(site_id == \"SRL\") %&gt;% ggplot() + geom_line(aes(x = date, y = spi_24))\n\n\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_SPI_1-6-12.jpg\", height = 8, width = 9, units = \"in\", res = 500)\nspi_monthly %&gt;% ggplot() + \n  geom_line(aes(x = date, y = spi_1), color = \"grey50\") + \n  geom_line(aes(x = date, y = spi_6), color = mycols[1]) + \n  geom_line(aes(x = date, y = spi_12), color = mycols[2]) +\n  geom_line(aes(x = date, y = spi_24), color = mycols[3]) +\n  facet_wrap(~ basin) + \n  xlab(\"\") + ylab(\"Standardized precipitation index (SPI): 1-, 6-, 12-, and 24-month\") + theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgStoryPlots.html",
    "href": "Big G Little g/GgStoryPlots.html",
    "title": "4  G-g Story Plots",
    "section": "",
    "text": "4.1 Site info and daily data\nPurpose: build visual story plots for each basin and climate year\nNotes:\nView map of sites\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\nLoad and view data structure\nCode\n# flow/yield (and temp) data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\") %&gt;% filter(!site_name %in% c(\"Wounded Buck Creek\"))\n\n# add water/climate year variables\ndat &lt;- add_date_variables(dat, dates = date, water_year_start = 4)\n\n# calculate completeness by site and water year\ncomplete &lt;- dat %&gt;% group_by(site_name, designation, WaterYear) %&gt;% summarize(completeness = sum(!is.na(Yield_filled_mm_7))/365)\ndat &lt;- dat %&gt;% left_join(complete)\nstr(dat)\n\n\ntibble [231,881 × 33] (S3: tbl_df/tbl/data.frame)\n $ station_no          : chr [1:231881] NA NA NA NA ...\n $ site_name           : chr [1:231881] \"BigCreekLower\" \"BigCreekLower\" \"BigCreekLower\" \"BigCreekLower\" ...\n $ site_id             : chr [1:231881] \"BIG_001\" \"BIG_001\" \"BIG_001\" \"BIG_001\" ...\n $ basin               : chr [1:231881] \"Flathead\" \"Flathead\" \"Flathead\" \"Flathead\" ...\n $ subbasin            : chr [1:231881] \"Big Creek\" \"Big Creek\" \"Big Creek\" \"Big Creek\" ...\n $ region              : chr [1:231881] \"Flat\" \"Flat\" \"Flat\" \"Flat\" ...\n $ lat                 : num [1:231881] 48.6 48.6 48.6 48.6 48.6 ...\n $ long                : num [1:231881] -114 -114 -114 -114 -114 ...\n $ elev_ft             : num [1:231881] 3429 3429 3429 3429 3429 ...\n $ area_sqmi           : num [1:231881] 81.2 81.2 81.2 81.2 81.2 ...\n $ designation         : chr [1:231881] \"little\" \"little\" \"little\" \"little\" ...\n $ date                : Date[1:231881], format: \"2017-07-28\" \"2017-07-29\" ...\n $ disch_reli          : num [1:231881] 1 1 1 1 1 1 1 1 1 1 ...\n $ temp_reli           : num [1:231881] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean           : num [1:231881] 81.4 76.5 77.6 92.1 98.1 ...\n $ tempc_mean          : num [1:231881] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean_filled    : num [1:231881] 81.4 76.5 77.6 92.1 98.1 ...\n $ flow_mean_cms       : num [1:231881] 2.3 2.17 2.2 2.61 2.78 ...\n $ flow_mean_filled_cms: num [1:231881] 2.3 2.17 2.2 2.61 2.78 ...\n $ area_sqkm           : num [1:231881] 210 210 210 210 210 ...\n $ Yield_mm            : num [1:231881] 0.946 0.89 0.902 1.071 1.141 ...\n $ Yield_filled_mm     : num [1:231881] 0.946 0.89 0.902 1.071 1.141 ...\n $ flow_mean_7         : num [1:231881] NA NA NA 91.3 94.4 ...\n $ flow_mean_filled_7  : num [1:231881] NA NA NA 91.3 94.4 ...\n $ tempc_mean_7        : num [1:231881] NA NA NA NA NA NA NA NA NA NA ...\n $ Yield_mm_7          : num [1:231881] NA NA NA 1.06 1.1 ...\n $ Yield_filled_mm_7   : num [1:231881] NA NA NA 1.06 1.1 ...\n $ CalendarYear        : num [1:231881] 2017 2017 2017 2017 2017 ...\n $ Month               : num [1:231881] 7 7 7 7 8 8 8 8 8 8 ...\n $ MonthName           : Factor w/ 12 levels \"Apr\",\"May\",\"Jun\",..: 4 4 4 4 5 5 5 5 5 5 ...\n $ WaterYear           : num [1:231881] 2018 2018 2018 2018 2018 ...\n $ DayofYear           : num [1:231881] 119 120 121 122 123 124 125 126 127 128 ...\n $ completeness        : num [1:231881] 0.268 0.268 0.268 0.268 0.268 ...\nView little and medium g time series data (yield), by basin and site\nCode\nmysubbasins &lt;- unique(dat$subbasin)[-c(4,7,13)]\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  myplots[[i]] &lt;- dat %&gt;% filter(designation %in% c(\"little\", \"medium\"), subbasin == mysubbasins[i]) %&gt;% ggplot() + geom_line(aes(x = date, y = log(Yield_filled_mm_7))) + facet_wrap(~site_name)\n}\nView little and medium g time series data (yield), by basin. Use the handles below the x-axis to change the time frame.\nCode\nmysubbasins &lt;- unique(dat$subbasin)[-c(4,7,13)]\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  myplots[[i]] &lt;- dat %&gt;% filter(designation %in% c(\"little\", \"medium\"), subbasin == mysubbasins[i]) %&gt;% mutate(logYield = log(Yield_filled_mm_7)) %&gt;% select(date, site_name, logYield) %&gt;% spread(key = site_name, value = logYield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"ln(Yield, mm)\")\n}",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>G-g Story Plots</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgStoryPlots.html#site-info-and-daily-data",
    "href": "Big G Little g/GgStoryPlots.html#site-info-and-daily-data",
    "title": "4  G-g Story Plots",
    "section": "",
    "text": "Big CreekCoal CreekMcGee CreekWest BrookPaine RunStaunton RiverDuck CreekShields RiverSnake RiverDonner Blitzen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBig CreekCoal CreekMcGee CreekWest BrookPaine RunStaunton RiverDuck CreekShields RiverSnake RiverDonner Blitzen",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>G-g Story Plots</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgStoryPlots.html#create-plotting-functions",
    "href": "Big G Little g/GgStoryPlots.html#create-plotting-functions",
    "title": "4  G-g Story Plots",
    "section": "4.2 Create plotting functions",
    "text": "4.2 Create plotting functions\nWrite functions to generate residual time series/scatter plot\n\n\nCode\nresidualplots &lt;- function(mybasin, CY, little, big) {\n  # essential elements\n  dat_basin &lt;- dat %&gt;% filter(basin == mybasin)\n  \n  # create residual data frame\n  delta_dat &lt;- dat_basin %&gt;% select(site_name, site_id, basin, region, designation, date, WaterYear, Yield_mm_mean_7) %&gt;% filter(site_name %in% little, WaterYear == CY) %&gt;% \n    left_join(dat_basin %&gt;% select(basin, site_name, date, WaterYear, Yield_mm_mean_7) %&gt;% filter(site_name == big, WaterYear == CY) %&gt;% rename(bigyield = Yield_mm_mean_7) %&gt;% select(-site_name)) %&gt;% \n    mutate(delta_yield = log(Yield_mm_mean_7) - log(bigyield), site_name = factor(site_name, levels = little)) %&gt;% \n    group_by(site_name) %&gt;% mutate(cum_resid = cumsum(coalesce(delta_yield, 0)) + delta_yield*0) \n  \n  # base plot\n  p1 &lt;- delta_dat %&gt;% \n    filter(WaterYear == CY) %&gt;%\n    group_by(site_name) %&gt;%\n    mutate(month = month(date), doy = 1:n()) %&gt;% \n    ungroup() %&gt;%\n    ggplot(aes(x = log(bigyield), y = log(Yield_mm_mean_7), color = doy)) +\n    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +\n    geom_point(aes(group = doy)) +\n    geom_path() +\n    scale_color_gradient2(midpoint = 182, low = \"orange\", mid = \"purple3\", high = \"orange\") +\n    facet_wrap(~site_name) +\n    xlab(\"Big G ln(Yield)\") + ylab(\"Little G ln(Yield)\") + labs(color = \"Days from April 1\") +\n    theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) \n  \n  # animated \n  # p1_anim &lt;- p1 + transition_reveal(along = doy)\n  \n  # write out - static\n  jpeg(paste(\"Big G Little g/Compare Time Series/BigGLittleG_ScatterByTime\", mybasin, \"_\", CY, \".jpg\", sep = \"\"), height = 10, width = 12, units = \"in\", res = 500)\n  print(p1)\n  dev.off()\n  \n  # write out - animated\n  # animate(p1_anim, renderer = gifski_renderer(), height = 10, width = 12, units = \"in\", res = 500)\n  # anim_save(paste(\"Big G Little g/Compare Time Series/BigGLittleG_ScatterByTime_Animated_\", mybasin, \"_\", CY, \".gif\", sep = \"\"))\n  \n  # residual time series\n  jpeg(paste(\"Big G Little g/Compare Time Series/BigGLittleG_YieldResiduals_TimeSeries_\", mybasin, \"_\", CY, \".jpg\", sep = \"\"), height = 4, width = 6, units = \"in\", res = 500)\n  print(ggplot(data = delta_dat) + \n    geom_line(aes(x = date, y = delta_yield, group = site_name, color = site_name)) + \n    geom_hline(aes(yintercept = 0), linetype = \"dashed\") +\n    xlab(\"\") + ylab(\"ln(Yield) residuals (difference from Big G)\") + labs(color = \"Little g\") +\n    theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()))\n  dev.off()\n  \n  \n  # plot little g cumulative residuals - difference from Big G by site\n  jpeg(paste(\"Big G Little g/Compare Time Series/BigGLittleG_YieldResiduals_Cumulative_TimeSeries_\", mybasin, \"_\", CY, \".jpg\", sep = \"\"), height = 4, width = 6, units = \"in\", res = 500)\n  print(delta_dat %&gt;% \n    ggplot() + \n    geom_line(aes(x = date, y = cum_resid, group = site_name, color = site_name)) + \n    geom_hline(aes(yintercept = 0), linetype = \"dashed\") +\n    xlab(\"\") + ylab(\"ln(Yield) cumulative residuals \") + labs(color = \"Little g\") +\n    theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()))\n  dev.off()\n}\n\n\nWrite function to generate flow story plot\n\n\nCode\nbigplotfun &lt;- function(mybasin, mysubbasin, CY, little, big, super, supergyears, mymap, evalyears) {\n  #### essential elements\n  dat_basin &lt;- dat %&gt;% filter(basin == mybasin)\n  months &lt;- c(\"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\", \"Jan\", \"Feb\", \"Mar\")\n  fudge &lt;- 0.01 # add small value to deal with 0 flow on log scale\n\n  # clean data...drop all dates that have missing data at any site\n  dat_basin_cy_clean &lt;- dat %&gt;% \n    filter(site_name %in% c(little, big), WaterYear == CY) %&gt;% \n    select(date, site_name, Yield_filled_mm_7) %&gt;%\n    spread(key = site_name, value = Yield_filled_mm_7) %&gt;% \n    drop_na() %&gt;%\n    gather(key = site_name, value = Yield_filled_mm_7, 2:ncol(.))\n  dat_basin_cy_clean &lt;- fill_missing_dates(dat_basin_cy_clean, dates = \"date\", groups = \"site_name\", pad_ends = FALSE)\n  \n  # get among-year yield min/max for y-axis limits\n  dat_basin_sub &lt;- dat %&gt;% \n    filter(site_name %in% c(little, big), WaterYear %in% evalyears) %&gt;% \n    select(date, WaterYear, site_name, Yield_filled_mm_7) %&gt;%\n    spread(key = site_name, value = Yield_filled_mm_7) %&gt;% \n    drop_na() %&gt;%\n    gather(key = site_name, value = Yield_filled_mm_7, 3:ncol(.)) %&gt;%\n    filter(!is.na(Yield_filled_mm_7)) %&gt;% \n    mutate(Yield_filled_mm_7_log = log(Yield_filled_mm_7+fudge)) \n  yield_lim &lt;- range(dat_basin_sub$Yield_filled_mm_7_log)\n  \n  \n  # clean months\n  cleanmonths &lt;- unlist(dat_basin_cy_clean %&gt;% filter(site_name == little[1]) %&gt;% drop_na() %&gt;% left_join(dat_basin %&gt;% select(date, site_name, MonthName, Month)) %&gt;% group_by(MonthName) %&gt;% summarize(ndays = n()) %&gt;% filter(ndays &gt;= 20) %&gt;% select(MonthName))\n  \n  #### MAP\n  p1 &lt;- mymap\n  # print(\"p1\")\n  \n  #### HYDROGRAPHS IN YIELD\n  p2 &lt;- ggplot() + \n    geom_line(data = dat_basin_cy_clean %&gt;% filter(site_name %in% little) %&gt;% mutate(site_name = factor(site_name, levels = little)), aes(x = date, y = log(Yield_filled_mm_7+fudge), group = site_name, color = site_name)) +\n    geom_line(data = dat_basin_cy_clean %&gt;% filter(site_name == big), aes(x = date, y = log(Yield_filled_mm_7+fudge)), color = \"black\", size = 1.25) +\n    xlab(\"Date\") + ylab(\"ln(Yield, mm)\") + theme_bw() + ylim(yield_lim) + \n    scale_x_date(limits = as.Date(c(paste(CY-1, '-04-01', sep = \"\"), paste(CY, '-04-01', sep = \"\")))) +\n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n  # print(\"p2\")\n  \n  \n  #### TOTAL ANNUAL YIELD\n  # get total yield per year and convert to percentiles\n  yeartotals &lt;- dat_basin %&gt;% \n    filter(site_name == super, WaterYear %in% supergyears) %&gt;% \n    group_by(WaterYear) %&gt;% \n    summarize(totalyield = sum(Yield_filled_mm, na.rm = TRUE)) %&gt;%\n    filter(!is.na(totalyield)) %&gt;%\n    mutate(percentile = percent_rank(totalyield))\n  p3 &lt;- ggplot() + \n    geom_line(data = yeartotals, aes(x = WaterYear, y = totalyield), color = \"grey40\") + \n    geom_point(data = yeartotals %&gt;% filter(WaterYear == CY), aes(x = WaterYear, y = totalyield)) +\n    xlab(\"Climate year\") + ylab(\"Total annual yield (mm)\") + theme_bw() + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # print(\"p3\")\n  \n  \n  #### EXCEEDANCE PROBABILITY - SUPER G PERIOD OF RECORD\n  exceedance &lt;- dat_basin %&gt;% \n    filter(site_name %in% c(little, big, super)) %&gt;%\n    filter(!is.na(Yield_filled_mm_7)) %&gt;% \n    mutate(Yield_filled_mm_7_log = log(Yield_filled_mm_7)) %&gt;%\n    group_by(site_name, WaterYear) %&gt;% \n    arrange(desc(Yield_filled_mm_7_log), .by_group = TRUE) %&gt;% \n    mutate(exceedance = 100/length(Yield_filled_mm_7_log)*1:length(Yield_filled_mm_7_log)) %&gt;%\n    ungroup()\n  p4 &lt;- ggplot() + \n    geom_line(data = exceedance %&gt;% filter(site_name == super, WaterYear %in% supergyears), aes(x = exceedance, y = Yield_filled_mm_7_log, group = WaterYear, color = WaterYear), size = 0.25) +\n    geom_line(data = exceedance %&gt;% filter(site_name == super, WaterYear == CY), aes(x = exceedance, y = Yield_filled_mm_7_log), color = \"black\", size = 1.25) +\n    geom_text(aes(x = 50, y = Inf, label = paste(\"Super G: \", super, \" (\", min(supergyears), \"-\", max(supergyears), \")\", \"\\nCurrent year: \", CY, \" (\", round(yeartotals$percentile[yeartotals$WaterYear == CY]*100), \"th perc.)\", sep = \"\")), vjust = 1.2) +\n    scale_color_continuous(trans = \"reverse\") +\n    xlab(\"Exceedance probability\") + ylab(\"ln(Yield, mm)\") + labs(color = \"Climate year\") + theme_bw() + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.15,0.23), \n          legend.text = element_text(size = 9), legend.title = element_text(size = 9), legend.key.height = unit(0.4, \"cm\"))\n  # print(\"p4\")\n  \n  \n  #### CUMULATIVE YIELD RESIDUALS\n  # get range of residuals among years\n  dat_basin_res &lt;- dat_basin_sub %&gt;% \n    filter(site_name %in% little, WaterYear %in% evalyears) %&gt;% select(site_name, date, WaterYear, Yield_filled_mm_7) %&gt;%\n    left_join(dat %&gt;% filter(site_name == big) %&gt;% rename(bigyield = Yield_filled_mm_7) %&gt;% select(date, WaterYear, bigyield)) %&gt;% \n    mutate(delta_yield = log(Yield_filled_mm_7+fudge) - log(bigyield+fudge), site_name = factor(site_name, levels = little)) %&gt;% \n    group_by(site_name, WaterYear) %&gt;% mutate(cum_resid = cumsum(coalesce(delta_yield, 0)) + delta_yield*0) \n  res_lim &lt;- range(dat_basin_res$cum_resid, na.rm = TRUE)\n  p5 &lt;- dat_basin_cy_clean %&gt;% filter(site_name %in% little) %&gt;% \n    left_join(dat_basin_cy_clean %&gt;% filter(site_name == big) %&gt;% rename(bigyield = Yield_filled_mm_7) %&gt;% select(-site_name)) %&gt;% \n    mutate(delta_yield = log(Yield_filled_mm_7+fudge) - log(bigyield+fudge), site_name = factor(site_name, levels = little)) %&gt;% \n    group_by(site_name) %&gt;% mutate(cum_resid = cumsum(coalesce(delta_yield, 0)) + delta_yield*0) %&gt;%\n    ggplot() + \n    geom_line(aes(x = date, y = cum_resid, group = site_name, color = site_name)) + \n    geom_hline(aes(yintercept = 0), linetype = \"dashed\") +\n    xlab(\"Date\") + ylab(\"ln(Yield) cumulative residuals \") + ylim(res_lim) +\n    scale_x_date(limits = as.Date(c(paste(CY-1, '-04-01', sep = \"\"), paste(CY, '-04-01', sep = \"\")))) +\n    theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n  # print(\"p5\")\n\n  \n  #### EXCEEDANCE PROBABILITY - BIG G/LITTLE G CURRENT YEAR\n  exceedance &lt;- dat_basin_cy_clean %&gt;% \n    filter(site_name %in% c(little, big)) %&gt;%\n    filter(!is.na(Yield_filled_mm_7)) %&gt;% \n    mutate(Yield_filled_mm_7_log = log(Yield_filled_mm_7+fudge)) %&gt;%\n    group_by(site_name) %&gt;% \n    arrange(desc(Yield_filled_mm_7_log), .by_group = TRUE) %&gt;% \n    mutate(exceedance = 100/length(Yield_filled_mm_7_log)*1:length(Yield_filled_mm_7_log)) %&gt;%\n    ungroup()\n  p6 &lt;- ggplot() + \n    geom_line(data = exceedance %&gt;% filter(site_name %in% little) %&gt;% mutate(site_name = factor(site_name, levels = little)), aes(x = exceedance, y = Yield_filled_mm_7_log, group = site_name, color = site_name)) +\n    geom_line(data = exceedance %&gt;% filter(site_name == big), aes(x = exceedance, y = Yield_filled_mm_7_log), color = \"black\", size = 1.25) +\n    xlab(\"Exceedance probability\") + ylab(\"ln(Yield, mm)\") + labs(color = \"Little g\") + theme_bw() + ylim(yield_lim) + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n  # print(\"p6\")\n  \n  \n  #### EXCEEDANCE PROBABILITY MONTHLY\n  exceedance_monthly &lt;- dat_basin_cy_clean %&gt;% \n    filter(site_name %in% c(little, big)) %&gt;%\n    filter(!is.na(Yield_filled_mm_7)) %&gt;% \n    left_join(dat_basin %&gt;% select(date, site_name, MonthName, Month)) %&gt;%\n    mutate(Yield_filled_mm_7_log = log(Yield_filled_mm_7+fudge),\n           site_name = factor(site_name, levels = c(little, big)),\n           MonthName = factor(MonthName, levels = months)) %&gt;%\n    group_by(site_name, Month) %&gt;% \n    arrange(desc(Yield_filled_mm_7_log), .by_group = TRUE) %&gt;% \n    mutate(exceedance = 100/length(Yield_filled_mm_7_log)*1:length(Yield_filled_mm_7_log)) %&gt;%\n    ungroup()\n  exceedance_monthly2 &lt;- exceedance_monthly %&gt;% mutate(Yield_filled_mm_7_log = ifelse(MonthName %in% cleanmonths, Yield_filled_mm_7_log, NA))\n  p7 &lt;- ggplot() + \n    geom_line(data = exceedance_monthly2 %&gt;% filter(site_name %in% little), aes(x = exceedance, y = Yield_filled_mm_7_log, group = site_name, color = site_name)) +\n    geom_line(data = exceedance_monthly2 %&gt;% filter(site_name == big), aes(x = exceedance, y = Yield_filled_mm_7_log), color = \"black\", size = 1.25) +\n    facet_wrap(~ factor(MonthName), nrow = 2) + \n    xlab(\"Exceedance probability\") + ylab(\"ln(Yield, mm)\") + labs(color = \"Little g\") + theme_bw() +  ylim(yield_lim) + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n  # print(\"p7\")\n  \n  \n  #### ANNUAL BIG-LITTLE DIFFERENCE\n  mypvals &lt;- tibble(type =  rep(NA, times = length(little)), \n                    month = rep(NA, times = length(little)),\n                    site_name = rep(NA, times = length(little)), \n                    stat = rep(NA, times = length(little)),\n                    pval = rep(NA, times = length(little)))\n  for (i in 1:length(little)) {\n    mytest &lt;- ks.test(exceedance$Yield_filled_mm_7_log[exceedance$site_name == big],\n                      exceedance$Yield_filled_mm_7_log[exceedance$site_name == little[i]], exact = TRUE)\n    mypvals$type &lt;- \"annual\"\n    mypvals$month &lt;- 0\n    mypvals$site_name[i] &lt;- little[i]\n    mypvals$stat[i] &lt;- mytest$statistic\n    mypvals$pval[i] &lt;- mytest$p.value\n  }\n  p8 &lt;- mypvals %&gt;% \n    mutate(site_name = factor(site_name, levels = little)) %&gt;% \n    ggplot() + \n    geom_boxplot(aes(x = month, y = pval, group = month), fill = \"grey90\", outlier.shape = NA) +\n    geom_point(aes(x = jitter(month, factor = 10), y = pval, color = site_name), size = 2) +\n    ylim(0,1) + geom_hline(yintercept = 0.05, linetype = \"dashed\") +\n    xlab(\"\") + ylab(\"Kolmogorov-Smirnov test p-value\") + scale_x_continuous(labels = \"Annual\", breaks = 0) +\n    theme_bw() + theme(axis.title.x = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n  # print(\"p8\")\n  \n  \n  #### MONTHLY BIG-LITTLE DIFFERENCE\n  mypvals_monthly_list &lt;- list()\n  for (i in 1:length(little)) {\n    mypvals_monthly &lt;- tibble(type =  rep(NA, times = 12), \n                              month = rep(NA, times = 12),\n                              site_name = rep(NA, times = 12), \n                              stat = rep(NA, times = 12),\n                              pval = rep(NA, times = 12))\n    for (j in 1:12) {\n      big_exc &lt;- exceedance_monthly$Yield_filled_mm_7_log[exceedance_monthly$site_name == big & exceedance_monthly$MonthName == months[j]]\n      lit_exc &lt;- exceedance_monthly$Yield_filled_mm_7_log[exceedance_monthly$site_name == little[i] & exceedance_monthly$MonthName == months[j]]\n      if(length(lit_exc) &lt; 20) {\n        mypvals_monthly$site_name[j] &lt;- little[i]\n        mypvals_monthly$type &lt;- \"monthly\"\n        mypvals_monthly$month[j] &lt;- months[j]\n        mypvals_monthly$stat[j] &lt;- NA\n        mypvals_monthly$pval[j] &lt;- NA\n      } else {\n        mytest &lt;- ks.test(big_exc, lit_exc, exact = TRUE)\n        mypvals_monthly$site_name[j] &lt;- little[i]\n        mypvals_monthly$type &lt;- \"monthly\"\n        mypvals_monthly$month[j] &lt;- months[j]\n        mypvals_monthly$stat[j] &lt;- mytest$statistic\n        mypvals_monthly$pval[j] &lt;- mytest$p.value\n      }\n    }\n    mypvals_monthly_list[[i]] &lt;- mypvals_monthly\n  }\n  mypvals_monthly &lt;- do.call(rbind, mypvals_monthly_list) %&gt;% \n    mutate(site_name = factor(site_name, levels = little),\n           month = factor(month, levels = months), \n           month_num = as.numeric(month)) \n  # compute the loess\n  # dum &lt;- rbind(mypvals_monthly %&gt;% mutate(month_num = month_num-12),\n  #              mypvals_monthly,\n  #              mypvals_monthly %&gt;% mutate(month_num = month_num+12)) \n  # mylo &lt;- loess(pval ~ month_num, dum, span = 0.25)\n  # plot(pval ~ month_num, dum)\n  # j &lt;- order(dum$month_num)[(dim(mypvals_monthly)[1]+1):(dim(mypvals_monthly)[1]+dim(mypvals_monthly)[1])]\n  # lines(dum$month_num[j], mylo$fitted[j], col = \"red\")\n  # the plot\n  p9 &lt;- mypvals_monthly %&gt;% \n    ggplot() + \n    geom_boxplot(aes(x = month, y = pval, group = month), fill = \"grey90\", outlier.shape = NA) +\n    # geom_line(aes(x = dum$month_num[j], y = mylo$fitted[j]), linewidth = 1.25) +\n    geom_smooth(aes(x = month_num, y = pval), linewidth = 1.25, color = \"black\", se = FALSE) +\n    geom_point(aes(x = jitter(month_num), y = pval, color = site_name), size = 2) +\n    ylim(0,1) + geom_hline(yintercept = (0.05), linetype = \"dashed\") +\n    xlab(\"\") + ylab(\"\") + \n    labs(color = \"\") + theme_bw() + \n    theme(axis.title.x = element_blank(), axis.text.y = element_blank(), panel.grid.minor = element_blank())\n  # print(\"p9\")\n  \n  \n  #### BIG PLOT\n  bigp &lt;- ggarrange(ggarrange(mymap, ggarrange(NA, p2, nrow = 2, heights = c(0.2,1))),\n                    ggarrange(p3, p4), \n                    ggarrange(p5, p6),\n                    p7, \n                    ggarrange(p8, p9, widths = c(0.13, 0.85)), nrow = 5, heights = c(1.2,0.9,0.9,1.2,0.9))\n  # print(\"big plot!\")\n  # write out\n  # jpeg(paste(\"Big G Little g/Compare Distributions/BigGLittleG_BigPlot_\", mybasin, \"_\", mysubbasin, \"_\", CY, \".jpg\", sep = \"\"), height = 18, width = 10, units = \"in\", res = 500)\n  # annotate_figure(bigp, fig.lab = \"The West Brook, CY 2021\", fig.lab.pos = \"top.right\", fig.lab.size = 24)\n  print(annotate_figure(bigp, top = text_grob(paste(mybasin, \", CY \", CY, sep = \"\"), x = 0.75, y = -0.5, just = \"centre\", size = 24)))\n  # dev.off()\n}",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>G-g Story Plots</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgStoryPlots.html#create-map-objects",
    "href": "Big G Little g/GgStoryPlots.html#create-map-objects",
    "title": "4  G-g Story Plots",
    "section": "4.3 Create map objects",
    "text": "4.3 Create map objects\n\nWest BrookStaunton RiverPaine RunBig CreekSpread CreekShields RiverDonner-Blitzen",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>G-g Story Plots</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgStoryPlots.html#flow-story-plots",
    "href": "Big G Little g/GgStoryPlots.html#flow-story-plots",
    "title": "4  G-g Story Plots",
    "section": "4.4 Flow story plots",
    "text": "4.4 Flow story plots\nGenerate streamflow story plots by basin and climate year\n\n4.4.1 West Brook\n\n20212022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.4.2 Staunton River\n\n202120222023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.4.3 Paine Run\n\n20212022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.4.4 Big Creek, Flathead\n\n201920202021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.4.5 Spread Creek, Snake\n\n20222023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.4.6 Shields River\n\n20202023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.4.7 Donner-Blitzen\n\n2020202120222023",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>G-g Story Plots</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html",
    "href": "Event Delineation/HydroEvents.html",
    "title": "5  Hydro Event Delineation",
    "section": "",
    "text": "5.1 Data\nPurpose: Conduct baseflow separation and delineate hydrologic events to model in Gg framework",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#data",
    "href": "Event Delineation/HydroEvents.html#data",
    "title": "5  Hydro Event Delineation",
    "section": "",
    "text": "5.1.1 Site info and daily data\n\n\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# flow/yield (and temp) data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\") %&gt;%\n  filter(!site_name %in% c(\"WoundedBuckCreek\", \"Brackett Creek\"))\n\n# add water/climate year variables\ndat &lt;- add_date_variables(dat, dates = date, water_year_start = 4)\nstr(dat)\n\n\ntibble [229,559 × 32] (S3: tbl_df/tbl/data.frame)\n $ station_no          : chr [1:229559] NA NA NA NA ...\n $ site_name           : chr [1:229559] \"BigCreekLower\" \"BigCreekLower\" \"BigCreekLower\" \"BigCreekLower\" ...\n $ site_id             : chr [1:229559] \"BIG_001\" \"BIG_001\" \"BIG_001\" \"BIG_001\" ...\n $ basin               : chr [1:229559] \"Flathead\" \"Flathead\" \"Flathead\" \"Flathead\" ...\n $ subbasin            : chr [1:229559] \"Big Creek\" \"Big Creek\" \"Big Creek\" \"Big Creek\" ...\n $ region              : chr [1:229559] \"Flat\" \"Flat\" \"Flat\" \"Flat\" ...\n $ lat                 : num [1:229559] 48.6 48.6 48.6 48.6 48.6 ...\n $ long                : num [1:229559] -114 -114 -114 -114 -114 ...\n $ elev_ft             : num [1:229559] 3429 3429 3429 3429 3429 ...\n $ area_sqmi           : num [1:229559] 81.2 81.2 81.2 81.2 81.2 ...\n $ designation         : chr [1:229559] \"little\" \"little\" \"little\" \"little\" ...\n $ date                : Date[1:229559], format: \"2017-07-28\" \"2017-07-29\" ...\n $ disch_reli          : num [1:229559] 1 1 1 1 1 1 1 1 1 1 ...\n $ temp_reli           : num [1:229559] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean           : num [1:229559] 81.4 76.5 77.6 92.1 98.1 ...\n $ tempc_mean          : num [1:229559] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean_filled    : num [1:229559] 81.4 76.5 77.6 92.1 98.1 ...\n $ flow_mean_cms       : num [1:229559] 2.3 2.17 2.2 2.61 2.78 ...\n $ flow_mean_filled_cms: num [1:229559] 2.3 2.17 2.2 2.61 2.78 ...\n $ area_sqkm           : num [1:229559] 210 210 210 210 210 ...\n $ Yield_mm            : num [1:229559] 0.946 0.89 0.902 1.071 1.141 ...\n $ Yield_filled_mm     : num [1:229559] 0.946 0.89 0.902 1.071 1.141 ...\n $ flow_mean_7         : num [1:229559] NA NA NA 91.3 94.4 ...\n $ flow_mean_filled_7  : num [1:229559] NA NA NA 91.3 94.4 ...\n $ tempc_mean_7        : num [1:229559] NA NA NA NA NA NA NA NA NA NA ...\n $ Yield_mm_7          : num [1:229559] NA NA NA 1.06 1.1 ...\n $ Yield_filled_mm_7   : num [1:229559] NA NA NA 1.06 1.1 ...\n $ CalendarYear        : num [1:229559] 2017 2017 2017 2017 2017 ...\n $ Month               : num [1:229559] 7 7 7 7 8 8 8 8 8 8 ...\n $ MonthName           : Factor w/ 12 levels \"Apr\",\"May\",\"Jun\",..: 4 4 4 4 5 5 5 5 5 5 ...\n $ WaterYear           : num [1:229559] 2018 2018 2018 2018 2018 ...\n $ DayofYear           : num [1:229559] 119 120 121 122 123 124 125 126 127 128 ...\n\n\n\n\n5.1.2 Trim to focal site\n\n\nCode\ndat_wb &lt;- dat %&gt;% filter(site_name == \"West Brook NWIS\")\n\n\nRaw flow\n\n\nCode\ndat_wb %&gt;% select(date, Yield_filled_mm) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTotal daily streamflow in yield (mm), over the period of record",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#sensitivity-analysis",
    "href": "Event Delineation/HydroEvents.html#sensitivity-analysis",
    "title": "5  Hydro Event Delineation",
    "section": "5.2 Sensitivity analysis",
    "text": "5.2 Sensitivity analysis\nMany of the EcoDrought time series data are incomplete. At some sites, discharge data is available only during the summer and/or fall periods, and at other sites, time series data are interrupted due to malfunctioning sensors and/or ice formation (“ice spikes”). So how does the length of the time series affect baseflow separation (and subsequent event identification)? Wasko and Guo (2022) use a 67 day time series of flow to demonstrate the utility of the hydroEvents packages, suggesting digital baseflow separation techniques may be valid for relatively short time series.\nHere, I perform a simple sensitivity analysis to explore the effect of time series length on the results of baseflow separation. Essentially, perform baseflow separation on increasingly smaller subsets of the data. With the default parameters, the minimum number of days/observations needed is 31. This is because the default number of points reflected at start and end of data (r) is 30. Reflection allows bf/bfi to be calculated over the entire period of record as the underlying baseflow separation equations result in “issues of”Warm-up” and “cool-down” as the recursive filter is moved forward and backward over the dataset” (Ladson et al. 2013, Australian Journal of Water Resources). baseflowB() uses a default reflection period of 30, which Ladson et al. (2013) found to “provide a realistic baselfow response for the start and end of the actual flow data”.\n\n\nCode\ndat_wb_sens &lt;- dat_wb %&gt;% mutate(bf_c = baseflowB(Yield_filled_mm)$bf, bfi_c = baseflowB(Yield_filled_mm)$bfi) %&gt;% select(date, bf_c, bfi_c) %&gt;%\n  left_join(dat_wb[1:(365*3),] %&gt;% mutate(bf_3y = baseflowB(Yield_filled_mm)$bf, bfi_3y = baseflowB(Yield_filled_mm)$bfi) %&gt;% select(date, bf_3y, bfi_3y)) %&gt;%\n  left_join(dat_wb[1:(365),] %&gt;% mutate(bf_1y = baseflowB(Yield_filled_mm)$bf, bfi_1y = baseflowB(Yield_filled_mm)$bfi) %&gt;% select(date, bf_1y, bfi_1y)) %&gt;%\n  left_join(dat_wb[1:(182),] %&gt;% mutate(bf_6m = baseflowB(Yield_filled_mm)$bf, bfi_6m = baseflowB(Yield_filled_mm)$bfi) %&gt;% select(date, bf_6m, bfi_6m)) %&gt;%\n  left_join(dat_wb[1:(90),] %&gt;% mutate(bf_3m = baseflowB(Yield_filled_mm)$bf, bfi_3m = baseflowB(Yield_filled_mm)$bfi) %&gt;% select(date, bf_3m, bfi_3m)) %&gt;%\n  left_join(dat_wb[1:(35),] %&gt;% mutate(bf_1m = baseflowB(Yield_filled_mm)$bf, bfi_1m = baseflowB(Yield_filled_mm)$bfi) %&gt;% select(date, bf_1m, bfi_1m))\n\n\n\n5.2.1 Compare baseflow\nDivergence in baseflow among datasets is a result of the reflected data of the shorter dataset not matching the actual data of the longer dataset. As a result, divergence really only occurs at the end of each time series and is generally small in magnitude.\n\n\nCode\ndat_wb_sens %&gt;% select(date, bf_c, bf_3y, bf_1y, bf_6m, bf_3m, bf_1m) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily baseflow in yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTime series of baseflow derived from datasets of different lengths.\n\n\n\n\nCode\nggpairs(dat_wb_sens %&gt;% select(bf_c, bf_3y, bf_1y, bf_6m, bf_3m, bf_1m)) + geom_abline(intercept = 0, slope = 1, color = \"red\")\n\n\n\n\n\nPairs plot of baseflow derrived from datasets of different lengths. Red lines are 1:1.\n\n\n\n\n\n\n5.2.2 Compare baseflow index\nThe story here is essentially the same as above: divergence is ~minimal and restricted to the end of each time series. However, we note that divergence in BFI appears to increase as absolute flow/baseflow decreases, because small differences in absolute space become much larger in relative space when absolute values are small.\n\n\nCode\ndat_wb_sens %&gt;% select(date, bfi_c, bfi_3y, bfi_1y, bfi_6m, bfi_3m, bfi_1m) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily baseflow in yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTime series of baseflow index derived from datasets of different lengths.\n\n\n\n\nCode\nggpairs(dat_wb_sens %&gt;% select(bf_c, bf_3y, bf_1y, bf_6m, bf_3m, bf_1m)) + geom_abline(intercept = 0, slope = 1, color = \"red\")\n\n\n\n\n\nPairs plot of baseflow derrived from datasets of different lengths. Red lines are 1:1.",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#baseflow-separation",
    "href": "Event Delineation/HydroEvents.html#baseflow-separation",
    "title": "5  Hydro Event Delineation",
    "section": "5.3 Baseflow separation",
    "text": "5.3 Baseflow separation\nPerform baseflow separation. See Wasko and Guo (2022, Hydrological Processes) for recommendations on parameterization, as different algorithms and alpha values can produce different results. Section 4.1: “…users should not simply use recommended filter parameter values from literature in combination with any baseflow filter code without verification of their choice of filter parameter. As the digital baseflow filter is not tied to any physical realism (Nathan and McMahon, 1990) and a larger fractional baseflow may aid identification of events—even if this is not strictly baseflow as per its definition (Linsley et al., 1958)…”.\nIt is not actually necessary to do this separately, as baseflow separation is conducted in the event delineation function internally. But it is helpful to view the results and explore how different parameterizations yield different baseflow contributions.\n\n5.3.1 West Brook\n\n\nCode\ndat_wb &lt;- dat %&gt;% filter(site_name %in% c(\"West Brook NWIS\", \"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\"))\ndat_wb_bf &lt;- dat_wb %&gt;% \n  filter(!is.na(Yield_filled_mm)) %&gt;% \n  select(site_name, basin, subbasin, WaterYear, date, Yield_filled_mm, flow_mean_filled_cms, area_sqkm) %&gt;%\n  group_by(site_name) %&gt;%\n  mutate(bf = baseflowB(Yield_filled_mm)$bf, bfi = baseflowB(Yield_filled_mm)$bfi) %&gt;%\n  ungroup()\nhead(dat_wb_bf)\n\n\n# A tibble: 6 × 10\n  site_name   basin      subbasin   WaterYear date       Yield_filled_mm\n  &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;date&gt;               &lt;dbl&gt;\n1 Avery Brook West Brook West Brook      2020 2020-02-20            1.43\n2 Avery Brook West Brook West Brook      2020 2020-02-21            1.42\n3 Avery Brook West Brook West Brook      2020 2020-02-22            1.22\n4 Avery Brook West Brook West Brook      2020 2020-02-23            1.28\n5 Avery Brook West Brook West Brook      2020 2020-02-24            1.40\n6 Avery Brook West Brook West Brook      2020 2020-02-25            1.76\n# ℹ 4 more variables: flow_mean_filled_cms &lt;dbl&gt;, area_sqkm &lt;dbl&gt;, bf &lt;dbl&gt;,\n#   bfi &lt;dbl&gt;\n\n\n\n\nCode\ndat_wb_bf %&gt;% filter(site_name == \"West Brook NWIS\") %&gt;% select(date, Yield_filled_mm, bf, bfi) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTotal daily streamflow in yield (mm), baseflow in yield, and fractional baseflow index over the period of record for site West Brook NWIS\n\n\n\n\n5.3.2 Spread Creek\nPerform baseflow separation for spread creek, an example of a snowmelt dominated stream. Note that with the default parameters, the ~entire summer/fall period could potentially be classified as a single event\n\n\nCode\nalp &lt;- 0.925\ndat_sh &lt;- dat %&gt;% \n  filter(site_name %in% c(\"SF Spread Creek Lower NWIS\")) %&gt;% \n  filter(!is.na(Yield_filled_mm)) %&gt;% \n  select(site_name, basin, subbasin, WaterYear, date, Yield_filled_mm) %&gt;%\n  group_by(site_name) %&gt;%\n  mutate(bf = baseflowB(Yield_filled_mm, alpha = alp)$bf, bfi = baseflowB(Yield_filled_mm, alpha = alp)$bfi) %&gt;%\n  ungroup()\ndat_sh %&gt;% filter(site_name == \"SF Spread Creek Lower NWIS\") %&gt;% select(date, Yield_filled_mm, bf, bfi) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTotal daily streamflow in yield (mm), baseflow in yield, and fractional baseflow index over the period of record for site SF Spread Creek Lower NWIS",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#event-identification",
    "href": "Event Delineation/HydroEvents.html#event-identification",
    "title": "5  Hydro Event Delineation",
    "section": "5.4 Event identification",
    "text": "5.4 Event identification\nThere are multiple options for methods of event identification. Section 4.2 in Wasko and Guo (2022): It can be generalized that, if the aim of the analysis is to identify independent streamflow maxima then eventMaxima() and eventMinima() work well and indeed have been traditionally employed for this task. If identifying independent small events becomes difficult, or the aim is to identify wet spells, eventBaseflow() may be preferred.” In our case, small events are likely important, so we use eventBaseflow() with a ~large values for BFI_Th to capture those small events.\nThe aim is to understand how water availability affects differences in yield between Big G and Little g during hydrologic events and the intervening periods (non-event baseflow periods). Therefore, we identify events from the Big G data, apply event/non-event time periods to the little g data, then explore G-g deviations during both events and non-events as a function of\nSeparate Big G and Little G data\n\n\nCode\ndat_big &lt;- dat_wb_bf %&gt;% filter(site_name == \"West Brook NWIS\")\ndat_little &lt;- dat_wb_bf %&gt;% filter(site_name != \"West Brook NWIS\")\n\n\nIdentify events at Big G:\n\n\nCode\nevents &lt;- eventBaseflow(dat_big$Yield_filled_mm, BFI_Th = 0.75)\nevents &lt;- events %&gt;% mutate(len = end - srt + 1)\nhead(events)\n\n\n  srt end which.max      max       sum len\n1   6   9         7 2.528865  7.652927   4\n2  12  15        13 2.006509  6.881830   4\n3  26  31        27 6.351183 19.045257   6\n4  31  35        33 3.026347 11.881521   5\n5  41  44        42 3.125843 10.115461   4\n6  47  50        48 3.125843 10.156918   4\n\n\nPlot Big G events using the default function\n\n\nCode\nplotEvents(dat_big$Yield_filled_mm, events = events)\n\n\n\n\n\nTime series of hydrologic events at Big G, identified using eventBaseflow().\n\n\n\n\nNow add variables to the Big G time series data specifying events and non-events\n\n\nCode\n# define positions of non-events\nsrt &lt;- c(1)\nend &lt;- c(events$srt[1]-1)\nfor (i in 2:(dim(events)[1])) {\n  srt[i] &lt;- events$end[i-1]+1\n  end[i] &lt;- events$srt[i]-1\n}\nnonevents &lt;- data.frame(tibble(srt, end) %&gt;% mutate(len = end - srt) %&gt;% filter(len &gt;= 0) %&gt;% select(-len) %&gt;% add_row(srt = events$end[dim(events)[1]]+1, end = dim(dat_big)[1]))\n\n# create vectors of binary event/non-event and event IDs\nisevent_vec &lt;- rep(2, times = dim(dat_big)[1])\neventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(events)[1]) { \n  isevent_vec[c(events[i,1]:events[i,2])] &lt;- 1 \n  eventid_vec[c(events[i,1]:events[i,2])] &lt;- i\n}\n\n# create vector of non-event IDs\nnoneventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n\n# create vector of \"agnostic events\": combined hydro events and non-events\nagnevents &lt;- rbind(events %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\nagneventid_vec &lt;- c()\nfor (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n# add event/non-event vectors to Big G data\ndat_big &lt;- dat_big %&gt;% \n  mutate(isevent = isevent_vec, \n         eventid = eventid_vec,\n         noneventid = noneventid_vec,\n         agneventid = agneventid_vec,\n         big_event_yield = ifelse(isevent_vec == 1, Yield_filled_mm, NA),\n         big_nonevent_yield = ifelse(isevent_vec == 2, Yield_filled_mm, NA),\n         big_event_quick = big_event_yield - bf) %&gt;%\n  rename(big_yield = Yield_filled_mm, big_bf = bf, big_bfi = bfi, big_flow = flow_mean_filled_cms, big_area_sqkm = area_sqkm)\n(dat_big)\n\n\n# A tibble: 1,780 × 17\n   site_name       basin      subbasin   WaterYear date       big_yield big_flow\n   &lt;chr&gt;           &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n 1 West Brook NWIS West Brook West Brook      2020 2020-02-01      1.57    0.535\n 2 West Brook NWIS West Brook West Brook      2020 2020-02-02      1.52    0.518\n 3 West Brook NWIS West Brook West Brook      2020 2020-02-03      1.45    0.496\n 4 West Brook NWIS West Brook West Brook      2020 2020-02-04      1.41    0.481\n 5 West Brook NWIS West Brook West Brook      2020 2020-02-05      1.42    0.484\n 6 West Brook NWIS West Brook West Brook      2020 2020-02-06      1.51    0.515\n 7 West Brook NWIS West Brook West Brook      2020 2020-02-07      2.53    0.864\n 8 West Brook NWIS West Brook West Brook      2020 2020-02-08      2.04    0.697\n 9 West Brook NWIS West Brook West Brook      2020 2020-02-09      1.58    0.538\n10 West Brook NWIS West Brook West Brook      2020 2020-02-10      1.47    0.501\n# ℹ 1,770 more rows\n# ℹ 10 more variables: big_area_sqkm &lt;dbl&gt;, big_bf &lt;dbl&gt;, big_bfi &lt;dbl&gt;,\n#   isevent &lt;dbl&gt;, eventid &lt;int&gt;, noneventid &lt;int&gt;, agneventid &lt;int&gt;,\n#   big_event_yield &lt;dbl&gt;, big_nonevent_yield &lt;dbl&gt;, big_event_quick &lt;dbl&gt;\n\n\n\n\nCode\ndat_big %&gt;% select(date, big_yield, big_bf, big_event_yield, big_nonevent_yield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTime series of hydrologic events at Big G, identified using eventBaseflow().\n\n\nApplying Big G event/non-event periods to little g time series data inherently assumes that event/non-event periods would be similarly delineated for little g. If this assumption does not hold, then non-event little g flow would be included in event periods, and vice-versa. How well does this assumption hold?\n\n\nCode\nsites &lt;- c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")\n\ndat_little2 &lt;- dat_little %&gt;% filter(site_name == \"Jimmy Brook\")\nevents_little &lt;- eventBaseflow(dat_little2$Yield_filled_mm, BFI_Th = 0.75)\n\n# define positions of non-events\nsrt &lt;- c(1)\nend &lt;- c(events_little$srt[1]-1)\nfor (i in 2:(dim(events_little)[1])) {\n  srt[i] &lt;- events_little$end[i-1]+1\n  end[i] &lt;- events_little$srt[i]-1\n}\nnonevents &lt;- data.frame(tibble(srt, end) %&gt;% mutate(len = end - srt) %&gt;% filter(len &gt;= 0) %&gt;% select(-len) %&gt;% add_row(srt = events_little$end[dim(events_little)[1]]+1, end = dim(dat_little2)[1]))\n\n# create vectors of binary event/non-event and event IDs\nisevent_vec &lt;- rep(2, times = dim(dat_little2)[1])\neventid_vec &lt;- rep(NA, times = dim(dat_little2)[1])\nfor (i in 1:dim(events_little)[1]) { \n  isevent_vec[c(events_little[i,1]:events_little[i,2])] &lt;- 1 \n  eventid_vec[c(events_little[i,1]:events_little[i,2])] &lt;- i\n}\n\n# create vector of non-event IDs\nnoneventid_vec &lt;- rep(NA, times = dim(dat_little2)[1])\nfor (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n\n# create vector of \"agnostic events\": combined hydro events and non-events\nagnevents &lt;- rbind(events_little %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\nagneventid_vec &lt;- c()\nfor (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n# add event/non-event vectors to Big G data\ndat_little2 &lt;- dat_little2 %&gt;% \n  mutate(isevent = isevent_vec, \n         eventid = eventid_vec,\n         noneventid = noneventid_vec,\n         agneventid = agneventid_vec,\n         little_event_yield = ifelse(isevent_vec == 1, Yield_filled_mm, NA),\n         little_nonevent_yield = ifelse(isevent_vec == 2, Yield_filled_mm, NA),\n         little_event_quick = little_event_yield - bf) %&gt;%\n  rename(little_yield = Yield_filled_mm, little_bf = bf, little_bfi = bfi)\n\n\ndat_big %&gt;% select(date, big_event_yield) %&gt;% left_join(dat_little2 %&gt;% select(date, little_event_yield)) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTime series of yield for Big G (West Brook NWIS) and one little g site (Jimmy Brook) during hydrologic events as delineated for Big G and little g, respectively.\n\n\nWhether or not events alight between G and g is highly variable. In some cases, g events begin/end prior to G events, and in other cases g events begin/end later G events. In some cases g events are shorter than G events, and in other cases they are longer. In many cases, events are perfectly matched. Importantly, peaks in yield are almost always synchronous.\nUltimately, does this matter given that we are simply using this as a method to break up our data? Furthermore, the framing of the ~entire project is that Big G is the reference by which to compare all little g’s. In this sense, applying event/non-event periods derived from G to g matches this persepctive.",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#join-events-to-little-g",
    "href": "Event Delineation/HydroEvents.html#join-events-to-little-g",
    "title": "5  Hydro Event Delineation",
    "section": "5.5 Join events to Little g",
    "text": "5.5 Join events to Little g\n\n\nCode\n# wide\ndat_wb2 &lt;- dat_little %&gt;% \n  filter(date &gt;= min(dat_big$date) & date &lt;= max(dat_big$date)) %&gt;%\n  left_join(dat_big %&gt;% select(-site_name)) %&gt;% \n  group_by(site_name, basin, subbasin, agneventid) %&gt;% \n  summarise(eventlen = n(),\n            mindate = min(date),\n            isevent = unique(isevent), \n            yield_little_cum = sum(Yield_filled_mm+0.01),\n            yield_big_cum = sum(big_yield+0.01),\n            yield_little_cum_log = log(yield_little_cum),\n            yield_big_cum_log = log(yield_big_cum),\n            xxx_little = sum(flow_mean_filled_cms * 86400 * (1/unique(area_sqkm)) * (1/1000000) * 1000),\n            yyy_little = sum(flow_mean_filled_cms * 86400) * (1/unique(area_sqkm)) * (1/1000000) * 1000,\n            yield_little_mean_log = mean(log(Yield_filled_mm+0.01)),\n            yield_big_mean_log = mean(log(big_yield+0.01))) %&gt;%\n  ungroup() %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")),\n         site_name_cd = as.numeric(site_name),\n         z_yield_big_cum_log = as.numeric(scale(yield_big_cum_log, center = TRUE, scale = TRUE)),\n         z_yield_big_mean_log = as.numeric(scale(yield_big_mean_log, center = TRUE, scale = TRUE)))\n\nplot(yield_little_cum ~ xxx_little, dat_wb2, main = \"cumulative yield derived using fasstr ~ by-hand\")\nabline(a = 0, b = 1, col = \"red\")\n\n\n\n\n\n\n\n\n\nCode\nplot(yyy_little ~ xxx_little, dat_wb2, main = \"cumulative yield derived from cumulative flow ~ summed daily yield\")\nabline(a = 0, b = 1, col = \"red\")\n\n\n\n\n\n\n\n\n\nCode\nplot(yield_little_mean_log ~ yield_little_cum_log, dat_wb2, main = \"mean log yield ~ cumulative log yield\")\nabline(a = 0, b = 1, col = \"red\")\n\n\n\n\n\n\n\n\n\nCode\n# write to file\nwrite_csv(dat_wb2, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Event Delineation/EcoDrought_Data_EventNonEvent_WestBrookonly.csv\")\n\n\nView relationship between Big G and little g, color by site, facet by event/non-event.\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, group = site_name, color = site_name)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~isevent)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods.\n\n\n\n\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~isevent)\n\n\n\n\n\nEffect of mean (log) yield at Big G on mean (log) yield at little g during baseflow and event periods.\n\n\n\n\nView relationship between Big G and little g, color by event/non-event, facet by site. For most sites (except may Obear Brook), G-g relationships are identical between events and non-event.\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, group = isevent, color = isevent)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods.\n\n\n\n\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = isevent, color = isevent)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\n\n\nEffect of mean (log) yield at Big G on mean (log) yield at little g during baseflow and event periods.\n\n\n\n\nView relationship between Big G and little g, color by site, all together\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, group = site_name, color = site_name)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = T)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g.\n\n\n\n\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = T)\n\n\n\n\n\nEffect of mean (log) yield at Big G on mean (log) yield at little g.\n\n\n\n\nView relationship between Big G and among-site/event-specific standard deviation in little g.\n\n\nCode\ndat_wb2 %&gt;% \n  select(agneventid, yield_big_cum_log, yield_little_cum_log) %&gt;% \n  group_by(agneventid) %&gt;% \n  summarize(unq_big = unique(yield_big_cum_log),\n            sd_little = sd(yield_little_cum_log)) %&gt;% \n  ggplot(aes(x = unq_big, y = sd_little)) + geom_point() + geom_smooth() + ylim(0,1.5)\n\n\n\n\n\nDerived from log cumulative yield\n\n\n\n\n\n\nCode\ndat_wb2 %&gt;% \n  select(agneventid, yield_big_mean_log, yield_little_mean_log) %&gt;% \n  group_by(agneventid) %&gt;% \n  summarize(unq_big = unique(yield_big_mean_log),\n            sd_little = sd(yield_little_mean_log)) %&gt;% \n  ggplot(aes(x = unq_big, y = sd_little)) + geom_point() + geom_smooth() + ylim(0,1.5)\n\n\n\n\n\nDerived from mean log yield",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html",
    "href": "Big G Little g/WedgeModel.html",
    "title": "6  The Wedge Model",
    "section": "",
    "text": "6.1 Q, H, A\nPurpose: Define the Wedge hypothesis and model in JAGS.\nQuestions:\nThe Wedge Hypothesis: Among- and within-site diversity in g response to G drive spatiotemporal variation in flow across river networks\nApproach",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#q-h-a",
    "href": "Big G Little g/WedgeModel.html#q-h-a",
    "title": "6  The Wedge Model",
    "section": "",
    "text": "How does water availability (G) affect upstream diversity in streamflow regimes (g)?\n\nHow does streamflow diversity manifest as heterogeneity within and among locations in the upstream river network?\n\nWhat are the relative contributions of within- and among-site diversity to the total streamflow diversity across the river network and does this change with water availability?\n\n\n\nAmong-site wedge: heterogeneity in physical characteristics among sites diversify little g response during low flows, but diversity in little g response attenuates (decreases) during high flows\nWithin-site wedge: within sites, variation in little g response to G is greater at low flows than at high flows\nAdditive diversity in the response of little g to Big G among and within sites drives total streamflow diversity across river networks\n\n\n\nBreak up data into manageable chunks using event/non-event delineation\n\nUsing Big G flow time series data, perform baseflow separation and event delineation to break up data into event and intervening non-event (baseflow) periods.\nApply Big G event/non-event periods to corresponding little g time series data and calculate (log) volumetric yield during each period for both G and g.\n\nUsing a Bayesian hierarchical model to account for site-level variation, model g ~ G, where g is (log) volumetric yield at little g and G is (log) volumetric yield at Big G during successive event/non-event periods.\n\nFit site-aware and site-agnostic models to describe within- and among-site diversity in g response to G, respectively.\nDerive measures of observed and expected g variance dampening with increasing G under different assumptions regarding among- and within-site streamflow diversity\n\n\n\n6.1.1 Conceptual diagram\nThe Wedge Hypothesis states that among- and within-site diversity in g response to G drive spatiotemporal variation in streamflow across entire river networks:\n\n\n\nThe Wedge Hypothesis - general\n\n\nThe hypothesis can be represented with a relatively simple hierarchical model:\n\n\n\nThe Wedge Hypothesis - parameters\n\n\nFrom the fitted model, we can assess the relative contributions of within- and among-site diversity to total streamflow diversity across the river network and explore the extent to which this changes with water availability:\n\n\n\nThe Wedge Hypothesis - portfolio strength",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#data",
    "href": "Big G Little g/WedgeModel.html#data",
    "title": "6  The Wedge Model",
    "section": "6.2 Data",
    "text": "6.2 Data\n\n6.2.1 Site info and event data\n\n\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# delineated event/non-event volumetric yield data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Event Delineation/EcoDrought_Data_EventNonEvent_WestBrookonly.csv\") %&gt;% mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")))\nstr(dat)\n\n\ntibble [689 × 18] (S3: tbl_df/tbl/data.frame)\n $ site_name            : Factor w/ 9 levels \"West Brook Lower\",..: 8 8 8 8 8 8 8 8 8 8 ...\n $ basin                : chr [1:689] \"West Brook\" \"West Brook\" \"West Brook\" \"West Brook\" ...\n $ subbasin             : chr [1:689] \"West Brook\" \"West Brook\" \"West Brook\" \"West Brook\" ...\n $ agneventid           : num [1:689] 5 6 7 8 9 10 11 12 13 14 ...\n $ eventlen             : num [1:689] 6 5 5 5 4 2 4 4 11 6 ...\n $ mindate              : Date[1:689], format: \"2020-02-20\" \"2020-02-26\" ...\n $ isevent              : num [1:689] 2 1 1 2 1 2 1 2 1 2 ...\n $ yield_little_cum     : num [1:689] 8.57 23.21 18.74 15.54 14.08 ...\n $ yield_big_cum        : num [1:689] 7.04 17.14 11.93 9.41 10.16 ...\n $ yield_little_cum_log : num [1:689] 2.15 3.14 2.93 2.74 2.64 ...\n $ yield_big_cum_log    : num [1:689] 1.95 2.84 2.48 2.24 2.32 ...\n $ xxx_little           : num [1:689] 8.51 23.16 18.69 15.49 14.04 ...\n $ yyy_little           : num [1:689] 8.51 23.16 18.69 15.49 14.04 ...\n $ yield_little_mean_log: num [1:689] 0.35 1.37 1.3 1.13 1.23 ...\n $ yield_big_mean_log   : num [1:689] 0.154 1.124 0.859 0.632 0.909 ...\n $ site_name_cd         : num [1:689] 8 8 8 8 8 8 8 8 8 8 ...\n $ z_yield_big_cum_log  : num [1:689] 0.284 0.868 0.63 0.475 0.525 ...\n $ z_yield_big_mean_log : num [1:689] 0.434 1.24 1.019 0.831 1.061 ...\n\n\n\n\n6.2.2 Visualize g~G relationships\nView relationship between Big G and little g, color by site, facet by event/non-event.\n\n\nCode\ndat %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, group = site_name, color = site_name)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~isevent)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods.\n\n\n\n\nView relationship between Big G and little g, color by event/non-event, facet by site. For most sites (except may Obear Brook), G-g relationships are identical between events and non-event.\n\n\nCode\ndat %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, group = isevent, color = isevent)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods.\n\n\n\n\n\n\n6.2.3 Examine hysteresis\nDoes the g~G relationship change over time?\n\n\nCode\ndat %&gt;% \n  mutate(doy = yday(mindate)) %&gt;%\n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, color = doy)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  scale_color_gradient2(midpoint = 182, low = \"orange\", mid = \"purple3\", high = \"orange\") +\n  facet_wrap(~site_name)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods. Points colored by day of year.\n\n\n\n\n\n\nCode\ndat %&gt;% \n  mutate(season = ifelse(month(mindate) %in% c(12,1,2), \"winter\",\n                         ifelse(month(mindate) %in% c(3,4,5), \"spring\",\n                                ifelse(month(mindate) %in% c(6,7,8), \"summer\", \"autumn\")))) %&gt;%\n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, group = season, color = season)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods, by season.\n\n\n\n\nYes, it does appear that the relationship between g and G changes is time-dependent, potentially motivating some inclusion of time as a covariate (and interaction with big G effect…circular regression?). However, this also likely drives the shape/existence of the little wedges. So, is it necessary to account for?",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#declare-model",
    "href": "Big G Little g/WedgeModel.html#declare-model",
    "title": "6  The Wedge Model",
    "section": "6.3 Declare model",
    "text": "6.3 Declare model\nBased on results above, there does not appear to be any significant difference in the G-g relationship for event and non-event periods. Therefore, do not include random intercepts/slopes (by event/non-event) in the model. Previously, I tried to estimate the G-g differences using an intercept model, with the magnitude of difference a function of water availability. However, when Q = Qg, this simplified to a linear regression between Qg (dependent var.) and QG (independent var.), which is ultimately what is of interest. I estimate this regression model below:\nCorrelation between site-level slopes and site-level intercepts is modeled as specified on pgs. 362 and 376 in Gelman and Hill (2007).\n\nData\n\nQg: log volumetric yield at little g\nsites: numeric site id\nQG: log volumetric yield at Big G\nnObs: number of observations\nnSites: number of sites (little g sites)\n\nParameters\n\nalpha: site-level intercept\nbeta: site-level effect of Big G on little g (slope)\nalpha.mu: global intercept\nbeta.mu: global effect of Big G on little g (slope)\nalpha.sigma: site-level variability in the intercept\nbeta.sigma: site-level variability in the slope\nsig.alpha: site-level intercept for process error\nsig.beta: site-level effect of Big G on process error (slope)\nsig.alpha.mu: global process error intercept\nsig.beta.mu: global process error slope\nsig.alpha.sigma: site-level variability in process error intercept\nsig.beta.sigma: site-level variability in process error slope\nrho: correlation between site-leve intercepts (alpha) and slopes (beta)\n\nDerived values\n\npredlg: predicted little g\ndiff: difference between predicted little g and Big G\nVpObs: observed population variance, conditional on x\nVpScen1: expected population variance, no within or among-site diversity\nVpScen2: expected population variance, no within-site diversity\nVpScen3: expected population variance, no among-size diversity\nport1, port2, port3: predicted portfolio strength (over a range of G) compared to 3 alternative hypotheses\nattenObs, atten1, atten2, atten3: attentuation strength (“wedginess”) of observed data and expected under 3 alternative hypotheses\n\n\n\n\nCode\ncat(\"model {\n\n##--- LIKELIHOOD ---------------------------------------------------##\n\nfor (i in 1:nObs) {\n\n  Qg[i] ~ dnorm(mu[i], pow(sigma[i], -2))\n  mu[i] &lt;- alpha[sites[i]] + beta[sites[i]] * QG[i]\n  log(sigma[i]) &lt;- sig.alpha[sites[i]] + sig.beta[sites[i]] * QG[i]\n  \n  # Log-likelihood\n  loglik[i] &lt;- logdensity.norm(Qg[i], mu[i], pow(sigma[i], -2))\n  \n  ## SITE AGNOSTIC\n  Qg2[i] ~ dnorm(ag.mu[i], pow(ag.sigma[i], -2))\n  ag.mu[i] &lt;- ag.alpha + ag.beta * QG[i]\n  log(ag.sigma[i]) &lt;- ag.sig.alpha + ag.sig.beta * QG[i]  \n  }\n\n\n##--- PRIORS --------------------------------------------------------##\n\n# Site-specific parameters\nfor (j in 1:nSites) {\n    alpha[j] &lt;- B[j,1]\n    beta[j] &lt;- B[j,2]\n    B[j,1:2] ~ dmnorm(B.hat[j,], Tau.B[,])\n    B.hat[j,1] &lt;- alpha.mu\n    B.hat[j,2] &lt;- beta.mu\n    \n    sig.alpha[j] ~ dnorm(sig.alpha.mu, pow(sig.alpha.sigma, -2))\n    sig.beta[j] ~ dnorm(sig.beta.mu, pow(sig.beta.sigma, -2))\n    }\n    \n# global parameters\nalpha.mu ~ dnorm(0, pow(10, -2))\nbeta.mu ~ dnorm(0, pow(10, -2))\nsig.alpha.mu ~ dnorm(0, pow(10, -2))\nsig.beta.mu ~ dnorm(0, pow(10, -2))\n\n# variance-covariance matrix components\nTau.B[1:2,1:2] &lt;- inverse(Sigma.B[,])\nSigma.B[1,1] &lt;- pow(alpha.sigma, 2)\nSigma.B[2,2] &lt;- pow(beta.sigma, 2)\nSigma.B[1,2] &lt;- rho * alpha.sigma * beta.sigma\nSigma.B[2,1] &lt;- Sigma.B[1,2]\n\nalpha.sigma ~ dunif(0.001, 100)\nbeta.sigma ~ dunif(0.001, 100)\nrho ~ dunif(-1,1)\n\n# among-site variation in sigma parameters\nsig.alpha.sigma ~ dunif(0.001, 100)\nsig.beta.sigma ~ dunif(0.001, 100)\n\n\n## SITE AGNOSTIC\nag.alpha ~ dnorm(0, pow(10, -2))\nag.beta ~ dnorm(0, pow(10, -2))\nag.sig.alpha ~ dnorm(0, pow(10, -2))\nag.sig.beta ~ dnorm(0, pow(10, -2))\n\n\n##--- DERIVED VALUES ------------------------------------------------##\n\n# expected deviation from Big G\nfor (j in 1:nSites) { \n  for (i in 1:nDiff) {\n    predlg[j,i] &lt;- alpha[j] + beta[j] * QGvec[i]\n    diff[j,i] &lt;- (alpha[j] + beta[j] * QGvec[i]) - QGvec[i]\n  }}\n\n\n# variance decomposition and standardization\nfor (i in 1:nDiff) {\n\n  # observed population variance, conditional on x\n  VpObs[i] &lt;- ((beta.mu^2) * varx) + ((alpha.sigma^2) + ((QGvec[i]^2) * (beta.sigma^2)) + (2 * QGvec[i] * (rho * alpha.sigma * beta.sigma))) + ((exp(sig.alpha.mu + sig.beta.mu * QGvec[i]))^2)\n  \n  # expected population variance, no within or among-site diversity\n  VpScen1[i] &lt;- ((beta.mu^2) * varx) + ((exp(sig.alpha.mu))^2)\n  \n  # expected population variance, no within-site diversity\n  VpScen2[i] &lt;- ((beta.mu^2) * varx) + ((alpha.sigma^2) + ((QGvec[i]^2) * (beta.sigma^2)) + (2 * QGvec[i] * (rho * alpha.sigma * beta.sigma))) + ((exp(sig.alpha.mu))^2)\n  \n  # expected population variance, no among-size diversity\n  VpScen3[i] &lt;- ((beta.mu^2) * varx) + ((exp(sig.alpha.mu + sig.beta.mu * QGvec[i]))^2)\n  \n  # portfolio strength: how much more diversity in streamflow do we observe at the little g gages than expected under alternative (null) hypotheses?\n  port1[i] &lt;- VpObs[i] / VpScen1[i]\n  port2[i] &lt;- VpObs[i] / VpScen2[i]\n  port3[i] &lt;- VpObs[i] / VpScen3[i]\n  \n  # variance in raw response values, agnostic to site (i.e., variance in the sample)\n  VarAg[i] &lt;- (exp(ag.sig.alpha + ag.sig.beta * QGvec[i]))^2\n}\n\n\n# attenuation strength: how much more diversity in streamflow (among little g gages) do we observe at low vs. high flows?\nattenObs &lt;- VpObs[1] / VpObs[nDiff]\natten1 &lt;- VpScen1[1] / VpScen1[nDiff]\natten2 &lt;- VpScen2[1] / VpScen2[nDiff]\natten3 &lt;- VpScen3[1] / VpScen3[nDiff]\n\n}\", file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod_Events_2_corr.txt\")",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#fit-the-model",
    "href": "Big G Little g/WedgeModel.html#fit-the-model",
    "title": "6  The Wedge Model",
    "section": "6.4 Fit the model",
    "text": "6.4 Fit the model\n\n\nCode\n# vector of QG for prediction\nndiff &lt;- 100\nQGvec &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = ndiff)\n\n# gather data for JAGS\njags.data &lt;- list(\"nObs\" = dim(dat)[1], \"nSites\" = length(unique(dat$site_name_cd)), \n                  \"sites\" = dat$site_name_cd, #\"indev\" = dat_wb2$isevent,\n                  \"Qg\" = dat$yield_little_cum_log, \"QG\" = dat$yield_big_cum_log, \"Qg2\" = dat$yield_little_cum_log, \n                  \"QGvec\" = QGvec, \"nDiff\" = ndiff, \"varx\" = var(dat$yield_big_cum_log))\n\n# parameters to monitor\njags.params &lt;- c(\"alpha\", \"beta\", \"alpha.mu\", \"beta.mu\", \"alpha.sigma\", \"beta.sigma\", \n                 \"sig.alpha\", \"sig.beta\", \"sig.alpha.mu\", \"sig.beta.mu\", \"sig.alpha.sigma\", \"sig.beta.sigma\", \n                 \"rho\", \"diff\", \"predlg\", \"loglik\", \"mu\", \"Qg\", \n                 \"VpObs\", \"VpScen1\", \"VpScen2\", \"VpScen3\", \"port1\", \"port2\", \"port3\", \"attenObs\", \"atten1\", \"atten2\", \"atten3\",\n                 \"VarAg\")\n\n# initial values\nmyinits &lt;- function() {\n  list(alpha.mu = 0, beta.mu = 1, alpha.sigma = 1, beta.sigma = 0.1, \n       sig.alpha.mu = -0.5, sig.beta.mu = -0.2, sig.alpha.sigma = 0.4, sig.beta.sigma = 0.05, \n       ag.alpha = 0.3, ag.beta = 1, ag.sig.alpha = 0, ag.sig.beta = -0.2, rho = -0.8)\n}\n\n# run in jags\nmod_0 &lt;- jags.parallel(data = jags.data, inits = myinits, parameters.to.save = jags.params,\n                       model.file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod_Events_2_corr.txt\",\n                       n.chains = 10, n.thin = 50, n.burnin = 4000, n.iter = 14000, DIC = FALSE)\n# saveRDS(mod_0, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/Fitted models/GgMod_Events.rds\")\n\n\nGet MCMC samples and summary\n\n\nCode\ntop_mod &lt;- mod_0\n# generate MCMC samples and store as an array\nmodelout &lt;- top_mod$BUGSoutput\nMcmcList &lt;- vector(\"list\", length = dim(modelout$sims.array)[2])\nfor(i in 1:length(McmcList)) { McmcList[[i]] = as.mcmc(modelout$sims.array[,i,]) }\n# rbind MCMC samples from 10 chains \nMcmcdat_0 &lt;- rbind(McmcList[[1]], McmcList[[2]], McmcList[[3]], McmcList[[4]], McmcList[[5]], McmcList[[6]], McmcList[[7]], McmcList[[8]], McmcList[[9]], McmcList[[10]])\nparam.summary_0 &lt;- modelout$summary\nhead(param.summary_0)\n\n\n          mean sd     2.5%      25%      50%      75%    97.5% Rhat n.eff\nQg[1] 2.148762  0 2.148762 2.148762 2.148762 2.148762 2.148762    1     1\nQg[2] 3.144685  0 3.144685 3.144685 3.144685 3.144685 3.144685    1     1\nQg[3] 2.930699  0 2.930699 2.930699 2.930699 2.930699 2.930699    1     1\nQg[4] 2.743658  0 2.743658 2.743658 2.743658 2.743658 2.743658    1     1\nQg[5] 2.644678  0 2.644678 2.644678 2.644678 2.644678 2.644678    1     1\nQg[6] 1.624893  0 1.624893 1.624893 1.624893 1.624893 1.624893    1     1",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#model-diagnostics",
    "href": "Big G Little g/WedgeModel.html#model-diagnostics",
    "title": "6  The Wedge Model",
    "section": "6.5 Model diagnostics",
    "text": "6.5 Model diagnostics\n\n6.5.1 View R-hat\nAny problematic R-hat values (&gt;1.01)?\n\n\nCode\nmod_0$BUGSoutput$summary[,8][mod_0$BUGSoutput$summary[,8] &gt; 1.01]\n\n\n loglik[452]    port1[65]    port1[66]    port1[67]    port1[68]    port1[69] \n    1.010080     1.010151     1.010424     1.010663     1.010867     1.011032 \n   port1[70]    port1[71]    port1[72]    port1[73]    port1[74]    port1[75] \n    1.011159     1.011246     1.011293     1.011301     1.011272     1.011207 \n   port1[76]    port1[77]    port1[78]    port1[79]    port1[80]    port1[81] \n    1.011109     1.010981     1.010826     1.010648     1.010450     1.010234 \n   port1[82]    port3[61]    port3[62]    port3[63]    port3[64]    port3[65] \n    1.010006     1.010254     1.010789     1.011316     1.011829     1.012322 \n   port3[66]    port3[67]    port3[68]    port3[69]    port3[70]    port3[71] \n    1.012787     1.013219     1.013611     1.013956     1.014251     1.014489 \n   port3[72]    port3[73]    port3[74]    port3[75]    port3[76]    port3[77] \n    1.014668     1.014785     1.014839     1.014830     1.014760     1.014629 \n   port3[78]    port3[79]    port3[80]    port3[81]    port3[82]    port3[83] \n    1.014444     1.014207     1.013924     1.013600     1.013243     1.012857 \n   port3[84]    port3[85]    port3[86]    port3[87]    port3[88]    port3[89] \n    1.012449     1.012026     1.011591     1.011152     1.010712     1.010275 \npredlg[1,33] \n    1.026732 \n\n\n\n\n6.5.2 View traceplots\nFor global parameters and hyperparameters only…\n\n\nCode\nMCMCtrace(mod_0, ind = TRUE, params = c(\"alpha.mu\", \"beta.mu\", \"alpha.sigma\", \"beta.sigma\", \"sig.alpha.mu\", \"sig.beta.mu\", \"sig.alpha.sigma\", \"sig.beta.sigma\", \"rho\"), pdf = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.5.3 PP check\nGet observed and expected values\n\n\nCode\nppdat_obs &lt;- as.matrix(Mcmcdat_0[,startsWith(colnames(Mcmcdat_0), \"Qg\")])\nppdat_exp &lt;- as.matrix(Mcmcdat_0[,startsWith(colnames(Mcmcdat_0), \"mu\")])\n\n\nBayesian p-value: values approaching 0.5 indicate lack of bias in model estimates\n\n\nCode\nsum(ppdat_exp &gt; ppdat_obs) / (dim(ppdat_obs)[1]*dim(ppdat_obs)[2])\n\n\n[1] 0.4930435\n\n\nPosterior predictive check: ensure linearity and ~1:1 relationship between expected and observed (log) volumetric Qg yield\n\n\nCode\npar(mar = c(4.5,4.5,1,1))\nplot(apply(ppdat_exp, 2, median) ~ apply(ppdat_obs, 2, median), xlab = \"Observed Qg\", ylab = \"Expected Qg\")\nabline(a = 0, b = 1, col = \"red\", lwd = 2)\nlegend(\"topleft\", legend = \"1:1\", lwd = 2, col = \"red\", bty = \"n\")\n\n\n\n\n\n\n\n\n\nSite-specific posterior predictive check: does the model fit some sites better than others?\n\n\nCode\ntibble(obs = apply(ppdat_obs, 2, median), exp = apply(ppdat_exp, 2, median), sitecd = dat$site_name) %&gt;% ggplot(aes(x = obs, y = exp)) + geom_point() + geom_smooth(method = \"lm\") + geom_abline(intercept = 0, slope = 1, color = \"red\") + facet_wrap(~sitecd)\n\n\n\n\n\n\n\n\n\n\n\n6.5.4 Model selection\nPerform model selection using leave-one-out cross-validation (LOO-CV). Does the site-aware (random slopes/random intercepts) model perform better than the site-agnostic model?\nNote: this will need to be updated once we add other random effects specifications. For now, use LOO-CV as an additional check on model fitting…i.e., examine Pareto k estimates.\nAgain, model is well specified for all but 1 data point (k &gt; 1)\n\n\nCode\n# get log-likelihoods\nloglik1 &lt;- mod_0$BUGSoutput$sims.list$loglik\n\n# get relative effective sample size\nreff1 &lt;- relative_eff(exp(loglik1), chain_id = c(rep(1,200), rep(2,200), rep(3,200), rep(4,200), rep(5,200), \n                                                 rep(6,200), rep(7,200), rep(8,200), rep(9,200), rep(10,200)))\n\n# calculate loo\nloo1 &lt;- loo(loglik1, r_eff = reff1)\n\n# compare\nprint(loo1)\n\n\n\nComputed from 2000 by 689 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -426.8 26.6\np_loo        35.6  4.6\nlooic       853.7 53.2\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.8, 1.1]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     687   99.7%   228     \n   (0.7, 1]   (bad)        2    0.3%   &lt;NA&gt;    \n   (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;    \nSee help('pareto-k-diagnostic') for details.\n\n\nCode\nplot(loo1)",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#plot-model-output",
    "href": "Big G Little g/WedgeModel.html#plot-model-output",
    "title": "6  The Wedge Model",
    "section": "6.6 Plot model output",
    "text": "6.6 Plot model output\n\n6.6.1 Slope-int. correlation\nSlopes and intercepts are negatively correlated (this is not unexpected, and explains the attenuation/wedge shape of the data). As noted in Gelman and Hill, the strength of the correlation between slopes and intercepts is sensitive to how the data is centered (or not). Currently, data span 0 (in log space), so this isn’t really an artifact of the issues mentioned in Gelman and Hill (although if we mean centered the data this relationship does weaken slightly). It may actually make the most sense to force the intercept to be at the lowest value of log(G) (i.e., add min(log(G)) to all data, G and g). Intercepts would then represent the maximum expected variation in g during periods of lowest water availability. Alternatively, we could force the intercept to be at the highest valyes of log(G) (i.e., subtract max log(G) from all data) and test for random vs. fixed intercept (as suggested by Ben). Random intercepts would suggest that we still do see site-level variation in g when overall flows are high, whereas a fixed intercept would suggest minimal/no site-level variation in g at high flows. However, we do ultimately need to the slope/intercept correlation structure to do the variance decomposition.\n\n\nCode\nsitib &lt;- tibble(site_name = levels(dat$site_name),\n                slopes = param.summary_0[str_subset(rownames(param.summary_0), pattern = \"^beta\")[1:9],5],\n                intercepts = param.summary_0[str_subset(rownames(param.summary_0), pattern = \"^alpha\")[1:9],5]) \n\n# slope-intercept scatterplot\np1 &lt;- sitib %&gt;% ggplot(aes(x = slopes, y = intercepts, color = site_name)) + geom_point(size = 3) + theme_bw() + xlab(\"Site-level slope\") + ylab(\"Site-level intercept\")\n\n# \"rho\" posterior density\np2 &lt;- tibble(Mcmcdat_0[,\"rho\"]) %&gt;% ggplot(aes(x = Mcmcdat_0[, \"rho\"])) + geom_density(color = \"black\", fill = \"grey\") + theme_bw() + xlab(\"rho\") + ylab(\"Posterior density\") + xlim(-1,0)\n\n# arrange plots\nggarrange(p2, p1, ncol = 2, widths = c(0.35, 0.65))\n\n\n\n\n\n\n\n\n\nCode\n# correlation\n# cor.test(sitib$intercepts, sitib$slopes)\n\n\n\n\n6.6.2 Effect of G on g\nHere, I plot the results of the fitted model: site-specific effects of Big G yield on little g yield.\n\n\nCode\n# control panel\nnvals &lt;- 100\nnsim &lt;- dim(Mcmcdat_0)[1]\nnsites &lt;- length(unique(dat$site_name_cd))\nx_seq &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = nvals)\n\n# predict from model\npred_arr &lt;- array(NA, dim = c(nsim, nvals, nsites))\npred_arr_summ &lt;- array(NA, dim = c(nvals, 3, nsites))\nfor (k in 1:nsites) {\n  for (j in 1:nsim) {\n    pred_arr[j,,k] &lt;- Mcmcdat_0[j,paste(\"alpha[\", k, \"]\", sep = \"\")] + Mcmcdat_0[j,paste(\"beta[\", k, \"]\", sep = \"\")] * x_seq\n  }\n  pred_arr_summ[,1,k] &lt;- apply(pred_arr[,,k], 2, quantile, probs = 0.025)\n  pred_arr_summ[,2,k] &lt;- apply(pred_arr[,,k], 2, quantile, probs = 0.5)\n  pred_arr_summ[,3,k] &lt;- apply(pred_arr[,,k], 2, quantile, probs = 0.975)\n}\n\n\n\n\nCode\npar(mar = c(5,5,1,11), mfrow = c(1,1))\ngg_color_hue &lt;- function(n) { \n  hues = seq(15, 375, length = n + 1) \n  hcl(h = hues, l = 65, c = 100)[1:n] }\nmycols &lt;- gg_color_hue(9)\n\n# combined\nplot(seq(from = range(pred_arr)[1], to = range(pred_arr)[2], length.out = nvals) ~ x_seq, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"(log) volumetric yield at little g\")\nfor (k in 1:nsites) { \n  polygon(x = c(x_seq, rev(x_seq)), y = c(pred_arr_summ[,1,k], rev(pred_arr_summ[,3,k])), col = alpha(mycols[k], 0.2), border = NA)\n  lines(pred_arr_summ[,2,k] ~ x_seq, lwd = 2, col = mycols[k])\n  points(yield_little_cum_log ~ yield_big_cum_log, data = dat %&gt;% filter(site_name_cd == k), col = mycols[k])\n  }\nabline(a = 0, b = 1, lty = 2)\nlegend(\"topleft\", legend = \"1:1\", lty = 2, bty = \"n\")\npar(xpd = TRUE)\nlegend(\"topright\", inset = c(-0.55, 0), legend = levels(dat$site_name), fill = alpha(mycols, 0.5), bty = \"n\")\n\n\n\n\n\nEffect of (log) volumetric yield at Big G on (log) cumulative yield at little g.\n\n\n\n\n\n\n6.6.3 Within-site variation\nHere, I plot the effect of Big G yield on site-level variation in little g (i.e., sigma). How does site-specific variation in little g response to big G attenuate with increasing Big G?\n\n\nCode\n# control panel\nnvals &lt;- 100\nnsim &lt;- dim(Mcmcdat_0)[1]\nnsites &lt;- length(unique(dat$site_name_cd))\nx_seq &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = nvals)\n\npred_arr &lt;- array(NA, dim = c(nsim, nvals, nsites))\npred_arr_summ &lt;- array(NA, dim = c(3, nvals, nsites))\nfor (k in 1:nsites) {\n  for (j in 1:nsim) {\n    pred_arr[j,,k] &lt;- (exp(Mcmcdat_0[j,paste(\"sig.alpha[\", k, \"]\", sep = \"\")] + Mcmcdat_0[j,paste(\"sig.beta[\", k, \"]\", sep = \"\")] * x_seq))\n  }\n  for (i in 1:nvals) {\n    pred_arr_summ[1,i,k] &lt;- quantile(pred_arr[,i,k], probs = 0.025)\n    pred_arr_summ[2,i,k] &lt;- quantile(pred_arr[,i,k], probs = 0.5)\n    pred_arr_summ[3,i,k] &lt;- quantile(pred_arr[,i,k], probs = 0.975)\n  }\n}\n\npar(mar = c(5,5,1,11), mfrow = c(1,1))\ngg_color_hue &lt;- function(n) { \n  hues = seq(15, 375, length = n + 1) \n  hcl(h = hues, l = 65, c = 100)[1:n] }\nmycols &lt;- gg_color_hue(9)\n\n# polygons as 95% CIs\nplot(seq(from = 0, to = range(pred_arr_summ)[2], length.out = nvals) ~ x_seq, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Within-site variation in little g, sigma\")\nfor (k in 1:nsites) { \n  polygon(x = c(x_seq, rev(x_seq)), y = c(pred_arr_summ[1,,k], rev(pred_arr_summ[3,,k])), col = alpha(mycols[k], 0.2), border = NA)\n  lines(pred_arr_summ[2,,k] ~ x_seq, col = mycols[k], lwd = 2)\n}\npar(xpd = TRUE)\nlegend(\"topright\", inset = c(-0.55, 0), legend = levels(dat$site_name), fill = alpha(mycols, 0.5), bty = \"n\")\n\n\n\n\n\nIncreasing water availability decreases site-level heterogeneity in little g response to Big G. Lines and polygons represent the median and 95% credible interval of the relationship for each site (color).\n\n\n\n\n\n\n6.6.4 Among-site variation\nHere, I plot the effect of Big G yield on global (i.e., among-site) variation in little g. How does among-site variation in little g response to big G attenuate with increasing Big G? This is a derived parameter: the square root of the “phenotypic variance” (conditional on x) as defined in Shielzeth and Nakagawa (2022).\nFrom S&N: “We note that the phenotypic variance VP as we calculate it here as the sum of additive variance components might differ slightly from the variance in response values as estimated from the raw data (Rights & Sterba, 2020). The difference is that the sum of the variance components aims to estimate the population variance while the variance in raw response values represents to variance in the sample. Since the population variance is what is relevant to biological interpretation (de Villemereuil et al., 2018), the sum of additive components is usually preferable.”\n\n\nCode\n# control panel\nnsim &lt;- dim(Mcmcdat_0)[1]\n\n# get derived values\npred_arr &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\nfor (j in 1:nsim) { pred_arr[j,] &lt;- sqrt(Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"VpObs\")]) }\nfor (j in 1:ndiff) { pred_arr_summ[j,] &lt;- quantile(pred_arr[,j], probs = c(0.025, 0.5, 0.95)) }\n\n\n\n\nCode\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0))\nplot(seq(from = 0, to = 2.5, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = expression(paste(\"Among-site variation in little g,  \", sqrt(VpObs), sep = \"\")))\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_summ[,1], rev(pred_arr_summ[,3])), col = alpha(\"black\", 0.2), border = NA)\nlines(pred_arr_summ[,2] ~ QGvec, col = \"black\", lwd = 2)\n\n\n\n\n\nIncreasing water availability decreases among-site heterogeneity in little g response to Big G. Line and polygon represent the median and 95% credible interval of the relationship.\n\n\n\n\nVisually comparing the figure above with the data/regression fits figure, it seems like there is not as much variation in VpObs with x in the plot above as there “should” be. In the plot below, I directly compare the population standard deviation (sqrt(VpObs)) with the sample standard deviation (sqrt(VarAg), derived from the site-agnostic model). While Schielzeth and Nakagawa (2022) state that the population and sample standard deviations (variances) may “differ slightly” (pg. 1216), the difference as plotted below seems quite large, which leads me to wonder if the variance decomposition model is specified correctly…\n\n\nCode\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0))\nnsim &lt;- 100\nplot(seq(from = 0, to = 3, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"\")\nfor (i in 1:nsim) { lines(sqrt(Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"VpObs\")]) ~ QGvec, col = alpha(\"black\", 0.3), lwd = 0.5) }\nfor (i in 1:nsim) { lines(sqrt(Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"VarAg\")]) ~ QGvec, col = alpha(\"blue\", 0.3), lwd = 0.5) }\nlegend(\"topright\", legend = c(expression(sqrt(VpObs)), expression(sqrt(VarAg))), lty = 1, col = c(\"black\", \"blue\"), bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n6.6.5 Portfolio strength\nFirst plot population/phenotypic variances, conditional on QG\n\n\nCode\n# control panel\nnsim &lt;- dim(Mcmcdat_0)[1]\nx_seq &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = ndiff)\n\n# get derived values\npred_arr_VpObs &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_VpScen1 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_VpScen2 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_VpScen3 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\n\npred_arr_VpObs_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_VpScen1_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_VpScen2_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_VpScen3_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\n\nfor (j in 1:nsim) { \n  pred_arr_VpObs[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"VpObs\")] \n  pred_arr_VpScen1[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"VpScen1\")] \n  pred_arr_VpScen2[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"VpScen2\")] \n  pred_arr_VpScen3[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"VpScen3\")] \n  }\nfor (j in 1:ndiff) { \n  pred_arr_VpObs_summ[j,] &lt;- quantile(pred_arr_VpObs[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_VpScen1_summ[j,] &lt;- quantile(pred_arr_VpScen1[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_VpScen2_summ[j,] &lt;- quantile(pred_arr_VpScen2[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_VpScen3_summ[j,] &lt;- quantile(pred_arr_VpScen3[,j], probs = c(0.025, 0.5, 0.95))\n  }\n\n\n\n\nCode\n# plot\nmycols &lt;- c(brewer.pal(3, \"Dark2\"), \"black\")\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0), mfrow = c(2,2))\n\n# VpScen1\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpScen1_summ[,1], rev(pred_arr_VpScen1_summ[,3])), col = alpha(mycols[1], 0.2), border = NA)\nlines(pred_arr_VpScen1_summ[,2] ~ QGvec, col = mycols[1], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 1\", bty = \"n\")\n# VpScen2\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpScen2_summ[,1], rev(pred_arr_VpScen2_summ[,3])), col = alpha(mycols[2], 0.2), border = NA)\nlines(pred_arr_VpScen2_summ[,2] ~ QGvec, col = mycols[2], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 2\", bty = \"n\")\n# VpScen3\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpScen3_summ[,1], rev(pred_arr_VpScen3_summ[,3])), col = alpha(mycols[3], 0.2), border = NA)\nlines(pred_arr_VpScen3_summ[,2] ~ QGvec, col = mycols[3], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 3\", bty = \"n\")\n# VpObs\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpObs_summ[,1], rev(pred_arr_VpObs_summ[,3])), col = alpha(mycols[4], 0.2), border = NA)\nlines(pred_arr_VpObs_summ[,2] ~ QGvec, col = mycols[4], lwd = 2)\nlegend(\"topright\", legend = \"Observed\", bty = \"n\")\n\n\n\n\n\nEffect of water availability (log cumulative yield at Big G) on population variance in little g expected under three alternative (null) hypotheses and for observed data.\n\n\n\n\nNow to show portfolio strength: How much more variable is the observed data than what is expected under three (null) alternative hypotheses?\nNote: subtracted 1 from ratios so values &gt;0 indicate the observed data is more variable than expected and values &lt;0 indicate the observed data is less variable than expected\n\n\nCode\n# control panel\nnsim &lt;- dim(Mcmcdat_0)[1]\nx_seq &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = ndiff)\n\n# get derived values\npred_arr_Port1 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_Port2 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_Port3 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\n\npred_arr_Port1_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_Port2_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_Port3_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\n\nfor (j in 1:nsim) { \n  pred_arr_Port1[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"port1\")] - 1\n  pred_arr_Port2[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"port2\")] - 1\n  pred_arr_Port3[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"port3\")] - 1\n  }\nfor (j in 1:ndiff) { \n  pred_arr_Port1_summ[j,] &lt;- quantile(pred_arr_Port1[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_Port2_summ[j,] &lt;- quantile(pred_arr_Port2[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_Port3_summ[j,] &lt;- quantile(pred_arr_Port3[,j], probs = c(0.025, 0.5, 0.95))\n  }\n\n\n\n\nCode\n# plot\nmycols &lt;- c(brewer.pal(3, \"Dark2\"), \"black\")\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0), mfrow = c(2,2))\nylim1 &lt;- -0.25\nylim2 &lt;- 1.25\n\n# VpScen1\nplot(seq(from = ylim1, to = ylim2, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Portfolio strength\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_Port1_summ[,1], rev(pred_arr_Port1_summ[,3])), col = alpha(mycols[1], 0.2), border = NA)\nlines(pred_arr_Port1_summ[,2] ~ QGvec, col = mycols[1], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 1\", bty = \"n\")\nabline(h = 0, lty = 2)\n# VpScen2\nplot(seq(from = ylim1, to = ylim2, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Portfolio strength\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_Port2_summ[,1], rev(pred_arr_Port2_summ[,3])), col = alpha(mycols[2], 0.2), border = NA)\nlines(pred_arr_Port2_summ[,2] ~ QGvec, col = mycols[2], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 2\", bty = \"n\")\nabline(h = 0, lty = 2)\n# VpScen3\nplot(seq(from = ylim1, to = ylim2, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Portfolio strength\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_Port3_summ[,1], rev(pred_arr_Port3_summ[,3])), col = alpha(mycols[3], 0.2), border = NA)\nlines(pred_arr_Port3_summ[,2] ~ QGvec, col = mycols[3], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 3\", bty = \"n\")\nabline(h = 0, lty = 2)\n\n\n\n\n\n\n\n\n\n\n\n6.6.6 Attenuation Strength\nTo what degree does diversity in streamflow regimes attenuate with increasing Big G? Attenuation strength is calculated as the variance at min G divided by variance at max G four our observed data and three alternative hypotheses. Note that for scenario 1, variance is constant over G and thus would equal 1. Therefore, a value of 1 represents no attenuation. These figures may provide a standardized approach to comparing “wedginess” across basins.\n\n\nCode\nmycols &lt;- c(brewer.pal(3, \"Dark2\"), \"black\")\npar(mar = c(5,5,1,1), mfrow = c(1,1))\nplot(seq(from = 0, to = 1, length.out = 100) ~ seq(from = 0.5, to = 3, length.out = 100), type = \"n\", xlab = \"Attenuation strength\", ylab = \"Density\")\n\n# observed\nobs_den &lt;- density(Mcmcdat_0[,\"attenObs\"])\nobs_den$y2 &lt;- obs_den$y / max(obs_den$y)\nobs_l &lt;- min(which(obs_den$x &gt;= hdi(obs_den, credMass = 0.95)[1]))\nobs_h &lt;- max(which(obs_den$x &lt; hdi(obs_den, credMass = 0.95)[2]))\npolygon(x = c(obs_den$x[c(obs_l,obs_l:obs_h,obs_h)]), y = c(0,obs_den$y2[obs_l:obs_h],0), col = alpha(mycols[4], 0.3), lty = 0)\nlines(obs_den$y2 ~ obs_den$x, col = mycols[4], lwd = 2)\n\n# scenario 2\nexp_den &lt;- density(Mcmcdat_0[,\"atten2\"])\nexp_den$y2 &lt;- exp_den$y / max(exp_den$y)\nexp_l &lt;- min(which(exp_den$x &gt;= hdi(exp_den, credMass = 0.95)[1]))\nexp_h &lt;- max(which(exp_den$x &lt; hdi(exp_den, credMass = 0.95)[2]))\npolygon(x = c(exp_den$x[c(exp_l,exp_l:exp_h,exp_h)]), y = c(0,exp_den$y2[exp_l:exp_h],0), col = alpha(mycols[2], 0.3), lty = 0)\nlines(exp_den$y2 ~ exp_den$x, col = mycols[2], lwd = 2)\n\n# scenario 3\nexp_den &lt;- density(Mcmcdat_0[,\"atten3\"])\nexp_den$y2 &lt;- exp_den$y / max(exp_den$y)\nexp_l &lt;- min(which(exp_den$x &gt;= hdi(exp_den, credMass = 0.95)[1]))\nexp_h &lt;- max(which(exp_den$x &lt; hdi(exp_den, credMass = 0.95)[2]))\npolygon(x = c(exp_den$x[c(exp_l,exp_l:exp_h,exp_h)]), y = c(0,exp_den$y2[exp_l:exp_h],0), col = alpha(mycols[3], 0.3), lty = 0)\nlines(exp_den$y2 ~ exp_den$x, col = mycols[3], lwd = 2)\n\nlegend(\"topright\", legend = c(\"Scenario 1\", \"Scenario 2\", \"Scenario 3\", \"Observed\"), fill = alpha(mycols, 0.3), bty = \"n\")\nabline(v = 1, lty = 1, lwd = 2, col = mycols[1])",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#deprecated",
    "href": "Big G Little g/WedgeModel.html#deprecated",
    "title": "6  The Wedge Model",
    "section": "6.7 DEPRECATED",
    "text": "6.7 DEPRECATED\n\n\nCode\n# vector of QG for prediction\nndiff &lt;- 100\nQGvec &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = ndiff)\n\n# gather data for JAGS\njags.data &lt;- list(\"nObs\" = dim(dat)[1], \"nSites\" = length(unique(dat$site_name_cd)), \n                  \"sites\" = dat$site_name_cd, #\"indev\" = dat_wb2$isevent,\n                  \"Qg\" = dat$yield_little_cum_log, \"Qg2\" = dat$yield_little_cum_log, \"QG\" = dat$yield_big_cum_log, \n                  \"QGvec\" = QGvec, \"nDiff\" = ndiff)\n\n# parameters to monitor\njags.params &lt;- c(\"alpha\", \"beta\", \"alpha.mu\", \"beta.mu\", \"alpha.sigma\", \"beta.sigma\", \n                 \"sig.alpha\", \"sig.beta\", \"sig.alpha.mu\", \"sig.beta.mu\", \"sig.alpha.sigma\", \"sig.beta.sigma\", \n                 \"ag.alpha\", \"ag.beta\", \"ag.sig.alpha\", \"ag.sig.beta\",\n                 \"diff\", \"predlg\", \"loglik\", \"loglik2\", \"mu\", \"Qg\", \"portfolio1\", \"portfolio3\", \"atten3\", \"attenObs\")\n\n# run in jags\nmod_0 &lt;- jags.parallel(data = jags.data, inits = NULL, parameters.to.save = jags.params,\n                       model.file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod_Events_2.txt\",\n                       n.chains = 10, n.thin = 20, n.burnin = 1000, n.iter = 5000, DIC = FALSE)\n# saveRDS(mod_0, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/Fitted models/GgMod_Events.rds\")\n\n\nHere, I plot the effect of Big G yield on global (i.e., among-site) variation in little g from the site-agnostic model. How does among-site variation in little g response to big G attenuate with increasing Big G? Note that this only considers the sites we have data for, not all possible locations in the river network. This could potentially be achieved by simulating data for new sites (see pg. 362 in Gelman and Hill, 2007), but would likely need to add slope-intercept correlation structure to the model to ensure that attenuation in preserved (see pg. 376 in Gelman and Hill).\nWe can visualize this another way, as site-specific differences between little g and Big G at different levels of water availability/Big G flow. This is ~equivalent to the plot above, but provides a site-level examination of Qg variation around QG and how those change over the range of Big G flow.\n\n6.7.0.1 Null model simulations\nHow much among-site variation in little G response to Big G might we expect assuming homogeneity in flow regimes? This is the null hypotheses. Although I’m not sure this is the proper way to do this…for each of n sites, I randomly sample from the posterior distributions of alpha.mu and beta.mu to generate site-specific relationships that all follow the global parameters/relationships.\nHere’s an example of an individual simulation…\n\nPortfolio strength\nThere are probably better ways to do this, but here I’m quantifying/visualizing what I’m calling “portfolio strength”, or the degree of heterogeneity in streamflow regimes across the network, as a function of water availability (big G flow). Portfolio strength is calculated as the (median) observed among-site variation in little G divided by the (median) expected/simulated among site variation in little g assuming flow homogeneity. Thus, values &gt;1 and &lt;1 indicate greater and less heterogeneity in streamflow than expected under the assumption of homogeneity, respectively. I think this would be a good way to compare/standardize among basins.\nAlternatively, portfolio strength can be defined as the ratio between among-site variation in little g at low vs. high values of Big G (sensu Chezik et al. 2017)…so we get distributions for observed and expected values, where a value of 1 indicates no portfolio behavior (no streamflow diversity at different levels of Big G). I don’t think this makes sense because the whole point is the evaluation how diversity in flow regimes (i.e., portfolio strength) changes with water availability.\n\n\n\n6.7.1 Agnostic to sites\nThis model evaluates the G-g relationship and the effect of G on sigma, but ignores site groupings. With respect to the sigma~G relationship, this is essentially what I am trying to reconstruct above using derived values.\n\n6.7.1.1 Fit the JAGS model\nGet MCMC samples and summary\n\n\n6.7.1.2 View traceplots\n\n\n6.7.1.3 Effect of G on sigma\nHere, I plot the effects of Big G yield on among-site variation in little g (i.e., sigma). This describes the effect of water availability on network-wide heterogeneity in streamflow.\n\n\n\n6.7.2 Porfolio strength\nHow much more heterogeneous is observed little g streamflow at different levels of water availability (Big G) relative to our expectations if among- and within-site streamflow diversity is eroded? What does this tell us about the relative contributions of within- and among-site diversity to the total streamflow diversity across the river network?\nPortfolio strength is calculated as the observed variance divided by expected variance under different scenarios in which diversity is eroded. These relationships may provide a standardized approach to comparing “wedginess” across basins\n\n\n6.7.3 Attenuation strength\nTo what degree does diversity in streamflow regimes attenuate with increasing Big G? Attenuation strength is calculated as the variance at min G divided by variance at max G four our observed data and relevant scenarios. Note that for scenario 1, variance is constant over G and thus would equal 1. Therfore, a value of 1 represents no attenuation. These figures may provide a standardized approach to comparing “wedginess” across basins.",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffKS.html",
    "href": "Big G Little g/GgDiffKS.html",
    "title": "7  G-g Difference (KS)",
    "section": "",
    "text": "7.1 Site info and daily data\nPurpose: Explore effects of monthly/annual water availability on Big-little difference using non-parametric Kolmogorov-Smirnov tests\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# flow/yield (and temp) data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\") %&gt;%\n  filter(!site_name %in% c(\"WoundedBuckCreek\", \"Brackett Creek\"))\n\n# add water/climate year variables\ndat &lt;- add_date_variables(dat, dates = date, water_year_start = 4)",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>G-g Difference (KS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffKS.html#separate-and-join-g-g",
    "href": "Big G Little g/GgDiffKS.html#separate-and-join-g-g",
    "title": "7  G-g Difference (KS)",
    "section": "7.2 Separate and join G-g",
    "text": "7.2 Separate and join G-g\n\n\nCode\n# pull out big G data\ndat_big &lt;- dat %&gt;% filter(site_name %in% c(\"West Brook NWIS\", \"Paine Run 10\", \"Piney River 10\", \"Staunton River 10\", \"Spread Creek Dam\", \"BigCreekLower\", \"Shields River ab Smith NWIS\", \"Donner Blitzen River nr Frenchglen NWIS\")) \n\n# pull out little G data, assign big G site name\ndat_little &lt;- dat %&gt;% \n  filter(designation %in% c(\"little\", \"medium\"), !subbasin %in% c(\"Coal Creek\", \"McGee Creek\", \"Duck Creek\", \"Flathead\"),\n         !site_name %in% c(\"West Brook NWIS\", \"West Brook 0\", \"Paine Run 10\", \"Piney River 10\", \"Staunton River 10\", \"Spread Creek Dam\", \"Shields River ab Smith NWIS\", \"BigCreekLower\")) %&gt;%\n  mutate(site_name_big = ifelse(subbasin == \"Big Creek\", \"BigCreekLower\",\n                                ifelse(subbasin == \"West Brook\", \"West Brook NWIS\", \n                                       ifelse(subbasin == \"Paine Run\", \"Paine Run 10\", \n                                              ifelse(subbasin == \"Piney River\", \"Piney River 10\",\n                                                     ifelse(subbasin == \"Staunton River\", \"Staunton River 10\",\n                                                            ifelse(subbasin == \"Shields River\", \"Shields River ab Smith NWIS\",\n                                                                   ifelse(subbasin == \"Snake River\", \"Spread Creek Dam\", \"Donner Blitzen River nr Frenchglen NWIS\"))))))))\n\n# Join big-little discharge data\ndat_Gg &lt;- dat_little %&gt;%\n  select(site_name, site_name_big, basin, subbasin, date, Month, MonthName, WaterYear, Yield_filled_mm_7) %&gt;% rename(yield_little = Yield_filled_mm_7) %&gt;%\n  left_join(dat_big %&gt;% select(site_name, date, Yield_filled_mm_7) %&gt;% rename(site_name_big = site_name, yield_big = Yield_filled_mm_7)) %&gt;%\n  drop_na() %&gt;% mutate(MonthName = as.character(MonthName))\n\n# table\ndat_Gg %&gt;% group_by(subbasin) %&gt;% summarize(site_name_big = unique(site_name_big)) %&gt;% kable(caption = \"Big G gage names for each focal sub-basin.\")\n\n\n\nBig G gage names for each focal sub-basin.\n\n\nsubbasin\nsite_name_big\n\n\n\n\nBig Creek\nBigCreekLower\n\n\nDonner Blitzen\nDonner Blitzen River nr Frenchglen NWIS\n\n\nPaine Run\nPaine Run 10\n\n\nShields River\nShields River ab Smith NWIS\n\n\nSnake River\nSpread Creek Dam\n\n\nStaunton River\nStaunton River 10\n\n\nWest Brook\nWest Brook NWIS\n\n\n\n\n\nView unique little g site names\n\n\nCode\nsort(unique(dat_Gg$site_name))\n\n\n [1] \"Avery Brook\"                      \"Avery Broook NWIS\"               \n [3] \"Big Creek NWIS\"                   \"BigCreekMiddle\"                  \n [5] \"BigCreekUpper\"                    \"Buck Creek\"                      \n [7] \"Crandall Creek\"                   \"Deep Creek\"                      \n [9] \"Donner Blitzen ab Fish NWIS\"      \"Donner Blitzen ab Indian NWIS\"   \n[11] \"Donner Blitzen nr Burnt Car NWIS\" \"Dugout Creek\"                    \n[13] \"Dugout Creek NWIS\"                \"Fish Creek\"                      \n[15] \"Grizzly Creek\"                    \"Grouse Creek\"                    \n[17] \"Hallowat Creek NWIS\"              \"HallowattCreekLower\"             \n[19] \"Jimmy Brook\"                      \"LangfordCreekLower\"              \n[21] \"LangfordCreekUpper\"               \"Leidy Creek Mouth\"               \n[23] \"Leidy Creek Mouth NWIS\"           \"Leidy Creek Upper\"               \n[25] \"Lodgepole Creek\"                  \"Mitchell Brook\"                  \n[27] \"NF Spread Creek Lower\"            \"NF Spread Creek Upper\"           \n[29] \"NicolaCreek\"                      \"Obear Brook Lower\"               \n[31] \"Paine Run 01\"                     \"Paine Run 02\"                    \n[33] \"Paine Run 06\"                     \"Paine Run 07\"                    \n[35] \"Paine Run 08\"                     \"Rock Creek\"                      \n[37] \"Sanderson Brook\"                  \"SF Spread Creek Lower\"           \n[39] \"SF Spread Creek Lower NWIS\"       \"SF Spread Creek Upper\"           \n[41] \"Shields River ab Dugout\"          \"SkookoleelCreek\"                 \n[43] \"Staunton River 02\"                \"Staunton River 03\"               \n[45] \"Staunton River 06\"                \"Staunton River 07\"               \n[47] \"Staunton River 09\"                \"WernerCreek\"                     \n[49] \"West Brook Lower\"                 \"West Brook Reservoir\"            \n[51] \"West Brook Upper\"                 \"West Whately Brook\"",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>G-g Difference (KS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffKS.html#compute-gg-difference",
    "href": "Big G Little g/GgDiffKS.html#compute-gg-difference",
    "title": "7  G-g Difference (KS)",
    "section": "7.3 Compute Gg Difference",
    "text": "7.3 Compute Gg Difference\n\n\nCode\nmysites &lt;- unique(dat_Gg$site_name)\nkscompare_list &lt;- list()\nfor (i in 1:length(mysites)) {\n  d &lt;- dat_Gg %&gt;% filter(site_name == mysites[i])\n  yrs &lt;- unique(d$WaterYear)\n  kscompare_list_yr &lt;- list()\n  for(j in 1:length(yrs)) {\n    dy &lt;- d %&gt;% filter(WaterYear == yrs[j])\n    mypvals_monthly &lt;- tibble(site_name = rep(NA, times = 12), \n                              site_name_big = rep(NA, times = 12), \n                              WaterYear = rep(NA, times = 12),\n                              Month = rep(NA, times = 12),\n                              MonthName = rep(NA, times = 12),\n                              days = rep(NA, times = 12),\n                              stat = rep(NA, times = 12),\n                              pval = rep(NA, times = 12))\n    for(k in 1:12) {\n      dym &lt;- dy %&gt;% filter(Month == k)\n      if(dim(dym)[1] &lt; 25) next\n      mytest &lt;- ks.test(dym$yield_little, dym$yield_big, exact = TRUE)\n      mypvals_monthly$site_name[k] &lt;- mysites[i]\n      mypvals_monthly$site_name_big[k] &lt;- unique(dym$site_name_big)\n      mypvals_monthly$WaterYear[k] &lt;- yrs[j]\n      mypvals_monthly$Month[k] &lt;- k\n      mypvals_monthly$MonthName[k] &lt;- unique(dym$MonthName)\n      mypvals_monthly$days[k] &lt;- dim(dym)[1]\n      mypvals_monthly$stat[k] &lt;- mytest$statistic\n      mypvals_monthly$pval[k] &lt;- mytest$p.value\n      }\n    kscompare_list_yr[[j]] &lt;- mypvals_monthly\n    }\n  kscompare_list[[i]] &lt;- do.call(rbind, kscompare_list_yr)\n}\nkscompare &lt;- do.call(rbind, kscompare_list) %&gt;% drop_na()\n\n\nView relationship between KS test statistic and p-value\n\n\nCode\nplot(pval ~ stat, kscompare, xlab = \"KS test statistic\", ylab = \"p-value\")\n\n\n\n\n\n\n\n\n\nView distribution of KS test statistics and p-values\n\n\nCode\nhist(kscompare$stat)\n\n\n\n\n\n\n\n\n\nCode\nhist(kscompare$pval)",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>G-g Difference (KS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffKS.html#calculate-total-yield",
    "href": "Big G Little g/GgDiffKS.html#calculate-total-yield",
    "title": "7  G-g Difference (KS)",
    "section": "7.4 Calculate total yield",
    "text": "7.4 Calculate total yield\n\n\nCode\n# Get total annual and monthly Big G yield and join to KS diffs\n\n# get total annual yield by big G site\ntotyield_annual &lt;- dat_big %&gt;% \n  group_by(site_name, WaterYear, basin, subbasin) %&gt;% \n  summarize(days = n(), yield_annual = sum(Yield_filled_mm, na.rm = TRUE)) %&gt;%\n  filter(!is.na(yield_annual), days &gt;= 360) %&gt;%\n  ungroup() %&gt;%\n  rename(site_name_big = site_name) %&gt;%\n  select(site_name_big, WaterYear, yield_annual) %&gt;%\n  ungroup()\n\n# get total monthly yield by big G site\ntotyield_monthly &lt;- dat_big %&gt;% \n  group_by(site_name, WaterYear, basin, subbasin, Month) %&gt;% \n  summarize(days = n(), yield_monthly = sum(Yield_filled_mm, na.rm = TRUE)) %&gt;%\n  filter(!is.na(yield_monthly), days &gt;= 28) %&gt;%\n  ungroup() %&gt;%\n  rename(site_name_big = site_name) %&gt;%\n  select(site_name_big, WaterYear, Month, yield_monthly) %&gt;%\n  ungroup()",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>G-g Difference (KS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffKS.html#explore-gg-diff-by-water-availability",
    "href": "Big G Little g/GgDiffKS.html#explore-gg-diff-by-water-availability",
    "title": "7  G-g Difference (KS)",
    "section": "7.5 Explore Gg diff by water availability",
    "text": "7.5 Explore Gg diff by water availability\nHypothesis: during wetter periods (months/years) flow regimes become more similar among locations within stream networks (i.e., positive relationship between monthly/annual total yield and KS-test p-value)\nHow might this vary among basins that differ in primary water source (rain vs. snow) and among sites within basins (due to surface vs. subsurface controls on flow)?\n\n\nCode\n# join KS comparison df with annual/monthly water availability\nkscompare &lt;- kscompare %&gt;% left_join(totyield_annual) %&gt;% left_join(totyield_monthly) %&gt;%\n  mutate(MonthName = factor(MonthName, levels = c(\"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\", \"Jan\", \"Feb\", \"Mar\"))) %&gt;%\n  left_join(siteinfo %&gt;% select(site_name, basin))\n\n\n\n7.5.1 Global relationship\nPlot relationship between log(monthly total yield) and log(KS p-value) for all basins, sites, and months combined\n\n\nCode\nkscompare %&gt;% ggplot(aes(x = log(yield_monthly), y = log(pval))) + \n  geom_point(aes(group = MonthName, color = MonthName)) + \n  geom_smooth(method = \"lm\") + geom_abline(slope = 0, intercept = log(0.05), linetype = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\n7.5.2 Basin-level effects\n\n\nCode\n# Plot all sites, facet by basin\nkscompare %&gt;% ggplot(aes(x = log(yield_monthly), y = log(pval))) + \n  geom_point(aes(group = MonthName, color = MonthName)) + facet_wrap(~ basin) + \n  geom_smooth(method = \"lm\") + geom_abline(slope = 0, intercept = log(0.05), linetype = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\n7.5.3 Basin and site effects\n\n\nCode\nmybasins &lt;- unique(kscompare$basin)\nmyplots &lt;- list()\nfor (i in 1:length(mybasins)) {\n  myplots[[i]] &lt;- kscompare %&gt;% \n    filter(basin == mybasins[i]) %&gt;%\n    ggplot(aes(x = log(yield_monthly), y = log(pval))) + \n    geom_point(aes(group = MonthName, color = MonthName)) + \n    facet_wrap(~ site_name) + \n    geom_smooth(method = \"lm\") + \n    geom_abline(slope = 0, intercept = log(0.05), linetype = \"dashed\")\n}\n\n\n\nBig CreekWest BrookPaine RunStaunton RiverShields RiverSnake RiverDonner Blitzen",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>G-g Difference (KS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffJAGS.html",
    "href": "Big G Little g/GgDiffJAGS.html",
    "title": "8  G-g Difference (JAGS)",
    "section": "",
    "text": "8.1 Data\nPurpose: Model effects of monthly/annual water availability on Big-little difference using JAGS",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>G-g Difference (JAGS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffJAGS.html#data",
    "href": "Big G Little g/GgDiffJAGS.html#data",
    "title": "8  G-g Difference (JAGS)",
    "section": "",
    "text": "8.1.1 Site info and daily data\n\n\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# flow/yield (and temp) data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\") %&gt;%\n  filter(!site_name %in% c(\"WoundedBuckCreek\", \"Brackett Creek\"))\n\n# add water/climate year variables\ndat &lt;- add_date_variables(dat, dates = date, water_year_start = 4)\n\n\n\n\n8.1.2 Separate and join G-g\n\n\nCode\n# pull out big G data\ndat_big &lt;- dat %&gt;% filter(site_name %in% c(\"West Brook NWIS\", \"Paine Run 10\", \"Piney River 10\", \"Staunton River 10\", \"Spread Creek Dam\", \"BigCreekLower\", \"Shields River ab Smith NWIS\", \"Donner Blitzen River nr Frenchglen NWIS\")) \n\n# pull out little G data, assign big G site name\ndat_little &lt;- dat %&gt;% \n  filter(designation %in% c(\"little\", \"medium\"), !subbasin %in% c(\"Coal Creek\", \"McGee Creek\", \"Duck Creek\", \"Flathead\"),\n         !site_name %in% c(\"West Brook NWIS\", \"West Brook 0\", \"Paine Run 10\", \"Piney River 10\", \"Staunton River 10\", \"Spread Creek Dam\", \"Shields River ab Smith NWIS\", \"BigCreekLower\")) %&gt;%\n  mutate(site_name_big = ifelse(subbasin == \"Big Creek\", \"BigCreekLower\",\n                                ifelse(subbasin == \"West Brook\", \"West Brook NWIS\", \n                                       ifelse(subbasin == \"Paine Run\", \"Paine Run 10\", \n                                              ifelse(subbasin == \"Piney River\", \"Piney River 10\",\n                                                     ifelse(subbasin == \"Staunton River\", \"Staunton River 10\",\n                                                            ifelse(subbasin == \"Shields River\", \"Shields River ab Smith NWIS\",\n                                                                   ifelse(subbasin == \"Snake River\", \"Spread Creek Dam\", \"Donner Blitzen River nr Frenchglen NWIS\"))))))))\n\n# Join big-little discharge data\ndat_Gg &lt;- dat_little %&gt;%\n  select(site_name, site_name_big, basin, subbasin, date, Month, MonthName, WaterYear, Yield_filled_mm_7) %&gt;% rename(yield_little = Yield_filled_mm_7) %&gt;%\n  left_join(dat_big %&gt;% select(site_name, date, Yield_filled_mm_7) %&gt;% rename(site_name_big = site_name, yield_big = Yield_filled_mm_7)) %&gt;%\n  drop_na() %&gt;% mutate(MonthName = as.character(MonthName))\n\n# table\ndat_Gg %&gt;% group_by(subbasin) %&gt;% summarise(site_name_big = unique(site_name_big)) %&gt;% kable(caption = \"Big G gage names for each focal sub-basin.\")\n\n\n\nBig G gage names for each focal sub-basin.\n\n\nsubbasin\nsite_name_big\n\n\n\n\nBig Creek\nBigCreekLower\n\n\nDonner Blitzen\nDonner Blitzen River nr Frenchglen NWIS\n\n\nPaine Run\nPaine Run 10\n\n\nShields River\nShields River ab Smith NWIS\n\n\nSnake River\nSpread Creek Dam\n\n\nStaunton River\nStaunton River 10\n\n\nWest Brook\nWest Brook NWIS\n\n\n\n\n\n\n\n8.1.3 Calculate total yield\n\n\nCode\n# Get total annual and monthly Big G yield and join to KS diffs\n\n# get total annual yield by big G site\ntotyield_annual &lt;- dat_big %&gt;% \n  group_by(site_name, WaterYear, basin, subbasin) %&gt;% \n  summarise(days = n(), yield_annual = sum(Yield_filled_mm, na.rm = TRUE)) %&gt;%\n  filter(!is.na(yield_annual), days &gt;= 360) %&gt;%\n  ungroup() %&gt;%\n  rename(site_name_big = site_name) %&gt;%\n  select(site_name_big, WaterYear, yield_annual) %&gt;%\n  ungroup()\n\n# get total monthly yield by big G site\ntotyield_monthly &lt;- dat_big %&gt;% \n  group_by(site_name, WaterYear, basin, subbasin, Month) %&gt;% \n  summarise(days = n(), yield_monthly = sum(Yield_filled_mm, na.rm = TRUE)) %&gt;%\n  filter(!is.na(yield_monthly), days &gt;= 28) %&gt;%\n  ungroup() %&gt;%\n  rename(site_name_big = site_name) %&gt;%\n  select(site_name_big, WaterYear, Month, yield_monthly) %&gt;%\n  ungroup()\n\n\n\n\n8.1.4 Final dataset\nJoin and filter G-g data to relevant basin(s) and years: currently, West Brook CY 2021 only!\n\n\nCode\n# wide format to enable direct difference calculation (Attempt 1)\ndat_Gg2 &lt;- dat_Gg %&gt;% left_join(totyield_annual) %&gt;% left_join(totyield_monthly) %&gt;% \n  filter(basin == \"West Brook\", site_name != \"Avery Broook NWIS\", WaterYear == 2021) %&gt;% \n  mutate(site_name_cd = as.numeric(as.factor(site_name)),\n         z_log_yield_monthly = as.numeric(scale(log(yield_monthly), center = TRUE, scale = TRUE)),\n         month_radian = as_radians((Month/12)*360))\n\n# long format for more standard intercept model (Attempt 2)\ndat_Gg3 &lt;- dat_Gg2 %&gt;% select(site_name, site_name_cd, Month, month_radian, WaterYear, yield_little, yield_big, z_log_yield_monthly) %&gt;%\n  gather(key = \"ind\", value = \"yield\", yield_little, yield_big) %&gt;% mutate(indnum = as.numeric(as.factor(ind))-1)\nhead(dat_Gg3)\n\n\n# A tibble: 6 × 9\n  site_name  site_name_cd Month month_radian WaterYear z_log_yield_monthly ind  \n  &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;               &lt;dbl&gt; &lt;chr&gt;\n1 Avery Bro…            1     4         2.09      2021                1.20 yiel…\n2 Avery Bro…            1     4         2.09      2021                1.20 yiel…\n3 Avery Bro…            1     4         2.09      2021                1.20 yiel…\n4 Avery Bro…            1     4         2.09      2021                1.20 yiel…\n5 Avery Bro…            1     4         2.09      2021                1.20 yiel…\n6 Avery Bro…            1     4         2.09      2021                1.20 yiel…\n# ℹ 2 more variables: yield &lt;dbl&gt;, indnum &lt;dbl&gt;\n\n\nExplore G-g data\n\n\nCode\ndat_Gg2 %&gt;% group_by(WaterYear, Month) %&gt;% summarise(z_log_yield_monthly = unique(z_log_yield_monthly)) %&gt;% \n  ggplot(aes(x = Month, y = z_log_yield_monthly)) + geom_point() + geom_smooth()\n\n\n\n\n\nStandardized (log) total monthly yield at Big G during CY 2021\n\n\n\n\n\n\nCode\ndat_Gg3 %&gt;% ggplot() + geom_boxplot(aes(x = as.factor(Month), y = log(yield), fill = ind)) + facet_wrap(~site_name)\n\n\n\n\n\nDistribution of (log) yield at G-g over time, by site\n\n\n\n\n\n\nCode\ndat_Gg2 %&gt;% \n  group_by(site_name, Month) %&gt;% \n  summarise(yield_little = mean(log(yield_little), na.rm = TRUE), \n            yield_big = mean(log(yield_big), na.rm = TRUE),\n            z_log_yield_monthly = unique(z_log_yield_monthly)) %&gt;%\n  mutate(Qd = yield_little - yield_big) %&gt;% \n  ggplot(aes(x = Month, y = Qd)) + geom_point() + geom_smooth() + ylab(\"mean[log(g) - log(G)]\") + \n  facet_wrap(~site_name) + geom_abline(intercept = 0, slope = 0, linetype = \"dashed\")\n\n\n\n\n\nG-g difference in (log) monthly mean yield over time\n\n\n\n\n\n\nCode\ndat_Gg2 %&gt;% \n  group_by(site_name, Month) %&gt;% \n  summarise(yield_little = mean(log(yield_little), na.rm = TRUE), \n            yield_big = mean(log(yield_big), na.rm = TRUE),\n            z_log_yield_monthly = unique(z_log_yield_monthly)) %&gt;%\n  mutate(Qd = yield_little - yield_big) %&gt;% \n  ggplot(aes(x = z_log_yield_monthly, y = Qd)) + geom_point() + geom_smooth(method = \"lm\") + \n  ylab(\"mean[log(g) - log(G)]\") + facet_wrap(~site_name) + geom_abline(intercept = 0, slope = 0, linetype = \"dashed\")\n\n\n\n\n\nG-g difference in (log) monthly mean yield as a function of (log) total monthly yield at G",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>G-g Difference (JAGS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffJAGS.html#declare-the-jags-model",
    "href": "Big G Little g/GgDiffJAGS.html#declare-the-jags-model",
    "title": "8  G-g Difference (JAGS)",
    "section": "8.2 Declare the JAGS model",
    "text": "8.2 Declare the JAGS model\nFirst attempt tries to model the difference as a derived parameter (like the growth model), but this maintains the temporal structure of the data, and we are primarily interested in the difference in the distributions\n\n\nCode\ncat(\"model {\n\n##--- LIKELIHOOD ---------------------------------------------------##\n\nfor (i in 1:nObs) {\n  Qg[i] ~ dnorm(mu[i], pow(sigma, -2))\n  mu[i] &lt;- QG[i] - Qd[i]\n  Qd[i] &lt;- alpha[sites[i]] + beta[sites[i]] * yield[i]\n  \n  # Log-likelihood\n  loglik[i] &lt;- logdensity.norm(Qg[i], mu[i], pow(sigma, -2))\n  }\n\n\n##--- PRIORS --------------------------------------------------------##\n\n# Process error is shared among sites\nsigma ~ dunif(0.001, 100)\n\n# Site-specific parameters\nfor (k in 1:nSites) {\n  alpha[k] ~ dnorm(alpha.mu, pow(sigma.alpha, -2))\n  beta[k] ~ dnorm(beta.mu, pow(sigma.beta, -2))\n  }\n\n# Global parameters\nalpha.mu ~ dnorm(0, pow(10, -2))\nbeta.mu ~ dnorm(0, pow(10, -2))\n\n# Site-level variation in alpha and beta\nsigma.alpha ~ dunif(0.001, 100)\nsigma.beta ~ dunif(0.001, 100)\n\n}\", file = \"./Big G Little g/JAGS Models/GgMod.txt\")\n\n\nSecond attempt is a more standard intercept model.\n\n“alpha” is the mean monthly yield at Big-G, which is shared among sites\n“beta1” is a Little-g offset to the intercept, which describes the site-level mean G-g difference\n“beta2” describes the effect of water availability (log total monthly yield at Big G) on the site-level mean G-g difference.\n\nNote that this is only “turned on” for little-g (ind[i] = 1)\n\nShould add covariates on sigma to deal with unequal variance among groups\n\n\n\nCode\ncat(\"model {\n\n##--- LIKELIHOOD ---------------------------------------------------##\n\nfor (i in 1:nObs) {\n  Q[i] ~ dnorm(mu[i], pow(sigma, -2))\n  mu[i] &lt;- alpha[months[i]] + beta1[sites[i]] * ind[i] + beta2[sites[i]] * ind[i] * yieldtot[i]\n  \n  # Log-likelihood\n  loglik[i] &lt;- logdensity.norm(Q[i], mu[i], pow(sigma, -2))\n  }\n\n\n##--- PRIORS --------------------------------------------------------##\n\n# Process error is shared among sites\nsigma ~ dunif(0.001, 100)\n\n# Site-specific parameters\nfor (j in 1:nSites) {\n  beta1[j] ~ dnorm(0, pow(10, -2))\n  beta2[j] ~ dnorm(0, pow(10, -2))\n  }\n\nfor(k in 1:nMonths) {\n  alpha[k] ~ dnorm(0, pow(10, -2))\n  }\n\n}\", file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod.txt\")",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>G-g Difference (JAGS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffJAGS.html#fit-the-jags-model",
    "href": "Big G Little g/GgDiffJAGS.html#fit-the-jags-model",
    "title": "8  G-g Difference (JAGS)",
    "section": "8.3 Fit the JAGS model",
    "text": "8.3 Fit the JAGS model\n\n\nCode\n# gather data for JAGS\n# jags.data &lt;- list(\"nObs\" = dim(dat_Gg2)[1], \"nSites\" = length(unique(dat_Gg2$site_name_cd)), \"sites\" = dat_Gg2$site_name_cd, \n#                   \"Qg\" = dat_Gg2$yield_little, \"QG\" = dat_Gg2$yield_big, \"yield\" = dat_Gg2$z_yield_monthly)\njags.data &lt;- list(\"nObs\" = dim(dat_Gg3)[1], \"nSites\" = length(unique(dat_Gg3$site_name_cd)), \"nMonths\" = length(unique(dat_Gg3$Month)), \n                  \"sites\" = dat_Gg3$site_name_cd, \"months\" = dat_Gg3$Month,\n                  \"Q\" = log(dat_Gg3$yield+0.01), \"ind\" = dat_Gg3$indnum, \"yieldtot\" = dat_Gg3$z_log_yield_monthly)\n\n# parameters to monitor\n# jags.params &lt;- c(\"alpha\", \"alpha.mu\", \"sigma.alpha\", \"beta\", \"beta.mu\", \"sigma.beta\", \"sigma\", \"loglik\")\njags.params &lt;- c(\"alpha\", \"beta1\", \"beta2\", \"sigma\", \"loglik\")\n\n# run in jags\nmod_0 &lt;- jags.parallel(data = jags.data, inits = NULL, parameters.to.save = jags.params,\n                       model.file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod.txt\",\n                       n.chains = 6, n.thin = 20, n.burnin = 1000, n.iter = 5000, DIC = TRUE)\n# saveRDS(mod_0, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod.RDS\")\n\n\nAny problematic R-hat values?\n\n\nCode\nmod_0$BUGSoutput$summary[,8][mod_0$BUGSoutput$summary[,8] &gt; 1.01]\n\n\nloglik[2211] \n    1.011407 \n\n\n\n8.3.1 View traceplots\n\n\nCode\nMCMCtrace(mod_0, ind = TRUE, params = c(\"alpha\", \"beta1\", \"beta2\", \"sigma\"), pdf = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.3.2 Get MCMC samples and summary\n\n\nCode\ntop_mod &lt;- mod_0\n# generate MCMC samples and store as an array\nmodelout &lt;- top_mod$BUGSoutput\nMcmcList &lt;- vector(\"list\", length = dim(modelout$sims.array)[2])\nfor(i in 1:length(McmcList)) { McmcList[[i]] = as.mcmc(modelout$sims.array[,i,]) }\n# rbind MCMC samples from 10 chains \nMcmcdat &lt;- rbind(McmcList[[1]], McmcList[[2]], McmcList[[3]], McmcList[[4]], McmcList[[5]], McmcList[[6]])\nparam.summary &lt;- modelout$summary\nhead(param.summary)\n\n\n               mean         sd       2.5%        25%        50%        75%\nalpha[1]  0.5462529 0.02781862  0.4936378  0.5270035  0.5462240  0.5655740\nalpha[2] -0.1422659 0.02915204 -0.1999043 -0.1625639 -0.1424827 -0.1225840\nalpha[3]  0.4374197 0.02802609  0.3807040  0.4192080  0.4371426  0.4555607\nalpha[4]  1.2530323 0.02901345  1.1953046  1.2329734  1.2536734  1.2737716\nalpha[5]  0.5094628 0.02926410  0.4531626  0.4896552  0.5098029  0.5290679\nalpha[6] -1.5593645 0.02751962 -1.6113834 -1.5774984 -1.5599359 -1.5417936\n               97.5%     Rhat n.eff\nalpha[1]  0.60321864 1.002291   920\nalpha[2] -0.08210678 1.004733   560\nalpha[3]  0.49472750 1.001976  1000\nalpha[4]  1.30751424 1.003528   700\nalpha[5]  0.56547757 1.000548  1200\nalpha[6] -1.50406241 1.000014  1200",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>G-g Difference (JAGS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffJAGS.html#plot-model-output",
    "href": "Big G Little g/GgDiffJAGS.html#plot-model-output",
    "title": "8  G-g Difference (JAGS)",
    "section": "8.4 Plot model output",
    "text": "8.4 Plot model output\n\n\nCode\n# control panel\nnvals &lt;- 100\nnsim &lt;- 50\nnsites &lt;- length(unique(dat_Gg3$site_name_cd))\nx_seq &lt;- seq(from = min(dat_Gg2$z_log_yield_monthly), to = max(dat_Gg2$z_log_yield_monthly), length.out = nvals)\n\n# predict from model\npred_arr &lt;- array(NA, dim = c(nsim, nvals, nsites))\nfor (k in 1:nsites) {\n  for (j in 1:nsim) {\n    pred_arr[j,,k] &lt;- Mcmcdat[j,paste(\"beta1[\", k, \"]\", sep = \"\")] + Mcmcdat[j,paste(\"beta2[\", k, \"]\", sep = \"\")] * x_seq\n  }\n}\n# pred_dist_lin &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nrgs)\n# for (i in 1:nrow(pred_dist_lin)) { pred_dist_lin[i,] &lt;- exp(Mcmcdat[i,\"alpha\"] + Mcmcdat[i,\"beta1\"]*pdist) }\n# pred_dist_tran &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nrgs)\n# for (i in 1:nrow(pred_dist_tran)) { pred_dist_tran[i,] &lt;-  pred_dist_lin[i,] / rowSums(pred_dist_lin)[i] }\n# pred_lower &lt;- apply(pred_dist_tran, MARGIN = 2, quantile, prob = 0.025)\n# pred_upper &lt;- apply(pred_dist_tran, MARGIN = 2, quantile, prob = 0.975)\n# pred_median &lt;- apply(pred_dist_tran, MARGIN = 2, quantile, prob = 0.5)\n\n\n\n\nCode\npar(mar = c(5,5,2,12))\nmycols &lt;- brewer.pal(9, \"Set1\")\nplot(seq(from = range(pred_arr)[1], to = range(pred_arr)[2], length.out = nvals) ~ x_seq, type = \"n\", xlab = \"(log) Monthly total yield at Big G (z-score)\", ylab = \"Little g deviation from Big G\")\nfor (k in 1:nsites) {\n  for (j in 1:nsim) {\n    lines(pred_arr[j,,k] ~ x_seq, col = alpha(mycols[k], 0.3))\n  }\n}\nabline(h = 0, lty = 2)\npar(xpd = TRUE)\nlegend(\"right\", inset = c(-0.4,0), legend = unlist(dat_Gg3 %&gt;% group_by(site_name) %&gt;% summarise(stcd = unique(site_name_cd)) %&gt;% select(site_name)), fill = mycols, bty = \"n\")\n\n\n\n\n\nG-g mean difference in (log) yield as a function of (log) total monthly yield at G",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>G-g Difference (JAGS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#correlated-sloint",
    "href": "Big G Little g/WedgeModel.html#correlated-sloint",
    "title": "6  The Wedge Model",
    "section": "6.7 Correlated SloInt",
    "text": "6.7 Correlated SloInt\n\n\nCode\ncat(\"model {\n\n##--- LIKELIHOOD ---------------------------------------------------##\n\nfor (i in 1:nObs) {\n\n  Qg[i] ~ dnorm(mu[i], pow(sigma[i], -2))\n  mu[i] &lt;- alpha[sites[i]] + beta[sites[i]] * QG[i]\n  log(sigma[i]) &lt;- sig.alpha[sites[i]] + sig.beta[sites[i]] * QG[i]\n  \n  # Log-likelihood\n  loglik[i] &lt;- logdensity.norm(Qg[i], mu[i], pow(sigma[i], -2))\n  }\n\n\n##--- PRIORS --------------------------------------------------------##\n\n# Site-specific parameters\nfor (j in 1:nSites) {\n    alpha[j] &lt;- B[j,1]\n    beta[j] &lt;- B[j,2]\n    B[j,1:2] ~ dmnorm(B.hat[j,], Tau.B[,])\n    B.hat[j,1] &lt;- alpha.mu\n    B.hat[j,2] &lt;- beta.mu\n    \n    sig.alpha[j] ~ dnorm(sig.alpha.mu, pow(sig.alpha.sigma, -2))\n    sig.beta[j] ~ dnorm(sig.beta.mu, pow(sig.beta.sigma, -2))\n    }\n    \n# global parameters\nalpha.mu ~ dnorm(0, pow(10, -2))\nbeta.mu ~ dnorm(0, pow(10, -2))\nsig.alpha.mu ~ dnorm(0, pow(10, -2))\nsig.beta.mu ~ dnorm(0, pow(10, -2))\n\n# variance-covariance matrix components\nTau.B[1:2,1:2] &lt;- inverse(Sigma.B[,])\nSigma.B[1,1] &lt;- pow(alpha.sigma, 2)\nSigma.B[2,2] &lt;- pow(beta.sigma, 2)\nSigma.B[1,2] &lt;- rho * alpha.sigma * beta.sigma\nSigma.B[2,1] &lt;- Sigma.B[1,2]\n\nalpha.sigma ~ dunif(0.001, 100)\nbeta.sigma ~ dunif(0.001, 100)\nrho ~ dunif(-1,1)\n\n# among-site variation in sigma parameters\nsig.alpha.sigma ~ dunif(0.001, 100)\nsig.beta.sigma ~ dunif(0.001, 100)\n\n\n##--- DERIVED VALUES ------------------------------------------------##\n\n# expected deviation from Big G\nfor (j in 1:nSites) { \n  for (i in 1:nDiff) {\n    predlg[j,i] &lt;- alpha[j] + beta[j] * QGvec[i]\n    diff[j,i] &lt;- (alpha[j] + beta[j] * QGvec[i]) - QGvec[i]\n  }}\n\n\n# variance decomposition and standardization\nfor (i in 1:nDiff) {\n\n  # observed population variance, conditional on x\n  VpObs[i] &lt;- (beta.mu^2) * varx + (alpha.sigma^2) + (QGvec[i]^2) * (beta.sigma^2) + 2 * QGvec[i] * (rho * alpha.sigma * beta.sigma) + (exp(sig.alpha.mu + sig.beta.mu * QGvec[i]))^2\n  \n  # expected population variance, no within or among-site diversity\n  VpScen1[i] &lt;- (beta.mu^2) * varx + (exp(sig.alpha.mu))^2\n  \n  # expected population variance, no within-site diversity\n  VpScen2[i] &lt;- (beta.mu^2) * varx + (alpha.sigma^2) + (QGvec[i]^2) * (beta.sigma^2) + 2 * QGvec[i] * (rho * alpha.sigma * beta.sigma) + (exp(sig.alpha.mu))^2\n  \n  # expected population variance, no among-size diversity\n  VpScen3[i] &lt;- (beta.mu^2) * varx + (exp(sig.alpha.mu + sig.beta.mu * QGvec[i]))^2\n  \n  # portfolio strength: how much more diversity in streamflow do we observe at the little g gages than expected under alternative (null) hypotheses?\n  port1[i] &lt;- VpObs[i] / VpScen1[i]\n  port2[i] &lt;- VpObs[i] / VpScen2[i]\n  port3[i] &lt;- VpObs[i] / VpScen3[i]\n}\n\n# attenuation strength: how much more diversity in streamflow (among little g gages) do we observe at low vs. high flows?\nattenObs &lt;- VpObs[1] / VpObs[nDiff]\natten1 &lt;- VpScen1[1] / VpScen1[nDiff]\natten2 &lt;- VpScen2[1] / VpScen2[nDiff]\natten3 &lt;- VpScen3[1] / VpScen3[nDiff]\n\n}\", file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod_Events_2_corr.txt\")\n\n\n\n6.7.1 Fit the model\n\n\nCode\n# vector of QG for prediction\nndiff &lt;- 100\nQGvec &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = ndiff)\n\n# gather data for JAGS\njags.data &lt;- list(\"nObs\" = dim(dat)[1], \"nSites\" = length(unique(dat$site_name_cd)), \n                  \"sites\" = dat$site_name_cd, #\"indev\" = dat_wb2$isevent,\n                  \"Qg\" = dat$yield_little_cum_log, \"QG\" = dat$yield_big_cum_log, \n                  \"QGvec\" = QGvec, \"nDiff\" = ndiff, \"varx\" = sd(dat$yield_little_cum_log)^2)\n\n# parameters to monitor\njags.params &lt;- c(\"alpha\", \"beta\", \"alpha.mu\", \"beta.mu\", \"alpha.sigma\", \"beta.sigma\", \n                 \"sig.alpha\", \"sig.beta\", \"sig.alpha.mu\", \"sig.beta.mu\", \"sig.alpha.sigma\", \"sig.beta.sigma\", \n                 \"rho\", \"diff\", \"predlg\", \"loglik\", \"mu\", \"Qg\", \n                 \"VpObs\", \"VpScen1\", \"VpScen2\", \"VpScen3\", \"port1\", \"port2\", \"port3\", \"attenObs\", \"atten1\", \"atten2\", \"atten3\")\n\n# initial values\nmyinits &lt;- function() {\n  list(alpha.mu = 0, beta.mu = 1, alpha.sigma = 1, beta.sigma = 0.1, \n       sig.alpha.mu = -0.5, sig.beta.mu = -0.2, sig.alpha.sigma = 0.4, sig.beta.sigma = 0.05, \n       ag.alpha = 0.3, ag.beta = 1, ag.sig.alpha = 0, ag.sig.beta = -0.2, rho = -0.8)\n}\n\n# run in jags\nmod_1 &lt;- jags.parallel(data = jags.data, inits = myinits, parameters.to.save = jags.params,\n                       model.file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod_Events_2_corr.txt\",\n                       n.chains = 10, n.thin = 50, n.burnin = 4000, n.iter = 14000, DIC = FALSE)\n# saveRDS(mod_0, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/Fitted models/GgMod_Events.rds\")\n\n\nGet MCMC samples and summary\n\n\nCode\ntop_mod &lt;- mod_1\n# generate MCMC samples and store as an array\nmodelout &lt;- top_mod$BUGSoutput\nMcmcList &lt;- vector(\"list\", length = dim(modelout$sims.array)[2])\nfor(i in 1:length(McmcList)) { McmcList[[i]] = as.mcmc(modelout$sims.array[,i,]) }\n# rbind MCMC samples from 10 chains \nMcmcdat_1 &lt;- rbind(McmcList[[1]], McmcList[[2]], McmcList[[3]], McmcList[[4]], McmcList[[5]], McmcList[[6]], McmcList[[7]], McmcList[[8]], McmcList[[9]], McmcList[[10]])\nparam.summary_1 &lt;- modelout$summary\nhead(param.summary_1)\n\n\n          mean sd     2.5%      25%      50%      75%    97.5% Rhat n.eff\nQg[1] 2.148762  0 2.148762 2.148762 2.148762 2.148762 2.148762    1     1\nQg[2] 3.144685  0 3.144685 3.144685 3.144685 3.144685 3.144685    1     1\nQg[3] 2.930699  0 2.930699 2.930699 2.930699 2.930699 2.930699    1     1\nQg[4] 2.743658  0 2.743658 2.743658 2.743658 2.743658 2.743658    1     1\nQg[5] 2.644678  0 2.644678 2.644678 2.644678 2.644678 2.644678    1     1\nQg[6] 1.624893  0 1.624893 1.624893 1.624893 1.624893 1.624893    1     1\n\n\n\n\n6.7.2 Model diagnostics\n\n6.7.2.1 View R-hat\nAny problematic R-hat values (&gt;1.01)?\n\n\nCode\nmod_1$BUGSoutput$summary[,8][mod_1$BUGSoutput$summary[,8] &gt; 1.01]\n\n\nloglik[311] loglik[350] \n   1.011173    1.015019 \n\n\n\n\n6.7.2.2 View traceplots\nFor global parameters and hyperparameters only…\n\n\nCode\nMCMCtrace(mod_1, ind = TRUE, params = c(\"alpha.mu\", \"beta.mu\", \"alpha.sigma\", \"beta.sigma\", \"sig.alpha.mu\", \"sig.beta.mu\", \"sig.alpha.sigma\", \"sig.beta.sigma\", \"ag.alpha\", \"ag.beta\", \"ag.sig.alpha\", \"ag.sig.beta\", \"rho\"), pdf = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.7.2.3 PP check\nGet observed and expected values\n\n\nCode\nppdat_obs &lt;- as.matrix(Mcmcdat_1[,startsWith(colnames(Mcmcdat_1), \"Qg\")])\nppdat_exp &lt;- as.matrix(Mcmcdat_1[,startsWith(colnames(Mcmcdat_1), \"mu\")])\n\n\nBayesian p-value: values approaching 0.5 indicate lack of bias in model estimates\n\n\nCode\nsum(ppdat_exp &gt; ppdat_obs) / (dim(ppdat_obs)[1]*dim(ppdat_obs)[2])\n\n\n[1] 0.4935653\n\n\n\n\n\n6.7.3 Plot\n\n6.7.3.1 Variances\n\n\nCode\n# control panel\nnsim &lt;- dim(Mcmcdat_1)[1]\nx_seq &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = ndiff)\n\n# get derived values\npred_arr_VpObs &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_VpScen1 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_VpScen2 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_VpScen3 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\n\npred_arr_VpObs_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_VpScen1_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_VpScen2_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_VpScen3_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\n\nfor (j in 1:nsim) { \n  pred_arr_VpObs[j,] &lt;- Mcmcdat_1[j, str_subset(colnames(Mcmcdat_1), pattern = \"VpObs\")] \n  pred_arr_VpScen1[j,] &lt;- Mcmcdat_1[j, str_subset(colnames(Mcmcdat_1), pattern = \"VpScen1\")] \n  pred_arr_VpScen2[j,] &lt;- Mcmcdat_1[j, str_subset(colnames(Mcmcdat_1), pattern = \"VpScen2\")] \n  pred_arr_VpScen3[j,] &lt;- Mcmcdat_1[j, str_subset(colnames(Mcmcdat_1), pattern = \"VpScen3\")] \n  }\nfor (j in 1:ndiff) { \n  pred_arr_VpObs_summ[j,] &lt;- quantile(pred_arr_VpObs[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_VpScen1_summ[j,] &lt;- quantile(pred_arr_VpScen1[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_VpScen2_summ[j,] &lt;- quantile(pred_arr_VpScen2[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_VpScen3_summ[j,] &lt;- quantile(pred_arr_VpScen3[,j], probs = c(0.025, 0.5, 0.95))\n  }\n\n\n\n\nCode\n# plot\nmycols &lt;- c(brewer.pal(3, \"Dark2\"), \"black\")\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0), mfrow = c(2,2))\n\n# VpScen1\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpScen1_summ[,1], rev(pred_arr_VpScen1_summ[,3])), col = alpha(mycols[1], 0.2), border = NA)\nlines(pred_arr_VpScen1_summ[,2] ~ QGvec, col = mycols[1], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 1\", bty = \"n\")\n# VpScen2\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpScen2_summ[,1], rev(pred_arr_VpScen2_summ[,3])), col = alpha(mycols[2], 0.2), border = NA)\nlines(pred_arr_VpScen2_summ[,2] ~ QGvec, col = mycols[2], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 2\", bty = \"n\")\n# VpScen3\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpScen3_summ[,1], rev(pred_arr_VpScen3_summ[,3])), col = alpha(mycols[3], 0.2), border = NA)\nlines(pred_arr_VpScen3_summ[,2] ~ QGvec, col = mycols[3], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 3\", bty = \"n\")\n# VpObs\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpObs_summ[,1], rev(pred_arr_VpObs_summ[,3])), col = alpha(mycols[4], 0.2), border = NA)\nlines(pred_arr_VpObs_summ[,2] ~ QGvec, col = mycols[4], lwd = 2)\nlegend(\"topright\", legend = \"Observed\", bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n6.7.3.2 Portfolio Strength\nHow much more variable is the observed data than what is expected under three (null) alternative hypotheses?\nNote: subtracted 1 from ratios so values &gt;0 indicate the observed data is more variable than expected and values &lt;0 indicate the observed data is less variable than expected\n\n\nCode\n# control panel\nnsim &lt;- dim(Mcmcdat_1)[1]\nx_seq &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = ndiff)\n\n# get derived values\npred_arr_Port1 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_Port2 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_Port3 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\n\npred_arr_Port1_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_Port2_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_Port3_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\n\nfor (j in 1:nsim) { \n  pred_arr_Port1[j,] &lt;- Mcmcdat_1[j, str_subset(colnames(Mcmcdat_1), pattern = \"port1\")] - 1\n  pred_arr_Port2[j,] &lt;- Mcmcdat_1[j, str_subset(colnames(Mcmcdat_1), pattern = \"port2\")] - 1\n  pred_arr_Port3[j,] &lt;- Mcmcdat_1[j, str_subset(colnames(Mcmcdat_1), pattern = \"port3\")] - 1\n  }\nfor (j in 1:ndiff) { \n  pred_arr_Port1_summ[j,] &lt;- quantile(pred_arr_Port1[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_Port2_summ[j,] &lt;- quantile(pred_arr_Port2[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_Port3_summ[j,] &lt;- quantile(pred_arr_Port3[,j], probs = c(0.025, 0.5, 0.95))\n  }\n\n\n\n\nCode\n# plot\nmycols &lt;- c(brewer.pal(3, \"Dark2\"), \"black\")\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0), mfrow = c(2,2))\nylim1 &lt;- -0.25\nylim2 &lt;- 1.25\n\n# VpScen1\nplot(seq(from = ylim1, to = ylim2, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Portfolio strength\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_Port1_summ[,1], rev(pred_arr_Port1_summ[,3])), col = alpha(mycols[1], 0.2), border = NA)\nlines(pred_arr_Port1_summ[,2] ~ QGvec, col = mycols[1], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 1\", bty = \"n\")\nabline(h = 0, lty = 2)\n# VpScen2\nplot(seq(from = ylim1, to = ylim2, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Portfolio strength\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_Port2_summ[,1], rev(pred_arr_Port2_summ[,3])), col = alpha(mycols[2], 0.2), border = NA)\nlines(pred_arr_Port2_summ[,2] ~ QGvec, col = mycols[2], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 2\", bty = \"n\")\nabline(h = 0, lty = 2)\n# VpScen3\nplot(seq(from = ylim1, to = ylim2, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Portfolio strength\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_Port3_summ[,1], rev(pred_arr_Port3_summ[,3])), col = alpha(mycols[3], 0.2), border = NA)\nlines(pred_arr_Port3_summ[,2] ~ QGvec, col = mycols[3], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 3\", bty = \"n\")\nabline(h = 0, lty = 2)\n\n\n\n\n\n\n\n\n\n\n\n6.7.3.3 Attenuation Strength\nTo what degree does diversity in streamflow regimes attenuate with increasing Big G? Attenuation strength is calculated as the variance at min G divided by variance at max G four our observed data and three alternative hypotheses. Note that for scenario 1, variance is constant over G and thus would equal 1. Therefore, a value of 1 represents no attenuation. These figures may provide a standardized approach to comparing “wedginess” across basins.\n\n\nCode\nmycols &lt;- c(brewer.pal(3, \"Dark2\"), \"black\")\npar(mar = c(5,5,1,1), mfrow = c(1,1))\nplot(seq(from = 0, to = 1, length.out = 100) ~ seq(from = 0.5, to = 3, length.out = 100), type = \"n\", xlab = \"Attenuation strength\", ylab = \"Density\")\n\n# observed\nobs_den &lt;- density(Mcmcdat_1[,\"attenObs\"])\nobs_den$y2 &lt;- obs_den$y / max(obs_den$y)\nobs_l &lt;- min(which(obs_den$x &gt;= hdi(obs_den, credMass = 0.95)[1]))\nobs_h &lt;- max(which(obs_den$x &lt; hdi(obs_den, credMass = 0.95)[2]))\npolygon(x = c(obs_den$x[c(obs_l,obs_l:obs_h,obs_h)]), y = c(0,obs_den$y2[obs_l:obs_h],0), col = alpha(mycols[4], 0.3), lty = 0)\nlines(obs_den$y2 ~ obs_den$x, col = mycols[4], lwd = 2)\n\n# scenario 1\n# exp_den &lt;- density(Mcmcdat_1[,\"atten1\"])\n# exp_den$y2 &lt;- exp_den$y / max(exp_den$y)\n# exp_l &lt;- min(which(exp_den$x &gt;= hdi(exp_den, credMass = 0.95)[1]))\n# exp_h &lt;- max(which(exp_den$x &lt; hdi(exp_den, credMass = 0.95)[2]))\n# polygon(x = c(exp_den$x[c(exp_l,exp_l:exp_h,exp_h)]), y = c(0,exp_den$y2[exp_l:exp_h],0), col = alpha(mycols[1], 0.3), lty = 0)\n# lines(exp_den$y2 ~ exp_den$x, col = mycols[1], lwd = 2)\n\n# scenario 2\nexp_den &lt;- density(Mcmcdat_1[,\"atten2\"])\nexp_den$y2 &lt;- exp_den$y / max(exp_den$y)\nexp_l &lt;- min(which(exp_den$x &gt;= hdi(exp_den, credMass = 0.95)[1]))\nexp_h &lt;- max(which(exp_den$x &lt; hdi(exp_den, credMass = 0.95)[2]))\npolygon(x = c(exp_den$x[c(exp_l,exp_l:exp_h,exp_h)]), y = c(0,exp_den$y2[exp_l:exp_h],0), col = alpha(mycols[2], 0.3), lty = 0)\nlines(exp_den$y2 ~ exp_den$x, col = mycols[2], lwd = 2)\n\n# scenario 3\nexp_den &lt;- density(Mcmcdat_1[,\"atten3\"])\nexp_den$y2 &lt;- exp_den$y / max(exp_den$y)\nexp_l &lt;- min(which(exp_den$x &gt;= hdi(exp_den, credMass = 0.95)[1]))\nexp_h &lt;- max(which(exp_den$x &lt; hdi(exp_den, credMass = 0.95)[2]))\npolygon(x = c(exp_den$x[c(exp_l,exp_l:exp_h,exp_h)]), y = c(0,exp_den$y2[exp_l:exp_h],0), col = alpha(mycols[3], 0.3), lty = 0)\nlines(exp_den$y2 ~ exp_den$x, col = mycols[3], lwd = 2)\n\nlegend(\"topright\", legend = c(\"Scenario 1\", \"Scenario 2\", \"Scenario 3\", \"Observed\"), fill = alpha(mycols, 0.3), bty = \"n\")\nabline(v = 1, lty = 1, lwd = 2, col = mycols[1])",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  }
]