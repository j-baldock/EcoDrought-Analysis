[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EcoDrought Capstone",
    "section": "",
    "text": "1 Introduction\nThis book provides a visual story of the USGS Eco-Drought Capstone Project. Our goals are to (1) quantify fine-scale spatial heterogeneity in flow regimes in headwater stream networks, (2) demonstrate the limitations of existing tools that model flow in headwater streams, and (3) assess the subsequent effects of streamflow heterogeneity on fish population dynamics and vulnerability to climatic variation, particularly drought.\nThis information is preliminary or provisional and is subject to revision. It is being provided to meet the need for timely best science. The information has not received final approval by the U.S. Geological Survey (USGS) and is provided on the condition that neither the USGS nor the U.S. Government shall be held liable for any damages resulting from the authorized or unauthorized use of the information.\nProject team: Jeff Baldock, Jenn Fair, Ben Letcher, Robert Al-Chokhachy, Clint Muhlfeld, and Jason Dunham\n\n\nSession Information\n\n\n\n\n\nCode\nsessionInfo()\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 22631)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Denver\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.1    fastmap_1.2.0     cli_3.6.3        \n [5] tools_4.4.1       htmltools_0.5.8.1 rstudioapi_0.17.1 rmarkdown_2.29   \n [9] knitr_1.48        jsonlite_1.8.9    xfun_0.49         digest_0.6.37    \n[13] rlang_1.1.4       evaluate_1.0.1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html",
    "href": "Data Availability/CollateData.html",
    "title": "2  Collate Data",
    "section": "",
    "text": "2.1 Gather site information\nPurpose: Collate EcoDrought streamflow and temperature data, povided by EcoD PIs/partners and NWIS\nNotes:\nCode\n# West Brook\nsiteinfo_wb &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Mass/MA_site_info.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_Name = factor(Site_Name)) %&gt;%\n  rename(site_id = Site_ID, station_no = Station_No, site_name = Site_Name, lat = Latitude_dec_deg, long = Longitude_dec_deg, elev_ft = Elevation_ft, area_sqmi = Drainage_Area_sqmi) %&gt;%\n  mutate(designation = \"little\", basin = \"West Brook\", region = \"Mass\") #%&gt;% select(-c(elev_ft, area_sqmi)) \n\n# Shenandoah\nsiteinfo_shen &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/VA_site_info.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_Name = factor(Site_Name)) %&gt;%\n  rename(site_id = Site_ID, station_no = Station_No, site_name = Site_Name, lat = Latitude_dec_deg, long = Longitude_dec_deg, elev_ft = Elevation_ft, area_sqmi = Drainage_Area_sqmi) %&gt;%\n  mutate(designation = ifelse(str_detect(site_id, \"10FL\"), \"medium\", \"little\"), \n         basin = str_sub(site_name, 1, str_length(site_name)-3), region = \"Shen\") #%&gt;% select(-c(elev_ft, area_sqmi))\n\n# Flathead/Muhlfeld\nsiteinfo_flat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Flathead/Flathead_SiteInfo_UpdateOct25.csv\") %&gt;% \n  select(basin, site_name, site_id, region, designation, lat, long) %&gt;%\n  rename(subbasin = basin) %&gt;%\n  mutate(basin = \"Flathead\", region = \"Flat\") %&gt;%\n  select(site_id, site_name, lat, long, designation, basin, subbasin, region) %&gt;%\n  filter(designation == \"little\")\n  \n# GYA/Al-Chokhachy\nsiteinfo_gya &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/Al-Chokhachy_sites.csv\") %&gt;%\n  mutate(region = ifelse(basin == \"Snake River\", \"Snake\", \"Shields\"), \n         designation = \"little\") %&gt;%\n  select(site_id, site_name, latitude, longitude, designation, basin, region) %&gt;% \n  rename(lat = latitude, long = longitude)\n  \n\n# NWIS Medium/Big/Super G\nsites &lt;- c(\"01169900\", # South River at Conway, Massachusetts\n           \"13011500\", # Pacific Creek, Snake River, Wyoming\n           \"06195600\", # Shields River at Livingston, Montana\n           \"12355500\", # North Fork Flathead River, Montana\n           \"10396000\", # Donner Blitzen River near Frenchglen, Oregon\n           \"06192500\", # Yellowstone River near Livingston\n           \"01665500\", # Rapidan River near Ruckersville\n           \"01662800\", # Battle Run near Laurel Mills\n           \"01627500\", # South River at Harriston\n           # Medium G\n           \"12355347\", # Big Creek (Flathead)\n           \"12355342\", # Hallowat Creek (Flathead)\n           \"06192980\", # Shields Rivera above Smith Creek (GYA)\n           \"06192900\", # Dugout Creek Mouth (GYA)\n           \"13012475\", # South Fork Spread Creek (GYA)\n           \"13012465\", # Leidy Creek, lower (GYA)\n           \"01171100\", # West Brook (Mass)\n           \"01171000\",  # Avery Brook (Mass)\n           \"424551118503200\", # Fish Creek at DB confluence (Oreg)\n           \"424547118503500\", # DB above Fish Creek (Oreg)\n           \"424325118495900\", # DB near Burnt Car Spring (Oreg)\n           \"424003118453700\", # Little Blitzen River (Oreg)\n           \"423830118453200\", # Indian Creek (Oreg)\n           \"423815118453900\" # DB above Indian Creek (Oreg)\n           )\nsiteinfo_nwis &lt;- tibble(readNWISsite(sites)[,c(2:3,7,8,20,30)]) # get site info\nnames(siteinfo_nwis) &lt;- c(\"station_no\", \"site_name\", \"lat\", \"long\", \"elev_ft\", \"area_sqmi\") # rename columns\nsiteinfo_nwis &lt;- siteinfo_nwis %&gt;% \n  mutate(site_name = c(\"South River Conway NWIS\", \n                       \"Avery Brook NWIS\", \n                       \"West Brook NWIS\", \n                       \"South River Harriston NWIS\",\n                       \"Battle Run NWIS\",\n                       \"Rapidan River NWIS\",\n                       \"Yellowstone River Livingston NWIS\",\n                       \"Dugout Creek NWIS\", \n                       \"Shields River ab Smith NWIS\", \n                       \"Shields River nr Livingston NWIS\",\n                       \"Donner Blitzen River nr Frenchglen NWIS\", \n                       \"Hallowat Creek NWIS\", \n                       \"Big Creek NWIS\", \n                       \"North Fork Flathead River NWIS\",\n                       \"Pacific Creek at Moran NWIS\", \n                       \"Leidy Creek Mouth NWIS\", \n                       \"SF Spread Creek Lower NWIS\",\n                       \"Donner Blitzen ab Indian NWIS\",\n                       \"Indian Creek NWIS\",\n                       \"Little Blizten River NWIS\",\n                       \"Donner Blitzen nr Burnt Car NWIS\",\n                       \"Donner Blitzen ab Fish NWIS\",\n                       \"Fish Creek NWIS\"),\n         site_id = c(\"SRC\", \n                     \"AVB\", \n                     \"WBR\", \n                     \"SRH\",\n                     \"BAT\",\n                     \"RAP\",\n                     \"YEL\",\n                     \"DUG\", \n                     \"SRS\", \n                     \"SRL\", \n                     \"DBF\", \n                     \"HAL\", \n                     \"BIG\", \n                     \"NFF\", \n                     \"PCM\", \n                     \"LEI\", \n                     \"SFS\", \n                     \"DBI\", \n                     \"IND\", \n                     \"LBL\", \n                     \"DBB\", \n                     \"DBA\", \n                     \"FSH\"),\n         designation = c(\"big\", \n                         \"medium\", \n                         \"medium\",\n                         \"big\",\n                         \"big\",\n                         \"big\",\n                         \"big\",\n                         \"medium\", \n                         \"medium\", \n                         \"big\", \n                         \"big\", \n                         \"medium\",\n                         \"medium\", \n                         \"big\", \n                         \"big\", \n                         \"medium\", \n                         \"medium\", \n                         \"medium\", \n                         \"medium\", \n                         \"medium\", \n                         \"medium\", \n                         \"medium\", \n                         \"medium\"),\n         basin = c(\"West Brook\", \n                   \"West Brook\", \n                   \"West Brook\", \n                   \"Paine Run\",\n                   \"Piney River\",\n                   \"Staunton River\",\n                   \"Shields River\",\n                   \"Shields River\", \n                   \"Shields River\", \n                   \"Shields River\", \n                   \"Donner Blitzen\", \n                   \"Flathead\", \n                   \"Flathead\", \n                   \"Flathead\", \n                   \"Snake River\", \n                   \"Snake River\", \n                   \"Snake River\", \n                   \"Donner Blitzen\", \n                   \"Donner Blitzen\", \n                   \"Donner Blitzen\", \n                   \"Donner Blitzen\", \n                   \"Donner Blitzen\", \n                   \"Donner Blitzen\"),\n         region = c(\"Mass\", \n                    \"Mass\",\n                    \"Mass\", \n                    \"Shen\",\n                    \"Shen\",\n                    \"Shen\",\n                    \"Shields\",\n                    \"Shields\", \n                    \"Shields\", \n                    \"Shields\", \n                    \"Oreg\", \n                    \"Flat\", \n                    \"Flat\", \n                    \"Flat\", \n                    \"Snake\", \n                    \"Snake\", \n                    \"Snake\",\n                    \"Oreg\",\n                    \"Oreg\", \n                    \"Oreg\", \n                    \"Oreg\", \n                    \"Oreg\", \n                    \"Oreg\")) %&gt;% \n  select(site_id, site_name, lat, long, station_no, designation, basin, region, elev_ft, area_sqmi)\n#mapview(st_as_sf(siteinfo_nwis, coords = c(\"long\", \"lat\"), crs = 4326))\n\n\n# bind together, fill in ragged subbasin\nsiteinfo &lt;- bind_rows(siteinfo_wb, siteinfo_shen, siteinfo_flat, siteinfo_gya, siteinfo_nwis)\nsiteinfo$subbasin[siteinfo$site_name == \"Hallowat Creek NWIS\"] &lt;- \"Big Creek\"\nsiteinfo$subbasin[siteinfo$site_name == \"Big Creek NWIS\"] &lt;- \"Big Creek\"\nsiteinfo$subbasin[siteinfo$site_id %in% c(\"DU01\", \"DU02\", \"DU03\")] &lt;- \"Duck Creek\"\nsiteinfo &lt;- siteinfo %&gt;% mutate(subbasin = ifelse(is.na(subbasin), basin, subbasin))\n\n\n# fix Shields River Valley Ranch site locations\nsiteinfo$lat[siteinfo$site_id == \"SH07\"] &lt;- siteinfo$lat[siteinfo$site_id == \"SRS\"]\nsiteinfo$long[siteinfo$site_id == \"SH07\"] &lt;- siteinfo$long[siteinfo$site_id == \"SRS\"]\n\n# add data source \nsiteinfo$source &lt;- ifelse(grepl(\"NWIS\", siteinfo$site_name), \"NWIS\", \"ECOD\")\n\n# add elevation and area variables (from watershed delineation)\nareafiles &lt;- list.files(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Area and Elevation\")\narealist &lt;- list()\nfor (i in 1:length(areafiles)) { arealist[[i]] &lt;- read_csv(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Area and Elevation/\", areafiles[i], sep = \"\"))}\nareaelev &lt;- do.call(rbind, arealist)\n# how well do provided and delineation area/elevation match?\n# siteinfo %&gt;% left_join(areaelev, by = \"site_id\") %&gt;% ggplot() + geom_point(aes(x = area_sqmi.x, y = area_sqmi.y)) + geom_abline(intercept = 0, slope = 1) + facet_wrap(~basin, scales = \"free\")\n# test %&gt;% ggplot() + geom_point(aes(x = elev_ft.x, y = elev_ft.y)) + geom_abline(intercept = 0, slope = 1) + facet_wrap(~basin, scales = \"free\")\n# add delineated variables\nsiteinfo &lt;- siteinfo %&gt;% \n  rename(area_sqmi_prov = area_sqmi, elev_ft_prov = elev_ft) %&gt;% \n  left_join(areaelev) %&gt;% \n  mutate(area_sqmi = ifelse(is.na(area_sqmi), area_sqmi_prov, area_sqmi),\n         elev_ft = ifelse(is.na(elev_ft), elev_ft_prov, elev_ft)) %&gt;%\n  select(-c(area_sqmi_prov, elev_ft_prov))\n# fix NF Flathead (no dem from Canada)\nsiteinfo$area_sqmi[siteinfo$site_id == \"NFF\"] &lt;- 1556\nWrite and re-load site information\nCode\nwrite_csv(siteinfo, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nCode\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\ndatatable(siteinfo)\nView unique basin names\nCode\nunique(siteinfo$basin)\n\n\n[1] \"West Brook\"     \"Paine Run\"      \"Piney River\"    \"Staunton River\"\n[5] \"Flathead\"       \"Shields River\"  \"Snake River\"    \"Donner Blitzen\"\nView unique subbasin names\nCode\nunique(siteinfo$subbasin)\n\n\n [1] \"West Brook\"         \"Paine Run\"          \"Piney River\"       \n [4] \"Staunton River\"     \"Big Creek\"          \"Coal Creek\"        \n [7] \"McGee Creek\"        \"Wounded Buck Creek\" \"Duck Creek\"        \n[10] \"Shields River\"      \"Snake River\"        \"Donner Blitzen\"    \n[13] \"Flathead\"\nMap sites\nCode\n# convert to spatial object and view on map\n#| fig-cap: \"Map of EcoDrought project locations\"\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#ecod-data",
    "href": "Data Availability/CollateData.html#ecod-data",
    "title": "2  Collate Data",
    "section": "2.2 EcoD data",
    "text": "2.2 EcoD data\n\n2.2.1 Load EcoD data\nLoad EcoDrought flow and temperature data and convert all date/times to UTC\n\n\nCode\n# West Brook\ndat_wb &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Mass/EcoDrought_Continuous_MA_updateFeb2025.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_Name = factor(Site_Name), DateTime_EST = mdy_hm(DateTime_EST)) %&gt;%\n  rename(station_no = Station_No, site_name = Site_Name, datetime = DateTime_EST, height = GageHeight_Hobo_ft, flow = Discharge_Hobo_cfs, tempf = WaterTemperature_Hobo_DegF) %&gt;%\n  mutate(tempc = (tempf - 32)*(5/9),\n         site_name = dplyr::recode(site_name, \"Obear Brook  Low\" = \"Obear Brook Lower\")) %&gt;% \n  select(station_no, site_name, datetime, height, flow, tempc) %&gt;%\n  left_join(siteinfo %&gt;% select(-station_no) %&gt;% filter(source == \"ECOD\")) %&gt;%\n  mutate(DischargeReliability = as.factor(1), TempReliability = as.factor(1))\n# set tz to local and convert to UTC\ntz(dat_wb$datetime) &lt;- \"EST\"\ndat_wb$datetime &lt;- with_tz(dat_wb$datetime, \"UTC\")\nhead(dat_wb)\n\n\n# A tibble: 6 × 18\n  station_no site_name   datetime            height  flow tempc site_id   lat\n  &lt;fct&gt;      &lt;chr&gt;       &lt;dttm&gt;               &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 01171000   Avery Brook 2020-01-08 18:15:00   4.22  6.27 1.11  AB       42.4\n2 01171000   Avery Brook 2020-01-08 18:30:00   4.19  5.78 1.11  AB       42.4\n3 01171000   Avery Brook 2020-01-08 18:45:00   4.2   5.85 1.00  AB       42.4\n4 01171000   Avery Brook 2020-01-08 19:00:00   4.2   5.83 1.00  AB       42.4\n5 01171000   Avery Brook 2020-01-08 19:15:00   4.2   6    1.00  AB       42.4\n6 01171000   Avery Brook 2020-01-08 19:30:00   4.22  6.28 0.889 AB       42.4\n# ℹ 10 more variables: long &lt;dbl&gt;, designation &lt;chr&gt;, basin &lt;chr&gt;,\n#   region &lt;chr&gt;, subbasin &lt;chr&gt;, source &lt;chr&gt;, area_sqmi &lt;dbl&gt;, elev_ft &lt;dbl&gt;,\n#   DischargeReliability &lt;fct&gt;, TempReliability &lt;fct&gt;\n\n\nCode\n# Shenandoah\ndat_shen &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/EcoDrought_Continuous_VA.csv\") %&gt;%\n  mutate(Station_No = factor(Station_No), Site_ID = factor(Site_ID), Discharge_Hobo_cfs = as.numeric(Discharge_Hobo_cfs)) %&gt;%\n  rename(station_no = Station_No, site_id = Site_ID, datetime = DateTime_EST, height = GageHeight_Hobo_ft, flow = Discharge_Hobo_cfs, tempf = WaterTemperature_HOBO_DegF) %&gt;%\n  mutate(tempc = (tempf - 32)*(5/9)) %&gt;% select(station_no, site_id, datetime, height, flow, tempc) %&gt;%\n  left_join(siteinfo %&gt;% filter(source == \"ECOD\"))\n# set tz to local and convert to UTC\ntz(dat_shen$datetime) &lt;- \"EST\"\ndat_shen$datetime &lt;- with_tz(dat_shen$datetime, \"UTC\")\n\n# pull in Big G data separately (UVA long-term gage sites)\ndat_shen_uva_q &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/Shen_BigG_Discharge_hourly_UVA.csv\") %&gt;%\n  rename(flow = cfs)\ndat_shen_uva_t &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/Shen_BigG_TempEtc_hourly_UVA.csv\") %&gt;%\n  select(site_id, datetime, tempc_mean) %&gt;% rename(tempc = tempc_mean)\ndat_shen_uva &lt;- dat_shen_uva_q %&gt;% left_join(dat_shen_uva_t) %&gt;% left_join(siteinfo %&gt;% filter(source == \"ECOD\"))\n# set tz to local and convert to UTC\ntz(dat_shen_uva$datetime) &lt;- \"EST\"\ndat_shen_uva$datetime &lt;- with_tz(dat_shen_uva$datetime, \"UTC\")\n\n# bind usgs and uva data\ndat_shen &lt;- bind_rows(dat_shen, dat_shen_uva) %&gt;% mutate(DischargeReliability = as.factor(1), TempReliability = as.factor(1))\nhead(dat_shen)\n\n\n# A tibble: 6 × 18\n  station_no site_id datetime            height  flow tempc site_name      lat\n  &lt;chr&gt;      &lt;chr&gt;   &lt;dttm&gt;               &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;\n1 0162732260 PA_01FL 2018-11-07 05:00:00   10.8  6.11  11.6 Paine Run 01  38.2\n2 0162732260 PA_01FL 2018-11-07 05:30:00   10.8  6.38  11.6 Paine Run 01  38.2\n3 0162732260 PA_01FL 2018-11-07 06:00:00   10.8  6.36  11.4 Paine Run 01  38.2\n4 0162732260 PA_01FL 2018-11-07 06:30:00   10.8  6.17  11.4 Paine Run 01  38.2\n5 0162732260 PA_01FL 2018-11-07 07:00:00   10.8  6.35  11.3 Paine Run 01  38.2\n6 0162732260 PA_01FL 2018-11-07 07:30:00   10.8  6.4   11.3 Paine Run 01  38.2\n# ℹ 10 more variables: long &lt;dbl&gt;, designation &lt;chr&gt;, basin &lt;chr&gt;,\n#   region &lt;chr&gt;, subbasin &lt;chr&gt;, source &lt;chr&gt;, area_sqmi &lt;dbl&gt;, elev_ft &lt;dbl&gt;,\n#   DischargeReliability &lt;fct&gt;, TempReliability &lt;fct&gt;\n\n\nCode\n# Flathead/Muhlfeld\nflatfiles &lt;- list.files(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Flathead/Export3/EMA/Continuous Data\")\nflatlist &lt;- list()\nfor (i in 1:length(flatfiles)) { \n  flatlist[[i]] &lt;- read_csv(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Flathead/Export3/EMA/Continuous Data/\", flatfiles[i], sep = \"\")) %&gt;%\n    mutate(#DateTime = mdy_hm(DateTime, tz = \"MST\"),\n           site_name = gsub(\"EMA.csv\", \"\", flatfiles[i])) %&gt;% \n    select(ISO.8601.UTC, GageHeightFT, DischargeCFS, TemperatureF, site_name, DischargeReliability_JB, GageReliability, TempReliability_JB) %&gt;% rename(DischargeReliability = DischargeReliability_JB, TempReliability = TempReliability_JB)\n}\ndat_flat &lt;- bind_rows(flatlist) %&gt;%\n  filter(!is.na(ISO.8601.UTC)) %&gt;% \n  rename(datetime = ISO.8601.UTC, height = GageHeightFT, flow = DischargeCFS, tempf = TemperatureF) %&gt;%\n  mutate(tempc = (tempf - 32) * (5/9), datetime = floor_date(datetime, unit = \"minute\")) %&gt;% \n  select(-tempf) %&gt;%\n  group_by(site_name, datetime) %&gt;% \n  summarise(height = mean(height, na.rm = TRUE), flow = mean(flow, na.rm = TRUE), tempc = mean(tempc, na.rm = TRUE),\n            DischargeReliability = unique(DischargeReliability), \n            GageReliability = unique(GageReliability), \n            TempReliability = unique(TempReliability)) %&gt;%\n  left_join(siteinfo %&gt;% filter(source == \"ECOD\")) %&gt;% ungroup() %&gt;% \n  mutate(DischargeReliability = as_factor(DischargeReliability),\n         GageReliability = as_factor(GageReliability),\n         TempReliability = as_factor(TempReliability))\n# set tz to local and convert to UTC\ntz(dat_flat$datetime) &lt;- \"UTC\"\nhead(dat_flat)\n\n\n# A tibble: 6 × 19\n  site_name     datetime            height  flow tempc DischargeReliability\n  &lt;chr&gt;         &lt;dttm&gt;               &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;               \n1 BigCreekLower 2017-09-18 18:45:00   1.64  38.1  8.59 1                   \n2 BigCreekLower 2017-09-18 19:45:00   1.65  38.7  8.69 1                   \n3 BigCreekLower 2017-09-18 20:45:00   1.65  39.4  8.79 1                   \n4 BigCreekLower 2017-09-18 21:45:00   1.66  39.6  8.79 1                   \n5 BigCreekLower 2017-09-18 22:45:00   1.67  41.2  8.79 1                   \n6 BigCreekLower 2017-09-18 23:45:00   1.67  41.3  8.69 1                   \n# ℹ 13 more variables: GageReliability &lt;fct&gt;, TempReliability &lt;fct&gt;,\n#   site_id &lt;chr&gt;, lat &lt;dbl&gt;, long &lt;dbl&gt;, station_no &lt;chr&gt;, designation &lt;chr&gt;,\n#   basin &lt;chr&gt;, region &lt;chr&gt;, subbasin &lt;chr&gt;, source &lt;chr&gt;, area_sqmi &lt;dbl&gt;,\n#   elev_ft &lt;dbl&gt;\n\n\nCode\n# Greater Yellowstone/Al-Chokhachy\ngyafiles &lt;- list.files(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/Al-Chokhachy data files\")\ngyalist &lt;- list()\nfor (i in 1:length(gyafiles)) { \n  gyalist[[i]] &lt;- read_csv(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/Al-Chokhachy data files/\", gyafiles[i], sep = \"\")) %&gt;%\n    mutate(date = mdy(date), datetime = ymd_hms(paste(date, time, sep = \" \"), tz = \"MST\"), discharge = as.numeric(discharge)*35.314666212661) %&gt;% \n    rename(DischargeReliability = DischargeReliability_JB, TempReliability = TempReliability_JB)\n}\ndat_gya &lt;- bind_rows(gyalist) %&gt;% select(datetime, depth, discharge, temperature, location, DischargeReliability, TempReliability) %&gt;% \n  rename(height = depth, flow = discharge, tempc = temperature, site_name = location) %&gt;%\n  filter(site_name != \"EF Henrys\") %&gt;% # drop weird duplicate site/year?\n  mutate(site_name = dplyr::recode(site_name,\n                            \"EF Above Confluence\" = \"EF Duck Creek ab HF\",\n                            \"EF Below Confluence\" = \"EF Duck Creek be HF\",\n                            \"NF Spread Creek\" = \"NF Spread Creek Lower\",\n                            \"Upper NF Spread Creek\" = \"NF Spread Creek Upper\",\n                            \"SF Spread Creek\" = \"SF Spread Creek Lower\",\n                            \"Upper SF Spread Creek\" = \"SF Spread Creek Upper\",\n                            \"Shields River above Dugout Creek\" = \"Shields River ab Dugout\",\n                            \"Upper Leidy Creek\" = \"Leidy Creek Upper\", \n                            \"Leidy Creek\" = \"Leidy Creek Mouth\",\n                            \"Spread Creek\" = \"Spread Creek Dam\",\n                            \"Shields River above Smith Creek\" = \"Shields River Valley Ranch\")) %&gt;%\n  left_join(siteinfo %&gt;% filter(source == \"ECOD\")) %&gt;% filter(tempc &lt;= 100) %&gt;%\n  mutate(DischargeReliability = as.factor(DischargeReliability), TempReliability = as.factor(TempReliability))\n# set tz to local and convert to UTC\ntz(dat_gya$datetime) &lt;- \"MST\"\ndat_gya$datetime &lt;- with_tz(dat_gya$datetime, \"UTC\")\nhead(dat_gya)\n\n\n# A tibble: 6 × 18\n  datetime            height  flow tempc site_name      DischargeReliability\n  &lt;dttm&gt;               &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;          &lt;fct&gt;               \n1 2019-06-17 15:45:00  0.521  45.3  5.66 Brackett Creek 1                   \n2 2019-06-17 16:45:00  0.551  50.4  6.27 Brackett Creek 1                   \n3 2019-06-17 17:45:00  0.526  46.1  7.08 Brackett Creek 1                   \n4 2019-06-17 18:45:00  0.533  47.3  7.88 Brackett Creek 1                   \n5 2019-06-17 19:45:00  0.528  46.4  8.38 Brackett Creek 1                   \n6 2019-06-17 20:45:00  0.53   46.8  9.77 Brackett Creek 1                   \n# ℹ 12 more variables: TempReliability &lt;fct&gt;, site_id &lt;chr&gt;, lat &lt;dbl&gt;,\n#   long &lt;dbl&gt;, station_no &lt;chr&gt;, designation &lt;chr&gt;, basin &lt;chr&gt;, region &lt;chr&gt;,\n#   subbasin &lt;chr&gt;, source &lt;chr&gt;, area_sqmi &lt;dbl&gt;, elev_ft &lt;dbl&gt;\n\n\nWrite formatted basin datasets to individual files\n\n\nCode\nwrite_csv(dat_wb, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Formatted data/EcoDrought_WestBrook_FlowTemp_DataClean.csv\")\n\nwrite_csv(dat_shen, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Formatted data/EcoDrought_Shenandoah_FlowTemp_DataClean.csv\")\n\nwrite_csv(dat_flat %&gt;% \n            mutate(region = \"CC\",\n                   flow = ifelse(DischargeReliability == 0, NA, flow),\n                   tempc = ifelse(TempReliability == 0, NA, tempc)) %&gt;%\n            select(-c(designation, source)) %&gt;%\n            select(-c(GageReliability, DischargeReliability, TempReliability)), \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Formatted data/EcoDrought_Flathead_FlowTemp_DataClean.csv\")\n\nwrite_csv(dat_gya %&gt;% \n            mutate(subbasin = ifelse(subbasin == \"Snake River\", \"Spread Creek\", subbasin),\n                   region = \"GYA\",\n                   flow = ifelse(DischargeReliability == 0, NA, flow),\n                   tempc = ifelse(TempReliability == 0, NA, tempc)) %&gt;%\n            select(-c(designation, source)) %&gt;%\n            select(-c(DischargeReliability, TempReliability)), \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Formatted data/EcoDrought_GreaterYellowstone_FlowTemp_DataClean.csv\")\n\ndat_flat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Formatted data/EcoDrought_Flathead_FlowTemp_DataClean.csv\")\ndat_gya &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Formatted data/EcoDrought_GreaterYellowstone_FlowTemp_DataClean.csv\")\ndat_flat\ndat_gya\n\ndat_flatgya &lt;- bind_rows(dat_flat, dat_gya)\nwrite_csv(bind_rows(dat_flat, dat_gya), \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Formatted data/EcoDrought_MT-WY_FlowTemp_DataClean.csv\")\n\n\nBind EcoD hourly flow/temp data from across basins\n\n\nCode\ndat &lt;- bind_rows(dat_wb, dat_shen, dat_flat, dat_gya)\n\n\n\n\n2.2.2 Duplicates\nCheck for duplicates: number of duplicated unique date/times by site. For the Duck Ck and Spread Ck sites, this is driven by errors in how the datetimes are coded/specified (see ReviewData.qmd).\n\n\nCode\ndat %&gt;% group_by(site_name, datetime) %&gt;% filter(n()&gt;1) %&gt;% arrange(site_name, datetime) %&gt;% group_by(site_name) %&gt;% summarize(num_dups = length(unique(datetime))) %&gt;% kable()\n\n\n\n\n\nsite_name\nnum_dups\n\n\n\n\nGrouse Creek\n733\n\n\nPiney River 10\n1\n\n\nRock Creek\n2\n\n\nStaunton River 10\n1\n\n\n\n\n\n\n\n2.2.3 Check unique\nCheck unique designations\n\n\nCode\nunique(dat$designation)\n\n\n[1] \"little\" \"medium\"\n\n\nCheck unique regions\n\n\nCode\nunique(dat$region)\n\n\n[1] \"Mass\"    \"Shen\"    \"Flat\"    \"Shields\" \"Snake\"  \n\n\nCheck unique basins\n\n\nCode\nunique(dat$basin)\n\n\n[1] \"West Brook\"     \"Paine Run\"      \"Staunton River\" \"Piney River\"   \n[5] \"Flathead\"       \"Shields River\"  \"Snake River\"   \n\n\nCheck unique subbasins\n\n\nCode\nunique(dat$subbasin)\n\n\n [1] \"West Brook\"         \"Paine Run\"          \"Staunton River\"    \n [4] \"Piney River\"        \"Big Creek\"          \"Coal Creek\"        \n [7] \"McGee Creek\"        \"Wounded Buck Creek\" \"Shields River\"     \n[10] \"Duck Creek\"         \"Snake River\"       \n\n\n\n\n2.2.4 Inspect raw data\nSee ReviewData.qmd for site-level dyGraph plots of raw flow and temperature time series data (file size too large to include here).\n\n\n2.2.5 Write to file\n\n\nCode\nwrite_csv(dat, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_Raw.csv\")\ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_Raw.csv\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#nwis-data",
    "href": "Data Availability/CollateData.html#nwis-data",
    "title": "2  Collate Data",
    "section": "2.3 NWIS data",
    "text": "2.3 NWIS data\n\n2.3.1 Download NWIS data\nDownload sub-daily flow and temp data from NWIS and ensure time zone = UTC\n\n\nCode\nnwis_list &lt;- list()\nfor (i in 1:length(sites)) {\n  nwis_list[[i]] &lt;- tibble(readNWISdata(sites = sites[i], service = \"uv\", parameterCd = c(\"00010\", \"00060\"), \n                                        startDate = \"1980-01-01\", endDate = Sys.Date(), tz = \"UTC\"))\n  print(i)\n}\nnwis_subdaily &lt;- do.call(bind_rows, nwis_list)\nnwis_subdaily &lt;- nwis_subdaily %&gt;% select(-1)\nnames(nwis_subdaily) &lt;- c(\"station_no\", \"datetime\", \"flowcfs\", \"flowcfs_appcd\", \"tz\", \"tempc\", \"tempc_appcd\")\nnwis_subdaily &lt;- nwis_subdaily %&gt;% left_join(siteinfo %&gt;% filter(source == \"NWIS\"))\nwrite_csv(nwis_subdaily, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_NWIS_FlowTempData_Raw_SubDaily.csv\")\n\n\n\n\nCode\nnwis_subdaily &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_NWIS_FlowTempData_Raw_SubDaily.csv\") %&gt;% \n  mutate(site_name = dplyr::recode(site_name, \"Fish Creek\" = \"Fish Creek NWIS\", \"Avery Broook NWIS\" = \"Avery Brook NWIS\")) %&gt;% filter(grepl(\"NWIS\", site_name))\n\ntz(nwis_subdaily$datetime) &lt;- \"UTC\"\nnwis_subdaily$datetime &lt;- with_tz(nwis_subdaily$datetime, \"UTC\")\n\nhead(nwis_subdaily)\n\n\n# A tibble: 6 × 17\n  station_no datetime            flowcfs flowcfs_appcd tz    tempc tempc_appcd\n  &lt;chr&gt;      &lt;dttm&gt;                &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;      \n1 01169900   1990-10-01 04:15:00      15 A [91]        UTC      NA &lt;NA&gt;       \n2 01169900   1990-10-01 04:30:00      16 A [91]        UTC      NA &lt;NA&gt;       \n3 01169900   1990-10-01 04:45:00      16 A [91]        UTC      NA &lt;NA&gt;       \n4 01169900   1990-10-01 05:00:00      16 A [91]        UTC      NA &lt;NA&gt;       \n5 01169900   1990-10-01 05:15:00      16 A [91]        UTC      NA &lt;NA&gt;       \n6 01169900   1990-10-01 05:30:00      16 A [91]        UTC      NA &lt;NA&gt;       \n# ℹ 10 more variables: site_id &lt;chr&gt;, site_name &lt;chr&gt;, lat &lt;dbl&gt;, long &lt;dbl&gt;,\n#   designation &lt;chr&gt;, basin &lt;chr&gt;, region &lt;chr&gt;, subbasin &lt;chr&gt;,\n#   area_sqmi &lt;dbl&gt;, elev_ft &lt;dbl&gt;\n\n\nDownload daily flow and temp data from NWIS\n\n\nCode\nnwis_list &lt;- list()\nfor (i in 1:length(sites)) {\n  nwis_list[[i]] &lt;- tibble(readNWISdata(sites = sites[i], service = \"dv\", parameterCd = c(\"00010\", \"00060\"), \n                                        startDate = \"1950-01-01\", endDate = Sys.Date(), tz = \"UTC\"))\n  print(i)\n}\nnwis_daily &lt;- do.call(bind_rows, nwis_list)\nnwis_daily &lt;- nwis_daily %&gt;% select(-c(1,7,8,9,10))\nnames(nwis_daily) &lt;- c(\"station_no\", \"date\", \"flowcfs\", \"flowcfs_appcd\", \"tz\", \"tempc\", \"tempc_appcd\")\nnwis_daily &lt;- nwis_daily %&gt;% left_join(siteinfo %&gt;% filter(source == \"NWIS\"))\nwrite_csv(nwis_daily, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_NWIS_FlowTempData_Raw_Daily.csv\")\n\n\n\n\nCode\nnwis_daily &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_NWIS_FlowTempData_Raw_Daily.csv\")\nhead(nwis_daily)\n\n\n# A tibble: 6 × 18\n  station_no date                flowcfs flowcfs_appcd tz    tempc tempc_appcd\n  &lt;chr&gt;      &lt;dttm&gt;                &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;      \n1 01169900   1966-06-15 00:00:00      17 A             UTC      NA &lt;NA&gt;       \n2 01169900   1966-06-16 00:00:00      14 A             UTC      NA &lt;NA&gt;       \n3 01169900   1966-06-17 00:00:00      14 A             UTC      NA &lt;NA&gt;       \n4 01169900   1966-06-18 00:00:00      11 A             UTC      NA &lt;NA&gt;       \n5 01169900   1966-06-19 00:00:00      11 A             UTC      NA &lt;NA&gt;       \n6 01169900   1966-06-20 00:00:00      10 A             UTC      NA &lt;NA&gt;       \n# ℹ 11 more variables: site_id &lt;chr&gt;, site_name &lt;chr&gt;, lat &lt;dbl&gt;, long &lt;dbl&gt;,\n#   designation &lt;chr&gt;, basin &lt;chr&gt;, region &lt;chr&gt;, subbasin &lt;chr&gt;, source &lt;chr&gt;,\n#   area_sqmi &lt;dbl&gt;, elev_ft &lt;dbl&gt;\n\n\n\n\n2.3.2 Check approval\n\nA, A[91], A[92], A[93]: approved and historical daily values ~match observed data\nA R: approved and revised (limited)\nA e: approved estimated data, often during ice affected periods (smoothed data)\nP: provisional data yet to be approved, typically these are just more recent observations\nP e: provisional estimated data, often during ice affected periods\nP Ice: ice affected observations\nP dis: provisional data yet to be approved, site has been discontinued\nNA: missing value, usually b/c temp is observed but flow is not\n\nFlow approval codes\n\n\nCode\nunique(nwis_daily$flowcfs_appcd)\n\n\n[1] \"A\"     \"A e\"   \"P\"     \"P e\"   \"P Ice\" \"A R\"   NA      \"P Dis\"\n\n\nTemp approval codes\n\n\nCode\nunique(nwis_daily$tempc_appcd)\n\n\n[1] NA      \"A\"     \"P\"     \"P Ssn\" \"A [4]\" \"P Eqp\" \"P Dis\"\n\n\nCheck approval for key sites: Sub-daily ::: panel-tabset #### West Brook\n\n\n\n\n\n\n\n2.3.2.1 Big Ck\n\n\n\n\n\n\n\n\n2.3.2.2 Shields ab Smith\n\n\n\n\n\n\n\n\n2.3.2.3 Donner-Blitzen\n\n\n\n\n\n\n\n\n2.3.2.4 SF Spread\n\n\n\n\n\n\n:::\nCheck approval for key sites: Daily ::: panel-tabset #### South River Conway (West Brook)\n\n\n\n\n\n\n\n\n2.3.2.5 Donner Blitzen (DB)\n\n\n\n\n\n\n\n\n2.3.2.6 NF Flathead (Big, Coal, McGee)\n\n\n\n\n\n\n\n\n2.3.2.7 Pacific Creek (Snake)\n\n\n\n\n\n\n\n\n2.3.2.8 Yellowstone (Shields/Duck)\n\n\n\n\n\n\n\n\n2.3.2.9 Rapidan River (Staunton)\n\n\n\n\n\n\n\n\n2.3.2.10 Battle Run (Piney)\n\n\n\n\n\n\n\n\n2.3.2.11 South River (Paine)\n\n\n\n\n\n\n:::\n\n\n\n2.3.3 View data\n\n\nCode\nnwis_subdaily %&gt;% filter(designation == \"big\") %&gt;% ggplot() + geom_line(aes(x = datetime, y = flowcfs)) + facet_wrap(~site_name, scales = \"free_y\")\n\n\n\n\n\nStream flow (cfs) for Big/Super G NWIS gages\n\n\n\n\n\n\nCode\nnwis_subdaily %&gt;% filter(designation == \"medium\") %&gt;% ggplot() + geom_line(aes(x = datetime, y = flowcfs)) + facet_wrap(~site_name, scales = \"free_y\" )\n\n\n\n\n\nStream flow (cfs) for Medium G NWIS gages\n\n\n\n\n\n\nCode\nnwis_daily %&gt;% filter(designation == \"big\") %&gt;% ggplot() + geom_line(aes(x = date, y = flowcfs)) + facet_wrap(~site_name, scales = \"free_y\")\n\n\n\n\n\nDaily mean stream flow (cfs) for Big/Super G NWIS gages\n\n\n\n\n\n\nCode\nnwis_daily %&gt;% filter(designation == \"medium\") %&gt;% ggplot() + geom_line(aes(x = date, y = flowcfs)) + facet_wrap(~site_name, scales = \"free_y\" )\n\n\n\n\n\nStream flow (cfs) for Medium G NWIS gages",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#bind-ecod-and-nwis",
    "href": "Data Availability/CollateData.html#bind-ecod-and-nwis",
    "title": "2  Collate Data",
    "section": "2.4 Bind EcoD and NWIS",
    "text": "2.4 Bind EcoD and NWIS\nBind EcoD and NWIS data, specify common reliability/approval codes. Also round date-times to nearest minute and summarize flow/temp data as loggers at some sites (e.g., in the Flathead) will take multiple readings within seconds of each other\n\n\nCode\ndat_full &lt;- bind_rows(dat %&gt;% mutate(tz = tz(datetime)), \n                      nwis_subdaily %&gt;% \n                        rename(flow = flowcfs) %&gt;%\n                        mutate(DischargeReliability = ifelse(flowcfs_appcd %in% c(\"A [91]\", \"A [92]\", \"A [93]\", \"A\"), 1, 0),\n                               TempReliability = ifelse(tempc_appcd %in% c(\"A\", \"P\", \"P Ssn\", \"P Eqp\", \"P Dis\"), 1, 0))) \nhead(dat_full)\n\n\n# A tibble: 6 × 22\n  station_no site_name   datetime            height  flow tempc site_id   lat\n  &lt;chr&gt;      &lt;chr&gt;       &lt;dttm&gt;               &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 01171000   Avery Brook 2020-01-08 18:15:00   4.22  6.27 1.11  AB       42.4\n2 01171000   Avery Brook 2020-01-08 18:30:00   4.19  5.78 1.11  AB       42.4\n3 01171000   Avery Brook 2020-01-08 18:45:00   4.2   5.85 1.00  AB       42.4\n4 01171000   Avery Brook 2020-01-08 19:00:00   4.2   5.83 1.00  AB       42.4\n5 01171000   Avery Brook 2020-01-08 19:15:00   4.2   6    1.00  AB       42.4\n6 01171000   Avery Brook 2020-01-08 19:30:00   4.22  6.28 0.889 AB       42.4\n# ℹ 14 more variables: long &lt;dbl&gt;, designation &lt;chr&gt;, basin &lt;chr&gt;,\n#   region &lt;chr&gt;, subbasin &lt;chr&gt;, source &lt;chr&gt;, area_sqmi &lt;dbl&gt;, elev_ft &lt;dbl&gt;,\n#   DischargeReliability &lt;dbl&gt;, TempReliability &lt;dbl&gt;, GageReliability &lt;dbl&gt;,\n#   tz &lt;chr&gt;, flowcfs_appcd &lt;chr&gt;, tempc_appcd &lt;chr&gt;\n\n\n\n2.4.1 Duplicates\nCheck for duplicates: number of duplicated unique date/times by site. For the Duck Ck and Spread Ck sites, this is driven by errors in how the datetimes are coded/specified (see ReviewData.qmd).\n\n\nCode\ndat_full %&gt;% group_by(site_name, datetime) %&gt;% filter(n()&gt;1) %&gt;% arrange(site_name, datetime) %&gt;% ungroup() %&gt;% group_by(site_name) %&gt;% summarize(num_dups = length(unique(datetime))) %&gt;% kable()\n\n\n\n\n\nsite_name\nnum_dups\n\n\n\n\nGrouse Creek\n733\n\n\nPiney River 10\n1\n\n\nRock Creek\n2\n\n\nStaunton River 10\n1\n\n\n\n\n\n\n\n2.4.2 Write to file\n\n\nCode\nwrite_csv(dat_full, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_Raw_ECODandNWIS.csv\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#calculate-daily-means",
    "href": "Data Availability/CollateData.html#calculate-daily-means",
    "title": "2  Collate Data",
    "section": "2.5 Calculate daily means",
    "text": "2.5 Calculate daily means\nGet daily summaries for DischargeReliability == 1 only! Duplicate Shields River Livingston data for Duck Creek big G.\n\n\nCode\ndat_daily &lt;- dat_full %&gt;% \n  mutate(date = as_date(datetime),\n         flow = ifelse(DischargeReliability == 1, flow, NA),\n         tempc = ifelse(TempReliability == 1, tempc, NA)) %&gt;% \n  group_by(station_no, site_name, site_id, basin, subbasin, region, lat, long, elev_ft, area_sqmi, designation, date) %&gt;% \n  summarize(DischargeReliability = max(DischargeReliability),\n            TempReliability = max(TempReliability),\n            flow_mean = mean(flow), flow_min = min(flow), flow_max = max(flow),\n            tempc_mean = mean(tempc), tempc_min = min(tempc), tempc_max = max(tempc)) %&gt;%\n  arrange(region, basin, site_name, date) %&gt;%\n  ungroup()\ndat_daily &lt;- bind_rows(dat_daily, dat_daily %&gt;% filter(site_id == \"SRL\") %&gt;% mutate(subbasin = \"Duck Creek\")) \nhead(dat_daily)\n\n\n# A tibble: 6 × 20\n  station_no site_name      site_id basin    subbasin region   lat  long elev_ft\n  &lt;chr&gt;      &lt;chr&gt;          &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 12355347   Big Creek NWIS BIG     Flathead Big Cre… Flat    48.6 -114.   3528.\n2 12355347   Big Creek NWIS BIG     Flathead Big Cre… Flat    48.6 -114.   3528.\n3 12355347   Big Creek NWIS BIG     Flathead Big Cre… Flat    48.6 -114.   3528.\n4 12355347   Big Creek NWIS BIG     Flathead Big Cre… Flat    48.6 -114.   3528.\n5 12355347   Big Creek NWIS BIG     Flathead Big Cre… Flat    48.6 -114.   3528.\n6 12355347   Big Creek NWIS BIG     Flathead Big Cre… Flat    48.6 -114.   3528.\n# ℹ 11 more variables: area_sqmi &lt;dbl&gt;, designation &lt;chr&gt;, date &lt;date&gt;,\n#   DischargeReliability &lt;dbl&gt;, TempReliability &lt;dbl&gt;, flow_mean &lt;dbl&gt;,\n#   flow_min &lt;dbl&gt;, flow_max &lt;dbl&gt;, tempc_mean &lt;dbl&gt;, tempc_min &lt;dbl&gt;,\n#   tempc_max &lt;dbl&gt;\n\n\nAdd missing dates\n\n\nCode\ndat_daily &lt;- fill_missing_dates(dat_daily, dates = date, groups = site_name)\n\n\nView daily mean time series data, for example, site_name = CoalCreekLower. Notice the many shorts gaps in the daily data.\n\n\nCode\ndat_daily %&gt;% filter(site_name == \"CoalCreekLower\") %&gt;% select(date, flow_mean) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Mean daily flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\n\n\nCheck for duplicates\n\n\nCode\ndups &lt;- dat_daily %&gt;% group_by(site_name, date) %&gt;% filter(n()&gt;1) %&gt;% arrange(site_name, date)\nnrow(dups)/2\n\n\n[1] 10085\n\n\nCode\nunique(dups$site_name)\n\n\n[1] \"Shields River nr Livingston NWIS\"",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#interpolate-missing-data",
    "href": "Data Availability/CollateData.html#interpolate-missing-data",
    "title": "2  Collate Data",
    "section": "2.6 Interpolate missing data",
    "text": "2.6 Interpolate missing data\nSmall periods of missing data (&lt;24 hours) become a problem when aggregating at the daily and weekly time scales. *Note that currently this discovers and fills missing data at the daily time scale, but should be changed to interpolate at the original timescale of the raw data (e.g., hourly).\n\n\nCode\n# explore data gaps\nmysites &lt;- unique(dat_daily$site_name)\nmynas &lt;- list()\nfor (i in 1:length(mysites)) {\n  mydisch &lt;- unlist(dat_daily$flow_mean[dat_daily$site_name == mysites[i]])\n  runsna &lt;- rle(is.na(mydisch))\n  mynas[[i]] &lt;- tibble(site_name = mysites[i], run = runsna$lengths[runsna$values == TRUE])\n}\nmynas &lt;- do.call(rbind, mynas)\n\n\nMost gaps are relatively short\n\n\nCode\nmynas %&gt;% ggplot() + geom_histogram(aes(x = run)) + xlab(\"Days\") + ylab(\"Frequency\")\n\n\n\n\n\nDistributiion of lengths of missing data (days)\n\n\n\n\nZoomed in…\n\n\nCode\nmynas %&gt;% ggplot() + geom_histogram(aes(x = run))  + xlab(\"Days\") + ylab(\"Frequency\") + xlim(0,30)\n\n\n\n\n\nDistributiion of lengths of missing data (days)\n\n\n\n\nConsidering just the short gaps, which are likely most commonly a function of ice effects, which sites are problematic?\n\n\nCode\nmynas %&gt;% filter(run &lt;= 40) %&gt;% select(site_name) %&gt;% ggplot() + geom_bar(aes(x = site_name)) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\nFrequency of short (&lt;40 days) data gaps by site\n\n\n\n\nFill short gaps (&lt;=7 days) using time series interpolation\n\n\nCode\ndatalist &lt;- list()\nfor (i in 1:length(mysites)) { datalist[[i]] &lt;- dat_daily %&gt;% filter(site_name == mysites[i]) %&gt;% mutate(flow_mean_filled = fillMissing(flow_mean, max.fill = 7, span = 100)) }\ndat_daily_fill &lt;- do.call(rbind, datalist)\n\n\nExplore interpolated/filled time series relative to original (daily) data Again, CoalCreekLower as an example.\n\n\nCode\ndat_daily_fill %&gt;% filter(site_name == \"CoalCreekLower\") %&gt;% select(date, flow_mean, flow_mean_filled) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dySeries(\"flow_mean\", strokeWidth = 5, color = \"black\") %&gt;% dySeries(\"flow_mean_filled\", strokeWidth = 1, color = \"red\") %&gt;% dyAxis(\"y\", label = \"Mean daily flow (cfs)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#calculate-yield",
    "href": "Data Availability/CollateData.html#calculate-yield",
    "title": "2  Collate Data",
    "section": "2.7 Calculate yield",
    "text": "2.7 Calculate yield\n\n\nCode\n# convert cfs and basin area to metric\ndat_daily_fill &lt;- dat_daily_fill %&gt;% mutate(flow_mean_cms = flow_mean*0.02831683199881, \n                                            flow_mean_filled_cms = flow_mean_filled*0.02831683199881, \n                                            area_sqkm = area_sqmi*2.58999)\n\n# sites\nsites &lt;- unique(dat_daily_fill$site_name)\n\n# site-specific basin area in square km\nbasinarea &lt;- dat_daily_fill %&gt;% filter(!is.na(site_id)) %&gt;% group_by(site_name) %&gt;% summarize(area_sqkm = unique(area_sqkm))\n\n# calculate yield\nyield_list &lt;- list()\nfor (i in 1:length(sites)) {\n  d &lt;- dat_daily_fill %&gt;% filter(site_name == sites[i])\n  ba &lt;- unlist(basinarea %&gt;% filter(site_name == sites[i]) %&gt;% select(area_sqkm))\n  yield_list[[i]] &lt;-  add_daily_yield(data = d, values = flow_mean_cms, basin_area = as.numeric(ba)) %&gt;% left_join(add_daily_yield(data = d, values = flow_mean_filled_cms, basin_area = as.numeric(ba)) %&gt;% rename(Yield_filled_mm = Yield_mm))\n}\ndat_daily_fill_wyield &lt;- do.call(rbind, yield_list)",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#calculate-7-day-means",
    "href": "Data Availability/CollateData.html#calculate-7-day-means",
    "title": "2  Collate Data",
    "section": "2.8 Calculate 7-day means",
    "text": "2.8 Calculate 7-day means\n\n\nCode\ndat_daily_fill_wyield &lt;- dat_daily_fill_wyield %&gt;%\n  group_by(site_name) %&gt;%\n  mutate(flow_mean_7 = rollapply(flow_mean, FUN = mean, width = 7, align = \"center\", fill = NA),\n         flow_mean_filled_7 = rollapply(flow_mean_filled, FUN = mean, width = 7, align = \"center\", fill = NA),\n         tempc_mean_7 = rollapply(tempc_mean, FUN = mean, width = 7, align = \"center\", fill = NA),\n         Yield_mm_7 = rollapply(Yield_mm, FUN = mean, width = 7, align = \"center\", fill = NA),\n         Yield_filled_mm_7 = rollapply(Yield_filled_mm, FUN = mean, width = 7, align = \"center\", fill = NA)) %&gt;%\n  ungroup() %&gt;% filter(!is.na(site_id))",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#view-daily-data",
    "href": "Data Availability/CollateData.html#view-daily-data",
    "title": "2  Collate Data",
    "section": "2.9 View daily data",
    "text": "2.9 View daily data\nView daily time series data by sub-basin (little and medium g’s only).\n\n2.9.1 Flow\n\nBig CreekCoal CreekMcGee CreekWest BrookPaine RunStaunton RiverDuck CreekShields RiverSnake RiverDonner Blitzen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.9.2 Temperature\n\nBig CreekCoal CreekMcGee CreekWest BrookPaine RunStaunton RiverDuck CreekShields RiverSnake RiverDonner Blitzen",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#write-out-and-read-data",
    "href": "Data Availability/CollateData.html#write-out-and-read-data",
    "title": "2  Collate Data",
    "section": "2.10 Write out and read data",
    "text": "2.10 Write out and read data\n\n\nCode\n# write out\nwrite_csv(dat_daily_fill_wyield, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\")\ndat_daily &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#view-data-availability",
    "href": "Data Availability/CollateData.html#view-data-availability",
    "title": "2  Collate Data",
    "section": "2.11 View data availability",
    "text": "2.11 View data availability\n\n\nCode\n# summarize data availability\ndat_summ &lt;- dat_daily %&gt;% filter(site_id != \"MRN\") %&gt;%\n  group_by(basin, date, designation) %&gt;% summarize(numflow = sum(!is.na(flow_mean)), numtemp = sum(!is.na(tempc_mean))) %&gt;% \n  gather(type, avail, numflow:numtemp) %&gt;% mutate(type2 = as.factor(paste(designation, type, sep = \"_\"))) %&gt;% \n  mutate(type3 = as.numeric(type2), avail = na_if(avail, 0)) %&gt;% ungroup() %&gt;% filter(!is.na(avail))\n\n\n\n\nCode\n# plot all years\n#| fig-cap: \"Data availability by basin, all years\"\nmyplot &lt;- dat_summ %&gt;% ggplot(aes(x = date, y = type3)) + \n  geom_errorbarh(aes(xmax = date, xmin = date, color = avail), size = 0.001) +\n  scale_color_continuous(trans = \"reverse\", na.value = \"grey60\") +\n  scale_y_discrete(limits = c(\"Big G flow\", \"Big G temp\", \"Medium g flow\", \"Medium g temp\", \"Little g flow\", \"Little g temp\")) + \n  labs(colour = \"Number \\nof sites\") + ylab(\"\") + xlab(\"Date\") + \n  facet_wrap(~ basin, nrow = 4,\n             labeller = as_labeller(c(`West Brook` = \"West Brook: G = South River Conway (NWIS)\", \n                                      `Staunton River` = \"Staunton River: G = Staunton River 10 (UVA)\",\n                                      `Paine Run` = \"Paine Run: G = Paine Run 10 (UVA)\",\n                                      `Piney River` = \"Piney River: G = Piney River 10 (UVA)\",\n                                      `Snake River` = \"Snake River: G = Pacific Creek Moran (NWIS)\",\n                                      `Shields River` = \"Shields River: G = Shields River Livingston (NWIS)\",\n                                      `Flathead` = \"NF Flathead River: G = NF Flathead (NWIS)\",\n                                      `Donner Blitzen` = \"Donner Blitzen River: G = DB Frenchglen (NWIS)\",\n                                      `Duck Creek` = \"Duck Creek: G = Shields River Livingston (NWIS)\")))\nmyplot\n\n\n\n\n\n\n\n\n\nCode\n# jpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Data Availability/DataAvailability_byBasin.jpg\", height = 6, width = 12, units = \"in\", res = 500)\n# myplot\n# dev.off()\n\n\n\n\nCode\n# plot recent years\n#| fig-cap: \"Data availability by basin, recent years\"\n# jpeg(\"./Data Availability/DataAvailability_byBasin_recent.jpg\", height = 6, width = 12, units = \"in\", res = 500)\nmyplot &lt;- dat_summ %&gt;% filter(date &gt;= \"2018-10-01\") %&gt;% ggplot(aes(x = date, y = type3)) + \n  geom_errorbarh(aes(xmax = date, xmin = date, color = avail), size = 0.001) +\n  scale_color_continuous(trans = \"reverse\", na.value = \"grey60\") +\n  scale_y_discrete(limits = c(\"Big G flow\", \"Big G temp\", \"Medium g flow\", \"Medium g temp\", \"Little g flow\", \"Little g temp\")) + \n  labs(colour = \"Number \\nof sites\") + ylab(\"\") + xlab(\"Date\") + \n  facet_wrap(~ basin, nrow = 4,\n             labeller = as_labeller(c(`West Brook` = \"West Brook: G = South River Conway (NWIS)\", \n                                      `Staunton River` = \"Staunton River: G = Staunton River 10 (UVA)\",\n                                      `Paine Run` = \"Paine Run: G = Paine Run 10 (UVA)\",\n                                      `Piney River` = \"Piney River: G = Piney River 10 (UVA)\",\n                                      `Snake River` = \"Snake River: G = Pacific Creek Moran (NWIS)\",\n                                      `Shields River` = \"Shields River: G = Shields River Livingston (NWIS)\",\n                                      `Flathead` = \"NF Flathead River: G = NF Flathead (NWIS)\",\n                                      `Donner Blitzen` = \"Donner Blitzen River: G = DB Frenchglen (NWIS)\",\n                                      `Duck Creek` = \"Duck Creek: G = Shields River Livingston (NWIS)\")))\nmyplot",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Data Availability/CollateData.html#compare-co-located-gages",
    "href": "Data Availability/CollateData.html#compare-co-located-gages",
    "title": "2  Collate Data",
    "section": "2.12 Compare co-located gages",
    "text": "2.12 Compare co-located gages\n\n2.12.1 Compare synchronous gages\nCompare streamflow data from co-located EcoDrought and NWIS gages with overlapping periods of record\n\n\nCode\n# WEST BROOK\np1 &lt;- dat_daily %&gt;% filter(site_name == \"West Brook 0\") %&gt;% select(date, flow_mean_7) %&gt;% rename(little = flow_mean_7) %&gt;% \n  left_join(dat_daily %&gt;% filter(site_name == \"West Brook NWIS\") %&gt;% select(date, flow_mean_7) %&gt;% rename(medium = flow_mean_7)) %&gt;%\n  ggplot() + geom_point(aes(x = log(medium), y = log(little))) + geom_abline(intercept = 0, slope = 1, color = \"red\")\n\np2 &lt;- dat_daily %&gt;% filter(site_name == \"Avery Brook\") %&gt;% select(date, flow_mean_7) %&gt;% rename(little = flow_mean_7) %&gt;% \n  left_join(dat_daily %&gt;% filter(site_name == \"Avery Broook NWIS\") %&gt;% select(date, flow_mean_7) %&gt;% rename(medium = flow_mean_7)) %&gt;%\n  ggplot() + geom_point(aes(x = log(medium), y = log(little))) + geom_abline(intercept = 0, slope = 1, color = \"red\")\n\n# FLATHEAD\np3 &lt;- dat_daily %&gt;% filter(site_name == \"BigCreekMiddle\") %&gt;% select(date, flow_mean_7) %&gt;% rename(little = flow_mean_7) %&gt;% \n  left_join(dat_daily %&gt;% filter(site_name == \"Big Creek NWIS\") %&gt;% select(date, flow_mean_7) %&gt;% rename(medium = flow_mean_7)) %&gt;%\n  ggplot() + geom_point(aes(x = log(medium), y = log(little))) + geom_abline(intercept = 0, slope = 1, color = \"red\")\n\n# jpeg(\"./Data Availability/LittleMedium_Co-Located_Gages.jpg\", height = 6, width = 6, units = \"in\", res = 500)\nggarrange(p1, p2, p3, ncol = 2, nrow = 2, labels = c(\"West Brook 0\", \"Avery Brook\", \"Big Creek (Flathead)\"))\n\n\n\n\n\nStreamflow measured at little g gages (EcoDrought) as a function of streamflow measured at medium g gages (NWIS), on a log-scale. Red line denotes 1:1\n\n\n\n\nCode\n# dev.off()\n\n\n\n\n2.12.2 Compare asynchronous gages\nFor Spread Creek and Shields River, compare data from co-located EcoDrought and NWIS gages, with NON-overlapping periods of record. Note that streamflow from NWIS gages is about ~1 order of magnitude greater than what is measured at EcoD gages.\n\nLeidy CreekSF Spread Creek LowerDugout CreekSheilds Valley Ranch",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Collate Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html",
    "href": "Explore Data/ExploreData.html",
    "title": "3  Explore Long-Term Data",
    "section": "",
    "text": "3.1 Site info and daily data\nPurpose: Explore (long-term) data and (recent) climatic context of EcoD years\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# flow (and temp) data\ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html#daymet-air-temp-and-precip",
    "href": "Explore Data/ExploreData.html#daymet-air-temp-and-precip",
    "title": "3  Explore Long-Term Data",
    "section": "3.2 Daymet air temp and precip",
    "text": "3.2 Daymet air temp and precip\n\n\nCode\nmycols &lt;- brewer.pal(6, \"Dark2\")\nsiteinfo_big &lt;- siteinfo %&gt;% filter(designation == \"big\")\n\n# download point location Daymet data\nclimlist &lt;- vector(\"list\", length = dim(siteinfo_big)[1])\nfor (i in 1:dim(siteinfo_big)[1]) {\n  clim &lt;- download_daymet(site = siteinfo_big$site_name[i], lat = siteinfo_big$lat[i], lon = siteinfo_big$long[i], start = 1980, end = 2023, internal = T)\n  climlist[[i]] &lt;- tibble(clim$data) %&gt;% \n    mutate(air_temp_mean = (tmax..deg.c. + tmin..deg.c.)/2, \n           date = as.Date(paste(year, yday, sep = \"-\"), \"%Y-%j\"),\n           site_name = siteinfo_big$site_name[i]) %&gt;%\n    select(12,2,11,10,4,6) %&gt;% rename(precip_mmday = 5, swe_kgm2 = 6)\n  #print(i)\n}\n\n# combine and calculate 7-day moving averages\nclimdf &lt;- do.call(rbind, climlist) %&gt;% left_join(siteinfo_big) %&gt;% mutate(year = year(date)) %&gt;% \n  group_by(station_no, site_name, site_id, basin, region, lat, long, elev_ft, area_sqmi, designation) %&gt;%\n  mutate(air_mean_7 = rollapply(air_temp_mean, FUN = mean, width = 7, align = \"center\", fill = NA),\n         precip_mean_7 = rollapply(precip_mmday, FUN = mean, width = 7, align = \"center\", fill = NA),\n         swe_mean_7 = rollapply(swe_kgm2, FUN = mean, width = 7, align = \"center\", fill = NA)) %&gt;%\n  ungroup() \n\n# trim to Big G sites\nclimdf_big &lt;- climdf %&gt;% filter(designation == \"big\")\n\n\nView long-term trends in mean annual air temperature, by basin\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Daymet_AirTemp_AnnualTrend_BigG.jpg\", height = 8, width = 8, units = \"in\", res = 500)\nclimdf_big_summ &lt;- climdf_big %&gt;% group_by(site_name, year) %&gt;% summarize(anntemp = mean(air_temp_mean)) %&gt;% ungroup()\nclimdf_big_summ %&gt;% \n  ggplot(aes(x = year, y = anntemp)) + geom_point() + facet_wrap(~site_name) + \n  geom_smooth(method = \"lm\", se = TRUE) + xlab(\"Year\") + ylab(\"Mean annual air temperature (deg C)\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nView long-term trends in total annual precipitation, by basin\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Daymet_AirTemp_AnnualTrend_BigG.jpg\", height = 8, width = 8, units = \"in\", res = 500)\nclimdf_big_summ &lt;- climdf_big %&gt;% group_by(site_name, year) %&gt;% summarize(annprec = sum(precip_mmday)) %&gt;% ungroup()\nclimdf_big_summ %&gt;% \n  ggplot(aes(x = year, y = annprec)) + geom_point() + facet_wrap(~site_name) + \n  geom_smooth(span = 0.3, se = TRUE) + xlab(\"Year\") + ylab(\"Total annual precipitaion (mm)\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nView annual air temperature time series\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Daymet_AirTemp_Regime_BigG.jpg\", height = 8, width = 8, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = climdf_big, aes(x = yday, y = air_mean_7, group = year, color = year), size = 0.2) +\n  facet_wrap(~ site_name) + xlab(\"Day of year\") + ylab(\"7-day mean air temperature (deg C)\") + \n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nView annual air temperature time series, highlight recent years\n\n\nCode\nclimdf_big_recent &lt;- climdf_big %&gt;% filter(year %in% c(2018:2023))\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Daymet_AirTemp_Regime_BigG_Recent.jpg\", height = 8, width = 8, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = climdf_big, aes(x = yday, y = air_mean_7, group = year), color = \"grey70\", size = 0.25) +\n  geom_line(data = climdf_big_recent, aes(x = yday, y = air_mean_7, group = as.factor(year), color = as.factor(year))) +\n  scale_colour_manual(values = mycols) + facet_wrap(~ site_name) +\n  xlab(\"Day of year\") + ylab(\"7-day mean air temperature\") + \n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html#big-g-temp-flow-and-yield",
    "href": "Explore Data/ExploreData.html#big-g-temp-flow-and-yield",
    "title": "3  Explore Long-Term Data",
    "section": "3.3 Big G temp, flow, and yield",
    "text": "3.3 Big G temp, flow, and yield\n\n\nCode\ndat_daily_G &lt;- dat %&gt;% filter(designation == \"big\", site_name != \"West Brook 0\") %&gt;% mutate(yday = yday(date), year = year(date))\ndat_daily_G_recent &lt;- dat_daily_G %&gt;% filter(year %in% c(2018:2023))\nyear_range &lt;- dat_daily_G %&gt;% group_by(site_name) %&gt;% summarize(minyear = min(year), maxyear = max(year)) %&gt;% mutate(yearrange = paste(minyear, maxyear, sep = \"-\"))\nmycols &lt;- brewer.pal(6, \"Dark2\")\ndat_daily_G %&gt;% group_by(site_name) %&gt;% summarize(mindate = min(date), maxdate = max(date)) %&gt;% kable(caption = \"Date range of Big G streamflow data\")\n\n\n\nDate range of Big G streamflow data\n\n\nsite_name\nmindate\nmaxdate\n\n\n\n\nDonner Blitzen River nr Frenchglen NWIS\n2006-10-01\n2025-01-22\n\n\nNorth Fork Flathead River NWIS\n1995-10-01\n2025-01-22\n\n\nPacific Creek at Moran NWIS\n1987-08-18\n2025-01-22\n\n\nPaine Run 10\n1992-10-01\n2024-01-01\n\n\nPiney River 10\n1992-10-01\n2024-01-01\n\n\nShields River nr Livingston NWIS\n1991-10-01\n2025-01-22\n\n\nSouth River Conway NWIS\n1990-10-01\n2025-01-22\n\n\nStaunton River 10\n1992-09-02\n2024-01-01\n\n\n\n\n\nIn-situ stream temperature\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_StreamTemp_BigG_Recent.jpg\", height = 8, width = 9, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = dat_daily_G, aes(x = yday, y = tempc_mean_7, group = year), color = \"grey70\", size = 0.25) +\n  geom_line(data = dat_daily_G_recent, aes(x = yday, y = tempc_mean_7, group = as.factor(year), color = as.factor(year))) +\n  scale_colour_manual(values = mycols) + facet_wrap(~ site_name, nrow = 3) + xlab(\"Day of calendar year\") + ylab(\"7-day mean temperature (deg C)\") + ylim(0,22) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.9,0.05), legend.justification = c(1,0)) + labs(color = \"Year\")\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nIn-situ streamflow\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_StreamFlow_BigG_Recent.jpg\", height = 8, width = 9, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = dat_daily_G, aes(x = yday, y = log(flow_mean_7), group = year), color = \"grey70\", size = 0.25) +\n  geom_line(data = dat_daily_G_recent, aes(x = yday, y = log(flow_mean_7), group = as.factor(year), color = as.factor(year))) +\n  scale_colour_manual(values = mycols) + \n  geom_text(data = year_range, aes(x = -Inf, y = -Inf, label = yearrange), hjust = -0.1, vjust = -1) +\n  facet_wrap(~ site_name, nrow = 3, scales = \"free_y\") + \n  xlab(\"Day of calendar year\") + ylab(\"ln 7-day mean streamflow (cfs)\") + labs(color = \"Year\") + theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.9,0.05), legend.justification = c(1,0))\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nStreamflow in Yield. Note same y-axis limits\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Yield_BigG_Recent.jpg\", height = 8, width = 9, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = dat_daily_G, aes(x = yday, y = log(Yield_filled_mm_7), group = year), color = \"grey70\", size = 0.25) +\n  geom_line(data = dat_daily_G_recent, aes(x = yday, y = log(Yield_filled_mm_7), group = as.factor(year), color = as.factor(year))) +\n  scale_colour_manual(values = mycols) + \n  geom_text(data = year_range, aes(x = -Inf, y = -Inf, label = yearrange), hjust = -0.1, vjust = -1) +\n  facet_wrap(~ site_name, nrow = 3) + \n  xlab(\"Day of year\") + ylab(\"ln 7-day mean yield\") + labs(color = \"Year\") + theme_bw() + ylim(-5,3.5) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.9,0.05), legend.justification = c(1,0))\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html#exceedance-probability",
    "href": "Explore Data/ExploreData.html#exceedance-probability",
    "title": "3  Explore Long-Term Data",
    "section": "3.4 Exceedance probability",
    "text": "3.4 Exceedance probability\n\n\nCode\nexceedance &lt;- dat_daily_G %&gt;% filter(!is.na(Yield_filled_mm)) %&gt;% \n  mutate(Yield_filled_mm_log = log(Yield_filled_mm)) %&gt;%\n  group_by(station_no, site_name, site_id, basin, region, lat, long, elev_ft, area_sqmi, designation, year) %&gt;% \n  arrange(desc(Yield_filled_mm_log), .by_group = TRUE) %&gt;% \n  mutate(exceedance = 100/length(Yield_filled_mm_log)*1:length(Yield_filled_mm_log)) %&gt;%\n  ungroup()\nexceedance_recent &lt;- exceedance %&gt;% filter(year %in% c(2018:2023))\n\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_Yield_Recent_Exceedance.jpg\", height = 8, width = 9, units = \"in\", res = 500)\nggplot() + \n  geom_line(data = exceedance, aes(x = exceedance, y = Yield_filled_mm_log, group = year), color = \"grey70\", size = 0.25) +\n  geom_line(data = exceedance_recent, aes(x = exceedance, y = Yield_filled_mm_log, group = as.factor(year), color = as.factor(year))) +\n  scale_colour_manual(values = mycols) + \n  geom_text(data = year_range, aes(x = -Inf, y = -Inf, label = yearrange), hjust = -0.1, vjust = -1) +\n  facet_wrap(~ site_name, nrow = 3) + \n  xlab(\"Exceedance probability\") + ylab(\"ln daily mean yield (mm)\") + labs(color = \"Year\") + theme_bw() + ylim(-5,5) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.9,0.05), legend.justification = c(1,0))\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html#dsci",
    "href": "Explore Data/ExploreData.html#dsci",
    "title": "3  Explore Long-Term Data",
    "section": "3.5 DSCI",
    "text": "3.5 DSCI\nView time series of drought severity and coverage index (DSCI), summarized over HUC08 basins. Accessed https://droughtmonitor.unl.edu/DmData/TimeSeries.aspx\n\n\nCode\n# get huc 8 codes\nhuctib &lt;- tibble(site_name = siteinfo$site_name, basin = siteinfo$basin, huc08 = NA)\nfor (i in 1:dim(siteinfo)[1]) {\n  huctib$huc08[i] &lt;- unlist(tibble(get_huc(AOI = siteinfo_sp[i,], type = \"huc08\"))[,11])\n  #print(i)\n}\nhuctib &lt;- huctib %&gt;% group_by(basin) %&gt;% summarize(huc08 = unique(huc08)) #%&gt;% filter(basin != \"Piney River\")\n# unique(huctib$huc08)\n#huctib &lt;- tibble(basin = c(\"Donner Blitzen\", \"Flathead\", \"Paine\"))\n\n# bring in drought indices\ndsci &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/dm_export_19800101_20241004.csv\") %&gt;%\n rename(huc08 = HUCID, name = Name, date = MapDate, dsci = DSCI) %&gt;% mutate(date = ymd(date)) %&gt;% left_join(huctib)\n\n# print table\ndsci %&gt;% group_by(basin) %&gt;% summarize(dsci_name = unique(name), huc08 = unique(huc08)) %&gt;% kable(caption = \"HUC08 basin codes for primary EcoDrought basins\")\n\n\n\nHUC08 basin codes for primary EcoDrought basins\n\n\nbasin\ndsci_name\nhuc08\n\n\n\n\nDonner Blitzen\nDonner und Blitzen\n17120003\n\n\nFlathead\nNorth Fork Flathead\n17010206\n\n\nPaine Run\nSouth Fork Shenandoah\n02070005\n\n\nPiney River\nRapidan-Upper Rappahannock\n02080103\n\n\nShields River\nShields\n10070003\n\n\nSnake River\nSnake Headwaters\n17040101\n\n\nStaunton River\nRapidan-Upper Rappahannock\n02080103\n\n\nWest Brook\nMiddle Connecticut\n01080201\n\n\n\n\n\n\n\nCode\n# calculate monthly means\ndsci_monthly &lt;- dsci %&gt;% \n  mutate(monthyear = as_date(paste(format_ISO8601(date, precision = \"ym\"), \"-01\", sep = \"\"))) %&gt;% \n  mutate(year = year(monthyear), month = month(monthyear)) %&gt;%\n  group_by(huc08, basin, year, month, monthyear) %&gt;% \n  summarize(dsci_monthly_1 = mean(dsci)) %&gt;% \n  ungroup() %&gt;%\n  group_by(huc08, basin) %&gt;%\n  mutate(dsci_monthly_2 = rollapply(dsci_monthly_1, FUN = mean, width = 2, align = \"right\", fill = NA),\n         dsci_monthly_3 = rollapply(dsci_monthly_1, FUN = mean, width = 3, align = \"right\", fill = NA),\n         dsci_monthly_4 = rollapply(dsci_monthly_1, FUN = mean, width = 4, align = \"right\", fill = NA),\n         dsci_monthly_5 = rollapply(dsci_monthly_1, FUN = mean, width = 5, align = \"right\", fill = NA),\n         dsci_monthly_6 = rollapply(dsci_monthly_1, FUN = mean, width = 6, align = \"right\", fill = NA),\n         dsci_monthly_7 = rollapply(dsci_monthly_1, FUN = mean, width = 7, align = \"right\", fill = NA),\n         dsci_monthly_8 = rollapply(dsci_monthly_1, FUN = mean, width = 8, align = \"right\", fill = NA),\n         dsci_monthly_9 = rollapply(dsci_monthly_1, FUN = mean, width = 9, align = \"right\", fill = NA),\n         dsci_monthly_10 = rollapply(dsci_monthly_1, FUN = mean, width = 10, align = \"right\", fill = NA),\n         dsci_monthly_11 = rollapply(dsci_monthly_1, FUN = mean, width = 11, align = \"right\", fill = NA),\n         dsci_monthly_12 = rollapply(dsci_monthly_1, FUN = mean, width = 12, align = \"right\", fill = NA),\n         dsci_monthly_13 = rollapply(dsci_monthly_1, FUN = mean, width = 13, align = \"right\", fill = NA),\n         dsci_monthly_14 = rollapply(dsci_monthly_1, FUN = mean, width = 14, align = \"right\", fill = NA),\n         dsci_monthly_15 = rollapply(dsci_monthly_1, FUN = mean, width = 15, align = \"right\", fill = NA),\n         dsci_monthly_16 = rollapply(dsci_monthly_1, FUN = mean, width = 16, align = \"right\", fill = NA),\n         dsci_monthly_17 = rollapply(dsci_monthly_1, FUN = mean, width = 17, align = \"right\", fill = NA),\n         dsci_monthly_18 = rollapply(dsci_monthly_1, FUN = mean, width = 18, align = \"right\", fill = NA),\n         dsci_monthly_19 = rollapply(dsci_monthly_1, FUN = mean, width = 19, align = \"right\", fill = NA),\n         dsci_monthly_20 = rollapply(dsci_monthly_1, FUN = mean, width = 20, align = \"right\", fill = NA),\n         dsci_monthly_21 = rollapply(dsci_monthly_1, FUN = mean, width = 21, align = \"right\", fill = NA),\n         dsci_monthly_22 = rollapply(dsci_monthly_1, FUN = mean, width = 22, align = \"right\", fill = NA),\n         dsci_monthly_23 = rollapply(dsci_monthly_1, FUN = mean, width = 23, align = \"right\", fill = NA),\n         dsci_monthly_24 = rollapply(dsci_monthly_1, FUN = mean, width = 24, align = \"right\", fill = NA),) %&gt;%\n  ungroup()\n\n# plot time series\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_DSCI_1-6-12.jpg\", height = 8, width = 9, units = \"in\", res = 500)\ndsci_monthly %&gt;% ggplot() + \n  geom_line(aes(x = monthyear, y = dsci_monthly_1), color = \"grey50\") + \n  geom_line(aes(x = monthyear, y = dsci_monthly_6), color = mycols[1]) + \n  geom_line(aes(x = monthyear, y = dsci_monthly_12), color = mycols[2]) + \n  facet_wrap(~ basin) + \n  xlab(\"\") + ylab(\"Drought severity and coverage index (DSCI): 1-, 6-, and 12-month\") + theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/ExploreData.html#spi",
    "href": "Explore Data/ExploreData.html#spi",
    "title": "3  Explore Long-Term Data",
    "section": "3.6 SPI",
    "text": "3.6 SPI\nCalculate standardized precipiation index (SPI) for EcoDrought basins at multiple time scales (1-24 months). View time series data.\n\n\nCode\n# combine and calculate monthly totals\nclimdf_monthly &lt;- do.call(rbind, climlist) %&gt;% left_join(siteinfo_big) %&gt;% mutate(year = year(date), month = month(date)) %&gt;%\n  group_by(station_no, site_name, site_id, basin, region, lat, long, elev_ft, area_sqmi, designation, year, month) %&gt;%\n  summarize(precip_mmmonth = sum(precip_mmday)) %&gt;%\n  ungroup() %&gt;%\n  mutate(date = date(paste(year, month, \"01\", sep = \"-\")))\n\n# calculate SPI at various time scales\nspi_list &lt;- list()\nfor (i in 1:dim(siteinfo_big)[1]) {\n  d &lt;- climdf_monthly %&gt;% filter(site_name == siteinfo_big$site_name[i])\n  for (j in 1:24) {\n    myspi &lt;- spi(unlist(d %&gt;% select(precip_mmmonth)), scale = j)\n    myspi &lt;- myspi$fitted\n    myspi[is.infinite(myspi)] &lt;- NA\n    d[,paste(\"spi\", j, sep = \"_\")] &lt;- myspi\n  }\n  spi_list[[i]] &lt;- d\n  #print(i)\n}\n\n\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 1. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 2. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 3. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 4. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 5. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 6. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 7. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 8. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 9. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 10. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 11. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 12. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 13. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 14. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 15. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 16. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 17. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 18. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 19. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 20. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 21. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 22. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 23. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n[1] \"Calculating the Standardized Precipitation Evapotranspiration Index (SPEI) at a time scale of 24. Using kernel type 'rectangular', with 0 shift. Fitting the data to a Gamma distribution. Using the ub-pwm parameter fitting method. Checking for missing values (`NA`): all the data must be complete. Using the whole time series as reference period. Input type is vector. No time information provided, assuming a monthly time series.\"\n\n\nCode\nspi_monthly &lt;- do.call(rbind, spi_list)\n# view(spi_monthly)\n\n# spi_monthly %&gt;% filter(site_id == \"SRL\") %&gt;% ggplot() + geom_line(aes(x = date, y = spi_1))\n# spi_monthly %&gt;% filter(site_id == \"SRL\") %&gt;% ggplot() + geom_line(aes(x = date, y = spi_3))\n# spi_monthly %&gt;% filter(site_id == \"SRL\") %&gt;% ggplot() + geom_line(aes(x = date, y = spi_6))\n# spi_monthly %&gt;% filter(site_id == \"SRL\") %&gt;% ggplot() + geom_line(aes(x = date, y = spi_12))\n# spi_monthly %&gt;% filter(site_id == \"SRL\") %&gt;% ggplot() + geom_line(aes(x = date, y = spi_24))\n\n\n\n\nCode\n# jpeg(\"./Explore Data/Long Term Plots/ClimaticContext_SPI_1-6-12.jpg\", height = 8, width = 9, units = \"in\", res = 500)\nspi_monthly %&gt;% ggplot() + \n  geom_line(aes(x = date, y = spi_1), color = \"grey50\") + \n  geom_line(aes(x = date, y = spi_6), color = mycols[1]) + \n  geom_line(aes(x = date, y = spi_12), color = mycols[2]) +\n  geom_line(aes(x = date, y = spi_24), color = mycols[3]) +\n  facet_wrap(~ basin) + \n  xlab(\"\") + ylab(\"Standardized precipitation index (SPI): 1-, 6-, 12-, and 24-month\") + theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nWrite climate metrics data to file\n\n\nCode\ndroughtmetrics &lt;- spi_monthly %&gt;% select(basin, year, month, date, spi_1:spi_24) %&gt;% full_join(dsci_monthly %&gt;% rename(date = monthyear) %&gt;% select(basin, year, month, date, dsci_monthly_1:dsci_monthly_24))\n\nwrite_csv(droughtmetrics, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Explore Data/EcoD_Basin_MonthlyDroughtMetrics.csv\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Long-Term Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/TemporalResolution.html",
    "href": "Explore Data/TemporalResolution.html",
    "title": "4  Explore Sub-Daily Data",
    "section": "",
    "text": "4.1 Data\nPurpose: Explore data at sub-daily temporal resolutions (e.g., 15-min and 1-hour time steps) and compare outputs to daily data.\nGiven that streamflow can change so quickly in small, headwater streams, are we missing a key part of the story by using flow data summarized as daily means? Using daily mean flow reduces the range of values, particularly at the upper end (i.e., high flows), and so we may be overlooking the g~G relationship at very high flows. (Note limited analysis of 15-min data as Montana and Wyoming data is collected at the hourly timescale).",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Explore Sub-Daily Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/TemporalResolution.html#data",
    "href": "Explore Data/TemporalResolution.html#data",
    "title": "4  Explore Sub-Daily Data",
    "section": "",
    "text": "4.1.1 Load data\nBring in site info and sub-daily data\n\n\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# flow/yield (and temp) data \ndat_sub &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_Raw_ECODandNWIS.csv\") \n\ndat_little &lt;- dat_sub %&gt;% \n  filter(site_name %in% c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")) %&gt;% \n  select(site_name, datetime, flow, area_sqmi)\n\ndat_big &lt;- dat_sub %&gt;% filter(site_name == \"West Brook NWIS\") %&gt;% select(site_name, datetime, flow, area_sqmi)\n\n\nCheck time zones\n\n\nCode\nunique(tz(dat_little$datetime))\n\n\n[1] \"UTC\"\n\n\nCode\nunique(tz(dat_big$datetime))\n\n\n[1] \"UTC\"\n\n\nOrganize 15-min data\n\n\nCode\ndat_15min &lt;- bind_rows(dat_little, dat_big) %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\", \"West Brook NWIS\"))) %&gt;%\n  mutate(flow_cms = flow*0.02831683199881, area_sqkm = area_sqmi*2.58999) %&gt;%\n  mutate(yield = flow_cms * 900 * (1/(area_sqkm)) * (1/1000000) * 1000)\nhead(dat_15min)\n\n\n# A tibble: 6 × 7\n  site_name   datetime             flow area_sqmi flow_cms area_sqkm  yield\n  &lt;fct&gt;       &lt;dttm&gt;              &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 Avery Brook 2020-01-08 18:15:00  6.27      2.83    0.178      7.34 0.0218\n2 Avery Brook 2020-01-08 18:30:00  5.78      2.83    0.164      7.34 0.0201\n3 Avery Brook 2020-01-08 18:45:00  5.85      2.83    0.166      7.34 0.0203\n4 Avery Brook 2020-01-08 19:00:00  5.83      2.83    0.165      7.34 0.0203\n5 Avery Brook 2020-01-08 19:15:00  6         2.83    0.170      7.34 0.0208\n6 Avery Brook 2020-01-08 19:30:00  6.28      2.83    0.178      7.34 0.0218\n\n\nOrganize 1-hour data\n\n\nCode\ndat_1hr &lt;- bind_rows(dat_little, dat_big) %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\", \"West Brook NWIS\"))) %&gt;%\n  filter(!is.na(flow)) %&gt;% \n  mutate(datetime = floor_date(datetime, unit = \"hour\")) %&gt;%\n  group_by(site_name, datetime) %&gt;% \n  summarise(flow = mean(flow), area_sqmi = unique(area_sqmi)) %&gt;%\n  ungroup() %&gt;%\n  mutate(flow_cms = flow*0.02831683199881, area_sqkm = area_sqmi*2.58999) %&gt;%\n  mutate(yield = flow_cms * 3600 * (1/(area_sqkm)) * (1/1000000) * 1000)\nhead(dat_1hr)\n\n\n# A tibble: 6 × 7\n  site_name        datetime             flow area_sqmi flow_cms area_sqkm  yield\n  &lt;fct&gt;            &lt;dttm&gt;              &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 West Brook Lower 2019-12-31 18:00:00  9.37      8.51    0.265      22.0 0.0433\n2 West Brook Lower 2019-12-31 19:00:00  9.27      8.51    0.263      22.0 0.0429\n3 West Brook Lower 2019-12-31 20:00:00  9.24      8.51    0.262      22.0 0.0428\n4 West Brook Lower 2019-12-31 21:00:00  9.38      8.51    0.266      22.0 0.0434\n5 West Brook Lower 2019-12-31 22:00:00  9.39      8.51    0.266      22.0 0.0434\n6 West Brook Lower 2019-12-31 23:00:00  9.49      8.51    0.269      22.0 0.0439\n\n\nLoad daily data\n\n\nCode\ndat_1day &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\") %&gt;%\n  filter(site_name %in% c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\", \"West Brook NWIS\")) %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\", \"West Brook NWIS\")))\nhead(dat_1day)\n\n\n# A tibble: 6 × 31\n  station_no site_name   site_id basin      subbasin  region   lat  long elev_ft\n  &lt;chr&gt;      &lt;fct&gt;       &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 01171000   Avery Brook AB      West Brook West Bro… Mass    42.4 -72.7    699.\n2 01171000   Avery Brook AB      West Brook West Bro… Mass    42.4 -72.7    699.\n3 01171000   Avery Brook AB      West Brook West Bro… Mass    42.4 -72.7    699.\n4 01171000   Avery Brook AB      West Brook West Bro… Mass    42.4 -72.7    699.\n5 01171000   Avery Brook AB      West Brook West Bro… Mass    42.4 -72.7    699.\n6 01171000   Avery Brook AB      West Brook West Bro… Mass    42.4 -72.7    699.\n# ℹ 22 more variables: area_sqmi &lt;dbl&gt;, designation &lt;chr&gt;, date &lt;date&gt;,\n#   DischargeReliability &lt;dbl&gt;, TempReliability &lt;dbl&gt;, flow_mean &lt;dbl&gt;,\n#   flow_min &lt;dbl&gt;, flow_max &lt;dbl&gt;, tempc_mean &lt;dbl&gt;, tempc_min &lt;dbl&gt;,\n#   tempc_max &lt;dbl&gt;, flow_mean_filled &lt;dbl&gt;, flow_mean_cms &lt;dbl&gt;,\n#   flow_mean_filled_cms &lt;dbl&gt;, area_sqkm &lt;dbl&gt;, Yield_mm &lt;dbl&gt;,\n#   Yield_filled_mm &lt;dbl&gt;, flow_mean_7 &lt;dbl&gt;, flow_mean_filled_7 &lt;dbl&gt;,\n#   tempc_mean_7 &lt;dbl&gt;, Yield_mm_7 &lt;dbl&gt;, Yield_filled_mm_7 &lt;dbl&gt;\n\n\n\n\n4.1.2 View 15-min data\nPlot 15 min time series data\n\n\nCode\ndat_15min %&gt;% select(datetime, site_name, yield) %&gt;% spread(key = site_name, value = yield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(colors = c(hcl.colors(9, \"Zissou 1\"), \"black\")) %&gt;% dyHighlight() \n\n\n\n\n\n\n\n\n4.1.3 View 1-hour data\nPlot 1-hour time series data\n\n\nCode\ndat_1hr %&gt;% select(datetime, site_name, yield) %&gt;% spread(key = site_name, value = yield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(colors = c(hcl.colors(9, \"Zissou 1\"), \"black\")) %&gt;% dyHighlight() \n\n\n\n\n\n\n\n\n4.1.4 View 1-day data\nPlot 1-day/daily time series data\n\n\nCode\ndat_1day %&gt;% select(date, site_name, Yield_filled_mm) %&gt;% spread(key = site_name, value = Yield_filled_mm) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(colors = c(hcl.colors(9, \"Zissou 1\"), \"black\")) %&gt;% dyHighlight()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Explore Sub-Daily Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/TemporalResolution.html#hourly-data",
    "href": "Explore Data/TemporalResolution.html#hourly-data",
    "title": "4  Explore Sub-Daily Data",
    "section": "4.2 Hourly data",
    "text": "4.2 Hourly data\nset baseflow separation (for the Lyne-Hollick one-parameter digital recursive filter) and event delineation paramters (as in Wasko and Guo, 2022)\n\nalp: alpha filter parameter, higher values “lower” the estimated baseflow (thus making it difficult to delineate events)\nnumpass: number of passes. Ladson et al. (2013) recommend 3 passes for daily data (default in baseflowB() function) and 9 passes for hourly data\nthresh: baseflow index threshold for event delineation, higher threshold values make it “easier” to delineate events\n\n\n4.2.1 Event pairing\nConduct event pairing using hydroEvents package to understand lag time between peak flows at big and little g’s\n\n4.2.1.1 Conduct event pairing\n\n\nCode\n# baseflow separation and event delineation parameters\nalp &lt;- 0.925\nnumpass &lt;- 9\nthresh &lt;- 0.5\n\n# sites\nsites &lt;- unique(dat_1hr$site_name)[1:9]\n\n# empty list to store output\noutlist &lt;- list()\n\nfor (j in 1:length(sites)) {\n  # grab big and little g data and combine into a single tibble\n  littleg &lt;- dat_1hr %&gt;% filter(site_name == sites[j])\n  bigg &lt;- dat_1hr %&gt;% filter(site_name == \"West Brook NWIS\")\n  mytib &lt;- bigg %&gt;% select(datetime, yield) %&gt;% rename(yield_big = yield) %&gt;% left_join(littleg %&gt;% select(datetime, yield) %&gt;% rename(yield_little = yield))\n  \n  # baseflow separation\n  mytib_bf &lt;- mytib %&gt;% \n  filter(!is.na(yield_big), !is.na(yield_little)) %&gt;% \n  mutate(bf_big = baseflowB(yield_big, alpha = alp, passes = numpass)$bf, \n         bfi_big = baseflowB(yield_big, alpha = alp, passes = numpass)$bfi,\n         bf_little = baseflowB(yield_little, alpha = alp, passes = numpass)$bf, \n         bfi_little = baseflowB(yield_little, alpha = alp, passes = numpass)$bfi)\n  \n  # delineate events\n  events_little &lt;- eventBaseflow(mytib_bf$yield_little, BFI_Th = thresh, bfi = mytib_bf$bfi_little)\n  events_big &lt;- eventBaseflow(mytib_bf$yield_big, BFI_Th = thresh, bfi = mytib_bf$bfi_big)\n  \n  # event matching\n  mypairs &lt;- pairEvents(events_little, events_big, lag = 5, type = 1)\n  mypairs_com &lt;- mypairs[complete.cases(mypairs),]\n  \n  # get matched event info\n  matchpeaktib &lt;- tibble(index_little = rep(NA, times = dim(mypairs_com)[1]), \n                         index_big = rep(NA, times = dim(mypairs_com)[1]),\n                         datetime_little = rep(NA, times = dim(mypairs_com)[1]), \n                         datetime_big = rep(NA, times = dim(mypairs_com)[1]),\n                         yield_little = rep(NA, times = dim(mypairs_com)[1]), \n                         yield_big = rep(NA, times = dim(mypairs_com)[1]))\n  for (i in 1:dim(mypairs_com)[1]) {\n    matchpeaktib$index_little[i] &lt;- events_little$which.max[events_little$srt == mypairs_com$srt[i]]\n    matchpeaktib$index_big[i] &lt;- events_big$which.max[events_big$srt == mypairs_com$matched.srt[i]]\n    matchpeaktib$datetime_little[i] &lt;- mytib_bf$datetime[events_little$which.max[events_little$srt == mypairs_com$srt[i]]]\n    matchpeaktib$datetime_big[i] &lt;- mytib_bf$datetime[events_big$which.max[events_big$srt == mypairs_com$matched.srt[i]]]\n    matchpeaktib$yield_little[i] &lt;- events_little$max[events_little$srt == mypairs_com$srt[i]]\n    matchpeaktib$yield_big[i] &lt;- events_big$max[events_big$srt == mypairs_com$matched.srt[i]]\n    }\n  matchpeaktib &lt;- matchpeaktib %&gt;% mutate(datetime_little = as_datetime(datetime_little),\n                                          datetime_big = as_datetime(datetime_big),\n                                          timediff_hrs = as.numeric(difftime(datetime_big, datetime_little), units = \"hours\"),\n                                          site_name = sites[j])\n  \n  # store output in list\n  outlist[[j]] &lt;- matchpeaktib\n}\nmatchpeaktib &lt;- do.call(rbind, outlist)\n(matchpeaktib)\n\n\n# A tibble: 1,482 × 8\n   index_little index_big datetime_little     datetime_big        yield_little\n          &lt;int&gt;     &lt;int&gt; &lt;dttm&gt;              &lt;dttm&gt;                     &lt;dbl&gt;\n 1          176       177 2020-02-07 22:00:00 2020-02-07 23:00:00        0.149\n 2          505       508 2020-02-21 15:00:00 2020-02-21 18:00:00        0.111\n 3          648       650 2020-02-27 14:00:00 2020-02-27 16:00:00        0.432\n 4         1012      1013 2020-03-13 18:00:00 2020-03-13 19:00:00        0.190\n 5         1153      1154 2020-03-19 15:00:00 2020-03-19 16:00:00        0.191\n 6         1406      1407 2020-03-30 04:00:00 2020-03-30 05:00:00        0.327\n 7         1664      1665 2020-04-09 22:00:00 2020-04-09 23:00:00        0.204\n 8         1762      1764 2020-04-14 00:00:00 2020-04-14 02:00:00        0.419\n 9         2166      2168 2020-04-30 20:00:00 2020-04-30 22:00:00        0.214\n10         2194      2194 2020-05-02 00:00:00 2020-05-02 00:00:00        0.810\n# ℹ 1,472 more rows\n# ℹ 3 more variables: yield_big &lt;dbl&gt;, timediff_hrs &lt;dbl&gt;, site_name &lt;fct&gt;\n\n\n\n\n4.2.1.2 Plot output\n\nDistribution of lags\nConstrain lag times to realistic values (&gt;=0 and &lt;= 24) as event pairing is not perfect, and view histograms by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= -5 & timediff_hrs &lt;= 10) %&gt;% ggplot() + geom_histogram(aes(x = timediff_hrs)) + facet_wrap(~site_name)\n\n\n\n\n\n\n\n\n\nView distributions summarized as boxplots. Sites are ordered from closest to Big G (bottom) to furthest (top). Interestingly, there is not a strong pattern of longer lag times for further sites.\n\n\nCode\n# matchpeaktib %&gt;% filter(timediff_hrs &gt;= -10 & timediff_hrs &lt;= 20) %&gt;% ggplot() + geom_boxplot(aes(x = site_name, y = timediff_hrs)) + coord_flip()\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= -5 & timediff_hrs &lt;= 10) %&gt;% mutate(bigevcd = as.numeric(datetime_big)) %&gt;% group_by(bigevcd, site_name) %&gt;% summarize(timediff_hrs = min(timediff_hrs)) %&gt;% ggplot() + geom_boxplot(aes(x = site_name, y = timediff_hrs)) + coord_flip()\n\n\n\n\n\n\n\n\n\nConnect specific events across sites.\n\nIs there consistency in lag time across sites? Generally, yes\nis there a pattern of longer lag times with increasing distance upstream? No\n\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= -5 & timediff_hrs &lt;= 10) %&gt;% mutate(bigevcd = as.factor(as.numeric(datetime_big))) %&gt;% group_by(bigevcd, site_name) %&gt;% summarize(timediff_hrs = min(timediff_hrs)) %&gt;% ggplot(aes(x = site_name, y = jitter(timediff_hrs), group = bigevcd, color = bigevcd)) + geom_line() + coord_flip() + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nLag by yield\nDoes lag time depend on the magnitude of yield at big G? Under high flows when water is moving more quickly, we might expect the lag to be shorter (negative relationship).\nView global relationship\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= -5 & timediff_hrs &lt;= 10) %&gt;% ggplot(aes(x = yield_big, y = jitter(timediff_hrs))) + geom_point() + geom_smooth()\n\n\n\n\n\n\n\n\n\nView by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= -5 & timediff_hrs &lt;= 10) %&gt;% ggplot(aes(x = yield_big, y = jitter(timediff_hrs))) + geom_point() + geom_smooth() + facet_wrap(~ site_name)\n\n\n\n\n\n\n\n\n\nThere appears to be some evidence for shorter lag times with increasing flow, but this relationship is only evident for very low flows. What is more apparent is the overall attenuation in variability in lag time as flows increase: at very low flows, lags are highly variable, but less variable (and intermediate in magnitude) under high flows.\n\n\nLag by time\nDoes lag time change over time? Perhaps lag time is seasonal and changes with antecedant conditions. Note that this is not the best way to get at the question of importance of antecedant conditions.\nView global relationship\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= -5 & timediff_hrs &lt;= 10) %&gt;% mutate(doy = yday(datetime_little)) %&gt;% ggplot(aes(x = doy, y = jitter(timediff_hrs))) + geom_point() + geom_smooth()\n\n\n\n\n\n\n\n\n\nView by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_hrs &gt;= -5 & timediff_hrs &lt;= 10) %&gt;% mutate(doy = yday(datetime_little)) %&gt;% ggplot(aes(x = doy, y = jitter(timediff_hrs))) + geom_point() + geom_smooth() + facet_wrap(~ site_name)\n\n\n\n\n\n\n\n\n\nThere does not appear to be any consistent pattern (within or among sites) in how lag times change with time of year\n\n\n\n\n4.2.2 Gg pseudo-analysis\n\n4.2.2.1 Prepare data\nSpecify big and little g data\n\n\nCode\ndat_big &lt;- dat_1hr %&gt;% filter(site_name %in% c(\"West Brook NWIS\"))\ndat_little &lt;- dat_1hr %&gt;% filter(site_name %in% c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\"))\n\n\nConduct baseflow separation and event delineation on big g data\n\n\nCode\n# baseflow separation\ndat_big &lt;- dat_big %&gt;% \n  filter(!is.na(yield)) %&gt;% \n  mutate(bf = baseflowB(yield, alpha = 0.925, passes = 9)$bf, \n         bfi = baseflowB(yield, alpha = 0.925, passes = 9)$bfi)\n\n# event delineation\nevents &lt;- eventBaseflow(dat_big$yield, BFI_Th = 0.75, bfi = dat_big$bfi)\nevents &lt;- events %&gt;% mutate(len = end - srt + 1)\n\n# define positions of non-events\nsrt &lt;- c(1)\nend &lt;- c(events$srt[1]-1)\nfor (i in 2:(dim(events)[1])) {\n  srt[i] &lt;- events$end[i-1]+1\n  end[i] &lt;- events$srt[i]-1\n}\nnonevents &lt;- data.frame(tibble(srt, end) %&gt;% mutate(len = end - srt) %&gt;% filter(len &gt;= 0) %&gt;% select(-len) %&gt;% add_row(srt = events$end[dim(events)[1]]+1, end = dim(dat_big)[1]))\n\n# create vectors of binary event/non-event and event IDs\nisevent_vec &lt;- rep(2, times = dim(dat_big)[1])\neventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(events)[1]) { \n  isevent_vec[c(events[i,1]:events[i,2])] &lt;- 1 \n  eventid_vec[c(events[i,1]:events[i,2])] &lt;- i\n}\n\n# create vector of non-event IDs\nnoneventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n\n# create vector of \"agnostic events\": combined hydro events and non-events\nagnevents &lt;- rbind(events %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\nagneventid_vec &lt;- c()\nfor (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n# add event/non-event vectors to Big G data\ndat_big &lt;- dat_big %&gt;% \n  mutate(isevent = isevent_vec, \n         eventid = eventid_vec,\n         noneventid = noneventid_vec,\n         agneventid = agneventid_vec,\n         big_event_yield = ifelse(isevent_vec == 1, yield, NA),\n         big_nonevent_yield = ifelse(isevent_vec == 2, yield, NA),\n         big_event_quick = big_event_yield - bf) %&gt;%\n  rename(big_yield = yield, big_bf = bf, big_bfi = bfi)\ndat_big\n\n\n# A tibble: 42,233 × 16\n   site_name    datetime             flow area_sqmi flow_cms area_sqkm big_yield\n   &lt;fct&gt;        &lt;dttm&gt;              &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 West Brook … 2020-01-31 15:00:00  23.2      11.4    0.657      29.5    0.0801\n 2 West Brook … 2020-01-31 16:00:00  26.8      11.4    0.759      29.5    0.0926\n 3 West Brook … 2020-01-31 17:00:00  23.3      11.4    0.660      29.5    0.0805\n 4 West Brook … 2020-01-31 18:00:00  18.9      11.4    0.534      29.5    0.0652\n 5 West Brook … 2020-01-31 19:00:00  18.7      11.4    0.530      29.5    0.0647\n 6 West Brook … 2020-01-31 20:00:00  19.0      11.4    0.539      29.5    0.0658\n 7 West Brook … 2020-01-31 21:00:00  18.9      11.4    0.534      29.5    0.0652\n 8 West Brook … 2020-01-31 22:00:00  19.0      11.4    0.539      29.5    0.0658\n 9 West Brook … 2020-01-31 23:00:00  19.4      11.4    0.549      29.5    0.0669\n10 West Brook … 2020-02-01 00:00:00  19.0      11.4    0.539      29.5    0.0658\n# ℹ 42,223 more rows\n# ℹ 9 more variables: big_bf &lt;dbl&gt;, big_bfi &lt;dbl&gt;, isevent &lt;dbl&gt;,\n#   eventid &lt;int&gt;, noneventid &lt;int&gt;, agneventid &lt;int&gt;, big_event_yield &lt;dbl&gt;,\n#   big_nonevent_yield &lt;dbl&gt;, big_event_quick &lt;dbl&gt;\n\n\nCode\n# plot\ndat_big %&gt;% select(datetime, big_yield, big_bf, big_event_yield, big_nonevent_yield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Hourly yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\n\n\nA few things to note:\n\nMany delineated events are &lt;24 hours in length\nMuch of the natural diel variation in streamflow (“stream breathing” due to diel cycle of ET) ends up being delineated as individual events\n\nWhen viewed at this time-scale, there also seems to be variation in terms of whether or not the “stream breathing” exists, which could be due to changes in how the data were processed and subsequently smoothed (or not)\n\nWMA interpolataion becomes an issue at the sub-daily time scale. I.e., the time scale of the data changes during observed (15-min) and interpolated (4-hour) periods\n\nCombine big and little g data\n\n\nCode\ndat_wb2 &lt;- dat_little %&gt;% \n  filter(datetime &gt;= min(dat_big$datetime) & datetime &lt;= max(dat_big$datetime)) %&gt;%\n  left_join(dat_big %&gt;% select(datetime, big_yield, big_bf, big_bfi, agneventid, isevent)) %&gt;%\n  group_by(site_name, agneventid) %&gt;% \n  summarise(eventlen = n(),\n            mindate = min(datetime),\n            isevent = unique(isevent), \n            yield_little_cumul = sum(yield+0.01),\n            yield_big_cumul = sum(big_yield+0.01),\n            yield_little_cumul_log = log(yield_little_cumul),\n            yield_big_cumul_log = log(yield_big_cumul),\n            yield_little_mean_log = mean(log(yield+0.01)),\n            yield_big_mean_log = mean(log(big_yield+0.01))) %&gt;%\n  ungroup() %&gt;%\n  filter(!is.na(isevent)) %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")),\n         site_name_cd = as.numeric(site_name))\ndat_wb2\n\n\n# A tibble: 8,351 × 12\n   site_name  agneventid eventlen mindate             isevent yield_little_cumul\n   &lt;fct&gt;           &lt;int&gt;    &lt;int&gt; &lt;dttm&gt;                &lt;dbl&gt;              &lt;dbl&gt;\n 1 West Broo…          1      168 2020-01-31 15:00:00       2            12.4   \n 2 West Broo…          2       29 2020-02-07 15:00:00       1             3.33  \n 3 West Broo…          3       19 2020-02-08 20:00:00       2             1.50  \n 4 West Broo…          4        6 2020-02-09 15:00:00       1             0.408 \n 5 West Broo…          5       90 2020-02-09 21:00:00       2             6.92  \n 6 West Broo…          6       25 2020-02-13 15:00:00       1             2.74  \n 7 West Broo…          7      104 2020-02-14 16:00:00       2             9.13  \n 8 West Broo…          8       36 2020-02-19 00:00:00       1             3.18  \n 9 West Broo…          9        1 2020-02-20 12:00:00       2             0.0642\n10 West Broo…         10        5 2020-02-20 13:00:00       1             0.305 \n# ℹ 8,341 more rows\n# ℹ 6 more variables: yield_big_cumul &lt;dbl&gt;, yield_little_cumul_log &lt;dbl&gt;,\n#   yield_big_cumul_log &lt;dbl&gt;, yield_little_mean_log &lt;dbl&gt;,\n#   yield_big_mean_log &lt;dbl&gt;, site_name_cd &lt;dbl&gt;\n\n\n\n\n4.2.2.2 Event-level distribution\nFind ~long events/non-events\n\n\nCode\nagntib1 &lt;- dat_big %&gt;% group_by(agneventid) %&gt;% summarize(eventlen = n(), isevent = unique(isevent), mindate = min(date(datetime)), maxdate = max(date(datetime))) %&gt;% filter(isevent == 1) %&gt;% arrange(desc(eventlen))\nagntib2 &lt;- dat_big %&gt;% group_by(agneventid) %&gt;% summarize(eventlen = n(), isevent = unique(isevent), mindate = min(date(datetime)), maxdate = max(date(datetime))) %&gt;% filter(isevent == 2) %&gt;% arrange(desc(eventlen))\nagntib1\n\n\n# A tibble: 560 × 5\n   agneventid eventlen isevent mindate    maxdate   \n        &lt;int&gt;    &lt;int&gt;   &lt;dbl&gt; &lt;date&gt;     &lt;date&gt;    \n 1        888      169       1 2024-06-19 2024-06-26\n 2        159      138       1 2020-09-29 2020-10-05\n 3        917      127       1 2024-08-09 2024-08-15\n 4        330      126       1 2021-07-17 2021-07-23\n 5        308      122       1 2021-05-29 2021-06-03\n 6        961      122       1 2024-12-09 2024-12-14\n 7        348      121       1 2021-08-22 2021-08-27\n 8        919      117       1 2024-08-18 2024-08-23\n 9        322      108       1 2021-06-30 2021-07-05\n10        729      108       1 2023-07-02 2023-07-06\n# ℹ 550 more rows\n\n\nCode\nagntib2\n\n\n# A tibble: 408 × 5\n   agneventid eventlen isevent mindate    maxdate   \n        &lt;int&gt;    &lt;int&gt;   &lt;dbl&gt; &lt;date&gt;     &lt;date&gt;    \n 1        380      415       2 2021-11-15 2021-12-03\n 2        924      393       2 2024-09-09 2024-09-26\n 3        920      366       2 2024-08-23 2024-09-07\n 4        682      360       2 2023-04-02 2023-04-17\n 5        152      355       2 2020-09-13 2020-09-28\n 6        594      353       2 2022-10-27 2022-11-10\n 7        826      345       2 2024-01-30 2024-02-13\n 8        794      342       2 2023-11-08 2023-11-22\n 9        278      327       2 2021-04-02 2021-04-15\n10        645      290       2 2023-02-11 2023-02-23\n# ℹ 398 more rows\n\n\nPlot exceedance curves for selected events (top row) and baseflow periods (bottom row)\n\n\nCode\nggarrange(p1, p2, nrow = 2)\n\n\n\n\n\n\n\n\n\n\n\n4.2.2.3 Plot output\ngG relationship with data summarized as cumulative yield per event/non-event:\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~isevent)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods.\n\n\n\n\nFacet by site\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~site_name) +\n  theme(legend.position = \"none\")\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods, faceted by site.\n\n\n\n\nGg relationship with data summarized as mean yield per event/non-event\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~isevent)\n\n\n\n\n\nEffect of (log) mean yield at Big G on (log) mean yield at little g during baseflow and event periods.\n\n\n\n\nFacet by site\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~site_name) +\n  theme(legend.position = \"none\")\n\n\n\n\n\nEffect of (log) mean yield at Big G on (log) mean yield at little g during baseflow and event periods, faceted by site.",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Explore Sub-Daily Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/TemporalResolution.html#daily-data",
    "href": "Explore Data/TemporalResolution.html#daily-data",
    "title": "4  Explore Sub-Daily Data",
    "section": "4.3 Daily data",
    "text": "4.3 Daily data\n\n4.3.1 Event pairing\n\n4.3.1.1 Conduct event pairing\n\n\nCode\n# baseflow separation and event delineation parameters\nalp &lt;- 0.925\nnumpass &lt;- 3\nthresh &lt;- 0.5\n\n# sites\nsites &lt;- unique(dat_1day$site_name)[1:9]\n\n# empty list to store output\noutlist &lt;- list()\n\nfor (j in 1:length(sites)) {\n  # grab big and little g data and combine into a single tibble\n  littleg &lt;- dat_1day %&gt;% filter(site_name == sites[j])\n  bigg &lt;- dat_1day %&gt;% filter(site_name == \"West Brook NWIS\")\n  mytib &lt;- bigg %&gt;% select(date, Yield_filled_mm) %&gt;% rename(yield_big = Yield_filled_mm) %&gt;% left_join(littleg %&gt;% select(date, Yield_filled_mm) %&gt;% rename(yield_little = Yield_filled_mm))\n  \n  # baseflow separation\n  mytib_bf &lt;- mytib %&gt;% \n  filter(!is.na(yield_big), !is.na(yield_little)) %&gt;% \n  mutate(bf_big = baseflowB(yield_big, alpha = alp, passes = numpass)$bf, \n         bfi_big = baseflowB(yield_big, alpha = alp, passes = numpass)$bfi,\n         bf_little = baseflowB(yield_little, alpha = alp, passes = numpass)$bf, \n         bfi_little = baseflowB(yield_little, alpha = alp, passes = numpass)$bfi)\n  \n  # delineate events\n  events_little &lt;- eventBaseflow(mytib_bf$yield_little, BFI_Th = thresh, bfi = mytib_bf$bfi_little)\n  events_big &lt;- eventBaseflow(mytib_bf$yield_big, BFI_Th = thresh, bfi = mytib_bf$bfi_big)\n  \n  # event matching\n  mypairs &lt;- pairEvents(events_little, events_big, lag = 5, type = 1)\n  mypairs_com &lt;- mypairs[complete.cases(mypairs),]\n  \n  # get matched event info\n  matchpeaktib &lt;- tibble(datetime_little = rep(NA, times = dim(mypairs_com)[1]), datetime_big = rep(NA, times = dim(mypairs_com)[1]),\n                         yield_little = rep(NA, times = dim(mypairs_com)[1]), yield_big = rep(NA, times = dim(mypairs_com)[1]))\n  for (i in 1:dim(mypairs_com)[1]) {\n    matchpeaktib$datetime_little[i] &lt;- mytib_bf$date[events_little$which.max[events_little$srt == mypairs_com$srt[i]]]\n    matchpeaktib$datetime_big[i] &lt;- mytib_bf$date[events_big$which.max[events_big$srt == mypairs_com$matched.srt[i]]]\n    matchpeaktib$yield_little[i] &lt;- events_little$max[events_little$srt == mypairs_com$srt[i]]\n    matchpeaktib$yield_big[i] &lt;- events_big$max[events_big$srt == mypairs_com$matched.srt[i]]\n    }\n  matchpeaktib &lt;- matchpeaktib %&gt;% mutate(datetime_little = as_date(datetime_little),\n                                          datetime_big = as_date(datetime_big),\n                                          timediff_dys = as.numeric(difftime(datetime_big, datetime_little), units = \"days\"),\n                                          site_name = sites[j])\n  \n  # store output in list\n  outlist[[j]] &lt;- matchpeaktib\n}\nmatchpeaktib &lt;- do.call(rbind, outlist)\n(matchpeaktib)\n\n\n# A tibble: 787 × 6\n   datetime_little datetime_big yield_little yield_big timediff_dys site_name  \n   &lt;date&gt;          &lt;date&gt;              &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt; &lt;fct&gt;      \n 1 2020-02-27      2020-02-27          9.61      5.56             0 Avery Brook\n 2 2020-03-30      2020-03-30          8.65      6.56             0 Avery Brook\n 3 2020-04-14      2020-04-14          8.18      7.40             0 Avery Brook\n 4 2020-05-01      2020-05-02         16.9      13.5              1 Avery Brook\n 5 2020-05-16      2020-05-16          2.84      1.99             0 Avery Brook\n 6 2020-06-12      2020-06-12          0.872     0.427            0 Avery Brook\n 7 2020-07-04      2020-07-04          1.10      0.576            0 Avery Brook\n 8 2020-07-10      2020-07-10          4.76      0.905            0 Avery Brook\n 9 2020-07-23      2020-07-23          0.676     1.17             0 Avery Brook\n10 2020-08-05      2020-08-05          0.801     0.243            0 Avery Brook\n# ℹ 777 more rows\n\n\n\n\n4.3.1.2 Plot output\n\nDistribution of lags\nConstrain lag times to realistic values (&gt;=0 and &lt;= 24) as event pairing is not perfect, and view histograms by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1) %&gt;% ggplot() + geom_histogram(aes(x = timediff_dys)) + facet_wrap(~site_name)\n\n\n\n\n\n\n\n\n\nView distributions summarized as means. Sites are ordered from closest to Big G (bottom) to furthest (top). There is general pattern of longer lag times for further sites.\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1) %&gt;% group_by(site_name) %&gt;% summarize(diffmean = mean(timediff_dys), diffsd = sd(timediff_dys)) %&gt;% ggplot() + \n  geom_point(aes(x = site_name, y = diffmean)) + \n  #geom_errorbar(aes(x = site_name, ymin = diffmean - diffsd, ymax = diffmean + diffsd)) + \n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\nLag by yield\nDoes lag time depend on the magnitude of yield at big G? Under high flows when water is moving more quickly, we might expect the lag to be shorter (negative relationship).\nView global relationship\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1) %&gt;% ggplot(aes(x = yield_big, y = jitter(timediff_dys))) + geom_point() + geom_smooth()\n\n\n\n\n\n\n\n\n\nView by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1)  %&gt;% ggplot(aes(x = yield_big, y = jitter(timediff_dys))) + geom_point() + geom_smooth() + facet_wrap(~ site_name)\n\n\n\n\n\n\n\n\n\nAs with the hourly data, there appears to be some evidence for shorter lag times with increasing flow, but this relationship is only evident for very low flows. Although we note that 1-day lags are very rare (16% of all observations)\n\n\nLag by time\nDoes lag time change over time? Perhaps lag time is seasonal and changes with antecedant conditions. Note that this is not the best way to get at the question of importance of antecedant conditions.\nView global relationship\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1) %&gt;% mutate(doy = yday(datetime_little)) %&gt;% ggplot(aes(x = doy, y = jitter(timediff_dys))) + geom_point() + geom_smooth()\n\n\n\n\n\n\n\n\n\nView by site\n\n\nCode\nmatchpeaktib %&gt;% filter(timediff_dys &gt;= 0 & timediff_dys &lt;= 1) %&gt;% mutate(doy = yday(datetime_little)) %&gt;% ggplot(aes(x = doy, y = (timediff_dys))) + geom_point() + geom_smooth() + facet_wrap(~ site_name)\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.3.2 Gg pseudo-analysis\n\n4.3.2.1 Prepare data\nSpecify big and little g data\n\n\nCode\ndat_big &lt;- dat_1day %&gt;% filter(site_name %in% c(\"West Brook NWIS\")) %&gt;% rename(yield = Yield_filled_mm)\ndat_little &lt;- dat_1day %&gt;% filter(site_name %in% c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")) %&gt;% rename(yield = Yield_filled_mm)\n\n\nConduct baseflow separation and event delineation on big g data\n\n\nCode\n# baseflow separation\ndat_big &lt;- dat_big %&gt;% \n  filter(!is.na(yield)) %&gt;% \n  mutate(bf = baseflowB(yield, alpha = 0.925, passes = 3)$bf, \n         bfi = baseflowB(yield, alpha = 0.925, passes = 3)$bfi)\n\n# event delineation\nevents &lt;- eventBaseflow(dat_big$yield, BFI_Th = 0.75, bfi = dat_big$bfi)\nevents &lt;- events %&gt;% mutate(len = end - srt + 1)\n\n# define positions of non-events\nsrt &lt;- c(1)\nend &lt;- c(events$srt[1]-1)\nfor (i in 2:(dim(events)[1])) {\n  srt[i] &lt;- events$end[i-1]+1\n  end[i] &lt;- events$srt[i]-1\n}\nnonevents &lt;- data.frame(tibble(srt, end) %&gt;% mutate(len = end - srt) %&gt;% filter(len &gt;= 0) %&gt;% select(-len) %&gt;% add_row(srt = events$end[dim(events)[1]]+1, end = dim(dat_big)[1]))\n\n# create vectors of binary event/non-event and event IDs\nisevent_vec &lt;- rep(2, times = dim(dat_big)[1])\neventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(events)[1]) { \n  isevent_vec[c(events[i,1]:events[i,2])] &lt;- 1 \n  eventid_vec[c(events[i,1]:events[i,2])] &lt;- i\n}\n\n# create vector of non-event IDs\nnoneventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n\n# create vector of \"agnostic events\": combined hydro events and non-events\nagnevents &lt;- rbind(events %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\nagneventid_vec &lt;- c()\nfor (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n# add event/non-event vectors to Big G data\ndat_big &lt;- dat_big %&gt;% \n  mutate(isevent = isevent_vec, \n         eventid = eventid_vec,\n         noneventid = noneventid_vec,\n         agneventid = agneventid_vec,\n         big_event_yield = ifelse(isevent_vec == 1, yield, NA),\n         big_nonevent_yield = ifelse(isevent_vec == 2, yield, NA),\n         big_event_quick = big_event_yield - bf) %&gt;%\n  rename(big_yield = yield, big_bf = bf, big_bfi = bfi)\ndat_big\n\n\n# A tibble: 1,411 × 40\n   station_no site_name       site_id basin  subbasin region   lat  long elev_ft\n   &lt;chr&gt;      &lt;fct&gt;           &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 2 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 3 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 4 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 5 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 6 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 7 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 8 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n 9 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n10 01171100   West Brook NWIS WBR     West … West Br… Mass    42.4 -72.6    154.\n# ℹ 1,401 more rows\n# ℹ 31 more variables: area_sqmi &lt;dbl&gt;, designation &lt;chr&gt;, date &lt;date&gt;,\n#   DischargeReliability &lt;dbl&gt;, TempReliability &lt;dbl&gt;, flow_mean &lt;dbl&gt;,\n#   flow_min &lt;dbl&gt;, flow_max &lt;dbl&gt;, tempc_mean &lt;dbl&gt;, tempc_min &lt;dbl&gt;,\n#   tempc_max &lt;dbl&gt;, flow_mean_filled &lt;dbl&gt;, flow_mean_cms &lt;dbl&gt;,\n#   flow_mean_filled_cms &lt;dbl&gt;, area_sqkm &lt;dbl&gt;, Yield_mm &lt;dbl&gt;,\n#   big_yield &lt;dbl&gt;, flow_mean_7 &lt;dbl&gt;, flow_mean_filled_7 &lt;dbl&gt;, …\n\n\nCode\n# plot\ndat_big %&gt;% select(date, big_yield, big_bf, big_event_yield, big_nonevent_yield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Hourly yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\n\n\nCombine big and little g data\n\n\nCode\ndat_wb2 &lt;- dat_little %&gt;% \n  filter(date &gt;= min(dat_big$date) & date &lt;= max(dat_big$date)) %&gt;%\n  left_join(dat_big %&gt;% select(date, big_yield, big_bf, big_bfi, agneventid, isevent)) %&gt;%\n  group_by(site_name, agneventid) %&gt;% \n  summarise(eventlen = n(),\n            mindate = min(date),\n            isevent = unique(isevent), \n            yield_little_cumul = sum(yield+0.01),\n            yield_big_cumul = sum(big_yield+0.01),\n            yield_little_cumul_log = log(yield_little_cumul),\n            yield_big_cumul_log = log(yield_big_cumul),\n            yield_little_mean_log = mean(log(yield+0.01)),\n            yield_big_mean_log = mean(log(big_yield+0.01))) %&gt;%\n  ungroup() %&gt;%\n  filter(!is.na(isevent)) %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")),\n         site_name_cd = as.numeric(site_name))\ndat_wb2\n\n\n# A tibble: 1,691 × 12\n   site_name        agneventid eventlen mindate    isevent yield_little_cumul\n   &lt;fct&gt;                 &lt;int&gt;    &lt;int&gt; &lt;date&gt;       &lt;dbl&gt;              &lt;dbl&gt;\n 1 West Brook Lower          1        6 2020-01-31       2               9.18\n 2 West Brook Lower          2        4 2020-02-06       1               7.51\n 3 West Brook Lower          3        3 2020-02-10       2               4.74\n 4 West Brook Lower          4        3 2020-02-13       1               6.97\n 5 West Brook Lower          5       10 2020-02-16       2              15.3 \n 6 West Brook Lower          6        6 2020-02-26       1              18.5 \n 7 West Brook Lower          7        4 2020-03-03       1              10.6 \n 8 West Brook Lower          8        5 2020-03-07       2              10.4 \n 9 West Brook Lower          9        4 2020-03-12       1              11.3 \n10 West Brook Lower         10        2 2020-03-16       2               4.68\n# ℹ 1,681 more rows\n# ℹ 6 more variables: yield_big_cumul &lt;dbl&gt;, yield_little_cumul_log &lt;dbl&gt;,\n#   yield_big_cumul_log &lt;dbl&gt;, yield_little_mean_log &lt;dbl&gt;,\n#   yield_big_mean_log &lt;dbl&gt;, site_name_cd &lt;dbl&gt;\n\n\n\n\n4.3.2.2 Plot output\ngG relationship with data summarized as cumulative yield per event/non-event:\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~isevent)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods.\n\n\n\n\nFacet by site\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~site_name) +\n  theme(legend.position = \"none\")\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods, faceted by site.\n\n\n\n\nGg relationship with data summarized as mean yield per event/non-event\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~isevent)\n\n\n\n\n\nEffect of (log) mean yield at Big G on (log) mean yield at little g during baseflow and event periods.\n\n\n\n\nFacet by site\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~site_name) +\n  theme(legend.position = \"none\")\n\n\n\n\n\nEffect of (log) mean yield at Big G on (log) mean yield at little g during baseflow and event periods, faceted by site.",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Explore Sub-Daily Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/TemporalResolution.html#summary",
    "href": "Explore Data/TemporalResolution.html#summary",
    "title": "4  Explore Sub-Daily Data",
    "section": "4.4 Summary",
    "text": "4.4 Summary\n\nEvent delineation at sub-daily (i.e., hourly) time scale is strongly affected by data processing steps (e.g., smoothing and interpolation by WMA) and landscape processes that are not the focus of this study (i.e., diel fluctuations in flow due to ET)\n\nIn some cases, changes in how WMA treats diel fluctuations may introduce further inconsistencies into downstream analyses\n\nAt the hourly timescale, temporal mismatches between big and little g time series data due to routing time are evident, typically in the 4-8 hour range for the West Brook.\n\nThere does not appear to be any predictable relationship between lag time and flow magnitude or time of year.\nBecause many of the event/non-event periods are very short, these mismatches may have a large effect on how reasonable it is to apply Big G events to little g data, and whether Big G events/non-events adequately encompass similar flow conditions at little g sites.\nTemporal mismatches are less prevalent and more predictable for the daily data.\n\nInferences regarding the g~G relationship derived from hourly data generally do not match those derived from daily data.\n\nthe g~G relationship is more strongly affected by assumptions of temporal alignment for hourly data relative to daily data.",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Explore Sub-Daily Data</span>"
    ]
  },
  {
    "objectID": "Explore Data/TemporalResolution.html#dynamic-time-warping",
    "href": "Explore Data/TemporalResolution.html#dynamic-time-warping",
    "title": "4  Explore Sub-Daily Data",
    "section": "4.5 Dynamic time warping",
    "text": "4.5 Dynamic time warping\nExplore the use of dynamic time warping (Giorgino 2009) to align hourly time series data.\n\n4.5.1 Select data\nTrim to restricted period b/c DTW cannot handle very large datasets\n\n\nCode\nlittleg &lt;- dat_1hr %&gt;% filter(site_name == \"Avery Brook\", datetime &gt;= as_datetime(\"2020-03-01 00:00:00\") & datetime &lt;= as_datetime(\"2020-06-01 00:00:00\"))\nbigg &lt;- dat_1hr %&gt;% filter(site_name == \"West Brook NWIS\", datetime &gt;= as_datetime(\"2020-03-01 00:00:00\") & datetime &lt;= as_datetime(\"2020-06-01 00:00:00\"))\n\nmytib &lt;- bigg %&gt;% select(datetime, yield) %&gt;% rename(yield_big = yield) %&gt;% left_join(littleg %&gt;% select(datetime, yield) %&gt;% rename(yield_little = yield))\nmytib %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\")\n\n\n\n\n\n\n\n\n4.5.2 Align data\n\n\nCode\nalign1hr &lt;- dtw(x = unlist(littleg %&gt;% select(yield)), y = unlist(bigg %&gt;% select(yield)), step = asymmetric, keep = TRUE)\nstr(align1hr)\n\n\nList of 20\n $ costMatrix        : num [1:2209, 1:2209] 0.00176 0.00908 0.02005 0.03084 0.04066 ...\n $ directionMatrix   : int [1:2209, 1:2209] NA 1 1 1 1 1 1 1 1 1 ...\n $ stepPattern       : 'stepPattern' num [1:6, 1:4] 1 1 2 2 3 3 1 0 1 0 ...\n  ..- attr(*, \"npat\")= num 3\n  ..- attr(*, \"norm\")= chr \"N\"\n $ N                 : int 2209\n $ M                 : int 2209\n $ call              : language dtw(x = unlist(littleg %&gt;% select(yield)), y = unlist(bigg %&gt;% select(yield)),      step.pattern = asymmetric, ke| __truncated__\n $ openEnd           : logi FALSE\n $ openBegin         : logi FALSE\n $ windowFunction    :function (iw, jw, ...)  \n $ jmin              : int 2209\n $ distance          : num 35.7\n $ normalizedDistance: num 0.0162\n $ index1            : num [1:2209] 1 2 3 4 5 6 7 8 9 10 ...\n $ index2            : num [1:2209] 1 3 5 7 9 11 13 13 13 13 ...\n $ index1s           : num [1:2209] 1 2 3 4 5 6 7 8 9 10 ...\n $ index2s           : num [1:2209] 1 3 5 7 9 11 13 13 13 13 ...\n $ stepsTaken        : int [1:2208] 3 3 3 3 3 3 1 1 1 1 ...\n $ localCostMatrix   : 'crossdist' num [1:2209, 1:2209] 0.00176 0.00732 0.01097 0.01079 0.00982 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:2209] \"yield1\" \"yield2\" \"yield3\" \"yield4\" ...\n  .. ..$ : chr [1:2209] \"yield1\" \"yield2\" \"yield3\" \"yield4\" ...\n  ..- attr(*, \"method\")= chr \"Euclidean\"\n  ..- attr(*, \"call\")= language proxy::dist(x = x, y = y, method = dist.method)\n $ query             : num [1:2209, 1] 0.1018 0.0962 0.0926 0.0928 0.0937 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:2209] \"yield1\" \"yield2\" \"yield3\" \"yield4\" ...\n  .. ..$ : NULL\n $ reference         : num [1:2209, 1] 0.1036 0.1012 0.1005 0.0982 0.096 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:2209] \"yield1\" \"yield2\" \"yield3\" \"yield4\" ...\n  .. ..$ : NULL\n - attr(*, \"class\")= chr \"dtw\"\n\n\nView index alignment\n\n\nCode\nplot(align1hr, type = \"threeway\")\n\n\n\n\n\n\n\n\n\nShow aligned values\n\n\nCode\nplot(align1hr, type = \"twoway\", offset = - 1)\n\n\n\n\n\n\n\n\n\nView aligned timeseries using dyGraphs. Clearly, this is not a great approach as it matches multiple query data points to the same reference index, i.e., the result is multiple little g flow readings at a single time point. As seen in the plots above, it also does not align the series correctly.\n\n\nCode\naligneddata &lt;- tibble(datetime = bigg$datetime[align1hr$index2], query = littleg$yield[align1hr$index1], reference = bigg$yield[align1hr$index2])\naligneddata %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Explore Sub-Daily Data</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgStoryPlots.html",
    "href": "Big G Little g/GgStoryPlots.html",
    "title": "5  G-g Story Plots",
    "section": "",
    "text": "5.1 Site info and daily data\nPurpose: build visual story plots for each basin and climate year\nNotes:\nView map of sites\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\nLoad and view data structure\nCode\n# flow/yield (and temp) data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\") %&gt;% filter(!site_name %in% c(\"Wounded Buck Creek\"))\n\n# add water/climate year variables\ndat &lt;- add_date_variables(dat, dates = date, water_year_start = 4)\n\n# calculate completeness by site and water year\ncomplete &lt;- dat %&gt;% group_by(site_name, designation, WaterYear) %&gt;% summarize(completeness = sum(!is.na(Yield_filled_mm_7))/365)\ndat &lt;- dat %&gt;% left_join(complete)\nstr(dat)\n\n\ntibble [190,182 × 37] (S3: tbl_df/tbl/data.frame)\n $ station_no          : chr [1:190182] \"12355347\" \"12355347\" \"12355347\" \"12355347\" ...\n $ site_name           : chr [1:190182] \"Big Creek NWIS\" \"Big Creek NWIS\" \"Big Creek NWIS\" \"Big Creek NWIS\" ...\n $ site_id             : chr [1:190182] \"BIG\" \"BIG\" \"BIG\" \"BIG\" ...\n $ basin               : chr [1:190182] \"Flathead\" \"Flathead\" \"Flathead\" \"Flathead\" ...\n $ subbasin            : chr [1:190182] \"Big Creek\" \"Big Creek\" \"Big Creek\" \"Big Creek\" ...\n $ region              : chr [1:190182] \"Flat\" \"Flat\" \"Flat\" \"Flat\" ...\n $ lat                 : num [1:190182] 48.6 48.6 48.6 48.6 48.6 ...\n $ long                : num [1:190182] -114 -114 -114 -114 -114 ...\n $ elev_ft             : num [1:190182] 3528 3528 3528 3528 3528 ...\n $ area_sqmi           : num [1:190182] 73.6 73.6 73.6 73.6 73.6 ...\n $ designation         : chr [1:190182] \"medium\" \"medium\" \"medium\" \"medium\" ...\n $ date                : Date[1:190182], format: \"2018-09-10\" \"2018-09-11\" ...\n $ DischargeReliability: num [1:190182] 1 1 1 1 1 1 1 1 1 1 ...\n $ TempReliability     : num [1:190182] 1 1 1 1 1 1 1 1 1 1 ...\n $ flow_mean           : num [1:190182] 30.3 29.1 29 31.2 32.3 ...\n $ flow_min            : num [1:190182] 28.4 28.4 28.2 29.6 30.3 29.1 29 29.5 28.9 28.3 ...\n $ flow_max            : num [1:190182] 31.5 29.7 30.5 33 34.1 31.4 31.3 32.2 30.1 29.5 ...\n $ tempc_mean          : num [1:190182] NA NA NA NA NA NA NA NA NA NA ...\n $ tempc_min           : num [1:190182] NA NA NA NA NA NA NA NA NA NA ...\n $ tempc_max           : num [1:190182] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean_filled    : num [1:190182] 30.3 29.1 29 31.2 32.3 ...\n $ flow_mean_cms       : num [1:190182] 0.857 0.825 0.821 0.885 0.915 ...\n $ flow_mean_filled_cms: num [1:190182] 0.857 0.825 0.821 0.885 0.915 ...\n $ area_sqkm           : num [1:190182] 191 191 191 191 191 ...\n $ Yield_mm            : num [1:190182] 0.389 0.374 0.372 0.401 0.415 ...\n $ Yield_filled_mm     : num [1:190182] 0.389 0.374 0.372 0.401 0.415 ...\n $ flow_mean_7         : num [1:190182] NA NA NA 30.3 30.4 ...\n $ flow_mean_filled_7  : num [1:190182] NA NA NA 30.3 30.4 ...\n $ tempc_mean_7        : num [1:190182] NA NA NA NA NA NA NA NA NA NA ...\n $ Yield_mm_7          : num [1:190182] NA NA NA 0.389 0.39 ...\n $ Yield_filled_mm_7   : num [1:190182] NA NA NA 0.389 0.39 ...\n $ CalendarYear        : num [1:190182] 2018 2018 2018 2018 2018 ...\n $ Month               : num [1:190182] 9 9 9 9 9 9 9 9 9 9 ...\n $ MonthName           : Factor w/ 12 levels \"Apr\",\"May\",\"Jun\",..: 6 6 6 6 6 6 6 6 6 6 ...\n $ WaterYear           : num [1:190182] 2019 2019 2019 2019 2019 ...\n $ DayofYear           : num [1:190182] 163 164 165 166 167 168 169 170 171 172 ...\n $ completeness        : num [1:190182] 0.43 0.43 0.43 0.43 0.43 ...\nView little and medium g time series data (yield), by basin and site\nCode\nmysubbasins &lt;- unique(dat$subbasin)[-c(4,5,9)]\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  myplots[[i]] &lt;- dat %&gt;% filter(designation %in% c(\"little\", \"medium\"), subbasin == mysubbasins[i]) %&gt;% ggplot() + geom_line(aes(x = date, y = log(Yield_filled_mm_7))) + facet_wrap(~site_name)\n}\nView little and medium g time series data (yield), by basin. Use the handles below the x-axis to change the time frame.\nCode\nmysubbasins &lt;- unique(dat$subbasin)[-c(4,5,9)]\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  myplots[[i]] &lt;- dat %&gt;% filter(designation %in% c(\"little\", \"medium\"), subbasin == mysubbasins[i]) %&gt;% mutate(logYield = log(Yield_filled_mm_7)) %&gt;% select(date, site_name, logYield) %&gt;% spread(key = site_name, value = logYield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"ln(Yield, mm)\")\n}",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>G-g Story Plots</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgStoryPlots.html#site-info-and-daily-data",
    "href": "Big G Little g/GgStoryPlots.html#site-info-and-daily-data",
    "title": "5  G-g Story Plots",
    "section": "",
    "text": "Big CreekCoal CreekMcGee CreekWest BrookDonner BlitzenPaine RunStaunton RiverDuck CreekShields RiverSnake River\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBig CreekCoal CreekMcGee CreekWest BrookDonner BlitzenPaine RunStaunton RiverDuck CreekShields RiverSnake River",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>G-g Story Plots</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgStoryPlots.html#create-plotting-functions",
    "href": "Big G Little g/GgStoryPlots.html#create-plotting-functions",
    "title": "5  G-g Story Plots",
    "section": "5.2 Create plotting functions",
    "text": "5.2 Create plotting functions\nWrite functions to generate residual time series/scatter plot\n\n\nCode\nresidualplots &lt;- function(mybasin, CY, little, big) {\n  # essential elements\n  dat_basin &lt;- dat %&gt;% filter(basin == mybasin)\n  \n  # create residual data frame\n  delta_dat &lt;- dat_basin %&gt;% select(site_name, site_id, basin, region, designation, date, WaterYear, Yield_mm_mean_7) %&gt;% filter(site_name %in% little, WaterYear == CY) %&gt;% \n    left_join(dat_basin %&gt;% select(basin, site_name, date, WaterYear, Yield_mm_mean_7) %&gt;% filter(site_name == big, WaterYear == CY) %&gt;% rename(bigyield = Yield_mm_mean_7) %&gt;% select(-site_name)) %&gt;% \n    mutate(delta_yield = log(Yield_mm_mean_7) - log(bigyield), site_name = factor(site_name, levels = little)) %&gt;% \n    group_by(site_name) %&gt;% mutate(cum_resid = cumsum(coalesce(delta_yield, 0)) + delta_yield*0) \n  \n  # base plot\n  p1 &lt;- delta_dat %&gt;% \n    filter(WaterYear == CY) %&gt;%\n    group_by(site_name) %&gt;%\n    mutate(month = month(date), doy = 1:n()) %&gt;% \n    ungroup() %&gt;%\n    ggplot(aes(x = log(bigyield), y = log(Yield_mm_mean_7), color = doy)) +\n    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +\n    geom_point(aes(group = doy)) +\n    geom_path() +\n    scale_color_gradient2(midpoint = 182, low = \"orange\", mid = \"purple3\", high = \"orange\") +\n    facet_wrap(~site_name) +\n    xlab(\"Big G ln(Yield)\") + ylab(\"Little G ln(Yield)\") + labs(color = \"Days from April 1\") +\n    theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) \n  \n  # animated \n  # p1_anim &lt;- p1 + transition_reveal(along = doy)\n  \n  # write out - static\n  jpeg(paste(\"Big G Little g/Compare Time Series/BigGLittleG_ScatterByTime\", mybasin, \"_\", CY, \".jpg\", sep = \"\"), height = 10, width = 12, units = \"in\", res = 500)\n  print(p1)\n  dev.off()\n  \n  # write out - animated\n  # animate(p1_anim, renderer = gifski_renderer(), height = 10, width = 12, units = \"in\", res = 500)\n  # anim_save(paste(\"Big G Little g/Compare Time Series/BigGLittleG_ScatterByTime_Animated_\", mybasin, \"_\", CY, \".gif\", sep = \"\"))\n  \n  # residual time series\n  jpeg(paste(\"Big G Little g/Compare Time Series/BigGLittleG_YieldResiduals_TimeSeries_\", mybasin, \"_\", CY, \".jpg\", sep = \"\"), height = 4, width = 6, units = \"in\", res = 500)\n  print(ggplot(data = delta_dat) + \n    geom_line(aes(x = date, y = delta_yield, group = site_name, color = site_name)) + \n    geom_hline(aes(yintercept = 0), linetype = \"dashed\") +\n    xlab(\"\") + ylab(\"ln(Yield) residuals (difference from Big G)\") + labs(color = \"Little g\") +\n    theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()))\n  dev.off()\n  \n  \n  # plot little g cumulative residuals - difference from Big G by site\n  jpeg(paste(\"Big G Little g/Compare Time Series/BigGLittleG_YieldResiduals_Cumulative_TimeSeries_\", mybasin, \"_\", CY, \".jpg\", sep = \"\"), height = 4, width = 6, units = \"in\", res = 500)\n  print(delta_dat %&gt;% \n    ggplot() + \n    geom_line(aes(x = date, y = cum_resid, group = site_name, color = site_name)) + \n    geom_hline(aes(yintercept = 0), linetype = \"dashed\") +\n    xlab(\"\") + ylab(\"ln(Yield) cumulative residuals \") + labs(color = \"Little g\") +\n    theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()))\n  dev.off()\n}\n\n\nWrite function to generate flow story plot\n\n\nCode\nbigplotfun &lt;- function(mybasin, mysubbasin, CY, little, big, super, supergyears, mymap, evalyears) {\n  #### essential elements\n  dat_basin &lt;- dat %&gt;% filter(basin == mybasin)\n  months &lt;- c(\"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\", \"Jan\", \"Feb\", \"Mar\")\n  fudge &lt;- 0.01 # add small value to deal with 0 flow on log scale\n\n  # clean data...drop all dates that have missing data at any site\n  dat_basin_cy_clean &lt;- dat %&gt;% \n    filter(site_name %in% c(little, big), WaterYear == CY) %&gt;% \n    select(date, site_name, Yield_filled_mm_7) %&gt;%\n    spread(key = site_name, value = Yield_filled_mm_7) %&gt;% \n    drop_na() %&gt;%\n    gather(key = site_name, value = Yield_filled_mm_7, 2:ncol(.))\n  dat_basin_cy_clean &lt;- fill_missing_dates(dat_basin_cy_clean, dates = \"date\", groups = \"site_name\", pad_ends = FALSE)\n  \n  # get among-year yield min/max for y-axis limits\n  dat_basin_sub &lt;- dat %&gt;% \n    filter(site_name %in% c(little, big), WaterYear %in% evalyears) %&gt;% \n    select(date, WaterYear, site_name, Yield_filled_mm_7) %&gt;%\n    spread(key = site_name, value = Yield_filled_mm_7) %&gt;% \n    drop_na() %&gt;%\n    gather(key = site_name, value = Yield_filled_mm_7, 3:ncol(.)) %&gt;%\n    filter(!is.na(Yield_filled_mm_7)) %&gt;% \n    mutate(Yield_filled_mm_7_log = log(Yield_filled_mm_7+fudge)) \n  yield_lim &lt;- range(dat_basin_sub$Yield_filled_mm_7_log)\n  \n  \n  # clean months\n  cleanmonths &lt;- unlist(dat_basin_cy_clean %&gt;% filter(site_name == little[1]) %&gt;% drop_na() %&gt;% left_join(dat_basin %&gt;% select(date, site_name, MonthName, Month)) %&gt;% group_by(MonthName) %&gt;% summarize(ndays = n()) %&gt;% filter(ndays &gt;= 20) %&gt;% select(MonthName))\n  \n  #### MAP\n  p1 &lt;- mymap\n  # print(\"p1\")\n  \n  #### HYDROGRAPHS IN YIELD\n  p2 &lt;- ggplot() + \n    geom_line(data = dat_basin_cy_clean %&gt;% filter(site_name %in% little) %&gt;% mutate(site_name = factor(site_name, levels = little)), aes(x = date, y = log(Yield_filled_mm_7+fudge), group = site_name, color = site_name)) +\n    geom_line(data = dat_basin_cy_clean %&gt;% filter(site_name == big), aes(x = date, y = log(Yield_filled_mm_7+fudge)), color = \"black\", size = 1.25) +\n    xlab(\"Date\") + ylab(\"ln(Yield, mm)\") + theme_bw() + ylim(yield_lim) + \n    scale_x_date(limits = as.Date(c(paste(CY-1, '-04-01', sep = \"\"), paste(CY, '-04-01', sep = \"\")))) +\n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n  # print(\"p2\")\n  \n  \n  #### TOTAL ANNUAL YIELD\n  # get total yield per year and convert to percentiles\n  yeartotals &lt;- dat_basin %&gt;% \n    filter(site_name == super, WaterYear %in% supergyears) %&gt;% \n    group_by(WaterYear) %&gt;% \n    summarize(totalyield = sum(Yield_filled_mm, na.rm = TRUE)) %&gt;%\n    filter(!is.na(totalyield)) %&gt;%\n    mutate(percentile = percent_rank(totalyield))\n  p3 &lt;- ggplot() + \n    geom_line(data = yeartotals, aes(x = WaterYear, y = totalyield), color = \"grey40\") + \n    geom_point(data = yeartotals %&gt;% filter(WaterYear == CY), aes(x = WaterYear, y = totalyield)) +\n    xlab(\"Climate year\") + ylab(\"Total annual yield (mm)\") + theme_bw() + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # print(\"p3\")\n  \n  \n  #### EXCEEDANCE PROBABILITY - SUPER G PERIOD OF RECORD\n  exceedance &lt;- dat_basin %&gt;% \n    filter(site_name %in% c(little, big, super)) %&gt;%\n    filter(!is.na(Yield_filled_mm_7)) %&gt;% \n    mutate(Yield_filled_mm_7_log = log(Yield_filled_mm_7)) %&gt;%\n    group_by(site_name, WaterYear) %&gt;% \n    arrange(desc(Yield_filled_mm_7_log), .by_group = TRUE) %&gt;% \n    mutate(exceedance = 100/length(Yield_filled_mm_7_log)*1:length(Yield_filled_mm_7_log)) %&gt;%\n    ungroup()\n  p4 &lt;- ggplot() + \n    geom_line(data = exceedance %&gt;% filter(site_name == super, WaterYear %in% supergyears), aes(x = exceedance, y = Yield_filled_mm_7_log, group = WaterYear, color = WaterYear), size = 0.25) +\n    geom_line(data = exceedance %&gt;% filter(site_name == super, WaterYear == CY), aes(x = exceedance, y = Yield_filled_mm_7_log), color = \"black\", size = 1.25) +\n    geom_text(aes(x = 50, y = Inf, label = paste(\"Super G: \", super, \" (\", min(supergyears), \"-\", max(supergyears), \")\", \"\\nCurrent year: \", CY, \" (\", round(yeartotals$percentile[yeartotals$WaterYear == CY]*100), \"th perc.)\", sep = \"\")), vjust = 1.2) +\n    scale_color_continuous(trans = \"reverse\") +\n    xlab(\"Exceedance probability\") + ylab(\"ln(Yield, mm)\") + labs(color = \"Climate year\") + theme_bw() + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.15,0.23), \n          legend.text = element_text(size = 9), legend.title = element_text(size = 9), legend.key.height = unit(0.4, \"cm\"))\n  # print(\"p4\")\n  \n  \n  #### CUMULATIVE YIELD RESIDUALS\n  # get range of residuals among years\n  dat_basin_res &lt;- dat_basin_sub %&gt;% \n    filter(site_name %in% little, WaterYear %in% evalyears) %&gt;% select(site_name, date, WaterYear, Yield_filled_mm_7) %&gt;%\n    left_join(dat %&gt;% filter(site_name == big) %&gt;% rename(bigyield = Yield_filled_mm_7) %&gt;% select(date, WaterYear, bigyield)) %&gt;% \n    mutate(delta_yield = log(Yield_filled_mm_7+fudge) - log(bigyield+fudge), site_name = factor(site_name, levels = little)) %&gt;% \n    group_by(site_name, WaterYear) %&gt;% mutate(cum_resid = cumsum(coalesce(delta_yield, 0)) + delta_yield*0) \n  res_lim &lt;- range(dat_basin_res$cum_resid, na.rm = TRUE)\n  p5 &lt;- dat_basin_cy_clean %&gt;% filter(site_name %in% little) %&gt;% \n    left_join(dat_basin_cy_clean %&gt;% filter(site_name == big) %&gt;% rename(bigyield = Yield_filled_mm_7) %&gt;% select(-site_name)) %&gt;% \n    mutate(delta_yield = log(Yield_filled_mm_7+fudge) - log(bigyield+fudge), site_name = factor(site_name, levels = little)) %&gt;% \n    group_by(site_name) %&gt;% mutate(cum_resid = cumsum(coalesce(delta_yield, 0)) + delta_yield*0) %&gt;%\n    ggplot() + \n    geom_line(aes(x = date, y = cum_resid, group = site_name, color = site_name)) + \n    geom_hline(aes(yintercept = 0), linetype = \"dashed\") +\n    xlab(\"Date\") + ylab(\"ln(Yield) cumulative residuals \") + ylim(res_lim) +\n    scale_x_date(limits = as.Date(c(paste(CY-1, '-04-01', sep = \"\"), paste(CY, '-04-01', sep = \"\")))) +\n    theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n  # print(\"p5\")\n\n  \n  #### EXCEEDANCE PROBABILITY - BIG G/LITTLE G CURRENT YEAR\n  exceedance &lt;- dat_basin_cy_clean %&gt;% \n    filter(site_name %in% c(little, big)) %&gt;%\n    filter(!is.na(Yield_filled_mm_7)) %&gt;% \n    mutate(Yield_filled_mm_7_log = log(Yield_filled_mm_7+fudge)) %&gt;%\n    group_by(site_name) %&gt;% \n    arrange(desc(Yield_filled_mm_7_log), .by_group = TRUE) %&gt;% \n    mutate(exceedance = 100/length(Yield_filled_mm_7_log)*1:length(Yield_filled_mm_7_log)) %&gt;%\n    ungroup()\n  p6 &lt;- ggplot() + \n    geom_line(data = exceedance %&gt;% filter(site_name %in% little) %&gt;% mutate(site_name = factor(site_name, levels = little)), aes(x = exceedance, y = Yield_filled_mm_7_log, group = site_name, color = site_name)) +\n    geom_line(data = exceedance %&gt;% filter(site_name == big), aes(x = exceedance, y = Yield_filled_mm_7_log), color = \"black\", size = 1.25) +\n    xlab(\"Exceedance probability\") + ylab(\"ln(Yield, mm)\") + labs(color = \"Little g\") + theme_bw() + ylim(yield_lim) + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n  # print(\"p6\")\n  \n  \n  #### EXCEEDANCE PROBABILITY MONTHLY\n  exceedance_monthly &lt;- dat_basin_cy_clean %&gt;% \n    filter(site_name %in% c(little, big)) %&gt;%\n    filter(!is.na(Yield_filled_mm_7)) %&gt;% \n    left_join(dat_basin %&gt;% select(date, site_name, MonthName, Month)) %&gt;%\n    mutate(Yield_filled_mm_7_log = log(Yield_filled_mm_7+fudge),\n           site_name = factor(site_name, levels = c(little, big)),\n           MonthName = factor(MonthName, levels = months)) %&gt;%\n    group_by(site_name, Month) %&gt;% \n    arrange(desc(Yield_filled_mm_7_log), .by_group = TRUE) %&gt;% \n    mutate(exceedance = 100/length(Yield_filled_mm_7_log)*1:length(Yield_filled_mm_7_log)) %&gt;%\n    ungroup()\n  exceedance_monthly2 &lt;- exceedance_monthly %&gt;% mutate(Yield_filled_mm_7_log = ifelse(MonthName %in% cleanmonths, Yield_filled_mm_7_log, NA))\n  p7 &lt;- ggplot() + \n    geom_line(data = exceedance_monthly2 %&gt;% filter(site_name %in% little), aes(x = exceedance, y = Yield_filled_mm_7_log, group = site_name, color = site_name)) +\n    geom_line(data = exceedance_monthly2 %&gt;% filter(site_name == big), aes(x = exceedance, y = Yield_filled_mm_7_log), color = \"black\", size = 1.25) +\n    facet_wrap(~ factor(MonthName), nrow = 2) + \n    xlab(\"Exceedance probability\") + ylab(\"ln(Yield, mm)\") + labs(color = \"Little g\") + theme_bw() +  ylim(yield_lim) + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n  # print(\"p7\")\n  \n  \n  #### ANNUAL BIG-LITTLE DIFFERENCE\n  mypvals &lt;- tibble(type =  rep(NA, times = length(little)), \n                    month = rep(NA, times = length(little)),\n                    site_name = rep(NA, times = length(little)), \n                    stat = rep(NA, times = length(little)),\n                    pval = rep(NA, times = length(little)))\n  for (i in 1:length(little)) {\n    mytest &lt;- ks.test(exceedance$Yield_filled_mm_7_log[exceedance$site_name == big],\n                      exceedance$Yield_filled_mm_7_log[exceedance$site_name == little[i]], exact = TRUE)\n    mypvals$type &lt;- \"annual\"\n    mypvals$month &lt;- 0\n    mypvals$site_name[i] &lt;- little[i]\n    mypvals$stat[i] &lt;- mytest$statistic\n    mypvals$pval[i] &lt;- mytest$p.value\n  }\n  p8 &lt;- mypvals %&gt;% \n    mutate(site_name = factor(site_name, levels = little)) %&gt;% \n    ggplot() + \n    geom_boxplot(aes(x = month, y = pval, group = month), fill = \"grey90\", outlier.shape = NA) +\n    geom_point(aes(x = jitter(month, factor = 10), y = pval, color = site_name), size = 2) +\n    ylim(0,1) + geom_hline(yintercept = 0.05, linetype = \"dashed\") +\n    xlab(\"\") + ylab(\"Kolmogorov-Smirnov test p-value\") + scale_x_continuous(labels = \"Annual\", breaks = 0) +\n    theme_bw() + theme(axis.title.x = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n  # print(\"p8\")\n  \n  \n  #### MONTHLY BIG-LITTLE DIFFERENCE\n  mypvals_monthly_list &lt;- list()\n  for (i in 1:length(little)) {\n    mypvals_monthly &lt;- tibble(type =  rep(NA, times = 12), \n                              month = rep(NA, times = 12),\n                              site_name = rep(NA, times = 12), \n                              stat = rep(NA, times = 12),\n                              pval = rep(NA, times = 12))\n    for (j in 1:12) {\n      big_exc &lt;- exceedance_monthly$Yield_filled_mm_7_log[exceedance_monthly$site_name == big & exceedance_monthly$MonthName == months[j]]\n      lit_exc &lt;- exceedance_monthly$Yield_filled_mm_7_log[exceedance_monthly$site_name == little[i] & exceedance_monthly$MonthName == months[j]]\n      if(length(lit_exc) &lt; 20) {\n        mypvals_monthly$site_name[j] &lt;- little[i]\n        mypvals_monthly$type &lt;- \"monthly\"\n        mypvals_monthly$month[j] &lt;- months[j]\n        mypvals_monthly$stat[j] &lt;- NA\n        mypvals_monthly$pval[j] &lt;- NA\n      } else {\n        mytest &lt;- ks.test(big_exc, lit_exc, exact = TRUE)\n        mypvals_monthly$site_name[j] &lt;- little[i]\n        mypvals_monthly$type &lt;- \"monthly\"\n        mypvals_monthly$month[j] &lt;- months[j]\n        mypvals_monthly$stat[j] &lt;- mytest$statistic\n        mypvals_monthly$pval[j] &lt;- mytest$p.value\n      }\n    }\n    mypvals_monthly_list[[i]] &lt;- mypvals_monthly\n  }\n  mypvals_monthly &lt;- do.call(rbind, mypvals_monthly_list) %&gt;% \n    mutate(site_name = factor(site_name, levels = little),\n           month = factor(month, levels = months), \n           month_num = as.numeric(month)) \n  # compute the loess\n  # dum &lt;- rbind(mypvals_monthly %&gt;% mutate(month_num = month_num-12),\n  #              mypvals_monthly,\n  #              mypvals_monthly %&gt;% mutate(month_num = month_num+12)) \n  # mylo &lt;- loess(pval ~ month_num, dum, span = 0.25)\n  # plot(pval ~ month_num, dum)\n  # j &lt;- order(dum$month_num)[(dim(mypvals_monthly)[1]+1):(dim(mypvals_monthly)[1]+dim(mypvals_monthly)[1])]\n  # lines(dum$month_num[j], mylo$fitted[j], col = \"red\")\n  # the plot\n  p9 &lt;- mypvals_monthly %&gt;% \n    ggplot() + \n    geom_boxplot(aes(x = month, y = pval, group = month), fill = \"grey90\", outlier.shape = NA) +\n    # geom_line(aes(x = dum$month_num[j], y = mylo$fitted[j]), linewidth = 1.25) +\n    geom_smooth(aes(x = month_num, y = pval), linewidth = 1.25, color = \"black\", se = FALSE) +\n    geom_point(aes(x = jitter(month_num), y = pval, color = site_name), size = 2) +\n    ylim(0,1) + geom_hline(yintercept = (0.05), linetype = \"dashed\") +\n    xlab(\"\") + ylab(\"\") + \n    labs(color = \"\") + theme_bw() + \n    theme(axis.title.x = element_blank(), axis.text.y = element_blank(), panel.grid.minor = element_blank())\n  # print(\"p9\")\n  \n  \n  #### BIG PLOT\n  bigp &lt;- ggarrange(ggarrange(mymap, ggarrange(NA, p2, nrow = 2, heights = c(0.2,1))),\n                    ggarrange(p3, p4), \n                    ggarrange(p5, p6),\n                    p7, \n                    ggarrange(p8, p9, widths = c(0.13, 0.85)), nrow = 5, heights = c(1.2,0.9,0.9,1.2,0.9))\n  # print(\"big plot!\")\n  # write out\n  # jpeg(paste(\"Big G Little g/Compare Distributions/BigGLittleG_BigPlot_\", mybasin, \"_\", mysubbasin, \"_\", CY, \".jpg\", sep = \"\"), height = 18, width = 10, units = \"in\", res = 500)\n  # annotate_figure(bigp, fig.lab = \"The West Brook, CY 2021\", fig.lab.pos = \"top.right\", fig.lab.size = 24)\n  print(annotate_figure(bigp, top = text_grob(paste(mybasin, \", CY \", CY, sep = \"\"), x = 0.75, y = -0.5, just = \"centre\", size = 24)))\n  # dev.off()\n}",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>G-g Story Plots</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgStoryPlots.html#create-map-objects",
    "href": "Big G Little g/GgStoryPlots.html#create-map-objects",
    "title": "5  G-g Story Plots",
    "section": "5.3 Create map objects",
    "text": "5.3 Create map objects\n\nWest BrookStaunton RiverPaine RunBig CreekSpread CreekShields RiverDonner-Blitzen",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>G-g Story Plots</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgStoryPlots.html#flow-story-plots",
    "href": "Big G Little g/GgStoryPlots.html#flow-story-plots",
    "title": "5  G-g Story Plots",
    "section": "5.4 Flow story plots",
    "text": "5.4 Flow story plots\nGenerate streamflow story plots by basin and climate year\n\n5.4.1 West Brook\n\n20212022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.2 Staunton River\n\n202120222023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.3 Paine Run\n\n20212022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.4 Big Creek, Flathead\n\n20202021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.5 Spread Creek, Snake\n\n20222023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.6 Shields River\n\n20202023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.7 Donner-Blitzen\n\n2020202120222023",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>G-g Story Plots</span>"
    ]
  },
  {
    "objectID": "Covariates/LandscapeCovariates.html",
    "href": "Covariates/LandscapeCovariates.html",
    "title": "6  Landscape Covariates",
    "section": "",
    "text": "6.1 Site info\nPurpose: Derive landscape/basin-level covariates to use in gG framework.\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")",
    "crumbs": [
      "Covariates",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Landscape Covariates</span>"
    ]
  },
  {
    "objectID": "Covariates/LandscapeCovariates.html#spatial-data",
    "href": "Covariates/LandscapeCovariates.html#spatial-data",
    "title": "6  Landscape Covariates",
    "section": "6.2 Spatial data",
    "text": "6.2 Spatial data\n\n6.2.1 Watersheds\n\n\nCode\nsheds_list &lt;- list()\nmyfiles &lt;- list.files(path = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Watersheds/\", pattern = \".shp\")\nfor (i in 1:length(myfiles)) {\n  sheds_list[[i]] &lt;- vect(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Watersheds/\", myfiles[i], sep = \"\"))\n}\nsheds &lt;- do.call(rbind, sheds_list) %&gt;% left_join(siteinfo)\nmapview(st_as_sf(sheds), alpha.regions = 0.2)\n\n\n\n\n\n\n\n\n6.2.2 Flowlines\n\n\nCode\nstreams_list &lt;- list()\nmyfiles &lt;- list.files(path = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Streams/\", pattern = \".shp\")\nsheds_basins &lt;- sheds[sheds$site_id %in% c(\"NFF\",      # Flathead\n                                           \"WBR\",      # West Brook\n                                           \"DBF\",      # Donner Blitzen\n                                           \"PI_10FL\",  # Shen, Piney River\n                                           \"SR_10FL\",  # Shen, Staunton River\n                                           \"PA_10FL\",  # Shen, Paine Run\n                                           \"SRS\",      # Shields River\n                                           \"DU01\",     # Duck Creek\n                                           \"SP11\"),]   # Spread Creek\nmyctr &lt;- c(1,2,3,4,4,4,5,5,6)\nfor (i in 1:length(myctr)) {\n  streams_list[[i]] &lt;- crop(vect(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Streams/\", myfiles[myctr[i]], sep = \"\")), sheds_basins[i])\n  crs(streams_list[[i]]) &lt;- crs(sheds)\n}\nstreams &lt;- do.call(rbind, streams_list)\nmapview(st_as_sf(streams)) + mapview(siteinfo_sp, zcol = \"designation\")",
    "crumbs": [
      "Covariates",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Landscape Covariates</span>"
    ]
  },
  {
    "objectID": "Covariates/LandscapeCovariates.html#define-g-g-clusterssub-basins",
    "href": "Covariates/LandscapeCovariates.html#define-g-g-clusterssub-basins",
    "title": "6  Landscape Covariates",
    "section": "6.3 Define G-g clusters/sub-basins",
    "text": "6.3 Define G-g clusters/sub-basins\n\n\nCode\nsiteinfo2 &lt;- siteinfo %&gt;% \n  filter(!site_name %in% c(\"WoundedBuckCreek\", \"Brackett Creek\", \"South River Conway NWIS\", \n                           \"Shields River nr Livingston NWIS\", \"North Fork Flathead River NWIS\", \n                           \"Pacific Creek at Moran NWIS\")) %&gt;%\n  mutate(designation = ifelse(site_name %in% c(\"Donner Blitzen River nr Frenchglen NWIS\", \n                                               \"BigCreekLower\", \"CoalCreekLower\", \"McGeeCreekLower\", \n                                               \"West Brook NWIS\", \"West Brook 0\", \n                                               \"Paine Run 10\", \"Staunton River 10\", \"Piney River 10\", \n                                               \"Shields River Valley Ranch\", \"Shields River ab Smith NWIS\", \n                                               \"EF Duck Creek be HF\",\n                                               \"Spread Creek Dam\"), \"big\", \"little\"))\nsiteinfo2 %&gt;% arrange(region, basin, subbasin, designation) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsite_id\nsite_name\nlat\nlong\nstation_no\ndesignation\nbasin\nregion\nsubbasin\nsource\narea_sqmi\nelev_ft\n\n\n\n\nBIG_001\nBigCreekLower\n48.60295\n-114.18700\nNA\nbig\nFlathead\nFlat\nBig Creek\nECOD\n81.2083617\n3428.6560\n\n\nBIG_004\nBigCreekMiddle\n48.59770\n-114.22500\nNA\nlittle\nFlathead\nFlat\nBig Creek\nECOD\n73.5768438\n3528.9551\n\n\nBIG_005\nBigCreekUpper\n48.57493\n-114.31700\nNA\nlittle\nFlathead\nFlat\nBig Creek\nECOD\n53.1555778\n3913.1550\n\n\nBIG_006\nHallowattCreekLower\n48.57427\n-114.31700\nNA\nlittle\nFlathead\nFlat\nBig Creek\nECOD\n28.1074377\n3916.4062\n\n\nBIG_002\nLangfordCreekLower\n48.60369\n-114.18700\nNA\nlittle\nFlathead\nFlat\nBig Creek\nECOD\n3.9917383\n3431.6910\n\n\nBIG_003\nLangfordCreekUpper\n48.61350\n-114.20200\nNA\nlittle\nFlathead\nFlat\nBig Creek\nECOD\n2.8629722\n3594.2884\n\n\nBIG_008\nNicolaCreek\n48.55442\n-114.37500\nNA\nlittle\nFlathead\nFlat\nBig Creek\nECOD\n3.3459243\n4958.1863\n\n\nBIG_007\nSkookoleelCreek\n48.57092\n-114.31200\nNA\nlittle\nFlathead\nFlat\nBig Creek\nECOD\n8.5886199\n3965.1819\n\n\nBIG_009\nWernerCreek\n48.59324\n-114.36800\nNA\nlittle\nFlathead\nFlat\nBig Creek\nECOD\n3.9795282\n4284.3249\n\n\nHAL\nHallowat Creek NWIS\n48.61005\n-114.38193\n12355342\nlittle\nFlathead\nFlat\nBig Creek\nNWIS\n10.0317552\n4453.6190\n\n\nBIG\nBig Creek NWIS\n48.59769\n-114.22472\n12355347\nlittle\nFlathead\nFlat\nBig Creek\nNWIS\n73.5899716\n3528.2743\n\n\nCOA_001\nCoalCreekLower\n48.66182\n-114.24200\nNA\nbig\nFlathead\nFlat\nCoal Creek\nECOD\n59.9694259\n3658.9180\n\n\nCOA_009\nCoalCreekHeadwaters\n48.70570\n-114.45500\nNA\nlittle\nFlathead\nFlat\nCoal Creek\nECOD\n12.4254748\n4595.6775\n\n\nCOA_006\nCoalCreekMiddle\n48.67442\n-114.31700\nNA\nlittle\nFlathead\nFlat\nCoal Creek\nECOD\n45.3748041\n3874.4946\n\n\nCOA_003\nCycloneCreekLower\n48.66582\n-114.24500\nNA\nlittle\nFlathead\nFlat\nCoal Creek\nECOD\n12.6353670\n3701.7687\n\n\nCOA_004\nCycloneCreekMiddle\n48.66871\n-114.26700\nNA\nlittle\nFlathead\nFlat\nCoal Creek\nECOD\n11.2380763\n3853.7423\n\n\nCOA_005\nCycloneCreekUpper\n48.69030\n-114.27600\nNA\nlittle\nFlathead\nFlat\nCoal Creek\nECOD\n9.8960331\n4039.1350\n\n\nCOA_002\nMeadowCreek\n48.65865\n-114.23600\nNA\nlittle\nFlathead\nFlat\nCoal Creek\nECOD\n5.7153134\n3684.4886\n\n\nCOA_008\nCoalCreekNorth\n48.69130\n-114.37600\nNA\nlittle\nFlathead\nFlat\nCoal Creek\nECOD\n20.8457145\n4154.4794\n\n\nMCG_002\nMcGeeCreekLower\n48.61789\n-114.06700\nNA\nbig\nFlathead\nFlat\nMcGee Creek\nECOD\n7.4164591\n3711.2340\n\n\nMCG_001\nMcGeeCreekTrib\n48.62212\n-114.07400\nNA\nlittle\nFlathead\nFlat\nMcGee Creek\nECOD\n1.2240208\n3697.0725\n\n\nMCG_003\nMcGeeCreekUpper\n48.59827\n-114.04000\nNA\nlittle\nFlathead\nFlat\nMcGee Creek\nECOD\n3.3382493\n3866.2909\n\n\nWM\nWest Brook 0\n42.41434\n-72.62929\n01171100\nbig\nWest Brook\nMass\nWest Brook\nECOD\n11.3860459\n154.5905\n\n\nWBR\nWest Brook NWIS\n42.41437\n-72.62876\n01171100\nbig\nWest Brook\nMass\nWest Brook\nNWIS\n11.3929050\n154.1473\n\n\nAB\nAvery Brook\n42.44981\n-72.69402\n01171000\nlittle\nWest Brook\nMass\nWest Brook\nECOD\n2.8322503\n699.2518\n\n\nJB\nJimmy Brook\n42.43485\n-72.67102\n01171040\nlittle\nWest Brook\nMass\nWest Brook\nECOD\n0.9743054\n452.0916\n\n\nMB\nMitchell Brook\n42.43355\n-72.66819\n01171080\nlittle\nWest Brook\nMass\nWest Brook\nECOD\n0.3514676\n437.5512\n\n\nOL\nObear Brook Lower\n42.43429\n-72.67154\n01171070\nlittle\nWest Brook\nMass\nWest Brook\nECOD\n0.5654137\n465.1764\n\n\nSD\nSanderson Brook\n42.43635\n-72.68685\n01171010\nlittle\nWest Brook\nMass\nWest Brook\nECOD\n1.7567871\n640.4320\n\n\nWL\nWest Brook Lower\n42.43187\n-72.66423\n01171090\nlittle\nWest Brook\nMass\nWest Brook\nECOD\n8.5098116\n401.9724\n\n\nWU\nWest Brook Upper\n42.43749\n-72.67602\n01171030\nlittle\nWest Brook\nMass\nWest Brook\nECOD\n6.3540403\n516.3184\n\n\nWR\nWest Brook Reservoir\n42.43738\n-72.68166\n01171020\nlittle\nWest Brook\nMass\nWest Brook\nECOD\n6.2101754\n568.7790\n\n\nWW\nWest Whately Brook\n42.45678\n-72.68820\n01171005\nlittle\nWest Brook\nMass\nWest Brook\nECOD\n0.4928159\n686.2488\n\n\nAVB\nAvery Brook NWIS\n42.44991\n-72.69355\n01171000\nlittle\nWest Brook\nMass\nWest Brook\nNWIS\n2.8334885\n696.2354\n\n\nDBF\nDonner Blitzen River nr Frenchglen NWIS\n42.79083\n-118.86750\n10396000\nbig\nDonner Blitzen\nOreg\nDonner Blitzen\nNWIS\n204.9669881\n4262.8244\n\n\nDBI\nDonner Blitzen ab Indian NWIS\n42.63743\n-118.76077\n423815118453900\nlittle\nDonner Blitzen\nOreg\nDonner Blitzen\nNWIS\n60.6960528\n5097.0236\n\n\nIND\nIndian Creek NWIS\n42.64180\n-118.75899\n423830118453200\nlittle\nDonner Blitzen\nOreg\nDonner Blitzen\nNWIS\n19.0189031\n5095.5474\n\n\nLBL\nLittle Blizten River NWIS\n42.66755\n-118.76015\n424003118453700\nlittle\nDonner Blitzen\nOreg\nDonner Blitzen\nNWIS\n18.5136726\n5069.1385\n\n\nDBB\nDonner Blitzen nr Burnt Car NWIS\n42.72374\n-118.83307\n424325118495900\nlittle\nDonner Blitzen\nOreg\nDonner Blitzen\nNWIS\n163.5486547\n4514.4190\n\n\nDBA\nDonner Blitzen ab Fish NWIS\n42.76296\n-118.84311\n424547118503500\nlittle\nDonner Blitzen\nOreg\nDonner Blitzen\nNWIS\n175.4902236\n4340.9354\n\n\nFSH\nFish Creek NWIS\n42.76407\n-118.84232\n424551118503200\nlittle\nDonner Blitzen\nOreg\nDonner Blitzen\nNWIS\n22.2913828\n4344.7481\n\n\nPA_10FL\nPaine Run 10\n38.19860\n-78.79310\n01627400\nbig\nPaine Run\nShen\nPaine Run\nECOD\n4.8965855\n1400.3952\n\n\nPA_01FL\nPaine Run 01\n38.20920\n-78.75270\n0162732260\nlittle\nPaine Run\nShen\nPaine Run\nECOD\n0.6700740\n1840.9670\n\n\nPA_02FL\nPaine Run 02\n38.20730\n-78.75700\n0162732518\nlittle\nPaine Run\nShen\nPaine Run\nECOD\n0.9912138\n1770.2417\n\n\nPA_03FL\nPaine Run 03\n38.20520\n-78.76120\n0162732782\nlittle\nPaine Run\nShen\nPaine Run\nECOD\n1.2384319\n1708.7624\n\n\nPA_04FL\nPaine Run 04\n38.20030\n-78.76560\n0162733238\nlittle\nPaine Run\nShen\nPaine Run\nECOD\n1.5651468\n1634.2663\n\n\nPA_05FL\nPaine Run 05\n38.19710\n-78.76870\n0162734220\nlittle\nPaine Run\nShen\nPaine Run\nECOD\n2.3149357\n1587.6120\n\n\nPA_06FL\nPaine Run 06\n38.19740\n-78.77370\n01627352\nlittle\nPaine Run\nShen\nPaine Run\nECOD\n2.8534416\n1552.5478\n\n\nPA_07FL\nPaine Run 07\n38.19560\n-78.77800\n01627358\nlittle\nPaine Run\nShen\nPaine Run\nECOD\n3.0594680\n1520.2334\n\n\nPA_08FL\nPaine Run 08\n38.19420\n-78.78370\n0162737249\nlittle\nPaine Run\nShen\nPaine Run\nECOD\n3.5932435\n1474.8519\n\n\nPA_09FL\nPaine Run 09\n38.19650\n-78.78860\n01627380\nlittle\nPaine Run\nShen\nPaine Run\nECOD\n4.0467174\n1433.8870\n\n\nPI_10FL\nPiney River 10\n38.70130\n-78.26740\n0166236713\nbig\nPiney River\nShen\nPiney River\nECOD\n4.8079952\n1183.1180\n\n\nPI_01FL\nPiney River 01\n38.74550\n-78.28180\n0166235777\nlittle\nPiney River\nShen\nPiney River\nECOD\n0.5466476\n2501.9557\n\n\nPI_02FL\nPiney River 02\n38.74250\n-78.28550\n0166235998\nlittle\nPiney River\nShen\nPiney River\nECOD\n1.1006113\n2369.7393\n\n\nPI_03FL\nPiney River 03\n38.73840\n-78.28930\n0166236114\nlittle\nPiney River\nShen\nPiney River\nECOD\n1.4355099\n2162.4096\n\n\nPI_04FL\nPiney River 04\n38.73410\n-78.29160\n0166236168\nlittle\nPiney River\nShen\nPiney River\nECOD\n1.8095900\n2024.9685\n\n\nPI_05FL\nPiney River 05\n38.72800\n-78.29160\n0166236224\nlittle\nPiney River\nShen\nPiney River\nECOD\n2.3054298\n1874.3122\n\n\nPI_06FL\nPiney River 06\n38.72570\n-78.28360\n0166236285\nlittle\nPiney River\nShen\nPiney River\nECOD\n2.6988937\n1603.3088\n\n\nPI_08FL\nPiney River 08\n38.71190\n-78.27720\n0166236472\nlittle\nPiney River\nShen\nPiney River\nECOD\n3.6105641\n1354.6080\n\n\nPI_09FL\nPiney River 09\n38.70450\n-78.27040\n0166236559\nlittle\nPiney River\nShen\nPiney River\nECOD\n4.2830953\n1238.9199\n\n\nSR_10FL\nStaunton River 10\n38.44450\n-78.37070\n0166526910\nbig\nStaunton River\nShen\nStaunton River\nECOD\n4.1061151\n996.5581\n\n\nSR_01FL\nStaunton River 01\n38.46700\n-78.41770\n0166526050\nlittle\nStaunton River\nShen\nStaunton River\nECOD\n0.4772281\n2940.0147\n\n\nSR_02FL\nStaunton River 02\n38.46300\n-78.41010\n0166526110\nlittle\nStaunton River\nShen\nStaunton River\nECOD\n0.8271327\n2487.8920\n\n\nSR_03FL\nStaunton River 03\n38.45940\n-78.40360\n0166526165\nlittle\nStaunton River\nShen\nStaunton River\nECOD\n1.2444908\n2199.2577\n\n\nSR_04FL\nStaunton River 04\n38.45840\n-78.39950\n0166526303\nlittle\nStaunton River\nShen\nStaunton River\nECOD\n1.9000379\n2053.1192\n\n\nSR_05FL\nStaunton River 05\n38.45920\n-78.38720\n0166526399\nlittle\nStaunton River\nShen\nStaunton River\nECOD\n2.4754040\n1710.9466\n\n\nSR_06FL\nStaunton River 06\n38.45650\n-78.38090\n0166526453\nlittle\nStaunton River\nShen\nStaunton River\nECOD\n2.8062837\n1524.8785\n\n\nSR_07FL\nStaunton River 07\n38.45350\n-78.37900\n0166526484\nlittle\nStaunton River\nShen\nStaunton River\nECOD\n2.9037810\n1432.0669\n\n\nSR_08FL\nStaunton River 08\n38.44870\n-78.37820\n0166526535\nlittle\nStaunton River\nShen\nStaunton River\nECOD\n3.1630527\n1265.5245\n\n\nSR_09FL\nStaunton River 09\n38.44640\n-78.37590\n0166526567\nlittle\nStaunton River\nShen\nStaunton River\nECOD\n3.2551121\n1154.3350\n\n\nDU01\nEF Duck Creek be HF\n45.87142\n-110.24438\nNA\nbig\nDuck Creek\nShields\nDuck Creek\nECOD\n9.4495375\n5342.4715\n\n\nDU02\nEF Duck Creek ab HF\n45.87570\n-110.24775\nNA\nlittle\nDuck Creek\nShields\nDuck Creek\nECOD\n5.4605992\n5429.5483\n\n\nDU03\nHenrys Fork\n45.90132\n-110.24998\nNA\nlittle\nDuck Creek\nShields\nDuck Creek\nECOD\n1.6960835\n5926.9079\n\n\nSH07\nShields River Valley Ranch\n46.16716\n-110.55429\nNA\nbig\nShields River\nShields\nShields River\nECOD\n53.4215153\n5744.1457\n\n\nSRS\nShields River ab Smith NWIS\n46.16716\n-110.55429\n06192980\nbig\nShields River\nShields\nShields River\nNWIS\n53.4215153\n5744.1457\n\n\nSH02\nBuck Creek\n46.18374\n-110.38463\nNA\nlittle\nShields River\nShields\nShields River\nECOD\n4.4298623\n6493.8012\n\n\nSH03\nCrandall Creek\n46.18454\n-110.40734\nNA\nlittle\nShields River\nShields\nShields River\nECOD\n2.5338355\n6361.7450\n\n\nSH04\nDeep Creek\n46.17037\n-110.45686\nNA\nlittle\nShields River\nShields\nShields River\nECOD\n6.1986519\n6142.5211\n\n\nSH05\nDugout Creek\n46.18431\n-110.37980\nNA\nlittle\nShields River\nShields\nShields River\nECOD\n2.3945376\n6496.1053\n\n\nSH06\nLodgepole Creek\n46.18146\n-110.35920\nNA\nlittle\nShields River\nShields\nShields River\nECOD\n1.3590115\n6610.3856\n\n\nSH08\nShields River ab Dugout\n46.18407\n-110.37945\nNA\nlittle\nShields River\nShields\nShields River\nECOD\n8.6790373\n6497.0348\n\n\nDUG\nDugout Creek NWIS\n46.18481\n-110.37964\n06192900\nlittle\nShields River\nShields\nShields River\nNWIS\n2.3849317\n6505.1692\n\n\nSP11\nSpread Creek Dam\n43.77230\n-110.48040\nNA\nbig\nSnake River\nSnake\nSnake River\nECOD\n97.4926478\n7130.2353\n\n\nSP01\nGrizzly Creek\n43.77399\n-110.23554\nNA\nlittle\nSnake River\nSnake\nSnake River\nECOD\n12.6823126\n8339.7503\n\n\nSP02\nGrouse Creek\n43.74895\n-110.31903\nNA\nlittle\nSnake River\nSnake\nSnake River\nECOD\n5.1508608\n7869.5257\n\n\nSP03\nLeidy Creek Lower\n43.73347\n-110.31434\nNA\nlittle\nSnake River\nSnake\nSnake River\nECOD\n5.1718308\n7958.3398\n\n\nSP04\nLeidy Creek Upper\n43.72041\n-110.37030\nNA\nlittle\nSnake River\nSnake\nSnake River\nECOD\n2.1816563\n8706.8560\n\n\nSP05\nLeidy Creek Mouth\n43.73165\n-110.31526\nNA\nlittle\nSnake River\nSnake\nSnake River\nECOD\n5.1585521\n7979.3625\n\n\nSP06\nNF Spread Creek Lower\n43.76467\n-110.32339\nNA\nlittle\nSnake River\nSnake\nSnake River\nECOD\n27.9304796\n7788.5460\n\n\nSP07\nNF Spread Creek Upper\n43.77413\n-110.23535\nNA\nlittle\nSnake River\nSnake\nSnake River\nECOD\n3.6804425\n8340.2053\n\n\nSP08\nRock Creek\n43.76640\n-110.44859\nNA\nlittle\nSnake River\nSnake\nSnake River\nECOD\n4.7413085\n7285.9575\n\n\nSP09\nSF Spread Creek Lower\n43.76430\n-110.32384\nNA\nlittle\nSnake River\nSnake\nSnake River\nECOD\n44.2556218\n7785.6007\n\n\nSP10\nSF Spread Creek Upper\n43.73664\n-110.31387\nNA\nlittle\nSnake River\nSnake\nSnake River\nECOD\n35.0605919\n7937.8850\n\n\nLEI\nLeidy Creek Mouth NWIS\n43.73311\n-110.31456\n13012465\nlittle\nSnake River\nSnake\nSnake River\nNWIS\n5.1689622\n7960.3743\n\n\nSFS\nSF Spread Creek Lower NWIS\n43.76348\n-110.32379\n13012475\nlittle\nSnake River\nSnake\nSnake River\nNWIS\n44.2420544\n7789.9333",
    "crumbs": [
      "Covariates",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Landscape Covariates</span>"
    ]
  },
  {
    "objectID": "Covariates/LandscapeCovariates.html#basin-overlap",
    "href": "Covariates/LandscapeCovariates.html#basin-overlap",
    "title": "6  Landscape Covariates",
    "section": "6.4 Basin overlap",
    "text": "6.4 Basin overlap\nCalculate area and proportional overlap between big and little g basin pairs. Proportional overlap is generally entirely correlated with absolute and relative difference in basin size (the exception being the few sites that are not nested within a Big G basin: Coal Creek and McGee Creek sites).\n\n\nCode\nmysubbasins &lt;- unique(siteinfo2$subbasin)\ntib_list1 &lt;- list()\ntib_list2 &lt;- list()\ntib_list3 &lt;- list()\n\nfor (i in 1:length(mysubbasins)) {\n  sites_big &lt;- siteinfo2 %&gt;% filter(subbasin == mysubbasins[i], designation == \"big\")\n  sites_little &lt;- siteinfo2 %&gt;% filter(subbasin == mysubbasins[i], designation == \"little\")\n  for (j in 1:length(unique(sites_big$site_name))) {\n    basin_big &lt;- sheds[sheds$site_name == unique(sites_big$site_name)[j]]\n    for (k in 1:length(unique(sites_little$site_name))) {\n      basin_little &lt;- sheds[sheds$site_name == unique(sites_little$site_name)[k]]\n      intersection &lt;- expanse(intersect(basin_big, basin_little), unit = \"km\")\n      shared_area_km2 &lt;- ifelse(length(intersection) == 0, 0, intersection)\n      shared_area_prop &lt;- shared_area_km2 / expanse(basin_big, unit = \"km\")\n      tib_list3[[k]] &lt;- tibble(subbasin = mysubbasins[i],\n                               site_name_big = unique(sites_big$site_name)[j], \n                               site_name_little = unique(sites_little$site_name)[k],\n                               shared_area_km2 = shared_area_km2, shared_area_prop = shared_area_prop)\n    }\n    tib_list2[[j]] &lt;- do.call(rbind, tib_list3)\n    tib_list3 &lt;- list()\n  }\n  tib_list1[[i]] &lt;- do.call(rbind, tib_list2)\n  tib_list2 &lt;- list()\n}\noverlap_tib &lt;- do.call(rbind, tib_list1)\nhead(overlap_tib)\n\n\n# A tibble: 6 × 5\n  subbasin   site_name_big site_name_little  shared_area_km2 shared_area_prop\n  &lt;chr&gt;      &lt;chr&gt;         &lt;chr&gt;                       &lt;dbl&gt;            &lt;dbl&gt;\n1 West Brook West Brook 0  Avery Brook                 7.35            0.249 \n2 West Brook West Brook 0  Jimmy Brook                 2.53            0.0856\n3 West Brook West Brook 0  Mitchell Brook              0.912           0.0309\n4 West Brook West Brook 0  Obear Brook Lower           1.47            0.0497\n5 West Brook West Brook 0  Sanderson Brook             4.56            0.154 \n6 West Brook West Brook 0  West Brook Lower           22.1             0.747",
    "crumbs": [
      "Covariates",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Landscape Covariates</span>"
    ]
  },
  {
    "objectID": "Covariates/LandscapeCovariates.html#basin-size-and-elevation",
    "href": "Covariates/LandscapeCovariates.html#basin-size-and-elevation",
    "title": "6  Landscape Covariates",
    "section": "6.5 Basin size and elevation",
    "text": "6.5 Basin size and elevation\nCalculate absolute and relative difference in basin size and elevation between big and little g pairs.\n\n\nCode\nsites_big &lt;- siteinfo2 %&gt;% filter(designation == \"big\") %&gt;% select(subbasin, site_name, area_sqmi, elev_ft) %&gt;% rename(site_name_big = site_name, area_sqmi_big = area_sqmi, elev_ft_big = elev_ft)\nsites_little &lt;- siteinfo2 %&gt;% filter(designation == \"little\") %&gt;% select(subbasin, site_name, area_sqmi, elev_ft) %&gt;% rename(site_name_little = site_name, area_sqmi_little = area_sqmi, elev_ft_little = elev_ft)\nareaelev_tib &lt;- sites_little %&gt;% left_join(sites_big) %&gt;% \n  mutate(area_sqmi_diff = (area_sqmi_little - area_sqmi_big),\n         area_sqmi_reldiff = (area_sqmi_little - area_sqmi_big) / area_sqmi_little,\n         elev_ft_diff = (elev_ft_little - elev_ft_big),\n         elev_ft_reldiff = (elev_ft_little - elev_ft_big) / elev_ft_little) %&gt;% \n  select(subbasin, site_name_big, site_name_little, \n         area_sqmi_big, area_sqmi_little, elev_ft_big, elev_ft_little,\n         area_sqmi_diff, area_sqmi_reldiff, elev_ft_diff, elev_ft_reldiff)\ndim(areaelev_tib)\n\n\n[1] 99 11\n\n\nCode\nhead(areaelev_tib)\n\n\n# A tibble: 6 × 11\n  subbasin   site_name_big   site_name_little area_sqmi_big area_sqmi_little\n  &lt;chr&gt;      &lt;chr&gt;           &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n1 West Brook West Brook 0    Avery Brook               11.4            2.83 \n2 West Brook West Brook NWIS Avery Brook               11.4            2.83 \n3 West Brook West Brook 0    Jimmy Brook               11.4            0.974\n4 West Brook West Brook NWIS Jimmy Brook               11.4            0.974\n5 West Brook West Brook 0    Mitchell Brook            11.4            0.351\n6 West Brook West Brook NWIS Mitchell Brook            11.4            0.351\n# ℹ 6 more variables: elev_ft_big &lt;dbl&gt;, elev_ft_little &lt;dbl&gt;,\n#   area_sqmi_diff &lt;dbl&gt;, area_sqmi_reldiff &lt;dbl&gt;, elev_ft_diff &lt;dbl&gt;,\n#   elev_ft_reldiff &lt;dbl&gt;",
    "crumbs": [
      "Covariates",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Landscape Covariates</span>"
    ]
  },
  {
    "objectID": "Covariates/LandscapeCovariates.html#river-distance",
    "href": "Covariates/LandscapeCovariates.html#river-distance",
    "title": "6  Landscape Covariates",
    "section": "6.6 River distance",
    "text": "6.6 River distance\nGet subbasins\n\n\nCode\nmysubbasins &lt;- unique(siteinfo2$subbasin)\nmysubbasins\n\n\n [1] \"West Brook\"     \"Paine Run\"      \"Piney River\"    \"Staunton River\"\n [5] \"Big Creek\"      \"Coal Creek\"     \"McGee Creek\"    \"Duck Creek\"    \n [9] \"Shields River\"  \"Snake River\"    \"Donner Blitzen\"\n\n\nConvert flowline objects\n\n\nCode\nnfflat &lt;- line2network(sf = st_transform(st_as_sf(streams_list[[1]]), \"+proj=utm +zone=11 +ellps=GRS80 +datum=NAD83\"))\n\n\n\n Units: metre \n\n Removed 36 segments with lengths shorter than the connectivity tolerance. \n\n\nCode\nwesbro &lt;- line2network(sf = st_transform(st_as_sf(streams_list[[2]]), \"+proj=utm +zone=18 +ellps=GRS80 +datum=NAD83\"))\n\n\n\n Units: metre \n\n Removed 2 segments with lengths shorter than the connectivity tolerance. \n\n\nCode\ndonblit &lt;- line2network(sf = st_transform(st_as_sf(streams_list[[3]]), \"+proj=utm +zone=11 +ellps=GRS80 +datum=NAD83\"))\n\n\n\n Units: metre \n\n Removed 4 segments with lengths shorter than the connectivity tolerance. \n\n\nCode\npaine &lt;- line2network(sf = st_transform(st_as_sf(streams_list[[4]]), \"+proj=utm +zone=17 +ellps=GRS80 +datum=NAD83\"))\n\n\n\n Units: metre \n\n Removed 1 segments with lengths shorter than the connectivity tolerance. \n\n\nCode\npiney &lt;- line2network(sf = st_transform(st_as_sf(streams_list[[5]]), \"+proj=utm +zone=17 +ellps=GRS80 +datum=NAD83\"))\n\n\n\n Units: metre \n\n Removed 1 segments with lengths shorter than the connectivity tolerance. \n\n\nCode\nstaunt &lt;- line2network(sf = st_transform(st_as_sf(streams_list[[6]]), \"+proj=utm +zone=17 +ellps=GRS80 +datum=NAD83\"))\n\n\n\n Units: metre \n\n\nCode\nduck &lt;- line2network(sf = st_transform(st_as_sf(streams_list[[7]]), \"+proj=utm +zone=12 +ellps=GRS80 +datum=NAD83\"))\n\n\n\n Units: metre \n\n\nCode\nshield &lt;- line2network(sf = st_transform(st_as_sf(streams_list[[8]]), \"+proj=utm +zone=12 +ellps=GRS80 +datum=NAD83\"))\n\n\n\n Units: metre \n\n Removed 2 segments with lengths shorter than the connectivity tolerance. \n\n\nCode\nspread &lt;- line2network(sf = st_transform(st_as_sf(streams_list[[9]]), \"+proj=utm +zone=12 +ellps=GRS80 +datum=NAD83\"))\n\n\n\n Units: metre \n\n Removed 4 segments with lengths shorter than the connectivity tolerance. \n\n\nCode\nflow_list &lt;- list(wesbro, paine, piney, staunt, nfflat, nfflat, nfflat, duck, shield, spread, donblit)\n\n\nCalulate river distance between big and little g pairs in loop\n\n\nCode\ntib_list1 &lt;- list()\ntib_list2 &lt;- list()\ntib_list3 &lt;- list()\n\nutmzones &lt;- c(18, 17, 17, 17, 11, 11, 11, 12, 12, 12, 11)\n\nfor (k in 1:length(mysubbasins)) {\n  # select sites\n  sites_big &lt;- st_transform(st_as_sf(siteinfo2, coords = c(\"long\", \"lat\"), crs = 4326) %&gt;% filter(subbasin == mysubbasins[k], designation == \"big\"), paste(\"+proj=utm +zone=\", utmzones[k], \" +ellps=GRS80 +datum=NAD83\", sep = \"\"))\n  sites_little &lt;- st_transform(st_as_sf(siteinfo2, coords = c(\"long\", \"lat\"), crs = 4326) %&gt;% filter(subbasin == mysubbasins[k], designation == \"little\"), paste(\"+proj=utm +zone=\", utmzones[k], \" +ellps=GRS80 +datum=NAD83\", sep = \"\"))\n  # convert sites\n  sites_big_riv &lt;- xy2segvert(x = st_coordinates(sites_big)[,1], y = st_coordinates(sites_big)[,2], rivers = flow_list[[k]])\n  sites_little_riv &lt;- xy2segvert(x = st_coordinates(sites_little)[,1], y = st_coordinates(sites_little)[,2], rivers = flow_list[[k]])\n  # compute river distance in loop\n  for (i in 1:dim(sites_big)[1]) {\n    for (j in 1:dim(sites_little)[1]) {\n      tib_list3[[j]] &lt;- tibble(site_name_big = sites_big$site_name[i],\n                               site_name_little = sites_little$site_name[j],\n                               riverdist_km = riverdistance(startseg = sites_big_riv$seg[i], startvert = sites_big_riv$vert[i],\n                                                            endseg = sites_little_riv$seg[j], endvert = sites_little_riv$vert[j], \n                                                            rivers = flow_list[[k]]) / 1000)\n      }\n    tib_list2[[i]] &lt;- do.call(rbind, tib_list3)\n    tib_list3 &lt;- list()\n  }\n  tib_list1[[k]] &lt;- do.call(rbind, tib_list2)\n  tib_list2 &lt;- list()\n}\nrivdist_tib &lt;- do.call(rbind, tib_list1)\nhead(rivdist_tib)\n\n\n# A tibble: 6 × 3\n  site_name_big site_name_little  riverdist_km\n  &lt;chr&gt;         &lt;chr&gt;                    &lt;dbl&gt;\n1 West Brook 0  Avery Brook               9.35\n2 West Brook 0  Jimmy Brook               5.52\n3 West Brook 0  Mitchell Brook            5.22\n4 West Brook 0  Obear Brook Lower         5.58\n5 West Brook 0  Sanderson Brook           7.38\n6 West Brook 0  West Brook Lower          4.77",
    "crumbs": [
      "Covariates",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Landscape Covariates</span>"
    ]
  },
  {
    "objectID": "Covariates/LandscapeCovariates.html#landcover",
    "href": "Covariates/LandscapeCovariates.html#landcover",
    "title": "6  Landscape Covariates",
    "section": "6.7 Landcover",
    "text": "6.7 Landcover\nLoad 2020 NLCD raster files for each region\n\n\nCode\nnlcd_list &lt;- list()\nnlcd_files &lt;- list.files(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Spatial data/NLCD/NLCD_2020\")\nfor (i in 1:length(nlcd_files)) {\n  nlcd_list[[i]] &lt;- rast(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Spatial data/NLCD/NLCD_2020/\", nlcd_files[i], sep = \"\"))\n}\nnlcd &lt;- do.call(merge, nlcd_list)\n\n\n\n|---------|---------|---------|---------|\n=========================\n                                          \n\n\nCode\nnames(nlcd) &lt;- c(\"lccode\")\n\n\nReproject watershed polygons to match NLCD (Albers equal area) and trim to focal big g little g sites.\n\n\nCode\nsheds_aea &lt;- project(sheds, nlcd)\n\n\nView NLCD rasters for each big G\n\n\nCode\nmysites &lt;- c(\"West Brook NWIS\", \"Paine Run 10\", \"Piney River 10\", \"Staunton River 10\", \"BigCreekLower\", \"CoalCreekLower\", \"McGeeCreekLower\", \"EF Duck Creek be HF\", \"Shields River ab Smith NWIS\", \"Spread Creek Dam\", \"Donner Blitzen River nr Frenchglen NWIS\")\nnlcd_big_list &lt;- list()\nfor (i in 1:length(mysites)) { nlcd_big_list[[i]] &lt;- crop(nlcd, sheds_aea %&gt;% filter(site_name == mysites[i]), mask = TRUE) }\n\n\n\nWest BrookPaine RunPiney RiverStaunton RiverBig CreekCoal CreekMcGee CreekDuck CreekShields RiverDuck CreekDonner-Blitzen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCalculate proportional cover by each landcover class for each watershed.\n\n\nCode\nmysites &lt;- siteinfo2$site_name\ntiblist &lt;- list()\nfor (i in 1:length(mysites)) {\n  bclc &lt;- crop(nlcd, sheds_aea %&gt;% filter(site_name == mysites[i]), mask = TRUE)\n  #plot(bclc, main = mysites[i])\n  bclc_tab &lt;- table(values(bclc)[!is.na(values(bclc))]) / sum(!is.na(values(bclc)))\n  names(bclc_tab) &lt;- paste(\"nlcd_\", names(bclc_tab), sep = \"\")\n  tiblist[[i]] &lt;- tibble(as.data.frame(bclc_tab)) %&gt;% \n    rename(class = Var1, prop_cover = Freq) %&gt;% \n    mutate(site_name = mysites[i]) %&gt;% \n    select(site_name, class, prop_cover)\n}\nnlcd_cover &lt;- do.call(rbind, tiblist)\n\n\nJoin big G proportional dominant cover to little g’s by subbasin and calculate difference.\n\n\nCode\nnlcd_cover &lt;- nlcd_cover %&gt;% left_join(siteinfo2 %&gt;% select(site_name, subbasin, designation))\nnlcd_cover_big &lt;- nlcd_cover %&gt;% filter(designation == \"big\") %&gt;% group_by(subbasin, site_name) %&gt;% filter(prop_cover == max(prop_cover)) %&gt;% rename(site_name_big = site_name, prop_cover_big = prop_cover) %&gt;% select(-designation)\n\nnlcd_cover_join &lt;- nlcd_cover %&gt;% filter(designation == \"little\") %&gt;% rename(site_name_little = site_name, prop_cover_little = prop_cover) %&gt;% select(-designation) %&gt;% left_join(nlcd_cover_big) %&gt;% filter(!is.na(site_name_big)) %&gt;% mutate(prop_cover_diff = prop_cover_little - prop_cover_big)\n\nhead(nlcd_cover_join)\n\n\n# A tibble: 6 × 7\n  site_name_little class prop_cover_little subbasin site_name_big prop_cover_big\n  &lt;chr&gt;            &lt;fct&gt;             &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;                  &lt;dbl&gt;\n1 Avery Brook      nlcd…             0.562 West Br… West Brook 0           0.519\n2 Avery Brook      nlcd…             0.562 West Br… West Brook N…          0.519\n3 Jimmy Brook      nlcd…             0.495 West Br… West Brook 0           0.519\n4 Jimmy Brook      nlcd…             0.495 West Br… West Brook N…          0.519\n5 Mitchell Brook   nlcd…             0.710 West Br… West Brook 0           0.519\n6 Mitchell Brook   nlcd…             0.710 West Br… West Brook N…          0.519\n# ℹ 1 more variable: prop_cover_diff &lt;dbl&gt;",
    "crumbs": [
      "Covariates",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Landscape Covariates</span>"
    ]
  },
  {
    "objectID": "Covariates/LandscapeCovariates.html#join-covariate-data",
    "href": "Covariates/LandscapeCovariates.html#join-covariate-data",
    "title": "6  Landscape Covariates",
    "section": "6.8 Join covariate data",
    "text": "6.8 Join covariate data\nJoin covariate data\n\n\nCode\ncovariates &lt;- overlap_tib %&gt;% left_join(areaelev_tib) %&gt;% left_join(rivdist_tib) %&gt;% left_join(nlcd_cover_join)\ncovariates\n\n\n# A tibble: 99 × 18\n   subbasin   site_name_big site_name_little    shared_area_km2 shared_area_prop\n   &lt;chr&gt;      &lt;chr&gt;         &lt;chr&gt;                         &lt;dbl&gt;            &lt;dbl&gt;\n 1 West Brook West Brook 0  Avery Brook                   7.35            0.249 \n 2 West Brook West Brook 0  Jimmy Brook                   2.53            0.0856\n 3 West Brook West Brook 0  Mitchell Brook                0.912           0.0309\n 4 West Brook West Brook 0  Obear Brook Lower             1.47            0.0497\n 5 West Brook West Brook 0  Sanderson Brook               4.56            0.154 \n 6 West Brook West Brook 0  West Brook Lower             22.1             0.747 \n 7 West Brook West Brook 0  West Brook Upper             16.5             0.558 \n 8 West Brook West Brook 0  West Brook Reservo…          16.1             0.545 \n 9 West Brook West Brook 0  West Whately Brook            1.28            0.0433\n10 West Brook West Brook 0  Avery Brook NWIS              7.35            0.249 \n# ℹ 89 more rows\n# ℹ 13 more variables: area_sqmi_big &lt;dbl&gt;, area_sqmi_little &lt;dbl&gt;,\n#   elev_ft_big &lt;dbl&gt;, elev_ft_little &lt;dbl&gt;, area_sqmi_diff &lt;dbl&gt;,\n#   area_sqmi_reldiff &lt;dbl&gt;, elev_ft_diff &lt;dbl&gt;, elev_ft_reldiff &lt;dbl&gt;,\n#   riverdist_km &lt;dbl&gt;, class &lt;fct&gt;, prop_cover_little &lt;dbl&gt;,\n#   prop_cover_big &lt;dbl&gt;, prop_cover_diff &lt;dbl&gt;\n\n\nView pairs plot\n\n\nCode\nggpairs(covariates %&gt;% select(shared_area_prop, area_sqmi_reldiff, elev_ft_reldiff, riverdist_km, prop_cover_diff))\n\n\n\n\n\n\n\n\n\nWrite data file\n\n\nCode\nwrite_csv(covariates, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Covariates/EcoDrought_LandscapeCovariates.csv\")",
    "crumbs": [
      "Covariates",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Landscape Covariates</span>"
    ]
  },
  {
    "objectID": "Covariates/PASTA.html",
    "href": "Covariates/PASTA.html",
    "title": "7  PASTA",
    "section": "",
    "text": "7.1 Data\nPurpose: use paired air-stream temperature signal analysis to estimate daily groundwater contributions to streamflow",
    "crumbs": [
      "Covariates",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>PASTA</span>"
    ]
  },
  {
    "objectID": "Covariates/PASTA.html#data",
    "href": "Covariates/PASTA.html#data",
    "title": "7  PASTA",
    "section": "",
    "text": "7.1.1 Site information\n\n\nCode\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nDefine G-g clusters/sub-basins\n\n\nCode\nsiteinfo2 &lt;- siteinfo %&gt;% \n  filter(!site_name %in% c(\"WoundedBuckCreek\", \"Brackett Creek\", \"South River Conway NWIS\", \n                           \"Shields River nr Livingston NWIS\", \"North Fork Flathead River NWIS\", \n                           \"Pacific Creek at Moran NWIS\")) %&gt;%\n  mutate(designation = ifelse(site_name %in% c(\"Donner Blitzen River nr Frenchglen NWIS\", \n                                               \"BigCreekLower\", \"CoalCreekLower\", \"McGeeCreekLower\", \n                                               \"West Brook NWIS\", \"West Brook 0\", \n                                               \"Paine Run 10\", \"Staunton River 10\", \"Piney River 10\", \n                                               \"Shields River Valley Ranch\", \"Shields River ab Smith NWIS\", \n                                               \"EF Duck Creek be HF\",\n                                               \"Spread Creek Dam\"), \"big\", \"little\"))\n\ndatatable(siteinfo2 %&gt;% \n            arrange(region, basin, subbasin, designation) %&gt;% \n            mutate(lat = round(lat, digits = 2), \n                   long = round(long, digits = 2), \n                   area_sqmi = round(area_sqmi, digits = 2), \n                   elev_ft = round(elev_ft, digits = 0)),\n          caption = \"EcoDrought monitoring locations and metadata.\")\n\n\n\n\n\n\n\n\n7.1.2 Stream temp\n\n\nCode\ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_Raw_ECODandNWIS.csv\") %&gt;% \n  filter(site_name %in% siteinfo2$site_name) %&gt;% \n  mutate(datetime = floor_date(datetime, unit = \"hour\")) %&gt;%\n  group_by(region, basin, subbasin, site_name, datetime) %&gt;% \n  summarise(tempc = mean(tempc), TempReliability = min(TempReliability), \n            flow = mean(flow), DischargeReliability = min(DischargeReliability)) %&gt;%\n  ungroup() %&gt;%\n  mutate(flow = ifelse(DischargeReliability == 0, NA, flow)) %&gt;% \n  group_by(region, basin, subbasin, site_name) %&gt;%\n  mutate(z_flow = scale(log(flow+0.0001))) %&gt;%\n  ungroup()\ntz(dat$datetime)\n\n\n[1] \"UTC\"\n\n\nCode\ndat\n\n\n# A tibble: 3,554,087 × 10\n   region basin    subbasin  site_name datetime            tempc TempReliability\n   &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;     &lt;dttm&gt;              &lt;dbl&gt;           &lt;dbl&gt;\n 1 Flat   Flathead Big Creek Big Cree… 2018-09-10 20:00:00    NA               0\n 2 Flat   Flathead Big Creek Big Cree… 2018-09-10 21:00:00    NA               0\n 3 Flat   Flathead Big Creek Big Cree… 2018-09-10 22:00:00    NA               0\n 4 Flat   Flathead Big Creek Big Cree… 2018-09-10 23:00:00    NA               0\n 5 Flat   Flathead Big Creek Big Cree… 2018-09-11 00:00:00    NA               0\n 6 Flat   Flathead Big Creek Big Cree… 2018-09-11 01:00:00    NA               0\n 7 Flat   Flathead Big Creek Big Cree… 2018-09-11 02:00:00    NA               0\n 8 Flat   Flathead Big Creek Big Cree… 2018-09-11 03:00:00    NA               0\n 9 Flat   Flathead Big Creek Big Cree… 2018-09-11 04:00:00    NA               0\n10 Flat   Flathead Big Creek Big Cree… 2018-09-11 05:00:00    NA               0\n# ℹ 3,554,077 more rows\n# ℹ 3 more variables: flow &lt;dbl&gt;, DischargeReliability &lt;dbl&gt;, z_flow &lt;dbl[,1]&gt;\n\n\n\n\n7.1.3 Air temp\nApply air temperature data from a single site within/near each sub-basin to all water temperature/flow sites within the same sub-basin. This implicitly assumes that air temperature is homogeneous within each sub-basin, which is an oversimplification, but necessary as we only have air temperature observations at a single site within most sub-basins.\nImportantly, SNOTEL data appears to be a reasonable surrogate for in-situ air temperature, at least as shown for the Shields River, Snake River/Spread Creek, and Duck Creek. To maintain consistency across basins (at least in western US) and years where in-situ data is missing, use SNOTEL air temperature data for all western US basins. Note that Duck Creek gets Shields River SNOTEL data, as this was the nearest SNOTEL site, and showed strong concordance with in-situ data. Additionally, using SNOTEL data as a surrogate for in-situ air temperature data may not be as robust in the Donner-Blitzen, where the SNOTEL site is at a considerably higher elevation than the stream monitoring locations.\n\n\n\n\n\nsubbasin\ntemp_site\n\n\n\n\nWest Brook\nWest Brook Central\n\n\nPaine Run\nPaine Run 10\n\n\nStaunton River\nStaunton River 10\n\n\nPiney River\nPiney River 10\n\n\nBig Creek\nSNOTEL Emery Creek\n\n\nCoal Creek\nSNOTEL Emery Creek\n\n\nMcGee Creek\nSNOTEL Emery Creek\n\n\nShields River\nSNOTEL Porcupine\n\n\nDuck Creek\nSNOTEL Porcupine\n\n\nSnake River\nSNOTEL Base Camp\n\n\nDonner Blitzen\nSNOTEL Silvies\n\n\n\n\n\nLoad air temperature data\n\n\nCode\n# West Brook\nairtemp_wb &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw Data/Mass/WestBrookCentral_AirTemp_31December2019_to_7July2024.csv\")\ntz(airtemp_wb$datetime_est) &lt;- \"EST\"\nairtemp_wb$datetime &lt;- with_tz(airtemp_wb$datetime_est, \"UTC\")\nairtemp_wb &lt;- airtemp_wb %&gt;% \n  select(datetime, tempc_air) %&gt;% \n  mutate(datetime = floor_date(datetime, unit = \"hour\")) %&gt;%\n  group_by(datetime) %&gt;% \n  summarise(tempc_air = mean(tempc_air)) %&gt;%\n  ungroup() %&gt;%\n  mutate(basin = \"West Brook\", subbasin = \"West Brook\", source = \"SOConte\") %&gt;% \n  select(basin, subbasin, source, datetime, tempc_air)\n\n\n# Shenandoah\nairtemp_shen &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Virg/Shen_BigG_TempEtc_hourly_UVA.csv\") %&gt;%\n  rename(tempc_air = airtempc_mean) %&gt;%\n  select(site_id, datetime, tempc_air) %&gt;%\n  left_join(siteinfo %&gt;% select(site_id, site_name, region, basin, subbasin))\ntz(airtemp_shen$datetime) &lt;- \"EST\"\nairtemp_shen$datetime &lt;- with_tz(airtemp_shen$datetime, \"UTC\")\nairtemp_shen &lt;- airtemp_shen %&gt;% \n  mutate(datetime = floor_date(datetime, unit = \"hour\")) %&gt;%\n  group_by(region, basin, subbasin, site_name, datetime) %&gt;% \n  summarise(tempc_air = mean(tempc_air)) %&gt;%\n  ungroup() %&gt;%\n  select(basin, subbasin, datetime, tempc_air) %&gt;%\n  mutate(source = \"UVA\")\n\n\n# Flathead\nairtemp_flat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Flathead/SNOTEL_469_EmeryCk_4340fasl_AirTemp.csv\") %&gt;%\n  mutate(datetime = mdy_hm(datetime),\n         tempc_air = (tempf - 32) * (5/9),\n         basin = \"Flathead\",\n         source = \"SNOTEL\")\ntz(airtemp_flat$datetime) &lt;- \"PST\" # ALL SNOTEL DATE/TIMES ARE IN PST\nairtemp_flat$datetime &lt;- with_tz(airtemp_flat$datetime, \"UTC\")\nairtemp_flat &lt;- airtemp_flat %&gt;% \n  mutate(datetime = floor_date(datetime, unit = \"hour\")) %&gt;%\n  group_by(basin, source, datetime) %&gt;% \n  summarise(tempc_air = mean(tempc_air)) %&gt;%\n  ungroup()\nairtemp_flat &lt;- bind_rows(airtemp_flat %&gt;% mutate(subbasin = \"Big Creek\"),\n                          airtemp_flat %&gt;% mutate(subbasin = \"Coal Creek\"),\n                          airtemp_flat %&gt;% mutate(subbasin = \"McGee Creek\"))\n\n\n# Shields\nairtemp_shields &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/SNOTEL_700_Porcupine_6480fasl_AirTemp.csv\") %&gt;%\n  mutate(datetime = mdy_hm(date),\n         tempc_air = (tempf - 32) * (5/9),\n         basin = \"Shields River\",\n         subbasin = \"Shields River\",\n         source = \"SNOTEL\")\ntz(airtemp_shields$datetime) &lt;- \"PST\" # ALL SNOTEL DATE/TIMES ARE IN PST\nairtemp_shields$datetime &lt;- with_tz(airtemp_shields$datetime, \"UTC\")\nairtemp_shields &lt;- airtemp_shields %&gt;% \n  mutate(datetime = floor_date(datetime, unit = \"hour\")) %&gt;%\n  group_by(basin, subbasin, source, datetime) %&gt;% \n  summarise(tempc_air = mean(tempc_air)) %&gt;%\n  ungroup()\n\n\n# Snake\nairtemp_snake &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/SNOTEL_314_BaseCampPacific_7040fasl_AirTemp.csv\") %&gt;%\n  mutate(datetime = mdy_hm(datetime),\n         tempc_air = (tempf - 32) * (5/9),\n         basin = \"Snake River\",\n         subbasin = \"Snake River\",\n         source = \"SNOTEL\")\ntz(airtemp_snake$datetime) &lt;- \"PST\" # ALL SNOTEL DATE/TIMES ARE IN PST\nairtemp_snake$datetime &lt;- with_tz(airtemp_snake$datetime, \"UTC\")\nairtemp_snake &lt;- airtemp_snake %&gt;% \n  mutate(datetime = floor_date(datetime, unit = \"hour\")) %&gt;%\n  group_by(basin, subbasin, source, datetime) %&gt;% \n  summarise(tempc_air = mean(tempc_air)) %&gt;%\n  ungroup()\n\n\n# Donner-Blitzen\nairtemp_db &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Oreg/SNOTEL_759_Silvies_7000fasl_AirTemp.csv\") %&gt;%\n  mutate(datetime = mdy_hm(date),\n         tempc_air = (tempf - 32) * (5/9),\n         basin = \"Donner Blitzen\",\n         subbasin = \"Donner Blitzen\",\n         source = \"SNOTEL\")\ntz(airtemp_db$datetime) &lt;- \"PST\" # ALL SNOTEL DATE/TIMES ARE IN PST\nairtemp_db$datetime &lt;- with_tz(airtemp_db$datetime, \"UTC\")\nairtemp_db &lt;- airtemp_db %&gt;% \n  mutate(datetime = floor_date(datetime, unit = \"hour\")) %&gt;%\n  group_by(basin, subbasin, source, datetime) %&gt;% \n  summarise(tempc_air = mean(tempc_air)) %&gt;%\n  ungroup()\n\n# headers\nhead(airtemp_wb)\n\n\n# A tibble: 6 × 5\n  basin      subbasin   source  datetime            tempc_air\n  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;   &lt;dttm&gt;                  &lt;dbl&gt;\n1 West Brook West Brook SOConte 2019-12-31 18:00:00    0.920 \n2 West Brook West Brook SOConte 2019-12-31 19:00:00    0.508 \n3 West Brook West Brook SOConte 2019-12-31 20:00:00    0.371 \n4 West Brook West Brook SOConte 2019-12-31 21:00:00    0.149 \n5 West Brook West Brook SOConte 2019-12-31 22:00:00    0.0378\n6 West Brook West Brook SOConte 2019-12-31 23:00:00    0.01  \n\n\nCode\nhead(airtemp_shen)\n\n\n# A tibble: 6 × 5\n  basin     subbasin  datetime            tempc_air source\n  &lt;chr&gt;     &lt;chr&gt;     &lt;dttm&gt;                  &lt;dbl&gt; &lt;chr&gt; \n1 Paine Run Paine Run 2014-10-06 17:00:00      18.6 UVA   \n2 Paine Run Paine Run 2014-10-06 18:00:00      19.4 UVA   \n3 Paine Run Paine Run 2014-10-06 19:00:00      19.3 UVA   \n4 Paine Run Paine Run 2014-10-06 20:00:00      19.4 UVA   \n5 Paine Run Paine Run 2014-10-06 21:00:00      18.9 UVA   \n6 Paine Run Paine Run 2014-10-06 22:00:00      18.2 UVA   \n\n\nCode\nhead(airtemp_flat)\n\n\n# A tibble: 6 × 5\n  basin    source datetime            tempc_air subbasin \n  &lt;chr&gt;    &lt;chr&gt;  &lt;dttm&gt;                  &lt;dbl&gt; &lt;chr&gt;    \n1 Flathead SNOTEL 2017-01-01 08:00:00     -5.61 Big Creek\n2 Flathead SNOTEL 2017-01-01 09:00:00     -5.61 Big Creek\n3 Flathead SNOTEL 2017-01-01 10:00:00     -5.39 Big Creek\n4 Flathead SNOTEL 2017-01-01 11:00:00     -5.28 Big Creek\n5 Flathead SNOTEL 2017-01-01 12:00:00     -4.72 Big Creek\n6 Flathead SNOTEL 2017-01-01 13:00:00     -5.39 Big Creek\n\n\nCode\nhead(airtemp_shields)\n\n\n# A tibble: 6 × 5\n  basin         subbasin      source datetime            tempc_air\n  &lt;chr&gt;         &lt;chr&gt;         &lt;chr&gt;  &lt;dttm&gt;                  &lt;dbl&gt;\n1 Shields River Shields River SNOTEL 2013-01-01 08:00:00     -7.5 \n2 Shields River Shields River SNOTEL 2013-01-01 09:00:00     -7.22\n3 Shields River Shields River SNOTEL 2013-01-01 10:00:00     -7   \n4 Shields River Shields River SNOTEL 2013-01-01 11:00:00     -6.72\n5 Shields River Shields River SNOTEL 2013-01-01 12:00:00     -6.22\n6 Shields River Shields River SNOTEL 2013-01-01 13:00:00     -5.39\n\n\nCode\nhead(airtemp_snake)\n\n\n# A tibble: 6 × 5\n  basin       subbasin    source datetime            tempc_air\n  &lt;chr&gt;       &lt;chr&gt;       &lt;chr&gt;  &lt;dttm&gt;                  &lt;dbl&gt;\n1 Snake River Snake River SNOTEL 2013-01-01 08:00:00     -13.7\n2 Snake River Snake River SNOTEL 2013-01-01 09:00:00     -13.7\n3 Snake River Snake River SNOTEL 2013-01-01 10:00:00     -13.6\n4 Snake River Snake River SNOTEL 2013-01-01 11:00:00     -13.6\n5 Snake River Snake River SNOTEL 2013-01-01 12:00:00     -13.6\n6 Snake River Snake River SNOTEL 2013-01-01 13:00:00     -13.6\n\n\nCode\nhead(airtemp_db)\n\n\n# A tibble: 6 × 5\n  basin          subbasin       source datetime            tempc_air\n  &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;  &lt;dttm&gt;                  &lt;dbl&gt;\n1 Donner Blitzen Donner Blitzen SNOTEL 2019-01-01 08:00:00     -11.3\n2 Donner Blitzen Donner Blitzen SNOTEL 2019-01-01 09:00:00     -11.6\n3 Donner Blitzen Donner Blitzen SNOTEL 2019-01-01 10:00:00     -11.7\n4 Donner Blitzen Donner Blitzen SNOTEL 2019-01-01 11:00:00     -11.7\n5 Donner Blitzen Donner Blitzen SNOTEL 2019-01-01 12:00:00     -11.6\n6 Donner Blitzen Donner Blitzen SNOTEL 2019-01-01 13:00:00     -12.3\n\n\n\n7.1.3.1 In-situ vs. SNOTEL\nAl-Chokhachy has in-situ air temperature for Duck Creek, the Shields River, and Spread Creek. For Shields and Spread, compare in-situ air temperature measurements with SNOTEL data. Can we justify using SNOTEL data for these and other western basins?\nLoad in-situ data\n\n\nCode\n# Duck\nairtemp_insitu_duck &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/duck_air_hourly_021625.csv\") %&gt;%\n  select(date, time, temperature) %&gt;%\n  rename(\"tempc_air\" = \"temperature\") %&gt;%\n  mutate(datetime = as_datetime(paste(date, time, sep = \" \")),\n         basin = \"Duck Creek\",\n         subbasin = \"Duck Creek\",\n         source = \"Al-Ch\") %&gt;%\n  select(basin, subbasin, source, datetime, tempc_air)\ntz(airtemp_insitu_duck$datetime) &lt;- \"MST\"\nairtemp_insitu_duck$datetime &lt;- with_tz(airtemp_insitu_duck$datetime, \"UTC\")\n\n# Shields\nairtemp_insitu_shields &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/Shields_air_hourly_021625.csv\") %&gt;%\n  select(date, time, temperature) %&gt;%\n  rename(\"tempc_air\" = \"temperature\") %&gt;%\n  mutate(datetime = as_datetime(paste(date, time, sep = \" \")),\n         basin = \"Shields River\",\n         subbasin = \"Shields River\",\n         source = \"Al-Ch\") %&gt;%\n  select(basin, subbasin, source, datetime, tempc_air)\ntz(airtemp_insitu_shields$datetime) &lt;- \"MST\"\nairtemp_insitu_shields$datetime &lt;- with_tz(airtemp_insitu_shields$datetime, \"UTC\")\n\n# Spread\nairtemp_insitu_spread &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Raw data/Al-Chokhachy/Spread_air_hourly_021625.csv\") %&gt;%\n  select(date, time, temperature) %&gt;%\n  rename(\"tempc_air\" = \"temperature\") %&gt;%\n  mutate(datetime = as_datetime(paste(date, time, sep = \" \")),\n         basin = \"Snake River\",\n         subbasin = \"Snake River\",\n         source = \"Al-Ch\") %&gt;%\n  select(basin, subbasin, source, datetime, tempc_air)\ntz(airtemp_insitu_spread$datetime) &lt;- \"MST\"\nairtemp_insitu_spread$datetime &lt;- with_tz(airtemp_insitu_spread$datetime, \"UTC\")\n\nairtemp_insitu_duck\n\n\n# A tibble: 92,400 × 5\n   basin      subbasin   source datetime            tempc_air\n   &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dttm&gt;                  &lt;dbl&gt;\n 1 Duck Creek Duck Creek Al-Ch  2014-06-18 07:52:51      5.30\n 2 Duck Creek Duck Creek Al-Ch  2014-06-18 08:52:51      4.42\n 3 Duck Creek Duck Creek Al-Ch  2014-06-18 09:52:51      3.69\n 4 Duck Creek Duck Creek Al-Ch  2014-06-18 10:52:51      3.58\n 5 Duck Creek Duck Creek Al-Ch  2014-06-18 11:52:51      3.36\n 6 Duck Creek Duck Creek Al-Ch  2014-06-18 12:52:51      3.46\n 7 Duck Creek Duck Creek Al-Ch  2014-06-18 13:52:51      4.14\n 8 Duck Creek Duck Creek Al-Ch  2014-06-18 14:52:51      5.35\n 9 Duck Creek Duck Creek Al-Ch  2014-06-18 15:52:51      7.12\n10 Duck Creek Duck Creek Al-Ch  2014-06-18 16:52:51     15.1 \n# ℹ 92,390 more rows\n\n\nCode\nairtemp_insitu_shields\n\n\n# A tibble: 116,979 × 5\n   basin         subbasin      source datetime            tempc_air\n   &lt;chr&gt;         &lt;chr&gt;         &lt;chr&gt;  &lt;dttm&gt;                  &lt;dbl&gt;\n 1 Shields River Shields River Al-Ch  2011-07-09 06:04:56      6.12\n 2 Shields River Shields River Al-Ch  2011-07-09 07:04:56      6.24\n 3 Shields River Shields River Al-Ch  2011-07-09 08:04:56      5.98\n 4 Shields River Shields River Al-Ch  2011-07-09 09:04:56      3.80\n 5 Shields River Shields River Al-Ch  2011-07-09 10:04:56      2.13\n 6 Shields River Shields River Al-Ch  2011-07-09 11:04:56      1.53\n 7 Shields River Shields River Al-Ch  2011-07-09 12:04:56      1.67\n 8 Shields River Shields River Al-Ch  2011-07-09 13:04:56      1.31\n 9 Shields River Shields River Al-Ch  2011-07-09 14:04:56      2.44\n10 Shields River Shields River Al-Ch  2011-07-09 15:04:56      4.95\n# ℹ 116,969 more rows\n\n\nCode\nairtemp_insitu_spread\n\n\n# A tibble: 117,992 × 5\n   basin       subbasin    source datetime            tempc_air\n   &lt;chr&gt;       &lt;chr&gt;       &lt;chr&gt;  &lt;dttm&gt;                  &lt;dbl&gt;\n 1 Snake River Snake River Al-Ch  2011-07-25 20:47:52      30.2\n 2 Snake River Snake River Al-Ch  2011-07-25 21:47:52      27.4\n 3 Snake River Snake River Al-Ch  2011-07-25 22:47:52      27.2\n 4 Snake River Snake River Al-Ch  2011-07-25 23:47:52      27.2\n 5 Snake River Snake River Al-Ch  2011-07-26 00:47:52      26.9\n 6 Snake River Snake River Al-Ch  2011-07-26 01:47:52      26.5\n 7 Snake River Snake River Al-Ch  2011-07-26 02:47:52      23.0\n 8 Snake River Snake River Al-Ch  2011-07-26 03:47:52      20.0\n 9 Snake River Snake River Al-Ch  2011-07-26 04:47:52      18.3\n10 Snake River Snake River Al-Ch  2011-07-26 05:47:52      18.2\n# ℹ 117,982 more rows\n\n\n\nShields River\nHow well does in-situ air temp align with SNOTEL air temp?\n\n\nCode\ncat_shields &lt;- airtemp_shields %&gt;% select(datetime, tempc_air) %&gt;% left_join(airtemp_insitu_shields %&gt;% select(datetime, tempc_air) %&gt;% mutate(datetime = floor_date(datetime, unit = \"hour\")) %&gt;% rename(\"tempc_air_alc\" = \"tempc_air\"))\ncat_shields %&gt;% dygraph() %&gt;% dyRangeSelector()\n\n\n\n\n\n\n\n\nCode\ncat_shields %&gt;% mutate(doy = yday(datetime), year = year(datetime)) %&gt;% filter(!year %in% c(2014,2015,2024)) %&gt;%\n  ggplot(aes(x = tempc_air, y = tempc_air_alc, color = doy)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  scale_color_gradient2(midpoint = 182, low = \"orange\", mid = \"purple3\", high = \"orange\") +\n  facet_wrap(~year) + xlab(\"SNOTEL air temp (C)\") + ylab(\"In-situ air temp (C)\")\n\n\n\n\n\n\n\n\n\nNotes:\n\nThere are a few periods where the in-situ data are clearly wrong, e.g., winter 2013 and November 2016. For the latter, logger appears to be sun affected (in-situ far too warm for August).\nGenerally, diel cycles match well. Daily max temps are similar between SNOTEL and in-situ data. However, in-situ daily minimums are far lower than SNOTEL. Could this be located in a cold pit/sink?\nThere is a lot of scatter around 1:1 in the scatter plots. Some of this is probably due to slight differences in the time of sensor readings, but most of it is probably due to the issues mentioned above.\n\n\n\nSpread Creek\nHow well does in-situ air temp align with SNOTEL air temp?\n\n\nCode\ncat_spread &lt;- airtemp_snake %&gt;% select(datetime, tempc_air) %&gt;% left_join(airtemp_insitu_spread %&gt;% select(datetime, tempc_air) %&gt;% mutate(datetime = floor_date(datetime, unit = \"hour\")) %&gt;% rename(\"tempc_air_alc\" = \"tempc_air\"))\ncat_spread %&gt;% dygraph() %&gt;% dyRangeSelector()\n\n\n\n\n\n\n\n\nCode\ncat_spread %&gt;% mutate(doy = yday(datetime), year = year(datetime)) %&gt;% filter(!year %in% c(2019,2024)) %&gt;%\n  ggplot(aes(x = tempc_air, y = tempc_air_alc, color = doy)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  scale_color_gradient2(midpoint = 182, low = \"orange\", mid = \"purple3\", high = \"orange\") +\n  facet_wrap(~year) + xlab(\"SNOTEL air temp (C)\") + ylab(\"In-situ air temp (C)\")\n\n\n\n\n\n\n\n\n\nNotes:\n\nThere is only one apparent period where the in-situ data are clearly wrong: November 2016. In-situ logger appears to be sun affected (in-situ far too warm for August).\nGenerally, diel cycles match well (much better than in Shields). Daily max and min temps are similar between SNOTEL and in-situ data, particularly during summer.\nThere is some scatter around 1:1 in the scatter plots. Much of this appears to be due to ~45 min lag between sensor readings, but less of the disagreement being driven by actual disagreement between sensor readings.\n\n\n\nDuck Creek\nThe closest SNOTEL station is Porcupine in the Shields River basin. How well do these align?\n\n\nCode\ncat_duck &lt;- airtemp_shields %&gt;% select(datetime, tempc_air) %&gt;% left_join(airtemp_insitu_duck %&gt;% select(datetime, tempc_air) %&gt;% mutate(datetime = floor_date(datetime, unit = \"hour\")) %&gt;% rename(\"tempc_air_alc\" = \"tempc_air\"))\ncat_duck %&gt;% dygraph() %&gt;% dyRangeSelector()\n\n\n\n\n\n\n\n\nCode\ncat_duck %&gt;% mutate(doy = yday(datetime), year = year(datetime)) %&gt;% filter(!year %in% c(2013,2024)) %&gt;%\n  ggplot(aes(x = tempc_air, y = tempc_air_alc, color = doy)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  scale_color_gradient2(midpoint = 182, low = \"orange\", mid = \"purple3\", high = \"orange\") +\n  facet_wrap(~year) + xlab(\"SNOTEL air temp (C)\") + ylab(\"In-situ air temp (C)\")\n\n\n\n\n\n\n\n\n\nNotes:\n\nThere is only one apparent period where the in-situ data are clearly wrong: 2020. Date/times are messed up, lack AM/PMs, drives “shotgun” scatter in scatterplot\nGenerally, diel cycles match surprisingly well. Daily max and min temps are similar between SNOTEL and in-situ data, particularly during summer. Although in some years daily variability is greater for in-situ data.\nThere is some scatter around 1:1 in the scatter plots…on par with what we see in the Snake.\n\n\n\n\n7.1.3.2 Final check\nCheck time zones (all should be UTC)\n\n\nCode\ntz(airtemp_wb$datetime)\n\n\n[1] \"UTC\"\n\n\nCode\ntz(airtemp_shen$datetime)\n\n\n[1] \"UTC\"\n\n\nCode\ntz(airtemp_flat$datetime)\n\n\n[1] \"UTC\"\n\n\nCode\ntz(airtemp_shields$datetime)\n\n\n[1] \"UTC\"\n\n\nCode\ntz(airtemp_snake$datetime)\n\n\n[1] \"UTC\"\n\n\nCode\ntz(airtemp_db$datetime)\n\n\n[1] \"UTC\"\n\n\nBind basin-specific air temp and show unique subbasins\n\n\nCode\nairtemp &lt;- bind_rows(airtemp_wb, airtemp_shen, airtemp_flat, airtemp_shields, airtemp_snake, airtemp_db, airtemp_shields %&gt;% mutate(basin = \"Duck Creek\", subbasin = \"Duck Creek\"))\nunique(airtemp$subbasin)\n\n\n [1] \"West Brook\"     \"Paine Run\"      \"Piney River\"    \"Staunton River\"\n [5] \"Big Creek\"      \"Coal Creek\"     \"McGee Creek\"    \"Shields River\" \n [9] \"Snake River\"    \"Donner Blitzen\" \"Duck Creek\"    \n\n\nCode\nstr(airtemp)\n\n\ntibble [805,771 × 5] (S3: tbl_df/tbl/data.frame)\n $ basin    : chr [1:805771] \"West Brook\" \"West Brook\" \"West Brook\" \"West Brook\" ...\n $ subbasin : chr [1:805771] \"West Brook\" \"West Brook\" \"West Brook\" \"West Brook\" ...\n $ source   : chr [1:805771] \"SOConte\" \"SOConte\" \"SOConte\" \"SOConte\" ...\n $ datetime : POSIXct[1:805771], format: \"2019-12-31 18:00:00\" \"2019-12-31 19:00:00\" ...\n $ tempc_air: num [1:805771] 0.9205 0.508 0.3705 0.1487 0.0377 ...\n\n\n\n\n\n7.1.4 Join data\n\n\nCode\ndat_join &lt;- dat %&gt;% left_join(airtemp)\ndat_join\n\n\n# A tibble: 3,554,087 × 12\n   region basin    subbasin  site_name datetime            tempc TempReliability\n   &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;     &lt;dttm&gt;              &lt;dbl&gt;           &lt;dbl&gt;\n 1 Flat   Flathead Big Creek Big Cree… 2018-09-10 20:00:00    NA               0\n 2 Flat   Flathead Big Creek Big Cree… 2018-09-10 21:00:00    NA               0\n 3 Flat   Flathead Big Creek Big Cree… 2018-09-10 22:00:00    NA               0\n 4 Flat   Flathead Big Creek Big Cree… 2018-09-10 23:00:00    NA               0\n 5 Flat   Flathead Big Creek Big Cree… 2018-09-11 00:00:00    NA               0\n 6 Flat   Flathead Big Creek Big Cree… 2018-09-11 01:00:00    NA               0\n 7 Flat   Flathead Big Creek Big Cree… 2018-09-11 02:00:00    NA               0\n 8 Flat   Flathead Big Creek Big Cree… 2018-09-11 03:00:00    NA               0\n 9 Flat   Flathead Big Creek Big Cree… 2018-09-11 04:00:00    NA               0\n10 Flat   Flathead Big Creek Big Cree… 2018-09-11 05:00:00    NA               0\n# ℹ 3,554,077 more rows\n# ℹ 5 more variables: flow &lt;dbl&gt;, DischargeReliability &lt;dbl&gt;, z_flow &lt;dbl[,1]&gt;,\n#   source &lt;chr&gt;, tempc_air &lt;dbl&gt;\n\n\n\n\n7.1.5 View data\nNotes:\n\nWest Brook\n\nMitchell, Obear, and WB Lower have erroneous water temp readings after ~Aug. 31, 2021\nAll WB sites have error in F to C conversion (from Aquarius)\nMitchell, Obear, WB0, and WB Lower stream temp signals appear to be shifted forward in time considerably!\n\nDuck Creek\n\nNo air temperature data (yet)\n\nShields River, Spread Creek, and Donner Blitzen: Should compare SNOTEL air temp data against in-situ/EcoD air temp data, where available\n\n\nWest BrookPaine RunStaunton RiverBig CreekCoal CreekMcGee CreekShields RiverDuck CreekSnake RiverDonner Blitzen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView single site using dyGraphs\n\n\nCode\nmysite &lt;- \"SF Spread Creek Lower\"\ndat_join %&gt;% filter(site_name %in% mysite) %&gt;% select(datetime, tempc, tempc_air) %&gt;% dygraph(main = mysite) %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Stream temp. (deg C)\") %&gt;% dyAxis(\"y2\", label = \"Air temp. (deg C)\") %&gt;% dySeries(\"tempc\", axis = \"y\", label = \"Stream\") %&gt;% dySeries(\"tempc_air\", axis = \"y2\", label = \"Air\")\n\n\n\n\n\n\n\n\n7.1.6 Format data for PASTA\n\n\nCode\ndat2 &lt;- dat_join %&gt;% \n  filter(TempReliability == 1) %&gt;%\n  mutate(year = year(datetime),\n         yday = yday(datetime),\n         hour = hour(datetime)) %&gt;%\n  rename(airTemperature = tempc_air,\n         waterTemperature = tempc) %&gt;%\n  select(subbasin, site_name, datetime, year, yday, hour, airTemperature, waterTemperature, flow, z_flow) %&gt;%\n  filter(waterTemperature &gt;= 1, waterTemperature &lt;= 25)\nrange(dat2$waterTemperature)\n\n\n[1]  1 25\n\n\nCode\ndat2\n\n\n# A tibble: 2,166,673 × 10\n   subbasin  site_name     datetime             year  yday  hour airTemperature\n   &lt;chr&gt;     &lt;chr&gt;         &lt;dttm&gt;              &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;          &lt;dbl&gt;\n 1 Big Creek BigCreekLower 2017-09-18 18:00:00  2017   261    18           8.22\n 2 Big Creek BigCreekLower 2017-09-18 19:00:00  2017   261    19           8.5 \n 3 Big Creek BigCreekLower 2017-09-18 20:00:00  2017   261    20           8.39\n 4 Big Creek BigCreekLower 2017-09-18 21:00:00  2017   261    21           7.22\n 5 Big Creek BigCreekLower 2017-09-18 22:00:00  2017   261    22           6.89\n 6 Big Creek BigCreekLower 2017-09-18 23:00:00  2017   261    23           6.78\n 7 Big Creek BigCreekLower 2017-09-19 00:00:00  2017   262     0           6.5 \n 8 Big Creek BigCreekLower 2017-09-19 01:00:00  2017   262     1           6.28\n 9 Big Creek BigCreekLower 2017-09-19 02:00:00  2017   262     2           5.72\n10 Big Creek BigCreekLower 2017-09-19 03:00:00  2017   262     3           5.22\n# ℹ 2,166,663 more rows\n# ℹ 3 more variables: waterTemperature &lt;dbl&gt;, flow &lt;dbl&gt;, z_flow &lt;dbl[,1]&gt;",
    "crumbs": [
      "Covariates",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>PASTA</span>"
    ]
  },
  {
    "objectID": "Covariates/PASTA.html#create-functions",
    "href": "Covariates/PASTA.html#create-functions",
    "title": "7  PASTA",
    "section": "7.2 Create functions",
    "text": "7.2 Create functions\n\n7.2.1 Curve fits\nFunctions to model air and water temperature time series data using sine wave regression:\n\n\nCode\ncurve_fit_air &lt;- function(d, minDataLength = 20) {\n  # return NAs if not enough data\n  if (length(d$airTemperature) &lt; minDataLength) { return(list(model = NA, rSquared = NA)) }\n  # convert hours to radians/circular\n  d$hour_rad &lt;- d$hour * (2 * pi / 24)\n  # starting values\n  startAir &lt;- list(A = -1, B = -1, C = mean(d$airTemperature, na.rm = TRUE))\n  # run sine wave regression as an NLS model\n  modelAir &lt;- tryCatch({\n    nlsLM(airTemperature ~ A * sin(hour_rad) + B * cos(hour_rad) + C, data = d, start = startAir)\n    }, error = function(e) {\n      return(list(model = NA, rSquared = NA))\n      })\n  # rSquared calculation\n  residuals &lt;- residuals(modelAir)\n  sst &lt;- sum((d$airTemperature - mean(d$airTemperature))^2)\n  ssr &lt;- sum(residuals^2)\n  rSquared &lt;- 1 - (ssr / sst)\n  # return fitted model object and R2\n  return(list(model = modelAir, rSquared = rSquared))\n  }\n\ncurve_fit_water &lt;- function(d, minDataLength = 20) {\n  # return NAs if not enough data\n  if (length(d$waterTemperature) &lt; minDataLength) { return(list(model = NA, rSquared = NA)) }\n  # convert hours to radians/circular\n  d$hour_rad &lt;- d$hour * (2 * pi / 24)\n  # starting values\n  startWater &lt;- list(A = -1, B = -1, C = mean(d$waterTemperature, na.rm = TRUE))\n  # run sine wave regression as an NLS model\n  modelWater &lt;- tryCatch({\n    nlsLM(waterTemperature ~ A * sin(hour_rad) + B * cos(hour_rad) + C, data = d, start = startWater)\n    }, error = function(e) {\n      return(list(model = NA, rSquared = NA))\n      })\n  # rSquared calculation\n  residuals &lt;- residuals(modelWater)\n  sst &lt;- sum((d$waterTemperature - mean(d$waterTemperature))^2)\n  ssr &lt;- sum(residuals^2)\n  rSquared &lt;- 1 - (ssr / sst)\n  # return fitted model object and R2\n  return(list(model = modelWater, rSquared = rSquared))\n  }\n\n\n\n\n7.2.2 Extract parameters\nFunction to extract model parameters from sine wave regression fits:\n\n\nCode\nextract_params &lt;- function(model) {\n  if (is.null(model)) {\n    return(NULL)\n  }\n\n  params &lt;- tryCatch({\n    broom.mixed::tidy(model)\n  }, error = function(e) {\n    NULL\n  })\n\n  return(params)\n}\n\n\n\n\n7.2.3 Get model parameters\nFunction to fit sine wave regression models to data and grab amplitude, phase, and mean temperature parameters from fitted model objects:\n\n\nCode\ngetParams &lt;- function(dtHOUR, minDataLength = 20) {\n  # Models for air temperature\n  modelsAir &lt;- dtHOUR %&gt;%\n    group_by(site_name, year, yday) %&gt;%\n    nest() %&gt;%\n    mutate(dataLength = map_dbl(data, ~length(.x$airTemperature))) |&gt;\n    filter(dataLength &gt; minDataLength) |&gt; # filter out daily datasets that are too short\n    mutate(\n      model0 = map(data, curve_fit_air),\n      model = map(model0, 'model'),\n      rSquared = map(model0, 'rSquared'),\n      params = map(model, extract_params)\n    ) %&gt;%\n    unnest(c(params, rSquared)) |&gt;\n    select(-model0, -model, -data) |&gt;\n    mutate(tempVar = \"air\")\n\n  # Models for water temperature\n  modelsWater &lt;- dtHOUR %&gt;%\n    group_by(site_name, year, yday) %&gt;%\n    nest() %&gt;%\n    mutate(dataLength = map_dbl(data, ~length(.x$waterTemperature))) |&gt;\n    filter(dataLength &gt; minDataLength) |&gt; # filter out daily datasets that are too short\n    mutate(\n      model0 = map(data, curve_fit_water),\n      model = map(model0, 'model'),\n      rSquared = map(model0, 'rSquared'),\n      params = map(model, extract_params)\n    ) %&gt;%\n    unnest(c(params, rSquared)) |&gt;\n    select(-model0, -model, -data) |&gt;\n    mutate(tempVar = \"water\")\n\n  # Collect air and water models\n  models &lt;- bind_rows(modelsAir, modelsWater) |&gt;\n    filter(!is.na(term)) |&gt;\n    #group_by(site_name, year, yday, tempVar) |&gt;\n    select(-std.error, -statistic, -p.value) |&gt; # need to lose these columns so there are no unique values remaining in non-widened cols\n    pivot_wider(names_from = term, values_from = estimate)\n  \n  # Calculate amplitude and phase for air and water data\n  params &lt;- models |&gt;\n    group_by(site_name, year, yday, tempVar) |&gt;\n    mutate(\n      amplitude = sqrt(A^2 + B^2),\n      phase = ifelse(A &lt; 0,\n        12 + (24 / (2 * pi)) * atan(B / A), #switched order of A and B per Tim's email 5/17/24\n        (24 / (2 * pi)) * atan(B / A)),\n      mean = C\n    ) |&gt;\n    left_join(\n      dtHOUR |&gt; select(site_name, year, yday) |&gt; distinct(), by = c(\"site_name\", \"year\", \"yday\")\n    ) |&gt;\n    ungroup()\n  \n  # Return amplitude and phase parameters\n  return(params)\n}\n\n\n\n\n7.2.4 Get derived parameters\nFunction to calculate amplitude ratio, phase lag, and mean ratio parameters from sine wave regression models fits to daily paired air-stream temperature data:\n\n\nCode\ngetAmpPhase &lt;- function(paramsIn) {\n  paramsIn |&gt;\n    select(site_name, year, yday, tempVar, amplitude, phase, mean, rSquared) |&gt;\n    pivot_wider(\n      names_from = tempVar,\n      values_from = c(amplitude, phase, mean, rSquared)\n    ) |&gt;\n    select(\n      site_name, year, yday,\n      starts_with(\"amplitude\"),\n      starts_with(\"phase\"),\n      starts_with(\"mean\"),\n      starts_with(\"rSquared\")\n    ) |&gt;\n    mutate(\n      amplitudeRatio = amplitude_water / amplitude_air,\n      phaseLag = ((phase_air - phase_water + 12) %% 24) - 12,#phase_water - phase_air, # Tim's equation for phase lag\n      meanRatio = mean_water / mean_air,\n      meanOffset = mean_water - mean_air\n    )\n}\n\n\n\n\n7.2.5 Predictions\nFunction to predict air or water temperature from fitted models:\n\n\nCode\ngetParamsPred &lt;- function(paramsIn) {\n\n  uniqueValues &lt;- paramsIn |&gt;\n    distinct(site_name, year, yday, tempVar)\n\n  preds &lt;- crossing(uniqueValues, hour = 0:23) %&gt;%\n    left_join(paramsIn, by = c(\"site_name\", \"year\", \"yday\", \"tempVar\")) %&gt;%\n    mutate(\n      hour_rad = hour * (2 * pi / 24),\n      predTemp = A * sin(hour_rad) + B * cos(hour_rad) + C\n    )\n\n    return(preds)\n }",
    "crumbs": [
      "Covariates",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>PASTA</span>"
    ]
  },
  {
    "objectID": "Covariates/PASTA.html#perform-pasta",
    "href": "Covariates/PASTA.html#perform-pasta",
    "title": "7  PASTA",
    "section": "7.3 Perform PASTA",
    "text": "7.3 Perform PASTA\n\n7.3.1 Get model parameters\nPerform PASTA and write output to file\n\n\nCode\npasta &lt;- getParams(dtHOUR = dat2)\nwrite_csv(pasta, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Covariates/pasta_daily_parameters.csv\")\n\n\nRead in\n\n\nCode\npasta &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Covariates/pasta_daily_parameters.csv\")\nhead(pasta)\n\n\n# A tibble: 6 × 12\n  site_name  year  yday dataLength rSquared tempVar      A     B     C amplitude\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 BigCreek…  2017   262         24    0.758 air     -0.599  1.26  4.97      1.40\n2 BigCreek…  2017   263         24    0.711 air     -0.822  1.62  3.56      1.81\n3 BigCreek…  2017   264         24    0.719 air     -1.78   2.16  4.53      2.80\n4 BigCreek…  2017   265         24    0.561 air     -1.08   2.26  4.58      2.51\n5 BigCreek…  2017   266         24    0.949 air     -1.74   2.49  4.52      3.04\n6 BigCreek…  2017   267         24    0.865 air     -4.38   3.23  4.02      5.44\n# ℹ 2 more variables: phase &lt;dbl&gt;, mean &lt;dbl&gt;\n\n\n\n\n7.3.2 Get derived parameters\n\n\nCode\npasta_derived &lt;- getAmpPhase(paramsIn = pasta)\npasta_derived &lt;- pasta_derived %&gt;% mutate(date = parse_date_time(x = paste(year, yday), orders = \"yj\")) %&gt;% relocate(date, .after = site_name)\nhead(pasta_derived)\n\n\n# A tibble: 6 × 16\n  site_name     date                 year  yday amplitude_air amplitude_water\n  &lt;chr&gt;         &lt;dttm&gt;              &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n1 BigCreekLower 2017-09-19 00:00:00  2017   262          1.40           1.04 \n2 BigCreekLower 2017-09-20 00:00:00  2017   263          1.81           1.05 \n3 BigCreekLower 2017-09-21 00:00:00  2017   264          2.80           1.41 \n4 BigCreekLower 2017-09-22 00:00:00  2017   265          2.51           1.22 \n5 BigCreekLower 2017-09-23 00:00:00  2017   266          3.04           0.798\n6 BigCreekLower 2017-09-24 00:00:00  2017   267          5.44           1.46 \n# ℹ 10 more variables: phase_air &lt;dbl&gt;, phase_water &lt;dbl&gt;, mean_air &lt;dbl&gt;,\n#   mean_water &lt;dbl&gt;, rSquared_air &lt;dbl&gt;, rSquared_water &lt;dbl&gt;,\n#   amplitudeRatio &lt;dbl&gt;, phaseLag &lt;dbl&gt;, meanRatio &lt;dbl&gt;, meanOffset &lt;dbl&gt;\n\n\nCode\nwrite_csv(pasta_derived, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Covariates/pasta_derived_parameters_daily.csv\")\n\n\n\n\n7.3.3 Predict temperature\nPredict air and stream temperature from fitted sine wave regression models and write predictions to file\n\n\nCode\npreds &lt;- getParamsPred(paramsIn = pasta)\npreds &lt;- preds %&gt;% mutate(datetime = parse_date_time(x = paste(year, yday, hour), orders = \"yjh\")) %&gt;% relocate(datetime, .after = site_name) %&gt;% select(site_name, datetime, tempVar, rSquared, predTemp) %&gt;% pivot_wider(names_from = tempVar, values_from = c(predTemp, rSquared))\nwrite_csv(preds, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Covariates/pasta_predicted_temp.csv\")\n\n\nRead in\n\n\nCode\npreds &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Covariates/pasta_predicted_temp.csv\")\ntz(preds$datetime) &lt;- \"UTC\"\nhead(preds)\n\n\n# A tibble: 6 × 6\n  site_name   datetime            predTemp_air predTemp_water rSquared_air\n  &lt;chr&gt;       &lt;dttm&gt;                     &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n1 Avery Brook 2020-01-11 00:00:00        3.76            1.76        0.893\n2 Avery Brook 2020-01-11 01:00:00        3.10            1.61        0.893\n3 Avery Brook 2020-01-11 02:00:00        2.38            1.48        0.893\n4 Avery Brook 2020-01-11 03:00:00        1.67            1.38        0.893\n5 Avery Brook 2020-01-11 04:00:00        0.999           1.30        0.893\n6 Avery Brook 2020-01-11 05:00:00        0.423           1.27        0.893\n# ℹ 1 more variable: rSquared_water &lt;dbl&gt;",
    "crumbs": [
      "Covariates",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>PASTA</span>"
    ]
  },
  {
    "objectID": "Covariates/PASTA.html#explore-pasta-output",
    "href": "Covariates/PASTA.html#explore-pasta-output",
    "title": "7  PASTA",
    "section": "7.4 Explore PASTA output",
    "text": "7.4 Explore PASTA output\nAdd mean daily flow to derived PASTA metrics (z-scored by site)\n\n\nCode\ndat3 &lt;- dat2 %&gt;% \n  mutate(date = as_date(datetime)) %&gt;% \n  group_by(site_name, date) %&gt;% \n  summarize(flow = mean(flow, na.rm = TRUE), z_flow = mean(z_flow, na.rm = TRUE))\npasta_derived &lt;- pasta_derived %&gt;% left_join(dat3)\nhead(pasta_derived)\n\n\n# A tibble: 6 × 18\n  site_name     date                 year  yday amplitude_air amplitude_water\n  &lt;chr&gt;         &lt;dttm&gt;              &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n1 BigCreekLower 2017-09-19 00:00:00  2017   262          1.40           1.04 \n2 BigCreekLower 2017-09-20 00:00:00  2017   263          1.81           1.05 \n3 BigCreekLower 2017-09-21 00:00:00  2017   264          2.80           1.41 \n4 BigCreekLower 2017-09-22 00:00:00  2017   265          2.51           1.22 \n5 BigCreekLower 2017-09-23 00:00:00  2017   266          3.04           0.798\n6 BigCreekLower 2017-09-24 00:00:00  2017   267          5.44           1.46 \n# ℹ 12 more variables: phase_air &lt;dbl&gt;, phase_water &lt;dbl&gt;, mean_air &lt;dbl&gt;,\n#   mean_water &lt;dbl&gt;, rSquared_air &lt;dbl&gt;, rSquared_water &lt;dbl&gt;,\n#   amplitudeRatio &lt;dbl&gt;, phaseLag &lt;dbl&gt;, meanRatio &lt;dbl&gt;, meanOffset &lt;dbl&gt;,\n#   flow &lt;dbl&gt;, z_flow &lt;dbl&gt;\n\n\nView all sites\n\n\nCode\nunique(pasta_derived$site_name)\n\n\n [1] \"BigCreekLower\"                          \n [2] \"BigCreekMiddle\"                         \n [3] \"BigCreekUpper\"                          \n [4] \"HallowattCreekLower\"                    \n [5] \"LangfordCreekLower\"                     \n [6] \"LangfordCreekUpper\"                     \n [7] \"NicolaCreek\"                            \n [8] \"SkookoleelCreek\"                        \n [9] \"WernerCreek\"                            \n[10] \"CoalCreekHeadwaters\"                    \n[11] \"CoalCreekLower\"                         \n[12] \"CoalCreekMiddle\"                        \n[13] \"CoalCreekNorth\"                         \n[14] \"CycloneCreekLower\"                      \n[15] \"CycloneCreekMiddle\"                     \n[16] \"CycloneCreekUpper\"                      \n[17] \"McGeeCreekLower\"                        \n[18] \"McGeeCreekTrib\"                         \n[19] \"McGeeCreekUpper\"                        \n[20] \"Avery Brook\"                            \n[21] \"Jimmy Brook\"                            \n[22] \"Mitchell Brook\"                         \n[23] \"Obear Brook Lower\"                      \n[24] \"Sanderson Brook\"                        \n[25] \"West Brook 0\"                           \n[26] \"West Brook Lower\"                       \n[27] \"West Brook Reservoir\"                   \n[28] \"West Brook Upper\"                       \n[29] \"West Whately Brook\"                     \n[30] \"Donner Blitzen River nr Frenchglen NWIS\"\n[31] \"Donner Blitzen ab Fish NWIS\"            \n[32] \"Donner Blitzen ab Indian NWIS\"          \n[33] \"Donner Blitzen nr Burnt Car NWIS\"       \n[34] \"Fish Creek NWIS\"                        \n[35] \"Indian Creek NWIS\"                      \n[36] \"Little Blizten River NWIS\"              \n[37] \"Paine Run 01\"                           \n[38] \"Paine Run 02\"                           \n[39] \"Paine Run 06\"                           \n[40] \"Paine Run 07\"                           \n[41] \"Paine Run 08\"                           \n[42] \"Paine Run 10\"                           \n[43] \"Piney River 10\"                         \n[44] \"Staunton River 02\"                      \n[45] \"Staunton River 03\"                      \n[46] \"Staunton River 06\"                      \n[47] \"Staunton River 07\"                      \n[48] \"Staunton River 09\"                      \n[49] \"Staunton River 10\"                      \n[50] \"EF Duck Creek ab HF\"                    \n[51] \"EF Duck Creek be HF\"                    \n[52] \"Henrys Fork\"                            \n[53] \"Buck Creek\"                             \n[54] \"Crandall Creek\"                         \n[55] \"Deep Creek\"                             \n[56] \"Dugout Creek\"                           \n[57] \"Dugout Creek NWIS\"                      \n[58] \"Lodgepole Creek\"                        \n[59] \"Shields River Valley Ranch\"             \n[60] \"Shields River ab Dugout\"                \n[61] \"Shields River ab Smith NWIS\"            \n[62] \"Grizzly Creek\"                          \n[63] \"Grouse Creek\"                           \n[64] \"Leidy Creek Mouth\"                      \n[65] \"Leidy Creek Mouth NWIS\"                 \n[66] \"Leidy Creek Upper\"                      \n[67] \"NF Spread Creek Lower\"                  \n[68] \"NF Spread Creek Upper\"                  \n[69] \"Rock Creek\"                             \n[70] \"SF Spread Creek Lower\"                  \n[71] \"SF Spread Creek Lower NWIS\"             \n[72] \"SF Spread Creek Upper\"                  \n[73] \"Spread Creek Dam\"                       \n\n\n\n7.4.1 Single site\nGenerate interactive time series plots of PASTA output for a single focal site\nSet focal site\n\n\nCode\nfocal_site &lt;- \"Leidy Creek Mouth NWIS\"\nfocal_site\n\n\n[1] \"Leidy Creek Mouth NWIS\"\n\n\n\n7.4.1.1 Amplitude ratio\nAmplitude ratio: amplitude_water - amplitude_air. Generally, lower amplitude ratios (greater decoupling between air and water temperature sinusoids) are indicative of greater fractional groundwater inputs. (In Rey et al. 2024, Ar values tend to be most similar among tributary/mainstem sites during periods of high surface water input. I.e., high flows homogenize spatial variation in groundwater-surface water dynamics).\n\n\nCode\npasta_derived %&gt;% filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) %&gt;% select(date, amplitudeRatio) %&gt;% dygraph(main = focal_site) %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Amplitude ratio\") %&gt;% dyOptions(drawPoints = T, strokeWidth = 0, pointSize = 3) %&gt;% dyHighlight(highlightCircleSize = 5)\n\n\n\n\n\n\n\n\nCode\npasta_derived %&gt;% filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) %&gt;% ggplot(aes(x = yday, y = amplitudeRatio, color = z_flow)) + geom_point() + ggtitle(focal_site) + geom_smooth(method = \"lm\", formula = y ~ poly(x, 2)) + facet_wrap(~year)\n\n\n\n\n\n\n\n\n\n\n\nCode\npasta_derived %&gt;% filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) %&gt;% ggplot(aes(x = z_flow, y = amplitudeRatio, color = as.factor(year))) + geom_point(alpha= 0.3) + ggtitle(focal_site) + geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n7.4.1.2 Phase lag\nPhase lag: phase_water - phase_air. Phase lags are likely a result of diel groundwater temperature variations that are subsequently transferred to water temperatures signals. Generally, phase lag tends to be inversely related to amplitude ratio and may provide a secondary metric of fractional groundwater contributions.\n\n\nCode\npasta_derived %&gt;% filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) %&gt;% select(date, phaseLag) %&gt;% dygraph(main = focal_site) %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Phase lag (hrs)\") %&gt;% dyOptions(drawPoints = T, strokeWidth = 0, pointSize = 3) %&gt;% dyLimit(0, color = \"red\") %&gt;% dyHighlight(highlightCircleSize = 5)\n\n\n\n\n\n\n\n\nCode\npasta_derived %&gt;% filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) %&gt;% ggplot(aes(x = yday, y = phaseLag, color = z_flow)) + geom_point() + ggtitle(focal_site) + geom_smooth() + facet_wrap(~year)\n\n\n\n\n\n\n\n\n\n\n\nCode\npasta_derived %&gt;% filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) %&gt;% ggplot(aes(x = z_flow, y = phaseLag, color = as.factor(year))) + geom_point(alpha= 0.3) + ggtitle(focal_site) + geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n7.4.1.3 Mean ratio\nMean ratio: mean_water / mean_air. On daily timescales, mean ratio values indicate runoff/quickflow vs. local groundwater influence, with higher, more stable values at sites where hillslope drainage is reduced compared to total channel water volume (e.g., lower in network). I.e., across sites at any given time, low values indicate high fractional groundwater input and high values indicate low groundwater input. Within a site across time, gradual rise/change in Mr may be driven by changes in groundwater temperature over time as terrestrial hillslopes accumulate (spring and early summer) and/or lose (late summer and autumn) heat. Thereby indicating that groundwater flowpaths are shallow enough to be sensitive to seasonal warming/cooling.\n(In Rey et al. 2024, Mr values tend to be most similar among tributary/mainstem sites during periods of high surface water input. I.e., high flows homogenize spatial variation in groundwater-surface water dynamics).\nNote this plot is trimmed to values [0,2] as very unreasonable values can result when daily mean air temperature is &lt; 1.\n\n\nCode\npasta_derived %&gt;% filter(site_name == focal_site, rSquared_air &gt;= 0.7, rSquared_water &gt;= 0.7, meanRatio &gt;=0, meanRatio &lt;= 2) %&gt;% select(date, meanRatio) %&gt;% dygraph(main = focal_site) %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Mean ratio\") %&gt;% dyOptions(drawPoints = T, strokeWidth = 0, pointSize = 3) %&gt;% dyHighlight(highlightCircleSize = 5)\n\n\n\n\n\n\n\n\nCode\npasta_derived %&gt;% filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7, meanRatio &gt;=0, meanRatio &lt;= 2) %&gt;% ggplot(aes(x = yday, y = meanRatio, color = z_flow)) + geom_point() + ggtitle(focal_site) + geom_smooth() + facet_wrap(~year)\n\n\n\n\n\n\n\n\n\n\n\nCode\npasta_derived %&gt;% filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7, meanRatio &gt;=0, meanRatio &lt;= 2) %&gt;% ggplot(aes(x = z_flow, y = meanRatio, color = as.factor(year))) + geom_point(alpha= 0.3) + ggtitle(focal_site) + geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n7.4.1.4 Pl-Ar correlation\nIn Rey et al. 2024, phase lag and amplitude ratio are often correlated.\n\n\nCode\npasta_derived %&gt;% filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) %&gt;% ggplot(aes(x = amplitudeRatio, y = phaseLag, color = z_flow)) + geom_point() + ggtitle(focal_site) + geom_smooth(method = \"lm\") + facet_wrap(~year)\n\n\n\n\n\n\n\n\n\nThis simple OLS model shows that phase lag is negatively related to both amplitude ratio and flow. I.e., the intercept of the Pl ~ Ar relationship declines with increasing streamflow.\n\n\nCode\nsummary(lm(phaseLag ~ amplitudeRatio*z_flow, pasta_derived %&gt;% filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7)))\n\n\n\nCall:\nlm(formula = phaseLag ~ amplitudeRatio * z_flow, data = pasta_derived %&gt;% \n    filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= \n        0.7))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.39573 -0.21486  0.02893  0.24727  2.79277 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            1.91249    0.10844  17.636  &lt; 2e-16 ***\namplitudeRatio        -1.92841    0.26245  -7.348 6.72e-13 ***\nz_flow                -0.60032    0.09622  -6.239 8.39e-10 ***\namplitudeRatio:z_flow  0.34113    0.25958   1.314    0.189    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5195 on 592 degrees of freedom\nMultiple R-squared:  0.4858,    Adjusted R-squared:  0.4832 \nF-statistic: 186.4 on 3 and 592 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n7.4.1.5 Model predictions\nPlot predicted air and stream temperature (orange and blue lines, respectively) over observed air and stream temperature (orange and blue points, respectively).\n\n\nCode\ndat2 %&gt;% \n  select(site_name, datetime, airTemperature, waterTemperature) %&gt;% \n  filter(site_name == focal_site) %&gt;% \n  left_join(preds) %&gt;% \n  filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) %&gt;% \n  select(-c(site_name, rSquared_air, rSquared_water)) %&gt;% \n  mutate(datetime = datetime) %&gt;% # need to fudge datetime b/c dyGraphs converts to local time zone\n  dygraph(main = focal_site) %&gt;% dyRangeSelector() %&gt;% \n  #dyAxis(\"y\", label = \"Water temp.\") %&gt;% \n  #dyAxis(\"y2\", label = \"Air temp.\") %&gt;% \n  dySeries(\"waterTemperature\", axis = \"y\", label = \"Obs. water temp.\", drawPoints = TRUE, strokeWidth = 0, pointSize = 3, color = \"dodgerblue\") %&gt;% \n  dySeries(\"airTemperature\", axis = \"y\", label = \"Obs. air temp.\", drawPoints = TRUE, strokeWidth = 0, pointSize = 3, color = \"darkorange\")  %&gt;% \n  dySeries(\"predTemp_water\", axis = \"y\", label = \"Pred. water temp.\", color = \"dodgerblue\") %&gt;% \n  dySeries(\"predTemp_air\", axis = \"y\", label = \"Pred. air temp.\", color = \"darkorange\")\n\n\n\n\n\n\n\n\n\n7.4.2 All sites\nDefine subbasins\n\n\nCode\nmysubbasins &lt;- c(\"West Brook\", \"Paine Run\", \"Staunton River\", \"Big Creek\", \"Coal Creek\", \"McGee Creek\", \"Shields River\", \"Snake River\", \"Donner Blitzen\", \"Duck Creek\")\n\n\n\n7.4.2.1 Amplitude ratio\n\nTemporal patterns\n\n\nCode\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  mysites &lt;- unlist(siteinfo2 %&gt;% filter(site_name %in% unique(pasta_derived$site_name)) %&gt;% filter(subbasin == mysubbasins[i]) %&gt;% arrange(desc(area_sqmi)) %&gt;% select(site_name))\n  myplots[[i]] &lt;- pasta_derived %&gt;% \n    filter(site_name %in% mysites, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) %&gt;% \n    mutate(year = factor(year), site_name = factor(site_name, levels = mysites)) %&gt;% \n    ggplot(aes(x = yday, y = amplitudeRatio, color = year)) + \n    geom_point(alpha = 0.2) + \n    geom_smooth(se = FALSE) + #geom_smooth(method = \"lm\", formula = y ~ poly(x, 2)) + \n    ggtitle(mysubbasins[i]) + ylim(0,1) + \n    facet_wrap(~site_name, ncol = 3)\n}\n\n\n\nWest BrookPaine RunStaunton RiverBig CreekCoal CreekMcGee CreekShields RiverSnake RiverDonner BlitzenDuck Creek\n\n\n\n\nCode\nmyplots[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[4]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[5]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[6]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[7]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[8]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[9]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[10]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBy Flow\n\n\nCode\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  mysites &lt;- unlist(siteinfo2 %&gt;% filter(site_name %in% unique(pasta_derived$site_name)) %&gt;% filter(subbasin == mysubbasins[i]) %&gt;% arrange(desc(area_sqmi)) %&gt;% select(site_name))\n  myplots[[i]] &lt;- pasta_derived %&gt;% \n    filter(site_name %in% mysites, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) %&gt;% \n    mutate(year = factor(year), site_name = factor(site_name, levels = mysites)) %&gt;% \n    ggplot(aes(x = z_flow, y = amplitudeRatio, color = year)) + \n    geom_point(alpha = 0.2) + \n    geom_smooth(se = FALSE) + #geom_smooth(method = \"lm\", formula = y ~ poly(x, 2)) + \n    ggtitle(mysubbasins[i]) + ylim(0,1) + \n    facet_wrap(~site_name, ncol = 3, scales = \"free_x\")\n}\n\n\n\nWest BrookPaine RunStaunton RiverBig CreekCoal CreekMcGee CreekShields RiverSnake RiverDonner BlitzenDuck Creek\n\n\n\n\nCode\nmyplots[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[4]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[5]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[6]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[7]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[8]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[9]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[10]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.4.2.2 Phase lag\n\nTemporal patterns\n\n\nCode\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  mysites &lt;- unlist(siteinfo2 %&gt;% filter(site_name %in% unique(pasta_derived$site_name)) %&gt;% filter(subbasin == mysubbasins[i]) %&gt;% arrange(desc(area_sqmi)) %&gt;% select(site_name))\n  myplots[[i]] &lt;- pasta_derived %&gt;% \n    filter(site_name %in% mysites, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) %&gt;% \n    mutate(year = factor(year), site_name = factor(site_name, levels = mysites)) %&gt;% \n    ggplot(aes(x = yday, y = phaseLag, color = year)) + \n    geom_point(alpha = 0.2) + \n    geom_smooth(se = FALSE) + #geom_smooth(method = \"lm\", formula = y ~ poly(x, 2)) + \n    ggtitle(mysubbasins[i]) + #ylim(0,1) + \n    geom_abline(slope = 0, intercept = 0, linetype = \"dashed\") +\n    facet_wrap(~site_name, ncol = 3)\n}\n\n\n\nWest BrookPaine RunStaunton RiverBig CreekCoal CreekMcGee CreekShields RiverSnake RiverDonner BlitzenDuck Creek\n\n\n\n\nCode\nmyplots[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[4]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[5]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[6]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[7]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[8]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[9]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[10]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBy Flow\n\n\nCode\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  mysites &lt;- unlist(siteinfo2 %&gt;% filter(site_name %in% unique(pasta_derived$site_name)) %&gt;% filter(subbasin == mysubbasins[i]) %&gt;% arrange(desc(area_sqmi)) %&gt;% select(site_name))\n  myplots[[i]] &lt;- pasta_derived %&gt;% \n    filter(site_name %in% mysites, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) %&gt;% \n    mutate(year = factor(year), site_name = factor(site_name, levels = mysites)) %&gt;% \n    ggplot(aes(x = z_flow, y = phaseLag, color = year)) + \n    geom_point(alpha = 0.2) + \n    geom_smooth(se = FALSE) + #geom_smooth(method = \"lm\", formula = y ~ poly(x, 2)) + \n    ggtitle(mysubbasins[i]) + #ylim(0,1) + \n    geom_abline(slope = 0, intercept = 0, linetype = \"dashed\") +\n    facet_wrap(~site_name, ncol = 3, scales = \"free_x\")\n}\n\n\n\nWest BrookPaine RunStaunton RiverBig CreekCoal CreekMcGee CreekShields RiverSnake RiverDonner BlitzenDuck Creek\n\n\n\n\nCode\nmyplots[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[4]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[5]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[6]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[7]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[8]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[9]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[10]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.4.2.3 Mean ratio\n\nTemporal patterns\n\n\nCode\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  mysites &lt;- unlist(siteinfo2 %&gt;% filter(site_name %in% unique(pasta_derived$site_name)) %&gt;% filter(subbasin == mysubbasins[i]) %&gt;% arrange(desc(area_sqmi)) %&gt;% select(site_name))\n  myplots[[i]] &lt;- pasta_derived %&gt;% \n    filter(site_name %in% mysites, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7, meanRatio &gt;=0, meanRatio &lt;= 2) %&gt;% \n    mutate(year = factor(year), site_name = factor(site_name, levels = mysites)) %&gt;% \n    ggplot(aes(x = yday, y = meanRatio, color = year)) + \n    geom_point(alpha = 0.2) + \n    geom_smooth(se = FALSE) + #geom_smooth(method = \"lm\", formula = y ~ poly(x, 2)) + \n    ggtitle(mysubbasins[i]) + #ylim(0,1) + \n    facet_wrap(~site_name, ncol = 3)\n}\n\n\n\nWest BrookPaine RunStaunton RiverBig CreekCoal CreekMcGee CreekShields RiverSnake RiverDonner BlitzenDuck Creek\n\n\n\n\nCode\nmyplots[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[4]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[5]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[6]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[7]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[8]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[9]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[10]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBy Flow\n\n\nCode\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  mysites &lt;- unlist(siteinfo2 %&gt;% filter(site_name %in% unique(pasta_derived$site_name)) %&gt;% filter(subbasin == mysubbasins[i]) %&gt;% arrange(desc(area_sqmi)) %&gt;% select(site_name))\n  myplots[[i]] &lt;- pasta_derived %&gt;% \n    filter(site_name %in% mysites, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7, meanRatio &gt;=0, meanRatio &lt;= 2) %&gt;% \n    mutate(year = factor(year), site_name = factor(site_name, levels = mysites)) %&gt;% \n    ggplot(aes(x = z_flow, y = meanRatio, color = year)) + \n    geom_point(alpha = 0.2) + \n    geom_smooth(se = FALSE) + #geom_smooth(method = \"lm\", formula = y ~ poly(x, 2)) + \n    ggtitle(mysubbasins[i]) + #ylim(0,1) + \n    facet_wrap(~site_name, ncol = 3, scales = \"free_x\")\n}\n\n\n\nWest BrookPaine RunStaunton RiverBig CreekCoal CreekMcGee CreekShields RiverSnake RiverDonner BlitzenDuck Creek\n\n\n\n\nCode\nmyplots[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[4]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[5]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[6]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[7]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[8]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[9]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[10]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.4.2.4 Pl-Ar Correlation\n\n\nCode\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  mysites &lt;- unlist(siteinfo2 %&gt;% filter(site_name %in% unique(pasta_derived$site_name)) %&gt;% filter(subbasin == mysubbasins[i]) %&gt;% arrange(desc(area_sqmi)) %&gt;% select(site_name))\n  myplots[[i]] &lt;- pasta_derived %&gt;% \n    filter(site_name %in% mysites, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7, phaseLag &gt;= -5, phaseLag &lt;= 10, amplitudeRatio &gt;= 0, amplitudeRatio &lt;= 1) %&gt;% \n    mutate(year = factor(year), site_name = factor(site_name, levels = mysites)) %&gt;% \n    ggplot(aes(x = amplitudeRatio, y = phaseLag, color = z_flow)) + \n    geom_point(alpha = 0.5) + \n    #geom_smooth(se = FALSE) + #geom_smooth(method = \"lm\", formula = y ~ poly(x, 2)) + \n    ggtitle(mysubbasins[i]) + #ylim(0,1) + \n    facet_wrap(~site_name, ncol = 3)\n}\n\n\n\nWest BrookPaine RunStaunton RiverBig CreekCoal CreekMcGee CreekShields RiverSnake RiverDonner BlitzenDuck Creek\n\n\n\n\nCode\nmyplots[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[4]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[5]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[6]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[7]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[8]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[9]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[10]]",
    "crumbs": [
      "Covariates",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>PASTA</span>"
    ]
  },
  {
    "objectID": "Covariates/PASTA.html#summarize-output",
    "href": "Covariates/PASTA.html#summarize-output",
    "title": "7  PASTA",
    "section": "7.5 Summarize output",
    "text": "7.5 Summarize output\n\n7.5.1 Rolling mean\n\n7.5.1.1 Summarize\nSummarize PASTA output as 7-day rolling means for use in the Wedge Model and elsewhere, per Rey et al. (2024)\nInterpolate short gaps and calulate 7-day rolling mean\n\n\nCode\n# Drop poor fits then fill missing dates\npasta_derived_filled &lt;- fill_missing_dates(pasta_derived %&gt;% filter(rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7), dates = date, groups = site_name) #%&gt;% group_by(site_name) %&gt;% arrange(site_name, date) \n\n# get rid of crazy mean ratio values\npasta_derived_filled &lt;- pasta_derived_filled %&gt;%\n  mutate(meanRatio = ifelse(meanRatio &lt; 0, NA,\n                            ifelse(meanRatio &gt; 2, NA, meanRatio)))\n\n# Interpolate short gaps (&lt;=3 days) and calculate 7-day rolling mean as in Rey et al. (2024)\ndatalist &lt;- list()\nmysites &lt;- unique(pasta_derived_filled$site_name)\nfor (i in 1:length(mysites)) { \n  datalist[[i]] &lt;- pasta_derived_filled %&gt;% \n    filter(site_name == mysites[i]) %&gt;% \n    mutate(amplitudeRatio_fill = na.approx(amplitudeRatio, maxgap = 3, na.rm = FALSE),\n           phaseLag_fill = na.approx(phaseLag, maxgap = 3, na.rm = FALSE),\n           meanRatio_fill = na.approx(meanRatio, maxgap = 3, na.rm = FALSE)) %&gt;%\n    mutate(amplitudeRatio_fill_roll7 = rollapply(amplitudeRatio_fill, FUN = mean, width = 7, align = \"center\", fill = NA),\n           phaseLag_fill_roll7 = rollapply(phaseLag_fill, FUN = mean, width = 7, align = \"center\", fill = NA),\n           meanRatio_fill_roll7 = rollapply(meanRatio_fill, FUN = mean, width = 7, align = \"center\", fill = NA))\n}\npasta_derived_filled &lt;- do.call(rbind, datalist)\n\n\nWrite to file\n\n\nCode\nwrite_csv(pasta_derived_filled, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Covariates/pasta_derived_parameters_7daymean.csv\")\n\n\nSet focal site\n\n\nCode\nfocal_site &lt;- \"McGeeCreekUpper\"\nprint(focal_site)\n\n\n[1] \"McGeeCreekUpper\"\n\n\nView focal data\n\n\nCode\npasta_derived_filled %&gt;% \n  filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) \n\n\n# A tibble: 974 × 24\n   site_name      date        year  yday amplitude_air amplitude_water phase_air\n   &lt;chr&gt;          &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;           &lt;dbl&gt;     &lt;dbl&gt;\n 1 McGeeCreekUpp… 2017-08-02  2017   214          4.86           1.08       6.46\n 2 McGeeCreekUpp… 2017-08-03  2017   215          9.33           1.26       8.12\n 3 McGeeCreekUpp… 2017-08-04  2017   216          9.39           1.14       8.31\n 4 McGeeCreekUpp… 2017-08-05  2017   217          4.11           0.945      7.47\n 5 McGeeCreekUpp… 2017-08-06  2017   218          9.13           1.10       8.40\n 6 McGeeCreekUpp… 2017-08-07  2017   219         10.3            1.14       8.43\n 7 McGeeCreekUpp… 2017-08-08  2017   220          6.72           0.913      6.70\n 8 McGeeCreekUpp… 2017-08-09  2017   221          9.14           1.05       7.57\n 9 McGeeCreekUpp… 2017-08-10  2017   222          8.98           1.02       7.84\n10 McGeeCreekUpp… 2017-08-11  2017   223          9.57           1.01       7.96\n# ℹ 964 more rows\n# ℹ 17 more variables: phase_water &lt;dbl&gt;, mean_air &lt;dbl&gt;, mean_water &lt;dbl&gt;,\n#   rSquared_air &lt;dbl&gt;, rSquared_water &lt;dbl&gt;, amplitudeRatio &lt;dbl&gt;,\n#   phaseLag &lt;dbl&gt;, meanRatio &lt;dbl&gt;, meanOffset &lt;dbl&gt;, flow &lt;dbl&gt;,\n#   z_flow &lt;dbl&gt;, amplitudeRatio_fill &lt;dbl&gt;, phaseLag_fill &lt;dbl&gt;,\n#   meanRatio_fill &lt;dbl&gt;, amplitudeRatio_fill_roll7 &lt;dbl&gt;,\n#   phaseLag_fill_roll7 &lt;dbl&gt;, meanRatio_fill_roll7 &lt;dbl&gt;\n\n\nAmplitude Ratio\n\n\nCode\npasta_derived_filled %&gt;% \n  filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) %&gt;% \n  ggplot() + \n  geom_point(aes(x = yday, y = amplitudeRatio), color = \"black\") + ggtitle(focal_site) + \n  geom_point(aes(x = yday, y = amplitudeRatio_fill_roll7), color = \"red\") + ggtitle(focal_site) + \n  #geom_smooth(method = \"lm\", formula = y ~ poly(x, 2)) + \n  facet_wrap(~year)\n\n\n\n\n\n\n\n\n\nPhase Lag\n\n\nCode\npasta_derived_filled %&gt;% \n  filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) %&gt;% \n  ggplot() + \n  geom_point(aes(x = yday, y = phaseLag), color = \"black\") + ggtitle(focal_site) + \n  geom_point(aes(x = yday, y = phaseLag_fill_roll7), color = \"red\") + ggtitle(focal_site) + \n  #geom_smooth(method = \"lm\", formula = y ~ poly(x, 2)) + \n  facet_wrap(~year)\n\n\n\n\n\n\n\n\n\nMean Ratio\n\n\nCode\npasta_derived_filled %&gt;% \n  filter(site_name == focal_site, rSquared_air &gt;= 0.7 & rSquared_water &gt;= 0.7) %&gt;% \n  ggplot() + \n  geom_point(aes(x = yday, y = meanRatio), color = \"black\") + ggtitle(focal_site) + \n  geom_point(aes(x = yday, y = meanRatio_fill_roll7), color = \"red\") + ggtitle(focal_site) + \n  #geom_smooth(method = \"lm\", formula = y ~ poly(x, 2)) + \n  facet_wrap(~year)\n\n\n\n\n\n\n\n\n\n\n\n7.5.1.2 Calculate Gg difference\nJoin big G PASTA derived parameters (7-day rolling means) to little g PASTA derived parameters and calculate difference (little - big).\n\n\nCode\npasta_derived_filled_big &lt;- pasta_derived_filled %&gt;% left_join(siteinfo2 %&gt;% select(site_name, subbasin, designation)) %&gt;% filter(designation == \"big\") %&gt;% select(-designation)\n\npasta_derived_filled_little &lt;- pasta_derived_filled %&gt;% left_join(siteinfo2 %&gt;% select(site_name, subbasin, designation)) %&gt;% filter(designation == \"little\") %&gt;% select(-designation)\n\npasta_derived_filled_join &lt;- pasta_derived_filled_little %&gt;% \n  select(site_name, subbasin, date, rSquared_air, rSquared_water, amplitudeRatio_fill_roll7, phaseLag_fill_roll7, meanRatio_fill_roll7) %&gt;% \n  rename(site_name_little = site_name, rSquared_air_little = rSquared_air, rSquared_water_little = rSquared_water, amplitudeRatio_fill_roll7_little = amplitudeRatio_fill_roll7, phaseLag_fill_roll7_little = phaseLag_fill_roll7, meanRatio_fill_roll7_little = meanRatio_fill_roll7) %&gt;% \n  left_join(pasta_derived_filled_big %&gt;% \n  select(site_name, subbasin, date, rSquared_air, rSquared_water, amplitudeRatio_fill_roll7, phaseLag_fill_roll7, meanRatio_fill_roll7) %&gt;% \n  rename(site_name_big = site_name, rSquared_air_big = rSquared_air, rSquared_water_big = rSquared_water, amplitudeRatio_fill_roll7_big = amplitudeRatio_fill_roll7, phaseLag_fill_roll7_big = phaseLag_fill_roll7, meanRatio_fill_roll7_big = meanRatio_fill_roll7)) %&gt;% \n  filter(rSquared_air_little &gt;= 0.7, rSquared_water_little &gt;= 0.7, rSquared_air_big &gt;= 0.7, rSquared_water_big &gt;= 0.7) %&gt;%\n  mutate(amplitudeRatio_diff = amplitudeRatio_fill_roll7_little - amplitudeRatio_fill_roll7_big,\n         phaseLag_diff = phaseLag_fill_roll7_little - phaseLag_fill_roll7_big,\n         meanRatio_diff = meanRatio_fill_roll7_little - meanRatio_fill_roll7_big,\n         yday = yday(date),\n         year = year(date))\n\n\nWrite to file\n\n\nCode\nwrite_csv(pasta_derived_filled_join, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Covariates/pasta_derived_parameters_7daymean_gGdiff.csv\")\n\n\n\nAmplitude ratio\n\n\nCode\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  mysites &lt;- unlist(siteinfo2 %&gt;% filter(site_name %in% unique(pasta_derived$site_name)) %&gt;% filter(subbasin == mysubbasins[i], designation == \"little\") %&gt;% arrange(desc(area_sqmi)) %&gt;% select(site_name))\n  myplots[[i]] &lt;- pasta_derived_filled_join %&gt;% \n    filter(site_name_little %in% mysites) %&gt;% \n    mutate(year = factor(year), site_name = factor(site_name_little, levels = mysites)) %&gt;% \n    ggplot(aes(x = yday, y = amplitudeRatio_diff, color = year)) + \n    geom_point(alpha = 0.5) + \n    geom_abline(slope = 0, intercept = 0, linetype = \"dashed\") +\n    ggtitle(mysubbasins[i]) + #ylim(0,1) + \n    facet_wrap(~site_name_little, ncol = 3)\n}\n\n\n\nWest BrookPaine RunStaunton RiverBig CreekCoal CreekMcGee CreekShields RiverSnake RiverDonner BlitzenDuck Creek\n\n\n\n\nCode\nmyplots[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[4]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[5]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[6]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[7]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[8]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[9]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[10]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhase lag\n\n\nCode\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  mysites &lt;- unlist(siteinfo2 %&gt;% filter(site_name %in% unique(pasta_derived$site_name)) %&gt;% filter(subbasin == mysubbasins[i], designation == \"little\") %&gt;% arrange(desc(area_sqmi)) %&gt;% select(site_name))\n  myplots[[i]] &lt;- pasta_derived_filled_join %&gt;% \n    filter(site_name_little %in% mysites) %&gt;% \n    mutate(year = factor(year), site_name = factor(site_name_little, levels = mysites)) %&gt;% \n    ggplot(aes(x = yday, y = phaseLag_diff, color = year)) + \n    geom_point(alpha = 0.5) + \n    geom_abline(slope = 0, intercept = 0, linetype = \"dashed\") +\n    ggtitle(mysubbasins[i]) + #ylim(0,1) + \n    facet_wrap(~site_name_little, ncol = 3)\n}\n\n\n\nWest BrookPaine RunStaunton RiverBig CreekCoal CreekMcGee CreekShields RiverSnake RiverDonner BlitzenDuck Creek\n\n\n\n\nCode\nmyplots[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[4]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[5]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[6]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[7]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[8]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[9]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[10]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean ratio\n\n\nCode\nmyplots &lt;- list()\nfor (i in 1:length(mysubbasins)) {\n  mysites &lt;- unlist(siteinfo2 %&gt;% filter(site_name %in% unique(pasta_derived$site_name)) %&gt;% filter(subbasin == mysubbasins[i], designation == \"little\") %&gt;% arrange(desc(area_sqmi)) %&gt;% select(site_name))\n  myplots[[i]] &lt;- pasta_derived_filled_join %&gt;% \n    filter(site_name_little %in% mysites) %&gt;% \n    mutate(year = factor(year), site_name = factor(site_name_little, levels = mysites)) %&gt;% \n    ggplot(aes(x = yday, y = meanRatio_diff, color = year)) + \n    geom_point(alpha = 0.5) + \n    geom_abline(slope = 0, intercept = 0, linetype = \"dashed\") +\n    ggtitle(mysubbasins[i]) + #ylim(0,1) + \n    facet_wrap(~site_name_little, ncol = 3)\n}\n\n\n\nWest BrookPaine RunStaunton RiverBig CreekCoal CreekMcGee CreekShields RiverSnake RiverDonner BlitzenDuck Creek\n\n\n\n\nCode\nmyplots[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[4]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[5]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[6]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[7]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[8]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[9]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplots[[10]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.5.2 August mean\nSummarize gG differenced PASTA output as site-level August means, across all years.\n\n\nCode\npasta_derived_august &lt;- pasta_derived_filled_join %&gt;% \n  mutate(month = month(date)) %&gt;% \n  filter(month == 8, \n         rSquared_air_little &gt;= 0.7, rSquared_water_little &gt;= 0.7, \n         rSquared_air_big &gt;= 0.7, rSquared_water_big &gt;= 0.7) %&gt;% \n  group_by(site_name_little) %&gt;% \n  summarize(amplitudeRatio_little_AugMean = mean(amplitudeRatio_fill_roll7_little, na.rm = TRUE),\n            phaseLag_little_AugMean = mean(phaseLag_fill_roll7_little, na.rm = TRUE),\n            meanRatio_little_AugMean = mean(meanRatio_fill_roll7_little, na.rm = TRUE),\n            amplitudeRatio_big_AugMean = mean(amplitudeRatio_fill_roll7_big, na.rm = TRUE),\n            phaseLag_big_AugMean = mean(phaseLag_fill_roll7_big, na.rm = TRUE),\n            meanRatio_big_AugMean = mean(meanRatio_fill_roll7_big, na.rm = TRUE),\n            amplitudeRatio_diff_AugMean = mean(amplitudeRatio_diff, na.rm = TRUE),\n            phaseLag_diff_AugMean = mean(phaseLag_diff, na.rm = TRUE),\n            meanRatio_diff_AugMean = mean(meanRatio_diff, na.rm = TRUE))\nhead(pasta_derived_august)\n\n\n# A tibble: 6 × 10\n  site_name_little    amplitudeRatio_little_AugMean phaseLag_little_AugMean\n  &lt;chr&gt;                                       &lt;dbl&gt;                   &lt;dbl&gt;\n1 Avery Brook                                 0.221                    2.19\n2 BigCreekMiddle                              0.364                    1.47\n3 BigCreekUpper                               0.152                    2.38\n4 Buck Creek                                  0.379                    1.17\n5 CoalCreekHeadwaters                         0.193                    2.30\n6 CoalCreekMiddle                             0.189                    1.62\n# ℹ 7 more variables: meanRatio_little_AugMean &lt;dbl&gt;,\n#   amplitudeRatio_big_AugMean &lt;dbl&gt;, phaseLag_big_AugMean &lt;dbl&gt;,\n#   meanRatio_big_AugMean &lt;dbl&gt;, amplitudeRatio_diff_AugMean &lt;dbl&gt;,\n#   phaseLag_diff_AugMean &lt;dbl&gt;, meanRatio_diff_AugMean &lt;dbl&gt;\n\n\nWrite to file\n\n\nCode\nwrite_csv(pasta_derived_august, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Covariates/pasta_derived_parameters_AugustDiff.csv\")",
    "crumbs": [
      "Covariates",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>PASTA</span>"
    ]
  },
  {
    "objectID": "Event Delineation/WeeklySummary.html",
    "href": "Event Delineation/WeeklySummary.html",
    "title": "8  Daily and Weekly Summaries",
    "section": "",
    "text": "8.1 Site info and daily data\nPurpose: Generate weekly summaries to use in Gg framework\nCode\n# site information\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\n\n# flow/yield (and temp) data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\")\n\n# add water/climate year variables and fill missing dates\ndat &lt;- add_date_variables(dat, dates = date, water_year_start = 4)\ndat &lt;- fill_missing_dates(dat, dates = date, groups = site_name)\nstr(dat)\n\n\ntibble [292,046 × 36] (S3: tbl_df/tbl/data.frame)\n $ station_no          : chr [1:292046] NA NA NA NA ...\n $ site_name           : chr [1:292046] \"Big Creek NWIS\" \"Big Creek NWIS\" \"Big Creek NWIS\" \"Big Creek NWIS\" ...\n $ site_id             : chr [1:292046] NA NA NA NA ...\n $ basin               : chr [1:292046] NA NA NA NA ...\n $ subbasin            : chr [1:292046] NA NA NA NA ...\n $ region              : chr [1:292046] NA NA NA NA ...\n $ lat                 : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ long                : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ elev_ft             : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ area_sqmi           : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ designation         : chr [1:292046] NA NA NA NA ...\n $ date                : Date[1:292046], format: \"2018-01-01\" \"2018-01-02\" ...\n $ DischargeReliability: num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ TempReliability     : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean           : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_min            : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_max            : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ tempc_mean          : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ tempc_min           : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ tempc_max           : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean_filled    : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean_cms       : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean_filled_cms: num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ area_sqkm           : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ Yield_mm            : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ Yield_filled_mm     : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean_7         : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean_filled_7  : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ tempc_mean_7        : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ Yield_mm_7          : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ Yield_filled_mm_7   : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ CalendarYear        : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ Month               : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ MonthName           : Factor w/ 12 levels \"Apr\",\"May\",\"Jun\",..: NA NA NA NA NA NA NA NA NA NA ...\n $ WaterYear           : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\n $ DayofYear           : num [1:292046] NA NA NA NA NA NA NA NA NA NA ...\nDefine G-g clusters/sub-basins\nCode\nsiteinfo2 &lt;- siteinfo %&gt;% \n  filter(!site_name %in% c(\"WoundedBuckCreek\", \"Brackett Creek\", \"South River Conway NWIS\", \n                           \"Shields River nr Livingston NWIS\", \"North Fork Flathead River NWIS\", \n                           \"Pacific Creek at Moran NWIS\")) %&gt;%\n  mutate(designation = ifelse(site_name %in% c(\"Donner Blitzen River nr Frenchglen NWIS\", \n                                               \"BigCreekLower\", \"CoalCreekLower\", \"McGeeCreekLower\", \n                                               \"West Brook NWIS\", \"West Brook 0\", \n                                               \"Paine Run 10\", \"Staunton River 10\", \"Piney River 10\", \n                                               \"Shields River Valley Ranch\", \"Shields River ab Smith NWIS\", \n                                               \"EF Duck Creek be HF\",\n                                               \"Spread Creek Dam\"), \"big\", \"little\"))\nMap focal sites/subbasins\nCode\nsiteinfo_sp &lt;- st_as_sf(siteinfo2, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\nCode\ndatatable(siteinfo2 %&gt;% \n            arrange(region, basin, subbasin, designation) %&gt;% \n            mutate(lat = round(lat, digits = 2), \n                   long = round(long, digits = 2), \n                   area_sqmi = round(area_sqmi, digits = 2), \n                   elev_ft = round(elev_ft, digits = 0)),\n          caption = \"EcoDrought monitoring locations and metadata.\")",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daily and Weekly Summaries</span>"
    ]
  },
  {
    "objectID": "Event Delineation/WeeklySummary.html#view-daily-data",
    "href": "Event Delineation/WeeklySummary.html#view-daily-data",
    "title": "8  Daily and Weekly Summaries",
    "section": "8.2 View daily data",
    "text": "8.2 View daily data\nView daily time series data by sub-basin (little and medium g’s only)\n\nWest BrookPaine RunPiney RiverStaunton RiverBig CreekCoal CreekMcGee CreekSnake RiverShields RiverDuck CreekDonner Blitzen",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daily and Weekly Summaries</span>"
    ]
  },
  {
    "objectID": "Event Delineation/WeeklySummary.html#daily-gg",
    "href": "Event Delineation/WeeklySummary.html#daily-gg",
    "title": "8  Daily and Weekly Summaries",
    "section": "8.3 Daily gG",
    "text": "8.3 Daily gG\n\n8.3.1 Organize data\n\n8.3.1.1 Get big and little g’s\nDefine focal basins\n\n\nCode\nfocalbasins &lt;- c(\"West Brook\", \"Paine Run\", \"Staunton River\", \"Big Creek\", \"Coal Creek\", \"McGee Creek\", \"Donner Blitzen\", \"Shields River\", \"Snake River\", \"Duck Creek\")\n\n\nRecode co-located gages and designate big and little g data:\n\n\nCode\ndat_day_big &lt;- dat %&gt;% \n  mutate(site_name = dplyr::recode(site_name, \"Leidy Creek Mouth NWIS\" = \"Leidy Creek Mouth\", \"SF Spread Creek Lower NWIS\" = \"SF Spread Creek Lower\", \"Dugout Creek NWIS\" = \"Dugout Creek\", \"Shields River ab Smith NWIS\" = \"Shields River Valley Ranch\")) %&gt;%\n  filter(site_name %in% c(\"Donner Blitzen River nr Frenchglen NWIS\", \"BigCreekLower\", \"CoalCreekLower\", \"McGeeCreekLower\", \"West Brook NWIS\", \"Paine Run 10\", \"Staunton River 10\", \"Spread Creek Dam\", \"Shields River Valley Ranch\", \"EF Duck Creek be HF\"))\n\ndat_day_little &lt;- dat %&gt;% \n  mutate(site_name = dplyr::recode(site_name, \"Leidy Creek Mouth NWIS\" = \"Leidy Creek Mouth\", \"SF Spread Creek Lower NWIS\" = \"SF Spread Creek Lower\", \"Dugout Creek NWIS\" = \"Dugout Creek\", \"Shields River ab Smith NWIS\" = \"Shields River Valley Ranch\")) %&gt;%\n  filter(subbasin %in% focalbasins, site_name %in% unlist(siteinfo2 %&gt;% filter(designation == \"little\") %&gt;% select(site_name)))\n\n#c(\"Donner Blitzen River nr Frenchglen NWIS\",  \"BigCreekLower\", \"Big Creek NWIS\", \"CoalCreekLower\", \"McGeeCreekLower\", \"West Brook NWIS\", \"Avery Brook NWIS\", \"West Brook 0\", \"Paine Run 10\", \"Staunton River 10\")\n\n\nBig G sites\n\n\nCode\nunique(dat_day_big$site_name)\n\n\n [1] \"BigCreekLower\"                          \n [2] \"CoalCreekLower\"                         \n [3] \"McGeeCreekLower\"                        \n [4] \"West Brook NWIS\"                        \n [5] \"Donner Blitzen River nr Frenchglen NWIS\"\n [6] \"Paine Run 10\"                           \n [7] \"Staunton River 10\"                      \n [8] \"EF Duck Creek be HF\"                    \n [9] \"Shields River Valley Ranch\"             \n[10] \"Spread Creek Dam\"                       \n\n\nLittle g sites\n\n\nCode\nunique(dat_day_little$site_name)\n\n\n [1] \"Big Creek NWIS\"                   \"BigCreekMiddle\"                  \n [3] \"BigCreekUpper\"                    \"CoalCreekHeadwaters\"             \n [5] \"CoalCreekMiddle\"                  \"CoalCreekNorth\"                  \n [7] \"CycloneCreekLower\"                \"CycloneCreekMiddle\"              \n [9] \"CycloneCreekUpper\"                \"Hallowat Creek NWIS\"             \n[11] \"HallowattCreekLower\"              \"LangfordCreekLower\"              \n[13] \"LangfordCreekUpper\"               \"McGeeCreekTrib\"                  \n[15] \"McGeeCreekUpper\"                  \"NicolaCreek\"                     \n[17] \"SkookoleelCreek\"                  \"WernerCreek\"                     \n[19] \"Avery Brook\"                      \"Avery Brook NWIS\"                \n[21] \"Jimmy Brook\"                      \"Mitchell Brook\"                  \n[23] \"Obear Brook Lower\"                \"Sanderson Brook\"                 \n[25] \"West Brook Lower\"                 \"West Brook Reservoir\"            \n[27] \"West Brook Upper\"                 \"West Whately Brook\"              \n[29] \"Donner Blitzen ab Fish NWIS\"      \"Donner Blitzen ab Indian NWIS\"   \n[31] \"Donner Blitzen nr Burnt Car NWIS\" \"Fish Creek NWIS\"                 \n[33] \"Indian Creek NWIS\"                \"Little Blizten River NWIS\"       \n[35] \"Paine Run 01\"                     \"Paine Run 02\"                    \n[37] \"Paine Run 06\"                     \"Paine Run 07\"                    \n[39] \"Paine Run 08\"                     \"Staunton River 02\"               \n[41] \"Staunton River 03\"                \"Staunton River 06\"               \n[43] \"Staunton River 07\"                \"Staunton River 09\"               \n[45] \"EF Duck Creek ab HF\"              \"Henrys Fork\"                     \n[47] \"Buck Creek\"                       \"Crandall Creek\"                  \n[49] \"Deep Creek\"                       \"Dugout Creek\"                    \n[51] \"Lodgepole Creek\"                  \"Shields River ab Dugout\"         \n[53] \"Grizzly Creek\"                    \"Grouse Creek\"                    \n[55] \"Leidy Creek Mouth\"                \"Leidy Creek Upper\"               \n[57] \"NF Spread Creek Lower\"            \"NF Spread Creek Upper\"           \n[59] \"Rock Creek\"                       \"SF Spread Creek Lower\"           \n[61] \"SF Spread Creek Upper\"           \n\n\n\n\n8.3.1.2 Zero flow proportion\nHow common is 0 flow and which sites experience drying?\n\n\nCode\npaste(round((nrow(dat %&gt;% filter(Yield_filled_mm == 0)) / nrow(dat))*100, digits = 3), \"% of all flow observations are 0 cfs/yield.\", sep = \"\")\n\n\n[1] \"0.025% of all flow observations are 0 cfs/yield.\"\n\n\nCode\ndat %&gt;% filter(Yield_filled_mm == 0) %&gt;% group_by(site_name) %&gt;% summarize(numdays_0flow = n()) %&gt;% left_join(dat %&gt;% filter(!is.na(Yield_filled_mm)) %&gt;% group_by(site_name) %&gt;% summarize(numdays = n())) %&gt;% mutate(prop_0flow = numdays_0flow / numdays) %&gt;% kable()\n\n\n\n\n\nsite_name\nnumdays_0flow\nnumdays\nprop_0flow\n\n\n\n\nJimmy Brook\n13\n1818\n0.0071507\n\n\nMitchell Brook\n4\n1394\n0.0028694\n\n\nObear Brook Lower\n27\n1800\n0.0150000\n\n\nPaine Run 10\n8\n11415\n0.0007008\n\n\nStaunton River 10\n5\n11444\n0.0004369\n\n\nWest Brook Upper\n16\n1831\n0.0087384\n\n\n\n\n\nDays with zero flow are exceptionally rare in our dataset. Thus, drop all days of zero flow for downstream analysis b/c of issues associated with log transforming 0s.\n\n\n8.3.1.3 Join data\nJoin big and little g data:\n\n\nCode\ndat_day_join &lt;- dat_day_little %&gt;% \n  filter(Yield_filled_mm &gt; 0 ) %&gt;%\n  select(basin, subbasin, site_name, date, Yield_filled_mm) %&gt;% \n  rename(site_name_little = site_name, yield_little = Yield_filled_mm) %&gt;% \n  left_join(dat_day_big %&gt;% filter(Yield_filled_mm &gt; 0 ) %&gt;%\n              select(basin, subbasin, site_name, date, Yield_filled_mm) %&gt;%\n              rename(site_name_big = site_name, yield_big = Yield_filled_mm)) %&gt;%\n  filter(!is.na(yield_big)) %&gt;%\n  mutate(yield_little_log = log(yield_little),\n         yield_big_log = log(yield_big))\nhead(dat_day_join)\n\n\n# A tibble: 6 × 9\n  basin    subbasin  site_name_little date       yield_little site_name_big\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;            &lt;date&gt;            &lt;dbl&gt; &lt;chr&gt;        \n1 Flathead Big Creek Big Creek NWIS   2019-03-30        0.666 BigCreekLower\n2 Flathead Big Creek Big Creek NWIS   2019-03-31        0.717 BigCreekLower\n3 Flathead Big Creek Big Creek NWIS   2019-04-01        0.749 BigCreekLower\n4 Flathead Big Creek Big Creek NWIS   2019-04-02        0.739 BigCreekLower\n5 Flathead Big Creek Big Creek NWIS   2019-04-03        0.770 BigCreekLower\n6 Flathead Big Creek Big Creek NWIS   2019-04-04        0.853 BigCreekLower\n# ℹ 3 more variables: yield_big &lt;dbl&gt;, yield_little_log &lt;dbl&gt;,\n#   yield_big_log &lt;dbl&gt;\n\n\nView sample size (number of days) per site:\n\n\nCode\ndatatable(dat_day_join %&gt;% group_by(subbasin, site_name_little) %&gt;% summarize(numdays = n()),\n          caption = \"Sample size (number of days) per site.\")\n\n\n\n\n\n\n\n\n\n8.3.2 View gG - sites combined\n\nWest BrookBig CreekCoal CreekMcGee CreekPaine RunStaunton RiverDonner BlitzenSnake RiverShields RiverDuck Creek\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"West Brook\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Big Creek\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Coal Creek\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"McGee Creek\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Paine Run\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Staunton River\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Donner Blitzen\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Snake River\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Shields River\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Duck Creek\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.3.3 View gG - facet by site\n\nWest BrookBig CreekCoal CreekMcGee CreekPaine RunStaunton RiverDonner BlitzenSnake RiverShields RiverDuck Creek\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"West Brook\") %&gt;% mutate(year = as.factor(year(date))) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.15) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little, ncol = 3, nrow = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Big Creek\") %&gt;% mutate(year = as.factor(year(date))) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.15) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little, ncol = 3, nrow = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Coal Creek\") %&gt;% mutate(year = as.factor(year(date))) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.15) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little, ncol = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"McGee Creek\") %&gt;% mutate(year = as.factor(year(date))) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.15) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Paine Run\") %&gt;% mutate(year = as.factor(year(date))) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.15) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Staunton River\") %&gt;% mutate(year = as.factor(year(date))) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.15) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Donner Blitzen\") %&gt;% mutate(year = as.factor(year(date))) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.15) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Snake River\") %&gt;% mutate(year = as.factor(year(date))) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.15) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Shields River\") %&gt;% mutate(year = as.factor(year(date))) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.15) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_day_join %&gt;% filter(subbasin == \"Duck Creek\") %&gt;% mutate(year = as.factor(year(date))) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.15) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.3.4 Hyteresis loops\nCreate plotting function\n\n\nCode\nmyplotfun &lt;- function(mysite) {\n  print(dat_day_join %&gt;%\n  mutate(doy = yday(date), year = year(date)) %&gt;%\n  filter(site_name_little == mysite) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = doy)) +\n  geom_segment(aes(xend = c(tail(yield_big_log, n = -1), NA), \n                   yend = c(tail(yield_little_log, n = -1), NA)), \n               arrow = arrow(length = unit(0.3, \"cm\")), color = \"black\") +\n  geom_point() + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  scale_color_gradient2(midpoint = 182, low = \"purple3\", mid = \"orange\", high = \"purple3\") +\n  facet_wrap(~year))\n}\n\n\n\n8.3.4.1 West Brook\n\nAvery BrookAvery Brook NWISJimmy BrookMitchell BrookAvery BrookObear Brook LowerSanderson BrookWest Brook LowerWest Brook ReservoirWest Brook Upper\n\n\n\n\nCode\nmyplotfun(mysite = \"Avery Brook\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Avery Brook NWIS\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Jimmy Brook\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Mitchell Brook\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Avery Brook\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Obear Brook Lower\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Sanderson Brook\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"West Brook Lower\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"West Brook Reservoir\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"West Brook Upper\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.3.4.2 Big Creek\n\nBig Creek NWISBigCreekMiddleBigCreekUpperHallowat Creek NWISHallowattCreekLowerLangfordCreekLowerLangfordCreekUpperNicolaCreekSkookoleelCreekWernerCreek\n\n\n\n\nCode\nmyplotfun(mysite = \"Big Creek NWIS\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"BigCreekMiddle\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"BigCreekUpper\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Hallowat Creek NWIS\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"HallowattCreekLower\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"LangfordCreekLower\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"LangfordCreekUpper\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"NicolaCreek\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"SkookoleelCreek\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"WernerCreek\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.3.4.3 Staunton River\n\nStaunton River 02Staunton River 03Staunton River 06Staunton River 07Staunton River 09\n\n\n\n\nCode\nmyplotfun(mysite = \"Staunton River 02\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Staunton River 03\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Staunton River 06\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Staunton River 07\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Staunton River 09\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.3.4.4 Shields River\n\nBuck CreekCrandall CreekDeep CreekDugout CreekLodgepole CreekShields River ab Dugout\n\n\n\n\nCode\nmyplotfun(mysite = \"Buck Creek\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Crandall Creek\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Deep Creek\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Dugout Creek\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Lodgepole Creek\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyplotfun(mysite = \"Shields River ab Dugout\")\n\n\n\n\n\n\n\n\n\n\n\n\nColor by rate of change (rising vs falling limbs)\n\n\nCode\ndat_day_join %&gt;%\n  mutate(doy = yday(date), year = year(date)) %&gt;%\n  filter(site_name_little == \"LangfordCreekLower\") %&gt;%\n  mutate(big_deriv1 = (yield_big_log - lag(yield_big_log)) / (doy - lag(doy))) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = big_deriv1)) +\n  geom_segment(aes(xend = c(tail(yield_big_log, n = -1), NA), \n                   yend = c(tail(yield_little_log, n = -1), NA)), \n               arrow = arrow(length = unit(0.3, \"cm\")), color = \"black\") +\n  geom_point() + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  scale_color_continuous_diverging(palette = \"Red-Green\") +\n  theme_dark()+\n  facet_wrap(~year)\n\n\n\n\n\n\n\n\n\nCode\n# \n# myplotfun &lt;- function(mysite) {\n#   print(dat_day_join %&gt;%\n#   mutate(doy = yday(date), year = year(date)) %&gt;%\n#   filter(site_name_little == mysite) %&gt;%\n#   ggplot(aes(x = yield_big_log, y = yield_little_log, color = doy)) +\n#   geom_segment(aes(xend = c(tail(yield_big_log, n = -1), NA), \n#                    yend = c(tail(yield_little_log, n = -1), NA)), \n#                arrow = arrow(length = unit(0.3, \"cm\")), color = \"black\") +\n#   geom_point() + \n#   geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n#   scale_color_gradient2(midpoint = 182, low = \"purple3\", mid = \"orange\", high = \"purple3\") +\n#   facet_wrap(~year))\n# }",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daily and Weekly Summaries</span>"
    ]
  },
  {
    "objectID": "Event Delineation/WeeklySummary.html#weekly-gg",
    "href": "Event Delineation/WeeklySummary.html#weekly-gg",
    "title": "8  Daily and Weekly Summaries",
    "section": "8.4 Weekly gG",
    "text": "8.4 Weekly gG\n\n8.4.1 Organize data\nSummarize daily data as weekly means:\n\n\nCode\ndat_week &lt;- dat %&gt;% mutate(year = year(date), week = week(date)) %&gt;% filter(!is.na(Yield_filled_mm)) %&gt;% group_by(basin, subbasin, region, site_name, lat, long, elev_ft, area_sqmi, designation, year, week) %&gt;% summarize(Yield_filled_mm_weekly = sum(Yield_filled_mm, na.rm = TRUE), n = n(), mindate = min(date), maxdate = max(date)) %&gt;% ungroup() %&gt;% filter(n == 7, !is.na(Yield_filled_mm_weekly))\n\n\n\n8.4.1.1 Get big and little g’s\nDesignate big and little g data:\n\n\nCode\ndat_week_big &lt;- dat_week %&gt;% \n  mutate(site_name = dplyr::recode(site_name, \"Leidy Creek Mouth NWIS\" = \"Leidy Creek Mouth\", \"SF Spread Creek Lower NWIS\" = \"SF Spread Creek Lower\", \"Dugout Creek NWIS\" = \"Dugout Creek\", \"Shields River ab Smith NWIS\" = \"Shields River Valley Ranch\")) %&gt;%\n  filter(site_name %in% c(\"Donner Blitzen River nr Frenchglen NWIS\", \"BigCreekLower\", \"CoalCreekLower\", \"McGeeCreekLower\", \"West Brook NWIS\", \"Paine Run 10\", \"Staunton River 10\", \"Spread Creek Dam\", \"Shields River Valley Ranch\", \"EF Duck Creek be HF\"))\n\ndat_week_little &lt;- dat_week %&gt;% \n  mutate(site_name = dplyr::recode(site_name, \"Leidy Creek Mouth NWIS\" = \"Leidy Creek Mouth\", \"SF Spread Creek Lower NWIS\" = \"SF Spread Creek Lower\", \"Dugout Creek NWIS\" = \"Dugout Creek\", \"Shields River ab Smith NWIS\" = \"Shields River Valley Ranch\")) %&gt;%\n  filter(subbasin %in% focalbasins, site_name %in% unlist(siteinfo2 %&gt;% filter(designation == \"little\") %&gt;% select(site_name)))\n\n\n\n\n8.4.1.2 Zero flow proportion\nHow common is 0 flow and which sites experience drying?\n\n\nCode\npaste(round((nrow(dat_week %&gt;% filter(Yield_filled_mm_weekly == 0)) / nrow(dat_week))*100, digits = 3), \"% of all weekly flow observations are 0 cfs/yield.\", sep = \"\")\n\n\n[1] \"0.013% of all weekly flow observations are 0 cfs/yield.\"\n\n\nCode\ndat_week %&gt;% filter(Yield_filled_mm_weekly == 0) %&gt;% group_by(site_name) %&gt;% summarize(numdays_0flow = n()) %&gt;% left_join(dat_week %&gt;% filter(!is.na(Yield_filled_mm_weekly)) %&gt;% group_by(site_name) %&gt;% summarize(numdays = n())) %&gt;% mutate(prop_0flow = numdays_0flow / numdays) %&gt;% kable()\n\n\n\n\n\nsite_name\nnumdays_0flow\nnumdays\nprop_0flow\n\n\n\n\nJimmy Brook\n1\n253\n0.0039526\n\n\nObear Brook Lower\n2\n251\n0.0079681\n\n\n\n\n\n\n\n8.4.1.3 Join data\nJoin big and little g data:\n\n\nCode\ndat_week_join &lt;- dat_week_little %&gt;% \n  filter(Yield_filled_mm_weekly &gt; 0) %&gt;%\n  select(basin, subbasin, site_name, year, week, Yield_filled_mm_weekly) %&gt;% \n  rename(site_name_little = site_name, yield_little = Yield_filled_mm_weekly) %&gt;% \n  left_join(dat_week_big %&gt;% filter(Yield_filled_mm_weekly &gt; 0) %&gt;%\n              select(basin, subbasin, site_name, year, week, Yield_filled_mm_weekly) %&gt;%\n              rename(site_name_big = site_name, yield_big = Yield_filled_mm_weekly)) %&gt;%\n  filter(!is.na(yield_big), !is.na(yield_little)) %&gt;%\n  mutate(yield_little_log = log(yield_little),\n         yield_big_log = log(yield_big))\n(dat_week_join)\n\n\n# A tibble: 6,935 × 10\n   basin        subbasin site_name_little  year  week yield_little site_name_big\n   &lt;chr&gt;        &lt;chr&gt;    &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;        \n 1 Donner Blit… Donner … Donner Blitzen …  2019    31         1.90 Donner Blitz…\n 2 Donner Blit… Donner … Donner Blitzen …  2019    32         1.77 Donner Blitz…\n 3 Donner Blit… Donner … Donner Blitzen …  2019    33         1.54 Donner Blitz…\n 4 Donner Blit… Donner … Donner Blitzen …  2019    34         1.41 Donner Blitz…\n 5 Donner Blit… Donner … Donner Blitzen …  2019    35         1.33 Donner Blitz…\n 6 Donner Blit… Donner … Donner Blitzen …  2019    36         1.32 Donner Blitz…\n 7 Donner Blit… Donner … Donner Blitzen …  2019    37         1.33 Donner Blitz…\n 8 Donner Blit… Donner … Donner Blitzen …  2019    38         1.50 Donner Blitz…\n 9 Donner Blit… Donner … Donner Blitzen …  2019    39         1.41 Donner Blitz…\n10 Donner Blit… Donner … Donner Blitzen …  2019    40         1.46 Donner Blitz…\n# ℹ 6,925 more rows\n# ℹ 3 more variables: yield_big &lt;dbl&gt;, yield_little_log &lt;dbl&gt;,\n#   yield_big_log &lt;dbl&gt;\n\n\nView sample size (number of weeks) per site:\n\n\nCode\ndatatable(dat_week_join %&gt;% group_by(subbasin, site_name_little) %&gt;% summarize(numweeks = n()),\n          caption = \"Sample size (number of weeks) per site.\")\n\n\n\n\n\n\n\n\nCode\nunique(dat_week_join$subbasin)\n\n\n [1] \"Donner Blitzen\" \"Duck Creek\"     \"Big Creek\"      \"Coal Creek\"    \n [5] \"McGee Creek\"    \"Paine Run\"      \"Shields River\"  \"Snake River\"   \n [9] \"Staunton River\" \"West Brook\"    \n\n\n\n\n\n8.4.2 View gG - sites combined\n\nWest BrookBig CreekCoal CreekMcGee CreekPaine RunStaunton RiverDonner Blitzen\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"West Brook\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"Big Creek\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"Coal Creek\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"McGee Creek\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"Paine Run\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"Staunton River\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"Donner Blitzen\") %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, group = site_name_little, color = site_name_little)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.4.3 View gG - facet by site\n\nWest BrookBig CreekCoal CreekMcGee CreekPaine RunStaunton RiverDonner BlitzenSnake RiverShields RiverDuck Creek\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"West Brook\") %&gt;% mutate(year = as.factor(year)) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little, ncol = 3, nrow = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"Big Creek\") %&gt;% mutate(year = as.factor(year)) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little, ncol = 3, nrow = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"Coal Creek\") %&gt;% mutate(year = as.factor(year)) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little, ncol = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"McGee Creek\") %&gt;% mutate(year = as.factor(year)) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"Paine Run\") %&gt;% mutate(year = as.factor(year)) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"Staunton River\") %&gt;% mutate(year = as.factor(year)) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"Donner Blitzen\") %&gt;% mutate(year = as.factor(year)) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"Snake River\") %&gt;% mutate(year = as.factor(year)) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"Shields River\") %&gt;% mutate(year = as.factor(year)) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_week_join %&gt;% filter(subbasin == \"Duck Creek\") %&gt;% mutate(year = as.factor(year)) %&gt;%\n  ggplot(aes(x = yield_big_log, y = yield_little_log, color = year)) + \n  geom_point(alpha = 0.25) + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #geom_smooth(method = \"lm\", se = F) +\n  facet_wrap(~site_name_little)",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daily and Weekly Summaries</span>"
    ]
  },
  {
    "objectID": "Event Delineation/WeeklySummary.html#write-data-files",
    "href": "Event Delineation/WeeklySummary.html#write-data-files",
    "title": "8  Daily and Weekly Summaries",
    "section": "8.5 Write data files",
    "text": "8.5 Write data files\nWrite daily and weekly paired g-G data to file\n\n\nCode\nwrite_csv(dat_day_join, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Event Delineation/EcoDrought_Data_Daily_Paired_gG.csv\")\n\nwrite_csv(dat_week_join, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Event Delineation/EcoDrought_Data_Weekly_Paired_gG.csv\")",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daily and Weekly Summaries</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html",
    "href": "Event Delineation/HydroEvents.html",
    "title": "9  Hydro Event Delineation",
    "section": "",
    "text": "9.1 Data\nPurpose: Conduct baseflow separation and delineate hydrologic events to model in Gg framework",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#data",
    "href": "Event Delineation/HydroEvents.html#data",
    "title": "9  Hydro Event Delineation",
    "section": "",
    "text": "9.1.1 Site info and daily data\n\n\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# flow/yield (and temp) data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\") %&gt;%\n  filter(!site_name %in% c(\"WoundedBuckCreek\", \"Brackett Creek\"))\n\n# add water/climate year variables\ndat &lt;- add_date_variables(dat, dates = date, water_year_start = 4)\nstr(dat)\n\n\ntibble [187,634 × 36] (S3: tbl_df/tbl/data.frame)\n $ station_no          : chr [1:187634] \"12355347\" \"12355347\" \"12355347\" \"12355347\" ...\n $ site_name           : chr [1:187634] \"Big Creek NWIS\" \"Big Creek NWIS\" \"Big Creek NWIS\" \"Big Creek NWIS\" ...\n $ site_id             : chr [1:187634] \"BIG\" \"BIG\" \"BIG\" \"BIG\" ...\n $ basin               : chr [1:187634] \"Flathead\" \"Flathead\" \"Flathead\" \"Flathead\" ...\n $ subbasin            : chr [1:187634] \"Big Creek\" \"Big Creek\" \"Big Creek\" \"Big Creek\" ...\n $ region              : chr [1:187634] \"Flat\" \"Flat\" \"Flat\" \"Flat\" ...\n $ lat                 : num [1:187634] 48.6 48.6 48.6 48.6 48.6 ...\n $ long                : num [1:187634] -114 -114 -114 -114 -114 ...\n $ elev_ft             : num [1:187634] 3528 3528 3528 3528 3528 ...\n $ area_sqmi           : num [1:187634] 73.6 73.6 73.6 73.6 73.6 ...\n $ designation         : chr [1:187634] \"medium\" \"medium\" \"medium\" \"medium\" ...\n $ date                : Date[1:187634], format: \"2018-09-10\" \"2018-09-11\" ...\n $ DischargeReliability: num [1:187634] 1 1 1 1 1 1 1 1 1 1 ...\n $ TempReliability     : num [1:187634] 1 1 1 1 1 1 1 1 1 1 ...\n $ flow_mean           : num [1:187634] 30.3 29.1 29 31.2 32.3 ...\n $ flow_min            : num [1:187634] 28.4 28.4 28.2 29.6 30.3 29.1 29 29.5 28.9 28.3 ...\n $ flow_max            : num [1:187634] 31.5 29.7 30.5 33 34.1 31.4 31.3 32.2 30.1 29.5 ...\n $ tempc_mean          : num [1:187634] NA NA NA NA NA NA NA NA NA NA ...\n $ tempc_min           : num [1:187634] NA NA NA NA NA NA NA NA NA NA ...\n $ tempc_max           : num [1:187634] NA NA NA NA NA NA NA NA NA NA ...\n $ flow_mean_filled    : num [1:187634] 30.3 29.1 29 31.2 32.3 ...\n $ flow_mean_cms       : num [1:187634] 0.857 0.825 0.821 0.885 0.915 ...\n $ flow_mean_filled_cms: num [1:187634] 0.857 0.825 0.821 0.885 0.915 ...\n $ area_sqkm           : num [1:187634] 191 191 191 191 191 ...\n $ Yield_mm            : num [1:187634] 0.389 0.374 0.372 0.401 0.415 ...\n $ Yield_filled_mm     : num [1:187634] 0.389 0.374 0.372 0.401 0.415 ...\n $ flow_mean_7         : num [1:187634] NA NA NA 30.3 30.4 ...\n $ flow_mean_filled_7  : num [1:187634] NA NA NA 30.3 30.4 ...\n $ tempc_mean_7        : num [1:187634] NA NA NA NA NA NA NA NA NA NA ...\n $ Yield_mm_7          : num [1:187634] NA NA NA 0.389 0.39 ...\n $ Yield_filled_mm_7   : num [1:187634] NA NA NA 0.389 0.39 ...\n $ CalendarYear        : num [1:187634] 2018 2018 2018 2018 2018 ...\n $ Month               : num [1:187634] 9 9 9 9 9 9 9 9 9 9 ...\n $ MonthName           : Factor w/ 12 levels \"Apr\",\"May\",\"Jun\",..: 6 6 6 6 6 6 6 6 6 6 ...\n $ WaterYear           : num [1:187634] 2019 2019 2019 2019 2019 ...\n $ DayofYear           : num [1:187634] 163 164 165 166 167 168 169 170 171 172 ...",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#west-brook",
    "href": "Event Delineation/HydroEvents.html#west-brook",
    "title": "9  Hydro Event Delineation",
    "section": "9.2 West Brook",
    "text": "9.2 West Brook\n\n9.2.1 Trim to focal sites\n\n\nCode\ndat_wb &lt;- dat %&gt;% filter(site_name %in% c(\"West Brook NWIS\", \"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\"))\n\n\nView daily yield at Big G\n\n\nCode\ndat_wb %&gt;% filter(site_name == \"West Brook NWIS\") %&gt;% select(date, Yield_filled_mm) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTotal daily streamflow in yield (mm), over the period of record\n\n\nView daily yield at all sites\n\n\nCode\ndat_wb %&gt;% filter(site_name != \"West Brook NWIS\") %&gt;% select(date, site_name, Yield_filled_mm) %&gt;% spread(key = site_name, value = Yield_filled_mm) %&gt;% left_join(dat_wb %&gt;% filter(site_name == \"West Brook NWIS\") %&gt;% select(date, Yield_filled_mm) %&gt;% rename(West_Brook_NWIS = Yield_filled_mm)) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(colors = c(hcl.colors(9, \"Zissou 1\"), \"black\")) \n\n\n\n\n\n\n\n\n9.2.2 Set parameters\nSet baseflow separation (for the Lyne-Hollick one-parameter digital recursive filter) and event delineation paramters (as in Wasko and Guo, 2022)\n\nalp: alpha filter parameter, higher values “lower” the estimated baseflow (thus making it difficult to delineate events)\nnumpass: number of passes. Ladson et al. (2013) recommend 3 passes for daily data (default in baseflowB() function)\nthresh: baseflow index threshold for event delineation, higher threshold values make it “easier” to delineate events\n\n\n\nCode\nalp &lt;- 0.925\nnumpass &lt;- 3\nthresh &lt;- 0.75\n\n\n\n\n9.2.3 Baseflow separation\nPerform baseflow separation. See Wasko and Guo (2022, Hydrological Processes) for recommendations on parameterization, as different algorithms and alpha values can produce different results. Section 4.1: “…users should not simply use recommended filter parameter values from literature in combination with any baseflow filter code without verification of their choice of filter parameter. As the digital baseflow filter is not tied to any physical realism (Nathan and McMahon, 1990) and a larger fractional baseflow may aid identification of events—even if this is not strictly baseflow as per its definition (Linsley et al., 1958)…”.\nIt is not actually necessary to do this separately, as baseflow separation is conducted in the event delineation function internally. But it is helpful to view the results and explore how different parameterizations yield different baseflow contributions.\n\n\nCode\ndat_wb_bf &lt;- dat_wb %&gt;% \n  filter(!is.na(Yield_filled_mm)) %&gt;% \n  select(site_name, basin, subbasin, WaterYear, date, Yield_filled_mm, flow_mean_filled_cms, area_sqkm) %&gt;%\n  group_by(site_name) %&gt;%\n  mutate(bf = baseflowB(Yield_filled_mm, alpha = alp, passes = numpass)$bf, \n         bfi = baseflowB(Yield_filled_mm, alpha = alp, passes = numpass)$bfi) %&gt;%\n  ungroup()\nhead(dat_wb_bf)\n\n\n# A tibble: 6 × 10\n  site_name   basin      subbasin   WaterYear date       Yield_filled_mm\n  &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;date&gt;               &lt;dbl&gt;\n1 Avery Brook West Brook West Brook      2020 2020-02-20            1.54\n2 Avery Brook West Brook West Brook      2020 2020-02-21            1.39\n3 Avery Brook West Brook West Brook      2020 2020-02-22            1.21\n4 Avery Brook West Brook West Brook      2020 2020-02-23            1.25\n5 Avery Brook West Brook West Brook      2020 2020-02-24            1.33\n6 Avery Brook West Brook West Brook      2020 2020-02-25            1.66\n# ℹ 4 more variables: flow_mean_filled_cms &lt;dbl&gt;, area_sqkm &lt;dbl&gt;, bf &lt;dbl&gt;,\n#   bfi &lt;dbl&gt;\n\n\n\n\nCode\ndat_wb_bf %&gt;% filter(site_name == \"West Brook NWIS\") %&gt;% select(date, Yield_filled_mm, bf, bfi) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTotal daily streamflow in yield (mm), baseflow in yield, and fractional baseflow index over the period of record for site West Brook NWIS\n\n\n\n\n9.2.4 Event identification\nThere are multiple options for methods of event identification. Section 4.2 in Wasko and Guo (2022): It can be generalized that, if the aim of the analysis is to identify independent streamflow maxima then eventMaxima() and eventMinima() work well and indeed have been traditionally employed for this task. If identifying independent small events becomes difficult, or the aim is to identify wet spells, eventBaseflow() may be preferred.” In our case, small events are likely important, so we use eventBaseflow() with a ~large values for BFI_Th to capture those small events.\nThe aim is to understand how water availability affects differences in yield between Big G and Little g during hydrologic events and the intervening periods (non-event baseflow periods). Therefore, we identify events from the Big G data, apply event/non-event time periods to the little g data, then explore G-g deviations during both events and non-events as a function of\n\n9.2.4.1 Identify events\nSeparate Big G and Little G data\n\n\nCode\ndat_big &lt;- dat_wb_bf %&gt;% filter(site_name == \"West Brook NWIS\")\ndat_little &lt;- dat_wb_bf %&gt;% filter(site_name != \"West Brook NWIS\")\n\n\nIdentify events at Big G\n\n\nCode\nevents &lt;- eventBaseflow(dat_big$Yield_filled_mm, BFI_Th = thresh, bfi = dat_big$bfi)\nevents &lt;- events %&gt;% mutate(len = end - srt + 1)\n(events)\n\n\n     srt  end which.max         max          sum len\n1      7   10         9  2.38497555   7.64869449   4\n2     14   16        15  2.07111297   5.56984542   3\n3     27   32        28  5.55987600  18.93125083   6\n4     33   36        34  3.05191193   9.89582615   4\n5     42   45        44  3.09587342  10.04006129   4\n6     48   51        50  2.99879539  10.11468354   4\n7     56   66        60  6.55907141  41.26316897  11\n8     70   72        71  3.35584214   8.36563814   3\n9     73   77        75  7.39796717  20.73565834   5\n10    91  123        93 13.49332693  81.02096355  33\n11   131  136       134  0.42653008   1.80433842   6\n12   151  154       152  0.35021501   1.21473626   4\n13   155  157       156  0.57631007   1.11656136   3\n14   161  165       162  0.90517483   2.21075332   5\n15   168  172       169  0.32221439   1.17910068   5\n16   174  184       175  1.16607633   3.04118498  11\n17   187  193       188  0.24304053   0.78984717   7\n18   210  214       213  0.13748977   0.48903486   5\n19   216  220       217  0.29573386   0.72424178   5\n20   224  227       225  0.26640317   0.51998064   4\n21   243  249       244  0.78269588   1.73834437   7\n22   256  266       261  1.00459343   3.35632581  11\n23   272  281       274  0.85217057   3.84481654  10\n24   290  294       291  0.82467953   2.12539548   5\n25   297  315       306 13.65535395  35.89563528  19\n26   321  327       326  3.66061955  16.06901178   7\n27   329  344       330 24.87600146  86.15566545  16\n28   351  356       353  3.36966108  13.08497738   6\n29   382  385       384  1.70473844   4.77951207   4\n30   406  412       408  2.03095169  10.77360433   7\n31   413  416       414  2.53707021   6.93624199   4\n32   419  428       424  4.85485118  23.07934982  10\n33   441  450       442  6.24762715  32.16321850  10\n34   454  476       456 13.97033931  92.61839297  23\n35   484  492       487  3.22862157  13.31926016   9\n36   501  503       502  0.88565558   2.32355902   3\n37   517  523       520  2.04546157   7.11885922   7\n38   524  544       536 17.64531250  83.43984731  21\n39   544  551       547  4.28110625  18.44361514   8\n40   566  569       567  1.76301980   4.41072787   4\n41   570  576       572 14.16492720  29.84383108   7\n42   580  587       581 14.64023626  29.47140889   8\n43   587  590       588  1.79127953   6.07791335   4\n44   602  604       603  1.62312899   3.48961808   3\n45   612  618       614  7.56655819  19.48346413   7\n46   625  627       626  1.67010474   4.24344965   3\n47   633  638       636  3.09932815  11.64858540   6\n48   639  644       640  5.01186884  15.45026095   6\n49   651  658       653  5.38610289  24.25542761   8\n50   681  683       682  1.75077277   4.09601888   3\n51   688  691       689  2.62335219   6.82594961   4\n52   691  694       693  1.87384767   6.39143045   4\n53   695  698       696  2.22398495   7.23654473   4\n54   702  705       703  1.92065931   6.67955850   4\n55   730  733       732  1.60304575   3.99293205   4\n56   735  740       736 11.81155383  22.61873988   6\n57   745  749       748  2.11013492   8.52400389   5\n58   749  754       750  3.69906996  14.03872475   6\n59   754  762       755  6.20288835  25.73226627   9\n60   766  769       768  4.03003346  10.26263252   4\n61   771  773       772  2.68795571   7.58745777   3\n62   775  777       776  2.77985163   7.36678820   3\n63   779  782       780  4.20026548  12.18916488   4\n64   783  788       785  4.49296781  18.97745789   6\n65   791  794       792  3.99799081  11.30743042   4\n66   798  804       799  7.87687966  26.61191978   7\n67   809  817       810  5.81630363  25.33149085   9\n68   817  833       818  2.25326382  26.69256100  17\n69   837  845       838  1.14862993   6.49759442   9\n70   848  852       850  0.67543502   2.54228686   5\n71   852  854       853  0.45228513   1.29758942   3\n72   859  868       861  1.12555230   4.48991900  10\n73   868  873       870  0.32774197   1.51574723   6\n74   873  892       875  0.25402658   3.20589805  20\n75   895  909       901  0.16721776   1.13500100  15\n76   910  912       911  0.03383048   0.09089405   3\n77   921  923       922  0.04333964   0.08305180   3\n78   935  938       937  0.03871029   0.10731267   4\n79   949  962       950  0.56033193   1.92024474  14\n80   963  970       966  0.32348401   1.42571686   8\n81   970  972       971  0.12139935   0.31966653   3\n82   978  982       979  0.30254832   0.88719294   5\n83   987  996       988  1.06432578   3.25327973  10\n84   997 1003       999  0.46835827   2.04060767   7\n85  1016 1026      1017  1.30848046   6.75761497  11\n86  1032 1049      1042  2.91231477  18.21371123  18\n87  1050 1056      1052  2.30137099   9.12951435   7\n88  1057 1064      1058 12.42267898  28.12266276   8\n89  1068 1075      1071  2.95992964  18.87027477   8\n90  1078 1082      1079  4.29699803  13.91765462   5\n91  1085 1091      1086  3.87422496  20.28939309   7\n92  1091 1104      1092  8.15066732  45.56772096  14\n93  1135 1164      1158  5.60090097 106.39616778  30\n94  1178 1185      1179 15.97823066  49.87849800   8\n95  1185 1204      1187 10.55274380  68.86113799  20\n96  1206 1213      1207  5.78633381  14.54188185   8\n97  1231 1233      1232  1.05613806   2.16265478   3\n98  1243 1279      1257 35.46223891 223.36833364  37\n99  1285 1287      1286  1.65974053   3.86178792   3\n100 1292 1299      1293  2.91710821  13.16789963   8\n101 1302 1305      1304  1.13047530   3.62194302   4\n102 1317 1324      1321  1.85389658  10.10111508   8\n103 1327 1329      1328  1.12710693   2.59046312   3\n104 1333 1337      1335  1.83273633   6.14163592   5\n105 1337 1344      1339  5.50857320  17.57774654   8\n106 1346 1350      1347  3.51743732   9.72965345   5\n107 1359 1365      1360  4.22436224  16.00094553   7\n108 1368 1374      1370  2.86008783  14.67285945   7\n109 1391 1395      1393  2.09391422   7.30686584   5\n110 1396 1400      1397  2.74504519   9.01132791   5\n111 1402 1408      1404  3.31922196  13.81375350   7\n\n\nPlot Big G events using the default function\n\n\nCode\npar(mar = c(3,3,1,1))\nplotEvents(dat_big$Yield_filled_mm, events = events, main = NA, xlab = \"Time-step\", ylab = \"Yield\")\n\n\n\n\n\nTime series of hydrologic events at Big G, identified using eventBaseflow().\n\n\n\n\n\n\n9.2.4.2 Tidy events\nNow add variables to the Big G time series data specifying events and non-events\n\n\nCode\n# define positions of non-events\nsrt &lt;- c(1)\nend &lt;- c(events$srt[1]-1)\nfor (i in 2:(dim(events)[1])) {\n  srt[i] &lt;- events$end[i-1]+1\n  end[i] &lt;- events$srt[i]-1\n}\nnonevents &lt;- data.frame(tibble(srt, end) %&gt;% mutate(len = end - srt) %&gt;% filter(len &gt;= 0) %&gt;% select(-len) %&gt;% add_row(srt = events$end[dim(events)[1]]+1, end = dim(dat_big)[1]))\n\n# create vectors of binary event/non-event and event IDs\nisevent_vec &lt;- rep(2, times = dim(dat_big)[1])\neventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(events)[1]) { \n  isevent_vec[c(events[i,1]:events[i,2])] &lt;- 1 \n  eventid_vec[c(events[i,1]:events[i,2])] &lt;- i\n}\n\n# create vector of non-event IDs\nnoneventid_vec &lt;- rep(NA, times = dim(dat_big)[1])\nfor (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n\n# create vector of \"agnostic events\": combined hydro events and non-events\nagnevents &lt;- rbind(events %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\nagneventid_vec &lt;- c()\nfor (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n# add event/non-event vectors to Big G data\ndat_big &lt;- dat_big %&gt;% \n  mutate(isevent = isevent_vec, \n         eventid = eventid_vec,\n         noneventid = noneventid_vec,\n         agneventid = agneventid_vec,\n         big_event_yield = ifelse(isevent_vec == 1, Yield_filled_mm, NA),\n         big_nonevent_yield = ifelse(isevent_vec == 2, Yield_filled_mm, NA),\n         big_event_quick = big_event_yield - bf) %&gt;%\n  rename(big_yield = Yield_filled_mm, big_bf = bf, big_bfi = bfi, big_flow = flow_mean_filled_cms, big_area_sqkm = area_sqkm)\n(dat_big)\n\n\n# A tibble: 1,411 × 17\n   site_name       basin      subbasin   WaterYear date       big_yield big_flow\n   &lt;chr&gt;           &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n 1 West Brook NWIS West Brook West Brook      2020 2020-01-31      1.67    0.572\n 2 West Brook NWIS West Brook West Brook      2020 2020-02-01      1.57    0.537\n 3 West Brook NWIS West Brook West Brook      2020 2020-02-02      1.53    0.523\n 4 West Brook NWIS West Brook West Brook      2020 2020-02-03      1.46    0.500\n 5 West Brook NWIS West Brook West Brook      2020 2020-02-04      1.41    0.482\n 6 West Brook NWIS West Brook West Brook      2020 2020-02-05      1.42    0.486\n 7 West Brook NWIS West Brook West Brook      2020 2020-02-06      1.45    0.495\n 8 West Brook NWIS West Brook West Brook      2020 2020-02-07      2.19    0.747\n 9 West Brook NWIS West Brook West Brook      2020 2020-02-08      2.38    0.815\n10 West Brook NWIS West Brook West Brook      2020 2020-02-09      1.63    0.556\n# ℹ 1,401 more rows\n# ℹ 10 more variables: big_area_sqkm &lt;dbl&gt;, big_bf &lt;dbl&gt;, big_bfi &lt;dbl&gt;,\n#   isevent &lt;dbl&gt;, eventid &lt;int&gt;, noneventid &lt;int&gt;, agneventid &lt;int&gt;,\n#   big_event_yield &lt;dbl&gt;, big_nonevent_yield &lt;dbl&gt;, big_event_quick &lt;dbl&gt;\n\n\n\n\nCode\ndat_big %&gt;% select(date, big_yield, big_bf, big_event_yield, big_nonevent_yield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTime series of hydrologic events at Big G, identified using eventBaseflow().\n\n\n\n\n9.2.4.3 Check congruency\nApplying Big G event/non-event periods to little g time series data inherently assumes that event/non-event periods would be similarly delineated for little g. If this assumption does not hold, then non-event little g flow would be included in event periods, and vice-versa. How well does this assumption hold?\n\n\nCode\nsites &lt;- c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")\n\ndat_little2 &lt;- dat_little %&gt;% filter(site_name == \"Jimmy Brook\")\nevents_little &lt;- eventBaseflow(dat_little2$Yield_filled_mm, BFI_Th = 0.75)\n\n# define positions of non-events\nsrt &lt;- c(1)\nend &lt;- c(events_little$srt[1]-1)\nfor (i in 2:(dim(events_little)[1])) {\n  srt[i] &lt;- events_little$end[i-1]+1\n  end[i] &lt;- events_little$srt[i]-1\n}\nnonevents &lt;- data.frame(tibble(srt, end) %&gt;% mutate(len = end - srt) %&gt;% filter(len &gt;= 0) %&gt;% select(-len) %&gt;% add_row(srt = events_little$end[dim(events_little)[1]]+1, end = dim(dat_little2)[1]))\n\n# create vectors of binary event/non-event and event IDs\nisevent_vec &lt;- rep(2, times = dim(dat_little2)[1])\neventid_vec &lt;- rep(NA, times = dim(dat_little2)[1])\nfor (i in 1:dim(events_little)[1]) { \n  isevent_vec[c(events_little[i,1]:events_little[i,2])] &lt;- 1 \n  eventid_vec[c(events_little[i,1]:events_little[i,2])] &lt;- i\n}\n\n# create vector of non-event IDs\nnoneventid_vec &lt;- rep(NA, times = dim(dat_little2)[1])\nfor (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n\n# create vector of \"agnostic events\": combined hydro events and non-events\nagnevents &lt;- rbind(events_little %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\nagneventid_vec &lt;- c()\nfor (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n# add event/non-event vectors to Big G data\ndat_little2 &lt;- dat_little2 %&gt;% \n  mutate(isevent = isevent_vec, \n         eventid = eventid_vec,\n         noneventid = noneventid_vec,\n         agneventid = agneventid_vec,\n         little_event_yield = ifelse(isevent_vec == 1, Yield_filled_mm, NA),\n         little_nonevent_yield = ifelse(isevent_vec == 2, Yield_filled_mm, NA),\n         little_event_quick = little_event_yield - bf) %&gt;%\n  rename(little_yield = Yield_filled_mm, little_bf = bf, little_bfi = bfi)\n\n\ndat_big %&gt;% select(date, big_event_yield) %&gt;% left_join(dat_little2 %&gt;% select(date, little_event_yield)) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTime series of yield for Big G (West Brook NWIS) and one little g site (Jimmy Brook) during hydrologic events as delineated for Big G and little g, respectively.\n\n\nWhether or not events alighn between G and g is highly variable. In some cases, g events begin/end prior to G events, and in other cases g events begin/end later G events. In some cases g events are shorter than G events, and in other cases they are longer. In many cases, events are perfectly matched. Importantly, peaks in yield are almost always synchronous.\nUltimately, does this matter given that we are simply using this as a method to break up our data? Furthermore, the framing of the ~entire project is that Big G is the reference by which to compare all little g’s. In this sense, applying event/non-event periods derived from G to g matches this persepctive.\n\n\n\n9.2.5 Join events to Little g\n\n\nCode\n# fudge factor to deal with 0 flow, when logged\nfudge &lt;- 0.01\n\n# join big g events to little g and summarize by event (cumulative, mean, and quantiles)\ndat_wb2 &lt;- dat_little %&gt;% \n  filter(date &gt;= min(dat_big$date) & date &lt;= max(dat_big$date)) %&gt;%\n  left_join(dat_big %&gt;% select(-site_name)) %&gt;% \n  group_by(site_name, basin, subbasin, agneventid) %&gt;% \n  summarise(eventlen = n(),\n            mindate = min(date),\n            isevent = unique(isevent), \n            # cumulative\n            yield_little_cumul = sum(Yield_filled_mm+fudge),\n            yield_big_cumul = sum(big_yield+fudge),\n            yield_little_cumul_log = log(yield_little_cumul),\n            yield_big_cumul_log = log(yield_big_cumul),\n            # mean\n            yield_little_mean = mean(Yield_filled_mm+fudge),\n            yield_big_mean = mean(big_yield+fudge),\n            yield_little_mean_log = mean(log(Yield_filled_mm+fudge)),\n            yield_big_mean_log = mean(log(big_yield+fudge)),\n            # quantiles\n            yield_little_q10_log = quantile(log(Yield_filled_mm+fudge), probs = 0.10),\n            yield_little_q50_log = quantile(log(Yield_filled_mm+fudge), probs = 0.50),\n            yield_little_q90_log = quantile(log(Yield_filled_mm+fudge), probs = 0.90),\n            yield_big_q10_log = quantile(log(big_yield+fudge), probs = 0.10),\n            yield_big_q50_log = quantile(log(big_yield+fudge), probs = 0.50),\n            yield_big_q90_log = quantile(log(big_yield+fudge), probs = 0.90)) %&gt;%\n  ungroup() %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")),\n         site_name_cd = as.numeric(site_name)\n         # z_yield_big_cumul_log = as.numeric(scale(yield_big_cum_log, center = TRUE, scale = TRUE)),\n         # z_yield_big_mean_log = as.numeric(scale(yield_big_mean_log, center = TRUE, scale = TRUE))\n         )\ndat_wb2\n\n\n# A tibble: 708 × 22\n   site_name   basin      subbasin   agneventid eventlen mindate    isevent\n   &lt;fct&gt;       &lt;chr&gt;      &lt;chr&gt;           &lt;int&gt;    &lt;int&gt; &lt;date&gt;       &lt;dbl&gt;\n 1 Avery Brook West Brook West Brook          5        6 2020-02-20       2\n 2 Avery Brook West Brook West Brook          6        6 2020-02-26       1\n 3 Avery Brook West Brook West Brook          7        4 2020-03-03       1\n 4 Avery Brook West Brook West Brook          8        5 2020-03-07       2\n 5 Avery Brook West Brook West Brook          9        4 2020-03-12       1\n 6 Avery Brook West Brook West Brook         10        2 2020-03-16       2\n 7 Avery Brook West Brook West Brook         11        4 2020-03-18       1\n 8 Avery Brook West Brook West Brook         12        4 2020-03-22       2\n 9 Avery Brook West Brook West Brook         13       11 2020-03-26       1\n10 Avery Brook West Brook West Brook         14        3 2020-04-06       2\n# ℹ 698 more rows\n# ℹ 15 more variables: yield_little_cumul &lt;dbl&gt;, yield_big_cumul &lt;dbl&gt;,\n#   yield_little_cumul_log &lt;dbl&gt;, yield_big_cumul_log &lt;dbl&gt;,\n#   yield_little_mean &lt;dbl&gt;, yield_big_mean &lt;dbl&gt;, yield_little_mean_log &lt;dbl&gt;,\n#   yield_big_mean_log &lt;dbl&gt;, yield_little_q10_log &lt;dbl&gt;,\n#   yield_little_q50_log &lt;dbl&gt;, yield_little_q90_log &lt;dbl&gt;,\n#   yield_big_q10_log &lt;dbl&gt;, yield_big_q50_log &lt;dbl&gt;, …\n\n\nCode\n# write to file\nwrite_csv(dat_wb2, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Event Delineation/Basin files/EcoDrought_Data_EventNonEvent_WestBrookonly.csv\")\n\n\nView pairs plot of summary statistics, for Big G only (limit to one little g site to avoid pseudo replication):\n\n\nCode\nmyplot &lt;- ggpairs(dat_wb2 %&gt;% filter(site_name == \"Avery Brook\") %&gt;% select(mindate, yield_big_cumul_log, yield_big_mean_log, yield_big_q10_log, yield_big_q50_log, yield_big_q90_log))\nrctib &lt;- tibble(r = c(3,4,4,5,5,5,6,6,6,6),\n                c = c(2,2,3,2,3,4,2,3,4,5))\nfor (i in 1:nrow(rctib)) {\n  myplot[rctib$r[i], rctib$c[i]] &lt;- myplot[rctib$r[i], rctib$c[i]] + geom_abline(intercept = 0, slope = 1, color = \"red\")\n}\nmyplot\n\n\n\n\n\n\n\n\n\n\n\n9.2.6 Plot gG relationships\n\n\nCode\np1 &lt;- dat_wb2 %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np2 &lt;- dat_wb2 %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np3 &lt;- dat_wb2 %&gt;% \n  ggplot(aes(x = yield_big_q10_log, y = yield_little_q10_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np4 &lt;- dat_wb2 %&gt;% \n  ggplot(aes(x = yield_big_q50_log, y = yield_little_q50_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np5 &lt;- dat_wb2 %&gt;% \n  ggplot(aes(x = yield_big_q90_log, y = yield_little_q90_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\nggarrange(p1, p2, p3, p4, p5, nrow = 2, ncol = 3)\n\n\n\n\n\nRelationship between yield at Big G and yield at little g, summarized during event/non-event periods with five different metrics.\n\n\n\n\nView relationship between Big G and little g, color by event/non-event, facet by site. For most sites (except may Obear Brook), G-g relationships are identical between events and non-event.\n\n\nCode\nmyplotlist &lt;- list()\n# cumulative \nmyplotlist[[1]] &lt;- dat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# mean\nmyplotlist[[2]] &lt;- dat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# 10% quantile\nmyplotlist[[3]] &lt;- dat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_q10_log, y = yield_little_q10_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# 50% quantile\nmyplotlist[[4]] &lt;- dat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_q50_log, y = yield_little_q50_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# 90% quantile\nmyplotlist[[5]] &lt;- dat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_q90_log, y = yield_little_q90_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\nCumul.MeanQ10Q50Q90\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeans, as above, but color by year.\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(year = as.factor(year(mindate))) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = year, color = year)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\n\n\n\n\n\n\n\n9.2.6.1 To log or not to log?\nDoes using log-transformed data fundamentally change nature of the relationship? What does the g~G relationship look like if we use data on the original scale? Means, for example:\n\n\nCode\ndat_wb2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean, y = yield_little_mean, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#spread-creek",
    "href": "Event Delineation/HydroEvents.html#spread-creek",
    "title": "9  Hydro Event Delineation",
    "section": "9.3 Spread Creek",
    "text": "9.3 Spread Creek\n\n9.3.1 Trim to focal sites\n\n\nCode\ndat_sp &lt;- dat %&gt;% filter(basin == \"Snake River\", site_name != \"Pacific Creek at Moran NWIS\") %&gt;%\n  mutate(site_name = recode(site_name, \"Leidy Creek Mouth NWIS\" = \"Leidy Creek Mouth\", \"SF Spread Creek Lower NWIS\" = \"SF Spread Creek Lower\")) %&gt;% \n  group_by(site_name, date) %&gt;% summarise(Yield_filled_mm = mean(Yield_filled_mm), flow_mean_filled_cms = mean(flow_mean_filled_cms), area_sqkm = mean(area_sqkm), WaterYear = unique(WaterYear)) %&gt;% ungroup()\nunique(dat_sp$site_name)\n\n\n [1] \"Grizzly Creek\"         \"Grouse Creek\"          \"Leidy Creek Mouth\"    \n [4] \"Leidy Creek Upper\"     \"NF Spread Creek Lower\" \"NF Spread Creek Upper\"\n [7] \"Rock Creek\"            \"SF Spread Creek Lower\" \"SF Spread Creek Upper\"\n[10] \"Spread Creek Dam\"     \n\n\nView daily yield at Big G\n\n\nCode\ntemp &lt;- dat_sp %&gt;% filter(site_name == \"Spread Creek Dam\")\ntemp &lt;- fill_missing_dates(temp, dates = date)\ntemp %&gt;% select(date, Yield_filled_mm) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Daily yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTotal daily streamflow in yield (mm), over the period of record\n\n\nView daily yield at all sites\n\n\nCode\ndat_sp %&gt;% filter(site_name != \"Spread Creek Dam\") %&gt;% select(date, site_name, Yield_filled_mm) %&gt;% spread(key = site_name, value = Yield_filled_mm) %&gt;% left_join(dat_sp %&gt;% filter(site_name == \"Spread Creek Dam\") %&gt;% select(date, Yield_filled_mm) %&gt;% rename(Spread_Creek_Dam = Yield_filled_mm)) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(colors = c(hcl.colors(9, \"Zissou 1\"), \"black\")) \n\n\n\n\n\n\n\n\n9.3.2 Set parameters\nSet baseflow separation (for the Lyne-Hollick one-parameter digital recursive filter) and event delineation paramters (as in Wasko and Guo, 2022)\n\nalp: alpha filter parameter, higher values “lower” the estimated baseflow (thus making it difficult to delineate events)\nnumpass: number of passes. Ladson et al. (2013) recommend 3 passes for daily data (default in baseflowB() function)\nthresh: baseflow index threshold for event delineation, higher threshold values make it “easier” to delineate events\n\n\n\nCode\nalp &lt;- 0.925\nnumpass &lt;- 3\nthresh &lt;- 0.85\n\n\n\n\n9.3.3 Baseflow separation\nPerform baseflow separation. See Wasko and Guo (2022, Hydrological Processes) for recommendations on parameterization, as different algorithms and alpha values can produce different results. Section 4.1: “…users should not simply use recommended filter parameter values from literature in combination with any baseflow filter code without verification of their choice of filter parameter. As the digital baseflow filter is not tied to any physical realism (Nathan and McMahon, 1990) and a larger fractional baseflow may aid identification of events—even if this is not strictly baseflow as per its definition (Linsley et al., 1958)…”.\nIt is not actually necessary to do this separately, as baseflow separation is conducted in the event delineation function internally. But it is helpful to view the results and explore how different parameterizations yield different baseflow contributions.\n\n\nCode\nyrs &lt;- unlist(unique(dat_sp %&gt;% filter(site_name == \"Spread Creek Dam\", !is.na(Yield_filled_mm)) %&gt;% select(WaterYear)))\ndatlist &lt;- list()\nfor(i in 1:length(yrs)) {\n  datlist[[i]] &lt;- dat_sp %&gt;% \n    filter(site_name == \"Spread Creek Dam\", WaterYear == yrs[i], !is.na(Yield_filled_mm)) %&gt;%\n    mutate(bf = baseflowB(Yield_filled_mm, alpha = alp, passes = numpass)$bf, \n           bfi = baseflowB(Yield_filled_mm, alpha = alp, passes = numpass)$bfi)\n}\ndat_sp_bf &lt;- do.call(rbind, datlist)\n\n\n\n\nCode\nfill_missing_dates(dat_sp_bf, dates = date) %&gt;% select(date, Yield_filled_mm, bf, bfi) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTotal daily streamflow in yield (mm), baseflow in yield, and fractional baseflow index over the period of record for site Spread Creek Dam (Big G)\n\n\n\n\n9.3.4 Event identification\n\n9.3.4.1 Identify events\nSeparate Big G and Little G data\n\n\nCode\ndat_big &lt;- dat_sp_bf %&gt;% filter(site_name == \"Spread Creek Dam\")\ndat_little &lt;- dat_sp %&gt;% filter(site_name != \"Spread Creek Dam\")\n\n\nIdentify events at Big G and tidy…loop over years, i.e., chunks of data\n\n\nCode\nyrs &lt;- unlist(unique(dat_sp %&gt;% filter(site_name == \"Spread Creek Dam\", !is.na(Yield_filled_mm)) %&gt;% select(WaterYear)))\nbiglist &lt;- list()\nfor (k in 1:length(yrs)) {\n  ddd &lt;- dat_sp_bf %&gt;% filter(WaterYear == yrs[k])\n  events &lt;- eventBaseflow(ddd$Yield_filled_mm, BFI_Th = thresh, bfi = ddd$bfi)\n  events &lt;- events %&gt;% mutate(len = end - srt + 1)\n  \n  # define positions of non-events\n  srt &lt;- c(1)\n  end &lt;- c(events$srt[1]-1)\n  for (i in 2:(dim(events)[1])) {\n    srt[i] &lt;- events$end[i-1]+1\n    end[i] &lt;- events$srt[i]-1\n    }\n  nonevents &lt;- tibble(srt, end) %&gt;% mutate(len = end - srt) %&gt;% filter(len &gt;= 0) %&gt;% select(-len)\n  if(events$end[dim(events)[1]] != dim(ddd)[1]) { nonevents &lt;- nonevents %&gt;% add_row(srt = events$end[dim(events)[1]]+1, end = dim(ddd)[1]) }\n  nonevents &lt;- data.frame(nonevents)\n  \n  # create vectors of binary event/non-event and event IDs\n  isevent_vec &lt;- rep(2, times = dim(ddd)[1])\n  eventid_vec &lt;- rep(NA, times = dim(ddd)[1])\n  for (i in 1:dim(events)[1]) { \n    isevent_vec[c(events[i,1]:events[i,2])] &lt;- 1 \n    eventid_vec[c(events[i,1]:events[i,2])] &lt;- i\n  }\n\n  # create vector of non-event IDs\n  noneventid_vec &lt;- rep(NA, times = dim(ddd)[1])\n  for (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n\n  # create vector of \"agnostic events\": combined hydro events and non-events\n  agnevents &lt;- rbind(events %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\n  agneventid_vec &lt;- c()\n  for (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n  # add event/non-event vectors to Big G data\n  biglist[[k]] &lt;- ddd %&gt;% \n    mutate(isevent = isevent_vec, \n           eventid = eventid_vec,\n           noneventid = noneventid_vec,\n           agneventid = agneventid_vec,\n           big_event_yield = ifelse(isevent_vec == 1, Yield_filled_mm, NA),\n           big_nonevent_yield = ifelse(isevent_vec == 2, Yield_filled_mm, NA),\n           big_event_quick = big_event_yield - bf) %&gt;% \n    mutate(agneventid = paste(yrs[k], \"_\", agneventid, sep = \"\")) %&gt;%\n    rename(big_yield = Yield_filled_mm, big_bf = bf, big_bfi = bfi, big_flow = flow_mean_filled_cms, big_area_sqkm = area_sqkm)\n}\ndat_big &lt;- do.call(rbind, biglist)\ndat_big\n\n\n# A tibble: 1,059 × 15\n   site_name        date       big_yield big_flow big_area_sqkm WaterYear big_bf\n   &lt;chr&gt;            &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n 1 Spread Creek Dam 2012-06-24      1.77     5.16          253.      2013  0.884\n 2 Spread Creek Dam 2012-06-25      1.72     5.03          253.      2013  0.914\n 3 Spread Creek Dam 2012-06-26      1.69     4.93          253.      2013  0.941\n 4 Spread Creek Dam 2012-06-27      1.67     4.89          253.      2013  0.966\n 5 Spread Creek Dam 2012-06-28      1.63     4.75          253.      2013  0.988\n 6 Spread Creek Dam 2012-06-29      1.55     4.52          253.      2013  1.01 \n 7 Spread Creek Dam 2012-06-30      1.51     4.41          253.      2013  1.02 \n 8 Spread Creek Dam 2012-07-01      1.44     4.21          253.      2013  1.04 \n 9 Spread Creek Dam 2012-07-02      1.40     4.08          253.      2013  1.05 \n10 Spread Creek Dam 2012-07-03      1.42     4.14          253.      2013  1.06 \n# ℹ 1,049 more rows\n# ℹ 8 more variables: big_bfi &lt;dbl&gt;, isevent &lt;dbl&gt;, eventid &lt;int&gt;,\n#   noneventid &lt;int&gt;, agneventid &lt;chr&gt;, big_event_yield &lt;dbl&gt;,\n#   big_nonevent_yield &lt;dbl&gt;, big_event_quick &lt;dbl&gt;\n\n\n\n\nCode\nfill_missing_dates(dat_big, dates = date) %&gt;% select(date, big_yield, big_bf, big_event_yield, big_nonevent_yield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\n\n\nTime series of hydrologic events at Big G, identified using eventBaseflow().\n\n\n\n\n\n9.3.5 Join events to Little g\n\n\nCode\n# fudge factor to deal with 0 flow, when logged\nfudge &lt;- 0.01\n\n# join big g events to little g and summarize by event (cumulative, mean, and quantiles)\ndat_sp2 &lt;- dat_little %&gt;% \n  filter(date &gt;= min(dat_big$date) & date &lt;= max(dat_big$date)) %&gt;%\n  left_join(dat_big %&gt;% select(-site_name)) %&gt;% \n  group_by(site_name, agneventid) %&gt;% \n  summarise(eventlen = n(),\n            mindate = min(date),\n            isevent = unique(isevent), \n            n_little = sum(!is.na(Yield_filled_mm)),\n            n_big = sum(!is.na(big_yield)),\n            # cumulative\n            yield_little_cumul = sum(Yield_filled_mm+fudge, na.rm = TRUE),\n            yield_big_cumul = sum(big_yield+fudge, na.rm = TRUE),\n            yield_little_cumul_log = log(yield_little_cumul),\n            yield_big_cumul_log = log(yield_big_cumul),\n            # mean\n            yield_little_mean = mean(Yield_filled_mm+fudge),\n            yield_big_mean = mean(big_yield+fudge),\n            yield_little_mean_log = mean(log(Yield_filled_mm+fudge), na.rm = TRUE),\n            yield_big_mean_log = mean(log(big_yield+fudge), na.rm = TRUE),\n            # quantiles\n            yield_little_q10_log = quantile(log(Yield_filled_mm+fudge), probs = 0.10, na.rm = TRUE),\n            yield_little_q50_log = quantile(log(Yield_filled_mm+fudge), probs = 0.50, na.rm = TRUE),\n            yield_little_q90_log = quantile(log(Yield_filled_mm+fudge), probs = 0.90, na.rm = TRUE),\n            yield_big_q10_log = quantile(log(big_yield+fudge), probs = 0.10, na.rm = TRUE),\n            yield_big_q50_log = quantile(log(big_yield+fudge), probs = 0.50, na.rm = TRUE),\n            yield_big_q90_log = quantile(log(big_yield+fudge), probs = 0.90, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  mutate(site_name = factor(site_name, levels = c(\"Rock Creek\", \"SF Spread Creek Lower\", \"Grouse Creek\", \"SF Spread Creek Upper\", \"Leidy Creek Mouth\", \"Leidy Creek Upper\", \"NF Spread Creek Lower\", \"NF Spread Creek Upper\", \"Grizzly Creek\")),\n         site_name_cd = as.numeric(site_name)\n         # z_yield_big_cumul_log = as.numeric(scale(yield_big_cum_log, center = TRUE, scale = TRUE)),\n         # z_yield_big_mean_log = as.numeric(scale(yield_big_mean_log, center = TRUE, scale = TRUE))\n         ) %&gt;%\n  filter(!is.na(agneventid))\ndat_sp2 &lt;- dat_sp2[dat_sp2$n_little == dat_sp2$n_big,]\n\ndat_sp2\n\n\n# A tibble: 609 × 22\n   site_name     agneventid eventlen mindate    isevent n_little n_big\n   &lt;fct&gt;         &lt;chr&gt;         &lt;int&gt; &lt;date&gt;       &lt;dbl&gt;    &lt;int&gt; &lt;int&gt;\n 1 Grizzly Creek 2019_1           13 2018-07-03       2       13    13\n 2 Grizzly Creek 2019_2           27 2018-07-16       1       27    27\n 3 Grizzly Creek 2019_3           14 2018-08-12       2       14    14\n 4 Grizzly Creek 2019_4            6 2018-08-26       1        6     6\n 5 Grizzly Creek 2019_5           33 2018-09-01       2       33    33\n 6 Grizzly Creek 2019_6            3 2018-10-04       1        3     3\n 7 Grizzly Creek 2019_7            8 2018-10-07       2        8     8\n 8 Grizzly Creek 2022_1           45 2021-06-15       2       45    45\n 9 Grizzly Creek 2022_10           5 2021-10-08       1        5     5\n10 Grizzly Creek 2022_11           2 2021-10-13       2        2     2\n# ℹ 599 more rows\n# ℹ 15 more variables: yield_little_cumul &lt;dbl&gt;, yield_big_cumul &lt;dbl&gt;,\n#   yield_little_cumul_log &lt;dbl&gt;, yield_big_cumul_log &lt;dbl&gt;,\n#   yield_little_mean &lt;dbl&gt;, yield_big_mean &lt;dbl&gt;, yield_little_mean_log &lt;dbl&gt;,\n#   yield_big_mean_log &lt;dbl&gt;, yield_little_q10_log &lt;dbl&gt;,\n#   yield_little_q50_log &lt;dbl&gt;, yield_little_q90_log &lt;dbl&gt;,\n#   yield_big_q10_log &lt;dbl&gt;, yield_big_q50_log &lt;dbl&gt;, …\n\n\nCode\n# write to file\nwrite_csv(dat_sp2, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Event Delineation/Basin files/EcoDrought_Data_EventNonEvent_SpreadCreekonly.csv\")\n\n\nView pairs plot of summary statistics, for Big G only (limit to one little g site to avoid pseudo replication):\n\n\nCode\nmyplot &lt;- ggpairs(dat_sp2 %&gt;% select(mindate, yield_big_cumul_log, yield_big_mean_log, yield_big_q10_log, yield_big_q50_log, yield_big_q90_log))\nrctib &lt;- tibble(r = c(3,4,4,5,5,5,6,6,6,6),\n                c = c(2,2,3,2,3,4,2,3,4,5))\nfor (i in 1:nrow(rctib)) {\n  myplot[rctib$r[i], rctib$c[i]] &lt;- myplot[rctib$r[i], rctib$c[i]] + geom_abline(intercept = 0, slope = 1, color = \"red\")\n}\nmyplot\n\n\n\n\n\n\n\n\n\n\n\n9.3.6 Plot gG relationships\n\n\nCode\np1 &lt;- dat_sp2 %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np2 &lt;- dat_sp2 %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np3 &lt;- dat_sp2 %&gt;% \n  ggplot(aes(x = yield_big_q10_log, y = yield_little_q10_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np4 &lt;- dat_sp2 %&gt;% \n  ggplot(aes(x = yield_big_q50_log, y = yield_little_q50_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\np5 &lt;- dat_sp2 %&gt;% \n  ggplot(aes(x = yield_big_q90_log, y = yield_little_q90_log, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.25) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + theme(legend.position=\"none\")\n\nggarrange(p1, p2, p3, p4, p5, nrow = 2, ncol = 3)\n\n\n\n\n\nRelationship between yield at Big G and yield at little g, summarized during event/non-event periods with five different metrics.\n\n\n\n\nView relationship between Big G and little g, color by event/non-event, facet by site. For most sites (except may Obear Brook), G-g relationships are identical between events and non-event.\n\n\nCode\nmyplotlist &lt;- list()\n# cumulative \nmyplotlist[[1]] &lt;- dat_sp2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cumul_log, y = yield_little_cumul_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# mean\nmyplotlist[[2]] &lt;- dat_sp2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# 10% quantile\nmyplotlist[[3]] &lt;- dat_sp2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_q10_log, y = yield_little_q10_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# 50% quantile\nmyplotlist[[4]] &lt;- dat_sp2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_q50_log, y = yield_little_q50_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n# 90% quantile\nmyplotlist[[5]] &lt;- dat_sp2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_q90_log, y = yield_little_q90_log, group = isevent, color = isevent)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\nCumul.MeanQ10Q50Q90\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeans, as above, but color by year.\n\n\nCode\ndat_sp2 %&gt;% \n  mutate(year = as.factor(year(mindate))) %&gt;% \n  ggplot(aes(x = yield_big_mean_log, y = yield_little_mean_log, group = year, color = year)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\n\n\n\n\n\n\n\n9.3.6.1 To log or not to log?\nDoes using log-transformed data fundamentally change nature of the relationship? What does the g~G relationship look like if we use data on the original scale? Means, for example:\n\n\nCode\ndat_sp2 %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_mean, y = yield_little_mean, group = site_name, color = site_name)) + \n  geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F)",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#deprecated",
    "href": "Event Delineation/HydroEvents.html#deprecated",
    "title": "9  Hydro Event Delineation",
    "section": "9.4 DEPRECATED",
    "text": "9.4 DEPRECATED",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Event Delineation/HydroEvents.html#sensitivity-analyses",
    "href": "Event Delineation/HydroEvents.html#sensitivity-analyses",
    "title": "9  Hydro Event Delineation",
    "section": "9.5 Sensitivity analyses",
    "text": "9.5 Sensitivity analyses\n\n9.5.1 Missing data\nMany of the EcoDrought time series data are incomplete. At some sites, discharge data is available only during the summer and/or fall periods, and at other sites, time series data are interrupted due to malfunctioning sensors and/or ice formation (“ice spikes”). So how does the length of the time series affect baseflow separation (and subsequent event identification)? Wasko and Guo (2022) use a 67 day time series of flow to demonstrate the utility of the hydroEvents packages, suggesting digital baseflow separation techniques may be valid for relatively short time series.\nHere, I perform a simple sensitivity analysis to explore the effect of time series length on the results of baseflow separation. Essentially, perform baseflow separation on increasingly smaller subsets of the data. With the default parameters, the minimum number of days/observations needed is 31. This is because the default number of points reflected at start and end of data (r) is 30. Reflection allows bf/bfi to be calculated over the entire period of record as the underlying baseflow separation equations result in “issues of”Warm-up” and “cool-down” as the recursive filter is moved forward and backward over the dataset” (Ladson et al. 2013, Australian Journal of Water Resources). baseflowB() uses a default reflection period of 30, which Ladson et al. (2013) found to “provide a realistic baselfow response for the start and end of the actual flow data”.\n\n9.5.1.1 Compare baseflow\nDivergence in baseflow among datasets is a result of the reflected data of the shorter dataset not matching the actual data of the longer dataset. As a result, divergence really only occurs at the end of each time series and is generally small in magnitude.\n\n\n9.5.1.2 Compare baseflow index\nThe story here is essentially the same as above: divergence is ~minimal and restricted to the end of each time series. However, we note that divergence in BFI appears to increase as absolute flow/baseflow decreases, because small differences in absolute space become much larger in relative space when absolute values are small.\nView relationship between Big G and among-site/event-specific standard deviation in little g.",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Hydro Event Delineation</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html",
    "href": "Big G Little g/WedgeModel.html",
    "title": "10  The Wedge Model",
    "section": "",
    "text": "10.1 Q, H, A\nPurpose: Define the Wedge hypothesis and model in JAGS.\nQuestions:\nThe Wedge Hypothesis: Among- and within-site diversity in g response to G drive spatiotemporal variation in flow across river networks\nApproach",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#q-h-a",
    "href": "Big G Little g/WedgeModel.html#q-h-a",
    "title": "10  The Wedge Model",
    "section": "",
    "text": "How does water availability (G) affect upstream diversity in streamflow regimes (g)?\n\nHow does streamflow diversity manifest as heterogeneity within and among locations in the upstream river network?\n\nWhat are the relative contributions of within- and among-site diversity to the total streamflow diversity across the river network and does this change with water availability?\n\n\n\nAmong-site wedge: heterogeneity in physical characteristics among sites diversify little g response during low flows, but diversity in little g response attenuates (decreases) during high flows\nWithin-site wedge: within sites, variation in little g response to G is greater at low flows than at high flows\nAdditive diversity in the response of little g to Big G among and within sites drives total streamflow diversity across river networks\n\n\n\nBreak up data into manageable chunks using event/non-event delineation\n\nUsing Big G flow time series data, perform baseflow separation and event delineation to break up data into event and intervening non-event (baseflow) periods.\nApply Big G event/non-event periods to corresponding little g time series data and calculate (log) volumetric yield during each period for both G and g.\n\nUsing a Bayesian hierarchical model to account for site-level variation, model g ~ G, where g is (log) volumetric yield at little g and G is (log) volumetric yield at Big G during successive event/non-event periods.\n\nFit site-aware and site-agnostic models to describe within- and among-site diversity in g response to G, respectively.\nDerive measures of observed and expected g variance dampening with increasing G under different assumptions regarding among- and within-site streamflow diversity\n\n\n\n10.1.1 Conceptual diagram\nThe Wedge Hypothesis states that among- and within-site diversity in g response to G drive spatiotemporal variation in streamflow across entire river networks:\n\n\n\nThe Wedge Hypothesis - general\n\n\nThe hypothesis can be represented with a relatively simple hierarchical model:\n\n\n\nThe Wedge Hypothesis - parameters\n\n\nFrom the fitted model, we can assess the relative contributions of within- and among-site diversity to total streamflow diversity across the river network and explore the extent to which this changes with water availability:\n\n\n\nThe Wedge Hypothesis - portfolio strength",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#data",
    "href": "Big G Little g/WedgeModel.html#data",
    "title": "10  The Wedge Model",
    "section": "10.2 Data",
    "text": "10.2 Data\n\n10.2.1 Site info and event data\n\n\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# delineated event/non-event volumetric yield data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Event Delineation/EcoDrought_Data_EventNonEvent_WestBrookonly.csv\") %&gt;% mutate(site_name = factor(site_name, levels = c(\"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")))\nstr(dat)\n\n\ntibble [689 × 24] (S3: tbl_df/tbl/data.frame)\n $ site_name            : Factor w/ 9 levels \"West Brook Lower\",..: 8 8 8 8 8 8 8 8 8 8 ...\n $ basin                : chr [1:689] \"West Brook\" \"West Brook\" \"West Brook\" \"West Brook\" ...\n $ subbasin             : chr [1:689] \"West Brook\" \"West Brook\" \"West Brook\" \"West Brook\" ...\n $ agneventid           : num [1:689] 5 6 7 8 9 10 11 12 13 14 ...\n $ eventlen             : num [1:689] 6 5 5 5 4 2 4 4 11 6 ...\n $ mindate              : Date[1:689], format: \"2020-02-20\" \"2020-02-26\" ...\n $ isevent              : num [1:689] 2 1 1 2 1 2 1 2 1 2 ...\n $ yield_little_cum     : num [1:689] 8.57 23.21 18.74 15.54 14.08 ...\n $ yield_big_cum        : num [1:689] 7.04 17.14 11.93 9.41 10.16 ...\n $ yield_little_cum_log : num [1:689] 2.15 3.14 2.93 2.74 2.64 ...\n $ yield_big_cum_log    : num [1:689] 1.95 2.84 2.48 2.24 2.32 ...\n $ xxx_little           : num [1:689] 8.51 23.16 18.69 15.49 14.04 ...\n $ yyy_little           : num [1:689] 8.51 23.16 18.69 15.49 14.04 ...\n $ yield_little_mean_log: num [1:689] 0.35 1.37 1.3 1.13 1.23 ...\n $ yield_big_mean_log   : num [1:689] 0.154 1.124 0.859 0.632 0.909 ...\n $ yield_little_q25_log : num [1:689] 0.274 0.985 1.175 1.081 1.059 ...\n $ yield_little_q50_log : num [1:689] 0.351 1.105 1.3 1.109 1.178 ...\n $ yield_little_q75_log : num [1:689] 0.366 1.487 1.369 1.205 1.353 ...\n $ yield_big_q25_log    : num [1:689] 0.0675 0.814 0.7804 0.602 0.7835 ...\n $ yield_big_q50_log    : num [1:689] 0.195 0.98 0.81 0.624 0.955 ...\n $ yield_big_q75_log    : num [1:689] 0.247 1.41 0.915 0.655 1.081 ...\n $ site_name_cd         : num [1:689] 8 8 8 8 8 8 8 8 8 8 ...\n $ z_yield_big_cum_log  : num [1:689] 0.284 0.868 0.63 0.475 0.525 ...\n $ z_yield_big_mean_log : num [1:689] 0.434 1.24 1.019 0.831 1.061 ...\n\n\n\n\n10.2.2 Visualize g~G relationships\nView relationship between Big G and little g, color by site, facet by event/non-event.\n\n\nCode\ndat %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, group = site_name, color = site_name)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\", se = F) + facet_wrap(~isevent)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods.\n\n\n\n\nView relationship between Big G and little g, color by event/non-event, facet by site. For most sites (except may Obear Brook), G-g relationships are identical between events and non-event.\n\n\nCode\ndat %&gt;% \n  mutate(isevent = dplyr::recode(isevent, \"1\" = \"Event\", \"2\" = \"Baseflow\")) %&gt;% \n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, group = isevent, color = isevent)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods.\n\n\n\n\n\n\n10.2.3 Examine hysteresis\nDoes the g~G relationship change over time?\n\n\nCode\ndat %&gt;% \n  mutate(doy = yday(mindate)) %&gt;%\n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, color = doy)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  scale_color_gradient2(midpoint = 182, low = \"orange\", mid = \"purple3\", high = \"orange\") +\n  facet_wrap(~site_name)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods. Points colored by day of year.\n\n\n\n\n\n\nCode\ndat %&gt;% \n  mutate(season = ifelse(month(mindate) %in% c(12,1,2), \"winter\",\n                         ifelse(month(mindate) %in% c(3,4,5), \"spring\",\n                                ifelse(month(mindate) %in% c(6,7,8), \"summer\", \"autumn\")))) %&gt;%\n  ggplot(aes(x = yield_big_cum_log, y = yield_little_cum_log, group = season, color = season)) + \n  geom_point() + geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  geom_smooth(method = \"lm\") + facet_wrap(~site_name)\n\n\n\n\n\nEffect of (log) cumulative yield at Big G on (log) cumulative yield at little g during baseflow and event periods, by season.\n\n\n\n\nYes, it does appear that the relationship between g and G changes is time-dependent, potentially motivating some inclusion of time as a covariate (and interaction with big G effect…circular regression?). However, this also likely drives the shape/existence of the little wedges. So, is it necessary to account for?",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#declare-model",
    "href": "Big G Little g/WedgeModel.html#declare-model",
    "title": "10  The Wedge Model",
    "section": "10.3 Declare model",
    "text": "10.3 Declare model\nBased on results above, there does not appear to be any significant difference in the G-g relationship for event and non-event periods. Therefore, do not include random intercepts/slopes (by event/non-event) in the model. Previously, I tried to estimate the G-g differences using an intercept model, with the magnitude of difference a function of water availability. However, when Q = Qg, this simplified to a linear regression between Qg (dependent var.) and QG (independent var.), which is ultimately what is of interest. I estimate this regression model below:\nCorrelation between site-level slopes and site-level intercepts is modeled as specified on pgs. 362 and 376 in Gelman and Hill (2007).\n\nData\n\nQg: log volumetric yield at little g\nsites: numeric site id\nQG: log volumetric yield at Big G\nnObs: number of observations\nnSites: number of sites (little g sites)\n\nParameters\n\nalpha: site-level intercept\nbeta: site-level effect of Big G on little g (slope)\nalpha.mu: global intercept\nbeta.mu: global effect of Big G on little g (slope)\nalpha.sigma: site-level variability in the intercept\nbeta.sigma: site-level variability in the slope\nsig.alpha: site-level intercept for process error\nsig.beta: site-level effect of Big G on process error (slope)\nsig.alpha.mu: global process error intercept\nsig.beta.mu: global process error slope\nsig.alpha.sigma: site-level variability in process error intercept\nsig.beta.sigma: site-level variability in process error slope\nrho: correlation between site-leve intercepts (alpha) and slopes (beta)\n\nDerived values\n\npredlg: predicted little g\ndiff: difference between predicted little g and Big G\nVpObs: observed population variance, conditional on x\nVpScen1: expected population variance, no within or among-site diversity\nVpScen2: expected population variance, no within-site diversity\nVpScen3: expected population variance, no among-size diversity\nport1, port2, port3: predicted portfolio strength (over a range of G) compared to 3 alternative hypotheses\nattenObs, atten1, atten2, atten3: attentuation strength (“wedginess”) of observed data and expected under 3 alternative hypotheses\n\n\n\n\nCode\ncat(\"model {\n\n##--- LIKELIHOOD ---------------------------------------------------##\n\nfor (i in 1:nObs) {\n\n  Qg[i] ~ dnorm(mu[i], pow(sigma[i], -2))\n  mu[i] &lt;- alpha[sites[i]] + beta[sites[i]] * QG[i]\n  log(sigma[i]) &lt;- sig.alpha[sites[i]] + sig.beta[sites[i]] * QG[i]\n  \n  # Log-likelihood\n  loglik[i] &lt;- logdensity.norm(Qg[i], mu[i], pow(sigma[i], -2))\n  \n  ## SITE AGNOSTIC\n  Qg2[i] ~ dnorm(ag.mu[i], pow(ag.sigma[i], -2))\n  ag.mu[i] &lt;- ag.alpha + ag.beta * QG[i]\n  log(ag.sigma[i]) &lt;- ag.sig.alpha + ag.sig.beta * QG[i]  \n  }\n\n\n##--- PRIORS --------------------------------------------------------##\n\n# Site-specific parameters\nfor (j in 1:nSites) {\n    alpha[j] &lt;- B[j,1]\n    beta[j] &lt;- B[j,2]\n    B[j,1:2] ~ dmnorm(B.hat[j,], Tau.B[,])\n    B.hat[j,1] &lt;- alpha.mu\n    B.hat[j,2] &lt;- beta.mu\n    \n    sig.alpha[j] ~ dnorm(sig.alpha.mu, pow(sig.alpha.sigma, -2))\n    sig.beta[j] ~ dnorm(sig.beta.mu, pow(sig.beta.sigma, -2))\n    }\n    \n# global parameters\nalpha.mu ~ dnorm(0, pow(10, -2))\nbeta.mu ~ dnorm(0, pow(10, -2))\nsig.alpha.mu ~ dnorm(0, pow(10, -2))\nsig.beta.mu ~ dnorm(0, pow(10, -2))\n\n# variance-covariance matrix components\nTau.B[1:2,1:2] &lt;- inverse(Sigma.B[,])\nSigma.B[1,1] &lt;- pow(alpha.sigma, 2)\nSigma.B[2,2] &lt;- pow(beta.sigma, 2)\nSigma.B[1,2] &lt;- rho * alpha.sigma * beta.sigma\nSigma.B[2,1] &lt;- Sigma.B[1,2]\n\nalpha.sigma ~ dunif(0.001, 100)\nbeta.sigma ~ dunif(0.001, 100)\nrho ~ dunif(-1,1)\n\n# among-site variation in sigma parameters\nsig.alpha.sigma ~ dunif(0.001, 100)\nsig.beta.sigma ~ dunif(0.001, 100)\n\n\n## SITE AGNOSTIC\nag.alpha ~ dnorm(0, pow(10, -2))\nag.beta ~ dnorm(0, pow(10, -2))\nag.sig.alpha ~ dnorm(0, pow(10, -2))\nag.sig.beta ~ dnorm(0, pow(10, -2))\n\n\n##--- DERIVED VALUES ------------------------------------------------##\n\n# expected deviation from Big G\nfor (j in 1:nSites) { \n  for (i in 1:nDiff) {\n    predlg[j,i] &lt;- alpha[j] + beta[j] * QGvec[i]\n    diff[j,i] &lt;- (alpha[j] + beta[j] * QGvec[i]) - QGvec[i]\n  }}\n\n\n# variance decomposition and standardization\nfor (i in 1:nDiff) {\n\n  # observed population variance, conditional on x\n  VpObs[i] &lt;- ((beta.mu^2) * varx) + ((alpha.sigma^2) + ((QGvec[i]^2) * (beta.sigma^2)) + (2 * QGvec[i] * (rho * alpha.sigma * beta.sigma))) + ((exp(sig.alpha.mu + sig.beta.mu * QGvec[i]))^2)\n  \n  # expected population variance, no within or among-site diversity\n  VpScen1[i] &lt;- ((beta.mu^2) * varx) + ((exp(sig.alpha.mu))^2)\n  \n  # expected population variance, no within-site diversity\n  VpScen2[i] &lt;- ((beta.mu^2) * varx) + ((alpha.sigma^2) + ((QGvec[i]^2) * (beta.sigma^2)) + (2 * QGvec[i] * (rho * alpha.sigma * beta.sigma))) + ((exp(sig.alpha.mu))^2)\n  \n  # expected population variance, no among-size diversity\n  VpScen3[i] &lt;- ((beta.mu^2) * varx) + ((exp(sig.alpha.mu + sig.beta.mu * QGvec[i]))^2)\n  \n  # portfolio strength: how much more diversity in streamflow do we observe at the little g gages than expected under alternative (null) hypotheses?\n  port1[i] &lt;- VpObs[i] / VpScen1[i]\n  port2[i] &lt;- VpObs[i] / VpScen2[i]\n  port3[i] &lt;- VpObs[i] / VpScen3[i]\n  \n  # variance in raw response values, agnostic to site (i.e., variance in the sample)\n  VarAg[i] &lt;- (exp(ag.sig.alpha + ag.sig.beta * QGvec[i]))^2\n  \n  Vf[i] &lt;- (beta.mu^2) * varx\n  Vix[i] &lt;- (alpha.sigma^2) + ((QGvec[i]^2) * (beta.sigma^2)) + (2 * QGvec[i] * (rho * alpha.sigma * beta.sigma))\n  Vr[i] &lt;- (exp(sig.alpha.mu + sig.beta.mu * QGvec[i]))^2\n}\n\n\n\n# attenuation strength: how much more diversity in streamflow (among little g gages) do we observe at low vs. high flows?\nattenObs &lt;- VpObs[1] / VpObs[nDiff]\natten1 &lt;- VpScen1[1] / VpScen1[nDiff]\natten2 &lt;- VpScen2[1] / VpScen2[nDiff]\natten3 &lt;- VpScen3[1] / VpScen3[nDiff]\n\n}\", file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod_Events_2_corr.txt\")",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#fit-the-model",
    "href": "Big G Little g/WedgeModel.html#fit-the-model",
    "title": "10  The Wedge Model",
    "section": "10.4 Fit the model",
    "text": "10.4 Fit the model\n\n\nCode\n# vector of QG for prediction\nndiff &lt;- 100\nQGvec &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = ndiff)\n\n# gather data for JAGS\njags.data &lt;- list(\"nObs\" = dim(dat)[1], \"nSites\" = length(unique(dat$site_name_cd)), \n                  \"sites\" = dat$site_name_cd, #\"indev\" = dat_wb2$isevent,\n                  \"Qg\" = dat$yield_little_cum_log, \"QG\" = dat$yield_big_cum_log, \"Qg2\" = dat$yield_little_cum_log, \n                  \"QGvec\" = QGvec, \"nDiff\" = ndiff, \"varx\" = var(dat$yield_big_cum_log))\n\n# parameters to monitor\njags.params &lt;- c(\"alpha\", \"beta\", \"alpha.mu\", \"beta.mu\", \"alpha.sigma\", \"beta.sigma\", \n                 \"sig.alpha\", \"sig.beta\", \"sig.alpha.mu\", \"sig.beta.mu\", \"sig.alpha.sigma\", \"sig.beta.sigma\", \n                 \"rho\", \"diff\", \"predlg\", \"loglik\", \"mu\", \"Qg\", \n                 \"VpObs\", \"VpScen1\", \"VpScen2\", \"VpScen3\", \"port1\", \"port2\", \"port3\", \"attenObs\", \"atten1\", \"atten2\", \"atten3\",\n                 \"VarAg\", \"Vf\", \"Vix\", \"Vr\")\n\n# initial values\nmyinits &lt;- function() {\n  list(alpha.mu = 0, beta.mu = 1, alpha.sigma = 1, beta.sigma = 0.1, \n       sig.alpha.mu = -0.5, sig.beta.mu = -0.2, sig.alpha.sigma = 0.4, sig.beta.sigma = 0.05, \n       ag.alpha = 0.3, ag.beta = 1, ag.sig.alpha = 0, ag.sig.beta = -0.2, rho = -0.8)\n}\n\n# run in jags\nmod_0 &lt;- jags.parallel(data = jags.data, inits = myinits, parameters.to.save = jags.params,\n                       model.file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod_Events_2_corr.txt\",\n                       n.chains = 10, n.thin = 50, n.burnin = 4000, n.iter = 14000, DIC = FALSE)\n# saveRDS(mod_0, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/Fitted models/GgMod_Events.rds\")\n\n\nGet MCMC samples and summary\n\n\nCode\ntop_mod &lt;- mod_0\n# generate MCMC samples and store as an array\nmodelout &lt;- top_mod$BUGSoutput\nMcmcList &lt;- vector(\"list\", length = dim(modelout$sims.array)[2])\nfor(i in 1:length(McmcList)) { McmcList[[i]] = as.mcmc(modelout$sims.array[,i,]) }\n# rbind MCMC samples from 10 chains \nMcmcdat_0 &lt;- rbind(McmcList[[1]], McmcList[[2]], McmcList[[3]], McmcList[[4]], McmcList[[5]], McmcList[[6]], McmcList[[7]], McmcList[[8]], McmcList[[9]], McmcList[[10]])\nparam.summary_0 &lt;- modelout$summary\nhead(param.summary_0)\n\n\n          mean sd     2.5%      25%      50%      75%    97.5% Rhat n.eff\nQg[1] 2.148762  0 2.148762 2.148762 2.148762 2.148762 2.148762    1     1\nQg[2] 3.144685  0 3.144685 3.144685 3.144685 3.144685 3.144685    1     1\nQg[3] 2.930699  0 2.930699 2.930699 2.930699 2.930699 2.930699    1     1\nQg[4] 2.743658  0 2.743658 2.743658 2.743658 2.743658 2.743658    1     1\nQg[5] 2.644678  0 2.644678 2.644678 2.644678 2.644678 2.644678    1     1\nQg[6] 1.624893  0 1.624893 1.624893 1.624893 1.624893 1.624893    1     1",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#model-diagnostics",
    "href": "Big G Little g/WedgeModel.html#model-diagnostics",
    "title": "10  The Wedge Model",
    "section": "10.5 Model diagnostics",
    "text": "10.5 Model diagnostics\n\n10.5.1 View R-hat\nAny problematic R-hat values (&gt;1.01)?\n\n\nCode\nmod_0$BUGSoutput$summary[,8][mod_0$BUGSoutput$summary[,8] &gt; 1.01]\n\n\n loglik[452]    port1[65]    port1[66]    port1[67]    port1[68]    port1[69] \n    1.010080     1.010151     1.010424     1.010663     1.010867     1.011032 \n   port1[70]    port1[71]    port1[72]    port1[73]    port1[74]    port1[75] \n    1.011159     1.011246     1.011293     1.011301     1.011272     1.011207 \n   port1[76]    port1[77]    port1[78]    port1[79]    port1[80]    port1[81] \n    1.011109     1.010981     1.010826     1.010648     1.010450     1.010234 \n   port1[82]    port3[61]    port3[62]    port3[63]    port3[64]    port3[65] \n    1.010006     1.010254     1.010789     1.011316     1.011829     1.012322 \n   port3[66]    port3[67]    port3[68]    port3[69]    port3[70]    port3[71] \n    1.012787     1.013219     1.013611     1.013956     1.014251     1.014489 \n   port3[72]    port3[73]    port3[74]    port3[75]    port3[76]    port3[77] \n    1.014668     1.014785     1.014839     1.014830     1.014760     1.014629 \n   port3[78]    port3[79]    port3[80]    port3[81]    port3[82]    port3[83] \n    1.014444     1.014207     1.013924     1.013600     1.013243     1.012857 \n   port3[84]    port3[85]    port3[86]    port3[87]    port3[88]    port3[89] \n    1.012449     1.012026     1.011591     1.011152     1.010712     1.010275 \npredlg[1,33] \n    1.026732 \n\n\n\n\n10.5.2 View traceplots\nFor global parameters and hyperparameters only…\n\n\nCode\nMCMCtrace(mod_0, ind = TRUE, params = c(\"alpha.mu\", \"beta.mu\", \"alpha.sigma\", \"beta.sigma\", \"sig.alpha.mu\", \"sig.beta.mu\", \"sig.alpha.sigma\", \"sig.beta.sigma\", \"rho\"), pdf = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.5.3 PP check\nGet observed and expected values\n\n\nCode\nppdat_obs &lt;- as.matrix(Mcmcdat_0[,startsWith(colnames(Mcmcdat_0), \"Qg\")])\nppdat_exp &lt;- as.matrix(Mcmcdat_0[,startsWith(colnames(Mcmcdat_0), \"mu\")])\n\n\nBayesian p-value: values approaching 0.5 indicate lack of bias in model estimates\n\n\nCode\nsum(ppdat_exp &gt; ppdat_obs) / (dim(ppdat_obs)[1]*dim(ppdat_obs)[2])\n\n\n[1] 0.4930435\n\n\nPosterior predictive check: ensure linearity and ~1:1 relationship between expected and observed (log) volumetric Qg yield\n\n\nCode\npar(mar = c(4.5,4.5,1,1))\nplot(apply(ppdat_exp, 2, median) ~ apply(ppdat_obs, 2, median), xlab = \"Observed Qg\", ylab = \"Expected Qg\")\nabline(a = 0, b = 1, col = \"red\", lwd = 2)\nlegend(\"topleft\", legend = \"1:1\", lwd = 2, col = \"red\", bty = \"n\")\n\n\n\n\n\n\n\n\n\nSite-specific posterior predictive check: does the model fit some sites better than others?\n\n\nCode\ntibble(obs = apply(ppdat_obs, 2, median), exp = apply(ppdat_exp, 2, median), sitecd = dat$site_name) %&gt;% ggplot(aes(x = obs, y = exp)) + geom_point() + geom_smooth(method = \"lm\") + geom_abline(intercept = 0, slope = 1, color = \"red\") + facet_wrap(~sitecd)\n\n\n\n\n\n\n\n\n\n\n\n10.5.4 Model selection\nPerform model selection using leave-one-out cross-validation (LOO-CV). Does the site-aware (random slopes/random intercepts) model perform better than the site-agnostic model?\nNote: this will need to be updated once we add other random effects specifications. For now, use LOO-CV as an additional check on model fitting…i.e., examine Pareto k estimates.\nAgain, model is well specified for all but 1 data point (k &gt; 1)\n\n\nCode\n# get log-likelihoods\nloglik1 &lt;- mod_0$BUGSoutput$sims.list$loglik\n\n# get relative effective sample size\nreff1 &lt;- relative_eff(exp(loglik1), chain_id = c(rep(1,200), rep(2,200), rep(3,200), rep(4,200), rep(5,200), \n                                                 rep(6,200), rep(7,200), rep(8,200), rep(9,200), rep(10,200)))\n\n# calculate loo\nloo1 &lt;- loo(loglik1, r_eff = reff1)\n\n# compare\nprint(loo1)\n\n\n\nComputed from 2000 by 689 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -426.9 26.6\np_loo        35.6  4.6\nlooic       853.7 53.2\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.8, 1.1]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     687   99.7%   230     \n   (0.7, 1]   (bad)        2    0.3%   &lt;NA&gt;    \n   (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;    \nSee help('pareto-k-diagnostic') for details.\n\n\nCode\nplot(loo1)",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#plot-model-output",
    "href": "Big G Little g/WedgeModel.html#plot-model-output",
    "title": "10  The Wedge Model",
    "section": "10.6 Plot model output",
    "text": "10.6 Plot model output\n\n10.6.1 Slope-int. correlation\nSlopes and intercepts are negatively correlated (this is not unexpected, and explains the attenuation/wedge shape of the data). As noted in Gelman and Hill, the strength of the correlation between slopes and intercepts is sensitive to how the data is centered (or not). Currently, data span 0 (in log space), so this isn’t really an artifact of the issues mentioned in Gelman and Hill (although if we mean centered the data this relationship does weaken slightly). It may actually make the most sense to force the intercept to be at the lowest value of log(G) (i.e., add min(log(G)) to all data, G and g). Intercepts would then represent the maximum expected variation in g during periods of lowest water availability. Alternatively, we could force the intercept to be at the highest valyes of log(G) (i.e., subtract max log(G) from all data) and test for random vs. fixed intercept (as suggested by Ben). Random intercepts would suggest that we still do see site-level variation in g when overall flows are high, whereas a fixed intercept would suggest minimal/no site-level variation in g at high flows. However, we do ultimately need to the slope/intercept correlation structure to do the variance decomposition.\n\n\nCode\nsitib &lt;- tibble(site_name = levels(dat$site_name),\n                slopes = param.summary_0[str_subset(rownames(param.summary_0), pattern = \"^beta\")[1:9],5],\n                intercepts = param.summary_0[str_subset(rownames(param.summary_0), pattern = \"^alpha\")[1:9],5]) \n\n# slope-intercept scatterplot\np1 &lt;- sitib %&gt;% ggplot(aes(x = slopes, y = intercepts, color = site_name)) + geom_point(size = 3) + theme_bw() + xlab(\"Site-level slope\") + ylab(\"Site-level intercept\")\n\n# \"rho\" posterior density\np2 &lt;- tibble(Mcmcdat_0[,\"rho\"]) %&gt;% ggplot(aes(x = Mcmcdat_0[, \"rho\"])) + geom_density(color = \"black\", fill = \"grey\") + theme_bw() + xlab(\"rho\") + ylab(\"Posterior density\") + xlim(-1,0)\n\n# arrange plots\nggarrange(p2, p1, ncol = 2, widths = c(0.35, 0.65))\n\n\n\n\n\n\n\n\n\nCode\n# correlation\n# cor.test(sitib$intercepts, sitib$slopes)\n\n\n\n\nCode\nsitib &lt;- tibble(site_name = levels(dat$site_name),\n                slopes = param.summary_0[str_subset(rownames(param.summary_0), pattern = \"^sig.beta\")[1:9],5],\n                intercepts = param.summary_0[str_subset(rownames(param.summary_0), pattern = \"^sig.alpha\")[1:9],5]) \n\n# slope-intercept scatterplot\np1 &lt;- sitib %&gt;% ggplot(aes(x = slopes, y = intercepts, color = site_name)) + geom_point(size = 3) + theme_bw() + xlab(\"Site-level slope\") + ylab(\"Site-level intercept\")\n\n# \"rho\" posterior density\n# p2 &lt;- tibble(Mcmcdat_0[,\"rho\"]) %&gt;% ggplot(aes(x = Mcmcdat_0[, \"rho\"])) + geom_density(color = \"black\", fill = \"grey\") + theme_bw() + xlab(\"rho\") + ylab(\"Posterior density\") + xlim(-1,0)\n\n# arrange plots\n# ggarrange(p2, p1, ncol = 2, widths = c(0.35, 0.65))\np1\n\n\n\n\n\n\n\n\n\nCode\n# correlation\ncor.test(sitib$intercepts, sitib$slopes)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  sitib$intercepts and sitib$slopes\nt = 1.1218, df = 7, p-value = 0.2989\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.3695613  0.8373947\nsample estimates:\n      cor \n0.3903705 \n\n\n\n\n10.6.2 Effect of G on g\nHere, I plot the results of the fitted model: site-specific effects of Big G yield on little g yield.\n\n\nCode\n# control panel\nnvals &lt;- 100\nnsim &lt;- dim(Mcmcdat_0)[1]\nnsites &lt;- length(unique(dat$site_name_cd))\nx_seq &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = nvals)\n\n# predict from model\npred_arr &lt;- array(NA, dim = c(nsim, nvals, nsites))\npred_arr_summ &lt;- array(NA, dim = c(nvals, 3, nsites))\nfor (k in 1:nsites) {\n  for (j in 1:nsim) {\n    pred_arr[j,,k] &lt;- Mcmcdat_0[j,paste(\"alpha[\", k, \"]\", sep = \"\")] + Mcmcdat_0[j,paste(\"beta[\", k, \"]\", sep = \"\")] * x_seq\n  }\n  pred_arr_summ[,1,k] &lt;- apply(pred_arr[,,k], 2, quantile, probs = 0.025)\n  pred_arr_summ[,2,k] &lt;- apply(pred_arr[,,k], 2, quantile, probs = 0.5)\n  pred_arr_summ[,3,k] &lt;- apply(pred_arr[,,k], 2, quantile, probs = 0.975)\n}\n\n\n\n\nCode\npar(mar = c(5,5,1,11), mfrow = c(1,1))\ngg_color_hue &lt;- function(n) { \n  hues = seq(15, 375, length = n + 1) \n  hcl(h = hues, l = 65, c = 100)[1:n] }\nmycols &lt;- gg_color_hue(9)\n\n# combined\nplot(seq(from = range(pred_arr)[1], to = range(pred_arr)[2], length.out = nvals) ~ x_seq, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"(log) volumetric yield at little g\")\nfor (k in 1:nsites) { \n  polygon(x = c(x_seq, rev(x_seq)), y = c(pred_arr_summ[,1,k], rev(pred_arr_summ[,3,k])), col = alpha(mycols[k], 0.2), border = NA)\n  lines(pred_arr_summ[,2,k] ~ x_seq, lwd = 2, col = mycols[k])\n  points(yield_little_cum_log ~ yield_big_cum_log, data = dat %&gt;% filter(site_name_cd == k), col = mycols[k])\n  }\nabline(a = 0, b = 1, lty = 2)\nlegend(\"topleft\", legend = \"1:1\", lty = 2, bty = \"n\")\npar(xpd = TRUE)\nlegend(\"topright\", inset = c(-0.55, 0), legend = levels(dat$site_name), fill = alpha(mycols, 0.5), bty = \"n\")\n\n\n\n\n\nEffect of (log) volumetric yield at Big G on (log) cumulative yield at little g.\n\n\n\n\n\n\n10.6.3 Within-site variation\nHere, I plot the effect of Big G yield on site-level variation in little g (i.e., sigma). How does site-specific variation in little g response to big G attenuate with increasing Big G?\n\n\nCode\n# control panel\nnvals &lt;- 100\nnsim &lt;- dim(Mcmcdat_0)[1]\nnsites &lt;- length(unique(dat$site_name_cd))\nx_seq &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = nvals)\n\npred_arr &lt;- array(NA, dim = c(nsim, nvals, nsites))\npred_arr_summ &lt;- array(NA, dim = c(3, nvals, nsites))\nfor (k in 1:nsites) {\n  for (j in 1:nsim) {\n    pred_arr[j,,k] &lt;- (exp(Mcmcdat_0[j,paste(\"sig.alpha[\", k, \"]\", sep = \"\")] + Mcmcdat_0[j,paste(\"sig.beta[\", k, \"]\", sep = \"\")] * x_seq))\n  }\n  for (i in 1:nvals) {\n    pred_arr_summ[1,i,k] &lt;- quantile(pred_arr[,i,k], probs = 0.025)\n    pred_arr_summ[2,i,k] &lt;- quantile(pred_arr[,i,k], probs = 0.5)\n    pred_arr_summ[3,i,k] &lt;- quantile(pred_arr[,i,k], probs = 0.975)\n  }\n}\n\npar(mar = c(5,5,1,11), mfrow = c(1,1))\ngg_color_hue &lt;- function(n) { \n  hues = seq(15, 375, length = n + 1) \n  hcl(h = hues, l = 65, c = 100)[1:n] }\nmycols &lt;- gg_color_hue(9)\n\n# polygons as 95% CIs\nplot(seq(from = 0, to = range(pred_arr_summ)[2], length.out = nvals) ~ x_seq, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Within-site variation in little g, sigma\")\nfor (k in 1:nsites) { \n  polygon(x = c(x_seq, rev(x_seq)), y = c(pred_arr_summ[1,,k], rev(pred_arr_summ[3,,k])), col = alpha(mycols[k], 0.2), border = NA)\n  lines(pred_arr_summ[2,,k] ~ x_seq, col = mycols[k], lwd = 2)\n}\npar(xpd = TRUE)\nlegend(\"topright\", inset = c(-0.55, 0), legend = levels(dat$site_name), fill = alpha(mycols, 0.5), bty = \"n\")\n\n\n\n\n\nIncreasing water availability decreases site-level heterogeneity in little g response to Big G. Lines and polygons represent the median and 95% credible interval of the relationship for each site (color).\n\n\n\n\n\n\n10.6.4 Among-site variation\nHere, I plot the effect of Big G yield on global (i.e., among-site) variation in little g. How does among-site variation in little g response to big G attenuate with increasing Big G? This is a derived parameter: the square root of the “phenotypic variance” (conditional on x) as defined in Shielzeth and Nakagawa (2022).\nFrom S&N: “We note that the phenotypic variance VP as we calculate it here as the sum of additive variance components might differ slightly from the variance in response values as estimated from the raw data (Rights & Sterba, 2020). The difference is that the sum of the variance components aims to estimate the population variance while the variance in raw response values represents to variance in the sample. Since the population variance is what is relevant to biological interpretation (de Villemereuil et al., 2018), the sum of additive components is usually preferable.”\n\n\nCode\n# control panel\nnsim &lt;- dim(Mcmcdat_0)[1]\n\n# get derived values\npred_arr &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\nfor (j in 1:nsim) { pred_arr[j,] &lt;- (Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"VpObs\")]) }\nfor (j in 1:ndiff) { pred_arr_summ[j,] &lt;- quantile(pred_arr[,j], probs = c(0.025, 0.5, 0.95)) }\n\n\n\n\nCode\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0))\nplot(seq(from = 0, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Global variance, VpObs\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_summ[,1], rev(pred_arr_summ[,3])), col = alpha(\"black\", 0.2), border = NA)\nlines(pred_arr_summ[,2] ~ QGvec, col = \"black\", lwd = 2)\n\n\n\n\n\nIncreasing water availability decreases among-site heterogeneity in little g response to Big G. Line and polygon represent the median and 95% credible interval of the relationship.\n\n\n\n\nVisually comparing the figure above with the data/regression fits figure, it seems like there is not as much variation in VpObs with x in the plot above as there “should” be. In the plot below, I directly compare the population variance (VpObs) with the sample variance (VarAg), derived from the site-agnostic model). While Schielzeth and Nakagawa (2022) state that the population and sample standard deviations (variances) may “differ slightly” (pg. 1216), the difference as plotted below seems quite large, which leads me to wonder if the variance decomposition model is specified correctly…\n\n\nCode\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0))\nnsim &lt;- 100\nplot(seq(from = 0, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"\")\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"VpObs\")]) ~ QGvec, col = alpha(\"black\", 0.3), lwd = 0.5) }\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"VarAg\")]) ~ QGvec, col = alpha(\"blue\", 0.3), lwd = 0.5) }\nlegend(\"topright\", legend = c(\"VpObs\", \"VarAg\"), lty = 1, col = c(\"black\", \"blue\"), bty = \"n\")\n\n\n\n\n\n\n\n\n\nSo what drives this difference? Below I plot the three components of Vp: Vf, Vix, and Vr, and the sum of Vix and Vr. The difference in VpObs and VarAg in the plot of above is driven in large part by the constant Vf, the variance explained by the fixed effects. Note that VarAg is the residual variance from the site-agnostic model, and thus does not include variance explained by fixed effects. For the site-aware model, the best approximation of VarAg is Vix + Vr, the between/amomg-site variance plus the residual variance (within site).\n\n\nCode\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0), mfrow = c(2,2))\nnsim &lt;- 100\n\n# Vf\nplot(seq(from = 0, to = 4, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Vf\")\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"Vf\")]) ~ QGvec, col = alpha(\"black\", 0.3), lwd = 0.5) }\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"VarAg\")]) ~ QGvec, col = alpha(\"blue\", 0.3), lwd = 0.5) }\nlegend(\"topright\", legend = c(\"Vf\", \"VarAg\"), lty = 1, col = c(\"black\", \"blue\"), bty = \"n\")\n\n# Vix\nplot(seq(from = 0, to = 4, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Vix\")\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"Vix\")]) ~ QGvec, col = alpha(\"black\", 0.3), lwd = 0.5) }\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"VarAg\")]) ~ QGvec, col = alpha(\"blue\", 0.3), lwd = 0.5) }\nlegend(\"topright\", legend = c(\"Vix\", \"VarAg\"), lty = 1, col = c(\"black\", \"blue\"), bty = \"n\")\n\n# Vr\nplot(seq(from = 0, to = 4, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Vr\")\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"Vr\")]) ~ QGvec, col = alpha(\"black\", 0.3), lwd = 0.5) }\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"VarAg\")]) ~ QGvec, col = alpha(\"blue\", 0.3), lwd = 0.5) }\nlegend(\"topright\", legend = c(\"Vr\", \"VarAg\"), lty = 1, col = c(\"black\", \"blue\"), bty = \"n\")\n\n# Vix + Vr\nplot(seq(from = 0, to = 4, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Vix + Vr\")\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"Vix\")]) + (Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"Vr\")]) ~ QGvec, col = alpha(\"black\", 0.3), lwd = 0.5) }\nfor (i in 1:nsim) { lines((Mcmcdat_0[i, str_subset(colnames(Mcmcdat_0), pattern = \"VarAg\")]) ~ QGvec, col = alpha(\"blue\", 0.3), lwd = 0.5) }\nlegend(\"topright\", legend = c(\"Vix + Vr\", \"VarAg\"), lty = 1, col = c(\"black\", \"blue\"), bty = \"n\")\n\n\n\n\n\n\n\n\n\nWhy does this matter?\n\nThe best way to compare the plot of within-site variation in little g (sigma ~ G) and among-site variation in little g is probably to use the sum of Vix and Vr, ignoring Vf, as within-site variation (sigma) also effectively ignores fixed effect variance.\nFor calculation of portfolio effects, it likely does not matter as all variance scenarios contain the constant and thus the constant is divided out\nBut for calculation of attenuation strength, it appears to lead to substantial underestimates of attenuation, i.e., “wedginess”. Attenuation strength is a ratio between variation at low vs high levels of G, so when a constant is added to both the numerator and denominator, the absolute difference is the same but the relative difference can be quite different\n\nConsider the following. 4 / 2 = 2 and 3 / 1 = 3. In both cases the absolute difference is the same (1) but the relative difference changes (2 vs. 3).\n\n\n\n\n10.6.5 Portfolio strength\nFirst plot population/phenotypic variances, conditional on QG\n\n\nCode\n# control panel\nnsim &lt;- dim(Mcmcdat_0)[1]\nx_seq &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = ndiff)\n\n# get derived values\npred_arr_VpObs &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_VpScen1 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_VpScen2 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_VpScen3 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\n\npred_arr_VpObs_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_VpScen1_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_VpScen2_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_VpScen3_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\n\nfor (j in 1:nsim) { \n  pred_arr_VpObs[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"VpObs\")] \n  pred_arr_VpScen1[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"VpScen1\")] \n  pred_arr_VpScen2[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"VpScen2\")] \n  pred_arr_VpScen3[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"VpScen3\")] \n  }\nfor (j in 1:ndiff) { \n  pred_arr_VpObs_summ[j,] &lt;- quantile(pred_arr_VpObs[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_VpScen1_summ[j,] &lt;- quantile(pred_arr_VpScen1[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_VpScen2_summ[j,] &lt;- quantile(pred_arr_VpScen2[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_VpScen3_summ[j,] &lt;- quantile(pred_arr_VpScen3[,j], probs = c(0.025, 0.5, 0.95))\n  }\n\n\n\n\nCode\n# plot\nmycols &lt;- c(brewer.pal(3, \"Dark2\"), \"black\")\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0), mfrow = c(2,2))\n\n# VpScen1\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpScen1_summ[,1], rev(pred_arr_VpScen1_summ[,3])), col = alpha(mycols[1], 0.2), border = NA)\nlines(pred_arr_VpScen1_summ[,2] ~ QGvec, col = mycols[1], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 1\", bty = \"n\")\n# VpScen2\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpScen2_summ[,1], rev(pred_arr_VpScen2_summ[,3])), col = alpha(mycols[2], 0.2), border = NA)\nlines(pred_arr_VpScen2_summ[,2] ~ QGvec, col = mycols[2], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 2\", bty = \"n\")\n# VpScen3\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpScen3_summ[,1], rev(pred_arr_VpScen3_summ[,3])), col = alpha(mycols[3], 0.2), border = NA)\nlines(pred_arr_VpScen3_summ[,2] ~ QGvec, col = mycols[3], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 3\", bty = \"n\")\n# VpObs\nplot(seq(from = 1, to = 6, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) cumulative yield at Big G\", ylab = \"Variance\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_VpObs_summ[,1], rev(pred_arr_VpObs_summ[,3])), col = alpha(mycols[4], 0.2), border = NA)\nlines(pred_arr_VpObs_summ[,2] ~ QGvec, col = mycols[4], lwd = 2)\nlegend(\"topright\", legend = \"Observed\", bty = \"n\")\n\n\n\n\n\nEffect of water availability (log cumulative yield at Big G) on population variance in little g expected under three alternative (null) hypotheses and for observed data.\n\n\n\n\nNow to show portfolio strength: How much more variable is the observed data than what is expected under three (null) alternative hypotheses?\nNote: subtracted 1 from ratios so values &gt;0 indicate the observed data is more variable than expected and values &lt;0 indicate the observed data is less variable than expected\n\n\nCode\n# control panel\nnsim &lt;- dim(Mcmcdat_0)[1]\nx_seq &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = ndiff)\n\n# get derived values\npred_arr_Port1 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_Port2 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\npred_arr_Port3 &lt;- matrix(NA, nrow = nsim, ncol = ndiff)\n\npred_arr_Port1_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_Port2_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\npred_arr_Port3_summ &lt;- matrix(NA, nrow = ndiff, ncol = 3)\n\nfor (j in 1:nsim) { \n  pred_arr_Port1[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"port1\")] - 1\n  pred_arr_Port2[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"port2\")] - 1\n  pred_arr_Port3[j,] &lt;- Mcmcdat_0[j, str_subset(colnames(Mcmcdat_0), pattern = \"port3\")] - 1\n  }\nfor (j in 1:ndiff) { \n  pred_arr_Port1_summ[j,] &lt;- quantile(pred_arr_Port1[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_Port2_summ[j,] &lt;- quantile(pred_arr_Port2[,j], probs = c(0.025, 0.5, 0.95))\n  pred_arr_Port3_summ[j,] &lt;- quantile(pred_arr_Port3[,j], probs = c(0.025, 0.5, 0.95))\n  }\n\n\n\n\nCode\n# plot\nmycols &lt;- c(brewer.pal(3, \"Dark2\"), \"black\")\npar(mar = c(4,4,0.5,0.5), mgp = c(2.5,1,0), mfrow = c(2,2))\nylim1 &lt;- -0.25\nylim2 &lt;- 1.25\n\n# VpScen1\nplot(seq(from = ylim1, to = ylim2, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Portfolio strength\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_Port1_summ[,1], rev(pred_arr_Port1_summ[,3])), col = alpha(mycols[1], 0.2), border = NA)\nlines(pred_arr_Port1_summ[,2] ~ QGvec, col = mycols[1], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 1\", bty = \"n\")\nabline(h = 0, lty = 2)\n# VpScen2\nplot(seq(from = ylim1, to = ylim2, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Portfolio strength\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_Port2_summ[,1], rev(pred_arr_Port2_summ[,3])), col = alpha(mycols[2], 0.2), border = NA)\nlines(pred_arr_Port2_summ[,2] ~ QGvec, col = mycols[2], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 2\", bty = \"n\")\nabline(h = 0, lty = 2)\n# VpScen3\nplot(seq(from = ylim1, to = ylim2, length.out = ndiff) ~ QGvec, type = \"n\", xlab = \"(log) volumetric yield at Big G\", ylab = \"Portfolio strength\")\npolygon(x = c(QGvec, rev(QGvec)), y = c(pred_arr_Port3_summ[,1], rev(pred_arr_Port3_summ[,3])), col = alpha(mycols[3], 0.2), border = NA)\nlines(pred_arr_Port3_summ[,2] ~ QGvec, col = mycols[3], lwd = 2)\nlegend(\"topright\", legend = \"Scenario 3\", bty = \"n\")\nabline(h = 0, lty = 2)\n\n\n\n\n\n\n\n\n\n\n\n10.6.6 Attenuation Strength\nTo what degree does diversity in streamflow regimes attenuate with increasing Big G? Attenuation strength is calculated as the variance at min G divided by variance at max G four our observed data and three alternative hypotheses. Note that for scenario 1, variance is constant over G and thus would equal 1. Therefore, a value of 1 represents no attenuation. These figures may provide a standardized approach to comparing “wedginess” across basins.\n\n\nCode\nmycols &lt;- c(brewer.pal(3, \"Dark2\"), \"black\")\npar(mar = c(5,5,1,1), mfrow = c(1,1))\nplot(seq(from = 0, to = 1, length.out = 100) ~ seq(from = 0.5, to = 3, length.out = 100), type = \"n\", xlab = \"Attenuation strength\", ylab = \"Density\")\n\n# observed\nobs_den &lt;- density(Mcmcdat_0[,\"attenObs\"])\nobs_den$y2 &lt;- obs_den$y / max(obs_den$y)\nobs_l &lt;- min(which(obs_den$x &gt;= hdi(obs_den, credMass = 0.95)[1]))\nobs_h &lt;- max(which(obs_den$x &lt; hdi(obs_den, credMass = 0.95)[2]))\npolygon(x = c(obs_den$x[c(obs_l,obs_l:obs_h,obs_h)]), y = c(0,obs_den$y2[obs_l:obs_h],0), col = alpha(mycols[4], 0.3), lty = 0)\nlines(obs_den$y2 ~ obs_den$x, col = mycols[4], lwd = 2)\n\n# scenario 2\nexp_den &lt;- density(Mcmcdat_0[,\"atten2\"])\nexp_den$y2 &lt;- exp_den$y / max(exp_den$y)\nexp_l &lt;- min(which(exp_den$x &gt;= hdi(exp_den, credMass = 0.95)[1]))\nexp_h &lt;- max(which(exp_den$x &lt; hdi(exp_den, credMass = 0.95)[2]))\npolygon(x = c(exp_den$x[c(exp_l,exp_l:exp_h,exp_h)]), y = c(0,exp_den$y2[exp_l:exp_h],0), col = alpha(mycols[2], 0.3), lty = 0)\nlines(exp_den$y2 ~ exp_den$x, col = mycols[2], lwd = 2)\n\n# scenario 3\nexp_den &lt;- density(Mcmcdat_0[,\"atten3\"])\nexp_den$y2 &lt;- exp_den$y / max(exp_den$y)\nexp_l &lt;- min(which(exp_den$x &gt;= hdi(exp_den, credMass = 0.95)[1]))\nexp_h &lt;- max(which(exp_den$x &lt; hdi(exp_den, credMass = 0.95)[2]))\npolygon(x = c(exp_den$x[c(exp_l,exp_l:exp_h,exp_h)]), y = c(0,exp_den$y2[exp_l:exp_h],0), col = alpha(mycols[3], 0.3), lty = 0)\nlines(exp_den$y2 ~ exp_den$x, col = mycols[3], lwd = 2)\n\nlegend(\"topright\", legend = c(\"Scenario 1\", \"Scenario 2\", \"Scenario 3\", \"Observed\"), fill = alpha(mycols, 0.3), bty = \"n\")\nabline(v = 1, lty = 1, lwd = 2, col = mycols[1])",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Big G Little g/WedgeModel.html#deprecated",
    "href": "Big G Little g/WedgeModel.html#deprecated",
    "title": "10  The Wedge Model",
    "section": "10.7 DEPRECATED",
    "text": "10.7 DEPRECATED\n\n\nCode\n# vector of QG for prediction\nndiff &lt;- 100\nQGvec &lt;- seq(from = min(dat$yield_big_cum_log), to = max(dat$yield_big_cum_log), length.out = ndiff)\n\n# gather data for JAGS\njags.data &lt;- list(\"nObs\" = dim(dat)[1], \"nSites\" = length(unique(dat$site_name_cd)), \n                  \"sites\" = dat$site_name_cd, #\"indev\" = dat_wb2$isevent,\n                  \"Qg\" = dat$yield_little_cum_log, \"Qg2\" = dat$yield_little_cum_log, \"QG\" = dat$yield_big_cum_log, \n                  \"QGvec\" = QGvec, \"nDiff\" = ndiff)\n\n# parameters to monitor\njags.params &lt;- c(\"alpha\", \"beta\", \"alpha.mu\", \"beta.mu\", \"alpha.sigma\", \"beta.sigma\", \n                 \"sig.alpha\", \"sig.beta\", \"sig.alpha.mu\", \"sig.beta.mu\", \"sig.alpha.sigma\", \"sig.beta.sigma\", \n                 \"ag.alpha\", \"ag.beta\", \"ag.sig.alpha\", \"ag.sig.beta\",\n                 \"diff\", \"predlg\", \"loglik\", \"loglik2\", \"mu\", \"Qg\", \"portfolio1\", \"portfolio3\", \"atten3\", \"attenObs\")\n\n# run in jags\nmod_0 &lt;- jags.parallel(data = jags.data, inits = NULL, parameters.to.save = jags.params,\n                       model.file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod_Events_2.txt\",\n                       n.chains = 10, n.thin = 20, n.burnin = 1000, n.iter = 5000, DIC = FALSE)\n# saveRDS(mod_0, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/Fitted models/GgMod_Events.rds\")\n\n\nHere, I plot the effect of Big G yield on global (i.e., among-site) variation in little g from the site-agnostic model. How does among-site variation in little g response to big G attenuate with increasing Big G? Note that this only considers the sites we have data for, not all possible locations in the river network. This could potentially be achieved by simulating data for new sites (see pg. 362 in Gelman and Hill, 2007), but would likely need to add slope-intercept correlation structure to the model to ensure that attenuation in preserved (see pg. 376 in Gelman and Hill).\nWe can visualize this another way, as site-specific differences between little g and Big G at different levels of water availability/Big G flow. This is ~equivalent to the plot above, but provides a site-level examination of Qg variation around QG and how those change over the range of Big G flow.\n\n10.7.0.1 Null model simulations\nHow much among-site variation in little G response to Big G might we expect assuming homogeneity in flow regimes? This is the null hypotheses. Although I’m not sure this is the proper way to do this…for each of n sites, I randomly sample from the posterior distributions of alpha.mu and beta.mu to generate site-specific relationships that all follow the global parameters/relationships.\nHere’s an example of an individual simulation…\n\nPortfolio strength\nThere are probably better ways to do this, but here I’m quantifying/visualizing what I’m calling “portfolio strength”, or the degree of heterogeneity in streamflow regimes across the network, as a function of water availability (big G flow). Portfolio strength is calculated as the (median) observed among-site variation in little G divided by the (median) expected/simulated among site variation in little g assuming flow homogeneity. Thus, values &gt;1 and &lt;1 indicate greater and less heterogeneity in streamflow than expected under the assumption of homogeneity, respectively. I think this would be a good way to compare/standardize among basins.\nAlternatively, portfolio strength can be defined as the ratio between among-site variation in little g at low vs. high values of Big G (sensu Chezik et al. 2017)…so we get distributions for observed and expected values, where a value of 1 indicates no portfolio behavior (no streamflow diversity at different levels of Big G). I don’t think this makes sense because the whole point is the evaluation how diversity in flow regimes (i.e., portfolio strength) changes with water availability.\n\n\n\n10.7.1 Agnostic to sites\nThis model evaluates the G-g relationship and the effect of G on sigma, but ignores site groupings. With respect to the sigma~G relationship, this is essentially what I am trying to reconstruct above using derived values.\n\n10.7.1.1 Fit the JAGS model\nGet MCMC samples and summary\n\n\n10.7.1.2 View traceplots\n\n\n10.7.1.3 Effect of G on sigma\nHere, I plot the effects of Big G yield on among-site variation in little g (i.e., sigma). This describes the effect of water availability on network-wide heterogeneity in streamflow.\n\n\n\n10.7.2 Porfolio strength\nHow much more heterogeneous is observed little g streamflow at different levels of water availability (Big G) relative to our expectations if among- and within-site streamflow diversity is eroded? What does this tell us about the relative contributions of within- and among-site diversity to the total streamflow diversity across the river network?\nPortfolio strength is calculated as the observed variance divided by expected variance under different scenarios in which diversity is eroded. These relationships may provide a standardized approach to comparing “wedginess” across basins\n\n\n10.7.3 Attenuation strength\nTo what degree does diversity in streamflow regimes attenuate with increasing Big G? Attenuation strength is calculated as the variance at min G divided by variance at max G four our observed data and relevant scenarios. Note that for scenario 1, variance is constant over G and thus would equal 1. Therfore, a value of 1 represents no attenuation. These figures may provide a standardized approach to comparing “wedginess” across basins.",
    "crumbs": [
      "Big G-Little g",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Wedge Model</span>"
    ]
  },
  {
    "objectID": "Qualitative/Overview.html",
    "href": "Qualitative/Overview.html",
    "title": "11  Overview",
    "section": "",
    "text": "11.1 Site information\nSignificance: Headwater streams account for a majority of river networks worldwide and have a disproportionately large influence on the functioning of aquatic ecosystems. Headwater streams also support critical habitat for many species, including cold-water fishes, many of which are declining or at risk of extinction.\nProblem: Headwater streams are largely underrepresented in streamflow monitoring networks, which place greater emphasis on mainstem rivers. As a result, less is known about how headwaters respond to changing water availability. Headwater streams therefore represent a blind spot in understanding flow regime variability and assessing the vulnerability of cold-water fish to changing climatic conditions, including the increasing frequency and severity of drought.\nExistential question: How do streamflow regimes vary spatially in headwater stream networks and what does this imply about the sensitivity of these systems (and the species they support) to changing climatic conditions (i.e., drought)?\nObjectives:\nConceptual Model: develop a conceptual framework and set of hypotheses based on the objectives above How do we link/combine what we have learned so far to enhance our understanding of spatial diversity in headwater streamflow regimes?\nBoxes: Use boxes to highlight additional details of the data, vignettes, and case studies that demonstrate spatiotemporal streamflow heterogeneity\nView site information\nCode\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\ndatatable(siteinfo)\nMap sites\nCode\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "Qualitative/Overview.html#little-g-data",
    "href": "Qualitative/Overview.html#little-g-data",
    "title": "11  Overview",
    "section": "11.2 Little g data",
    "text": "11.2 Little g data\nLittle g daily data\n\n\nCode\n# flow/yield (and temp) data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\") %&gt;%\n  mutate(site_name = dplyr::recode(site_name, \"Leidy Creek Mouth NWIS\" = \"Leidy Creek Mouth\", \"SF Spread Creek Lower NWIS\" = \"SF Spread Creek Lower\", \"Dugout Creek NWIS\" = \"Dugout Creek\", \"Shields River ab Smith NWIS\" = \"Shields River Valley Ranch\")) %&gt;%\n  filter(!site_name %in% c(\"Avery Brook NWIS\", \"West Brook 0\", \"BigCreekMiddle\",                # drop co-located sites\n                           \"South River Conway NWIS\", \"North Fork Flathead River NWIS\",         # drop big Gs\n                           \"Pacific Creek at Moran NWIS\", \"Shields River nr Livingston NWIS\",   # drop big Gs\n                           \"Donner Blitzen River nr Frenchglen NWIS\",                           # drop big Gs\n                           \"WoundedBuckCreek\")) %&gt;%                                             # drop little g outside of focal basin\n  group_by(site_name, basin, subbasin, region, date) %&gt;%\n  summarize(flow_mean = mean(flow_mean),\n            tempc_mean = mean(tempc_mean),\n            Yield_mm = mean(Yield_mm),\n            Yield_filled_mm = mean(Yield_filled_mm)) %&gt;%\n  ungroup()\n\n# add water/climate year variables and fill missing dates\ndat &lt;- fill_missing_dates(dat, dates = date, groups = site_name)\ndat &lt;- add_date_variables(dat, dates = date, water_year_start = 10)\n\n\nClean and bind little g data (for each basin, restrict to time period for which data quality/availability is ~consistent)\n\n\nCode\ndat_clean &lt;- bind_rows(\n  dat %&gt;% filter(site_name %in% unlist(siteinfo %&gt;% filter(subbasin == \"West Brook\") %&gt;% select(site_name)), year(date) &gt;= 2020, date &lt;= date(\"2025-01-03\")) %&gt;% \n    mutate(Yield_filled_mm = ifelse(site_name == \"West Brook Upper\" & date &gt; date(\"2024-10-06\"), NA, Yield_filled_mm)) %&gt;%\n    mutate(Yield_filled_mm = ifelse(site_name == \"Mitchell Brook\" & date &gt; date(\"2021-02-28\") & date &lt; date(\"2021-03-26\"), NA, Yield_filled_mm)) %&gt;% \n    mutate(Yield_filled_mm = ifelse(site_name == \"Mitchell Brook\" & date &gt; date(\"2021-11-01\") & date &lt; date(\"2022-05-01\"), NA, Yield_filled_mm)) %&gt;% \n    mutate(Yield_filled_mm = ifelse(site_name == \"Jimmy Brook\" & date &gt; date(\"2024-12-10\"), NA, Yield_filled_mm)) %&gt;% \n    mutate(subbasin = \"West Brook\"),\n  \n  dat %&gt;% filter(site_name %in% unlist(siteinfo %&gt;% filter(subbasin == \"Paine Run\") %&gt;% select(site_name)), date &gt;= as_date(\"2018-11-07\"), date &lt;= as_date(\"2023-05-15\")) %&gt;% mutate(subbasin = \"Paine Run\"),\n  \n  dat %&gt;% filter(site_name %in% unlist(siteinfo %&gt;% filter(subbasin == \"Staunton River\") %&gt;% select(site_name)), date &gt;= as_date(\"2018-11-07\"), date &lt;= as_date(\"2022-10-19\")) %&gt;% mutate(subbasin = \"Staunton River\"),\n  \n  dat %&gt;% filter(site_name %in% c(unlist(siteinfo %&gt;% filter(subbasin == \"Big Creek\") %&gt;% select(site_name)), \"North Fork Flathead River NWIS\"), date &gt;= date(\"2018-08-08\"), date &lt;= date(\"2023-08-03\"), site_name != \"SkookoleelCreek\", Yield_filled_mm &gt; 0)  %&gt;% mutate(subbasin = \"Big Creek\"),\n  \n  dat %&gt;% filter(site_name %in% c(unlist(siteinfo %&gt;% filter(subbasin == \"Coal Creek\") %&gt;% select(site_name)), \"North Fork Flathead River NWIS\"), date &gt;= date(\"2018-07-29\"), date &lt;= date(\"2023-08-03\")) %&gt;% mutate(subbasin = \"Coal Creek\"),\n  \n  dat %&gt;% filter(site_name %in% c(unlist(siteinfo %&gt;% filter(subbasin == \"McGee Creek\") %&gt;% select(site_name)), \"North Fork Flathead River NWIS\"), date &gt;= date(\"2017-07-30\"), date &lt;= date(\"2023-12-11\")) %&gt;% mutate(subbasin = \"McGee Creek\"),\n  \n  dat %&gt;% filter(subbasin == \"Snake River\", date &gt;= date(\"2016-04-01\"), date &lt;= date(\"2023-10-03\"), site_name != \"Leidy Creek Upper\") %&gt;% mutate(subbasin = \"Snake River\"),\n  \n  dat %&gt;% filter(subbasin == \"Shields River\", date &gt;= date(\"2016-04-01\"), date &lt;= date(\"2023-12-31\"), site_name != \"Brackett Creek\") %&gt;% \n  mutate(logYield = log10(Yield_filled_mm)) %&gt;% mutate(subbasin = \"Shields River\"),\n  \n  dat %&gt;% filter(subbasin == \"Duck Creek\", date &gt;= date(\"2015-04-01\"), date &lt;= date(\"2023-12-31\")) %&gt;% mutate(subbasin = \"Duck Creek\"),\n  \n  dat %&gt;% filter(subbasin == \"Donner Blitzen\", date &gt;= as_date(\"2019-04-23\"), date &lt;= as_date(\"2022-12-31\"), !site_name %in% c(\"Indian Creek NWIS\", \"Little Blizten River NWIS\")) %&gt;% mutate(subbasin = \"Donner Blitzen\")\n) %&gt;%\n  filter(Yield_filled_mm &gt; 0) %&gt;%\n  mutate(logYield = log10(Yield_filled_mm), \n         designation = \"little\", \n         doy_calendar = yday(date)) %&gt;%\n  select(-Yield_mm) %&gt;%\n  rename(Yield_mm = Yield_filled_mm)\nhead(dat_clean)\n\n\n# A tibble: 6 × 16\n  site_name   basin     subbasin region date       flow_mean tempc_mean Yield_mm\n  &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;  &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1 Avery Brook West Bro… West Br… Mass   2020-01-08      5.96     0.594      1.99\n2 Avery Brook West Bro… West Br… Mass   2020-01-09      4.81     0.0336     1.61\n3 Avery Brook West Bro… West Br… Mass   2020-01-10      4.88     0.363      1.63\n4 Avery Brook West Bro… West Br… Mass   2020-01-11      6.43     1.77       2.15\n5 Avery Brook West Bro… West Br… Mass   2020-01-12     21.2      2.81       7.08\n6 Avery Brook West Bro… West Br… Mass   2020-01-13     14.3      1.92       4.78\n# ℹ 8 more variables: CalendarYear &lt;dbl&gt;, Month &lt;dbl&gt;, MonthName &lt;fct&gt;,\n#   WaterYear &lt;dbl&gt;, DayofYear &lt;dbl&gt;, logYield &lt;dbl&gt;, designation &lt;chr&gt;,\n#   doy_calendar &lt;dbl&gt;\n\n\nView streamflow data availability by subbasin and site\n\nWest BrookPaine RunStaunton RiverBig CreekCoal CreekMcGee CreekSnake RiverShields RiverDuck CreekDonner Blitzen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWrite to file\n\n\nCode\nwrite_csv(dat_clean, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/LittleG_data_clean.csv\")",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "Qualitative/Overview.html#big-g-data",
    "href": "Qualitative/Overview.html#big-g-data",
    "title": "11  Overview",
    "section": "11.3 Big G data",
    "text": "11.3 Big G data\nLoad big/super G data\n\n\nCode\nnwis_daily &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_NWIS_FlowTempData_Raw_Daily.csv\") %&gt;%\n  filter(designation == \"big\", \n         year(date) &gt;= 1970,\n         site_name != \"Shields River nr Livingston NWIS\") %&gt;%\n  mutate(flowcfs = ifelse(site_name == \"Rapidan River NWIS\" & date &gt; date(\"1995-06-26\") & date &lt; date(\"1995-07-01\"), NA, flowcfs),\n         flow_mean_cms = flowcfs*0.02831683199881, \n         area_sqkm = area_sqmi*2.58999)\n\n# sites\nsites &lt;- unique(nwis_daily$site_name)\n\n# site-specific basin area in square km\nbasinarea &lt;- nwis_daily %&gt;% filter(!is.na(site_id)) %&gt;% group_by(site_name) %&gt;% summarize(area_sqkm = unique(area_sqkm))\n\n# calculate yield\nyield_list &lt;- list()\nfor (i in 1:length(sites)) {\n  d &lt;- nwis_daily %&gt;% filter(site_name == sites[i])\n  ba &lt;- unlist(basinarea %&gt;% filter(site_name == sites[i]) %&gt;% select(area_sqkm))\n  yield_list[[i]] &lt;-  add_daily_yield(data = d, values = flow_mean_cms, basin_area = as.numeric(ba))\n}\nnwis_daily_wyield &lt;- do.call(rbind, yield_list)\n\ndat_clean_big &lt;- nwis_daily_wyield %&gt;% \n  select(site_name, basin, subbasin, region, date, Yield_mm, tempc, flowcfs) %&gt;% \n  mutate(logYield = log10(Yield_mm), doy_calendar = yday(date)) %&gt;%\n  rename(tempc_mean = tempc, flow_mean = flowcfs)\n\n# add water/climate year variables and fill missing dates\ndat_clean_big &lt;- fill_missing_dates(dat_clean_big, dates = date, groups = site_name)\ndat_clean_big &lt;- add_date_variables(dat_clean_big, dates = date, water_year_start = 10)\n\nhead(dat_clean_big)\n\n\n# A tibble: 6 × 15\n  site_name       basin subbasin region date       Yield_mm tempc_mean flow_mean\n  &lt;chr&gt;           &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;date&gt;        &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1 South River Co… West… West Br… Mass   1970-01-01     1.81         NA        46\n2 South River Co… West… West Br… Mass   1970-01-02     1.69         NA        43\n3 South River Co… West… West Br… Mass   1970-01-03     1.61         NA        41\n4 South River Co… West… West Br… Mass   1970-01-04     1.53         NA        39\n5 South River Co… West… West Br… Mass   1970-01-05     1.49         NA        38\n6 South River Co… West… West Br… Mass   1970-01-06     1.49         NA        38\n# ℹ 7 more variables: logYield &lt;dbl&gt;, doy_calendar &lt;dbl&gt;, CalendarYear &lt;dbl&gt;,\n#   Month &lt;dbl&gt;, MonthName &lt;fct&gt;, WaterYear &lt;dbl&gt;, DayofYear &lt;dbl&gt;\n\n\nWrite to file\n\n\nCode\nwrite_csv(dat_clean_big, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/BigG_data_clean.csv\")\n\n\nView big G streamflow time series data\n\n\nCode\ndat_clean_big %&gt;% ggplot() + geom_line(aes(x = date, y = logYield)) + facet_wrap(~site_name, nrow = 8) + theme_bw()",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "Qualitative/Overview.html#climate-data",
    "href": "Qualitative/Overview.html#climate-data",
    "title": "11  Overview",
    "section": "11.4 Climate data",
    "text": "11.4 Climate data\nDownload Daymet precip data and summarize by water year\n\n\nCode\n# big G site lat/long\nmysites &lt;- nwis_daily %&gt;% group_by(site_name, basin, subbasin, region) %&gt;% summarize(lat = unique(lat), long = unique(long)) %&gt;% ungroup()\n\n# download point location Daymet data\nclimlist &lt;- vector(\"list\", length = dim(mysites)[1])\nfor (i in 1:dim(mysites)[1]) {\n  clim &lt;- download_daymet(site = mysites$site_name[i], lat = mysites$lat[i], lon = mysites$long[i], start = 1980, end = 2024, internal = T)\n  climlist[[i]] &lt;- tibble(clim$data) %&gt;% \n    mutate(air_temp_mean = (tmax..deg.c. + tmin..deg.c.)/2, \n           date = as.Date(paste(year, yday, sep = \"-\"), \"%Y-%j\"),\n           site_name = mysites$site_name[i]) %&gt;%\n    select(12,2,11,10,4,6) %&gt;% rename(precip_mmday = 5, swe_kgm2 = 6)\n  print(i)\n}\n\n\n[1] 1\n\n\n[1] 2\n\n\n[1] 3\n\n\n[1] 4\n\n\n[1] 5\n\n\n[1] 6\n\n\n[1] 7\n\n\n[1] 8\n\n\nCode\n# combine and add water years\nclimdf &lt;- do.call(rbind, climlist) %&gt;% left_join(mysites) %&gt;% mutate(year = year(date))\nclimdf &lt;- add_date_variables(climdf, dates = date, water_year_start = 10)\n\n# calculate total annual precipitation in mm, by site and water year\nclimdf_summ &lt;- climdf %&gt;% \n  group_by(site_name, basin, subbasin, region, WaterYear) %&gt;% \n  summarize(precip_total = sum(precip_mmday), sampsize = n()) %&gt;% \n  mutate(precip_total_z = scale(precip_total)[,1]) %&gt;%\n  ungroup() %&gt;% \n  filter(sampsize &gt;= 350)\n\n\nWrite to file(s)\n\n\nCode\nwrite_csv(climdf, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/Daymet_climate.csv\")\n\nwrite_csv(climdf_summ, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/Daymet_climate_summary.csv\")\n\n\nCalculate annual water availability at big g as sum of daily yield values…retain only years with &gt;95% data coverage (at least 350 days)\n\n\nCode\nwateravail_sum &lt;- dat_clean_big %&gt;% \n  filter(!is.na(Yield_mm), Month %in% c(7:9)) %&gt;%\n  group_by(basin, site_name, WaterYear) %&gt;% \n  summarize(sampsize = n(), totalyield_sum = sum(Yield_mm, na.rm = TRUE)) %&gt;% \n  mutate(totalyield_sum_z = scale(totalyield_sum)[,1]) %&gt;%\n  ungroup() %&gt;%\n  filter(sampsize &gt;= 85) %&gt;% \n  complete(basin, WaterYear = 1971:2024, fill = list(sampsize = NA, totalyield = NA)) %&gt;%\n  select(-sampsize)\n\nwateravail &lt;- dat_clean_big %&gt;% \n  filter(!is.na(Yield_mm)) %&gt;%\n  group_by(basin, site_name, WaterYear) %&gt;% \n  summarize(sampsize = n(), totalyield = sum(Yield_mm, na.rm = TRUE)) %&gt;% \n  mutate(totalyield_z = scale(totalyield)[,1]) %&gt;%\n  ungroup() %&gt;%\n  filter(sampsize &gt;= 350) %&gt;% \n  complete(basin, WaterYear = 1971:2024, fill = list(sampsize = NA, totalyield = NA)) %&gt;%\n  left_join(wateravail_sum)\n\n# get range of years for little g data\ndaterange &lt;- dat_clean %&gt;% group_by(basin) %&gt;% summarize(minyear = year(min(date)), maxyear = year(max(date)))\n\n# spread ecod years\nmylist &lt;- vector(\"list\", length = dim(daterange)[1])\nfor (i in 1:dim(daterange)[1]) {\n  mylist[[i]] &lt;- tibble(basin = daterange$basin[i], WaterYear = seq(from = daterange$minyear[i], to = daterange$maxyear[i], by = 1))\n}\nyrdf &lt;- do.call(rbind, mylist) %&gt;% mutate(ecodyr = \"yes\")\n\n\nWrite water availability to file\n\n\nCode\nwrite_csv(wateravail, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/BigG_wateravailability_annual.csv\")\n\n\nView time series and scatter plots of big G water availability (total annual yield, sum of daily values, black lines) and precipitation (total annual precip, blues lines). Note that the panel labels indicate basins, not NWIS gage names. In the manuscript, pair these plots with CONUS map and detailed inset maps of focal basins (Figure 1)\n\nRaw valuesz-scoresscatter\n\n\n\n\nCode\nggplot() + \n  geom_rect(data = daterange, aes(xmin = minyear-0.5, xmax = maxyear+0.5, ymin = -Inf, ymax = +Inf), fill = \"grey\") +\n  geom_line(data = wateravail, aes(x = WaterYear, y = totalyield), linewidth = 1) + \n  geom_line(data = climdf_summ, aes(x = WaterYear, y = precip_total), linewidth = 0.5, col = \"blue\") +\n  facet_wrap(~basin) + \n  xlab(\"Water year\") + ylab(\"Total annual yield (mm) / Total annual precipitation (mm)\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot() + \n  geom_rect(data = daterange, aes(xmin = minyear-0.5, xmax = maxyear+0.5, ymin = -Inf, ymax = +Inf), fill = \"grey\") +\n  geom_line(data = wateravail, aes(x = WaterYear, y = totalyield_z), linewidth = 1) + \n  geom_line(data = climdf_summ, aes(x = WaterYear, y = precip_total_z), linewidth = 0.5, col = \"blue\") +\n  facet_wrap(~basin) + \n  xlab(\"Water year\") + ylab(\"Total annual yield (scaled) / Total annual precipitation (scaled)\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nwateravail %&gt;% select(-sampsize) %&gt;% left_join(climdf_summ %&gt;% select(-sampsize)) %&gt;% left_join(yrdf) %&gt;%\n  ggplot(aes(x = precip_total_z, y = totalyield_z)) +\n  geom_point(aes(color = ecodyr)) +\n  facet_wrap(~basin) + \n  xlab(\"Total annual precipitation (scaled)\") + ylab(\"Total annual yield (scaled)\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\") +\n  stat_cor(method = \"pearson\", aes(label = ..r.label..))",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "Qualitative/SpaceTimeVar.html",
    "href": "Qualitative/SpaceTimeVar.html",
    "title": "12  Objective 1",
    "section": "",
    "text": "12.1 Data\nPurpose: Evaluate the extent and magnitude of spatial and temporal variation in headwater streamflow.\nApproach:\nNotes:\nSite information\nCode\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nLittle g’s\nCode\ndat_clean &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/LittleG_data_clean.csv\")\nBig G’s\nCode\ndat_clean_big &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/BigG_data_clean.csv\")\nClimate\nCode\nclimdf &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/Daymet_climate.csv\")\nclimdf_summ &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/Daymet_climate_summary.csv\")\nWater availability. In western, snowmelt-dominated basins, annual (water year) total yield is strongly related to summer total yield. But in eastern, rain-dominated basins, the relationship is much weaker, suggesting “faster” response to climate forcing.\nCode\nwateravail &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/BigG_wateravailability_annual.csv\") %&gt;%\n  filter(!is.na(totalyield), !is.na(totalyield_sum)) %&gt;%\n  group_by(site_name) %&gt;%\n  mutate(tyz_perc = percentile(totalyield_z),\n         tyz_sum_perc = percentile(totalyield_sum_z)) %&gt;%\n  mutate(tyz_perc = ifelse(is.na(tyz_perc), 0, tyz_perc),\n         tyz_sum_perc = ifelse(is.na(tyz_sum_perc), 0, tyz_sum_perc))\n\nwateravail %&gt;% \n  ggplot(aes(x = tyz_perc, y = tyz_sum_perc)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") +\n  xlab(\"Total annual yield (percentile)\") + ylab(\"Total summer yield (percentile)\") + \n  facet_wrap(~basin) + theme_bw()\nWatersheds\nCode\nsheds_list &lt;- list()\nmyfiles &lt;- list.files(path = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Watersheds/\", pattern = \".shp\")\nfor (i in 1:length(myfiles)) {\n  sheds_list[[i]] &lt;- st_read(paste(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Watersheds/\", myfiles[i], sep = \"\"))\n}\nsheds &lt;- do.call(rbind, sheds_list) %&gt;% \n  mutate(site_id = ifelse(site_id == \"SP01\", \"SP07\", ifelse(site_id == \"SP07\", \"SP01\", site_id))) %&gt;%\n  left_join(siteinfo)\n#mapview(sheds %&gt;% arrange(desc(area_sqmi)), alpha.regions = 0.2)",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Objective 1</span>"
    ]
  },
  {
    "objectID": "Qualitative/SpaceTimeVar.html#spaghetti-plots",
    "href": "Qualitative/SpaceTimeVar.html#spaghetti-plots",
    "title": "12  Objective 1",
    "section": "12.4 Spaghetti plots",
    "text": "12.4 Spaghetti plots\nView daily time series data by sub-basin. Note that we are using the “Super G” NWIS data for the reference gage (black line). Per Robert comment, entirely nested design is cute, but doesn’t reflect how the data is actually used.\nBig G NWIS sites/reference gages for each basin/subbasin:\n\n\nCode\ndat_clean_big %&gt;% group_by(region, basin, subbasin) %&gt;% summarize(site_name = unique(site_name)) %&gt;% ungroup() %&gt;% filter(!is.na(region)) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\nregion\nbasin\nsubbasin\nsite_name\n\n\n\n\nFlat\nFlathead\nFlathead\nNorth Fork Flathead River NWIS\n\n\nMass\nWest Brook\nWest Brook\nSouth River Conway NWIS\n\n\nOreg\nDonner Blitzen\nDonner Blitzen\nDonner Blitzen River nr Frenchglen NWIS\n\n\nShen\nPaine Run\nPaine Run\nSouth River Harriston NWIS\n\n\nShen\nPiney River\nPiney River\nBattle Run NWIS\n\n\nShen\nStaunton River\nStaunton River\nRapidan River NWIS\n\n\nShields\nShields River\nShields River\nYellowstone River Livingston NWIS\n\n\nSnake\nSnake River\nSnake River\nPacific Creek at Moran NWIS\n\n\n\n\n\nCode\ndat_clean %&gt;% group_by(region, basin) %&gt;% summarize(subbasin = unique(subbasin)) %&gt;% ungroup() #%&gt;% filter(!is.na(region)) %&gt;% kable()\n\n\n# A tibble: 10 × 3\n   region  basin          subbasin      \n   &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;         \n 1 Flat    Flathead       Big Creek     \n 2 Flat    Flathead       Coal Creek    \n 3 Flat    Flathead       McGee Creek   \n 4 Mass    West Brook     West Brook    \n 5 Oreg    Donner Blitzen Donner Blitzen\n 6 Shen    Paine Run      Paine Run     \n 7 Shen    Staunton River Staunton River\n 8 Shields Shields River  Shields River \n 9 Shields Shields River  Duck Creek    \n10 Snake   Snake River    Snake River   \n\n\n\n12.4.1 Interactive\n\nWest BrookPaine RunStaunton RiverFlatheadYellowstoneSnake RiverDonner Blitzen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_clean %&gt;% \n  filter(basin == \"Flathead\") %&gt;% \n  bind_rows(dat_clean_big %&gt;% filter(basin == \"Flathead\", date &gt;= date(\"2017-07-29\"), date &lt;= date(\"2023-12-11\"))) %&gt;% \n  select(date, site_name, logYield) %&gt;% \n  spread(key = site_name, value = logYield) %&gt;% \n  relocate(\"North Fork Flathead River NWIS\", .after = last_col()) %&gt;% \n  dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"ln(Yield, mm)\") %&gt;% \n  #dyOptions(colors = c(brewer.pal(7, \"Dark2\"), \"black\")) %&gt;% \n  dySeries(\"North Fork Flathead River NWIS\", strokeBorderWidth = 1, strokeWidth = 1.5, color = \"black\")\n\n\n\n\n\n\n\n\n\n\nCode\ndat_clean %&gt;% \n  filter(basin == \"Shields River\") %&gt;% \n  bind_rows(dat_clean_big %&gt;% filter(basin == \"Shields River\", date &gt;= date(\"2015-04-01\"), date &lt;= date(\"2023-12-31\"))) %&gt;% \n  select(date, site_name, logYield) %&gt;% \n  spread(key = site_name, value = logYield) %&gt;% \n  relocate(\"Yellowstone River Livingston NWIS\", .after = last_col()) %&gt;% \n  dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"ln(Yield, mm)\") %&gt;% \n  #dyOptions(colors = c(brewer.pal(7, \"Dark2\"), \"black\")) %&gt;% \n  dySeries(\"Yellowstone River Livingston NWIS\", strokeBorderWidth = 1, strokeWidth = 1.5, color = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12.4.2 Static\nCreate time series data plots objects\n\n\nCode\n### WEST BROOK\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"West Brook\") %&gt;%\n  mutate(site_name = factor(site_name, levels = wborder))\ntempdat &lt;- fill_missing_dates(tempdat, dates = date, groups = site_name, pad_ends = FALSE)  \nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"West Brook\", date &gt;= date(\"2020-01-01\"), date &lt;= date(\"2025-01-03\"))\n# color\npwb1 &lt;- ggplot() +\n  geom_line(data = tempdat, aes(x = date, y = logYield, color = factor(site_name, levels = wborder))) +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  ylim(-3,2) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"The West Brook\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n# greyscale\npwb2 &lt;- ggplot() +\n  geom_line(data = tempdat, aes(x = date, y = logYield, group = site_name), color = \"grey\") +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"black\", size = 1) +\n  ylim(-3,2) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"The West Brook\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\n\n### PAINE RUN\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Paine Run\") %&gt;%\n  mutate(site_name = factor(site_name, levels = paineorder))\ntempdat &lt;- fill_missing_dates(tempdat, dates = date, groups = site_name, pad_ends = FALSE)  \nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"Paine Run\", date &gt;= as_date(\"2018-11-07\"), date &lt;= as_date(\"2023-05-15\"))\n# color\nppa1 &lt;- ggplot() +\n  geom_line(data = tempdat, aes(x = date, y = logYield, color = factor(site_name, levels = paineorder))) +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"Paine Run\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n# greyscale\nppa2 &lt;- ggplot() +\n  geom_line(data = tempdat, aes(x = date, y = logYield, group = site_name), color = \"grey\") +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"black\", size = 1) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"Paine Run\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\n\n### STAUNTON RIVER\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Staunton River\") %&gt;%\n  mutate(site_name = factor(site_name, levels = stauntorder))\ntempdat &lt;- fill_missing_dates(tempdat, dates = date, groups = site_name, pad_ends = FALSE)  \nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"Staunton River\", date &gt;= as_date(\"2018-11-07\"), date &lt;= as_date(\"2022-10-19\"))\n# color\npst1 &lt;- ggplot() +\n  geom_line(data = tempdat, aes(x = date, y = logYield, color = factor(site_name, levels = stauntorder))) +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"Staunton River\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n# greyscale\npst2 &lt;- ggplot() +\n  geom_line(data = tempdat, aes(x = date, y = logYield, group = site_name), color = \"grey\") +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"black\", size = 1) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"Staunton River\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\n\n### FLATHEAD\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Flathead\", date &gt;= date(\"2017-07-29\"), date &lt;= date(\"2023-12-11\")) %&gt;%\n  mutate(site_name = factor(site_name, levels = flatorder))\ntempdat &lt;- fill_missing_dates(tempdat, dates = date, groups = site_name, pad_ends = FALSE)  \nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"Flathead\", date &gt;= date(\"2017-07-29\"), date &lt;= date(\"2023-12-11\"))\n# color\npfl1 &lt;- ggplot() +\n  geom_line(data = tempdat, aes(x = date, y = logYield, color = factor(site_name, levels = flatorder))) +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"Flathead River\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n# greyscale\npfl2 &lt;- ggplot() +\n  geom_line(data = tempdat, aes(x = date, y = logYield, group = site_name), color = \"grey\") +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"black\", size = 1) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"Flathead River\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\n\n### YELLOWSTONE\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Shields River\") %&gt;%\n  mutate(site_name = factor(site_name, levels = yellorder))\ntempdat &lt;- fill_missing_dates(tempdat, dates = date, groups = site_name, pad_ends = FALSE)  \nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"Shields River\", date &gt;= date(\"2015-04-01\"), date &lt;= date(\"2023-12-31\"))\n# color\npye1 &lt;- ggplot() +\n  geom_line(data = tempdat, aes(x = date, y = logYield, color = factor(site_name, levels = yellorder))) +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"Yellowstone River\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n# greyscale\npye2 &lt;- ggplot() +\n  geom_line(data = tempdat, aes(x = date, y = logYield, group = site_name), color = \"grey\") +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"black\", size = 1) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"Yellowstone River\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\n\n### SNAKE\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Snake River\") %&gt;%\n  mutate(site_name = factor(site_name, levels = snakeorder))\ntempdat &lt;- fill_missing_dates(tempdat, dates = date, groups = site_name, pad_ends = FALSE)  \nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"Snake River\", date &gt;= date(\"2016-04-01\"), date &lt;= date(\"2023-10-03\"))\n# color\npsn1 &lt;- ggplot() +\n  geom_line(data = tempdat, aes(x = date, y = logYield, color = factor(site_name, levels = snakeorder))) +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"Snake River\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n# greyscale\npsn2 &lt;- ggplot() +\n  geom_line(data = tempdat, aes(x = date, y = logYield, group = site_name), color = \"grey\") +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"black\", size = 1) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"Snake River\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\n\n### DONNER BLITZEN\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Donner Blitzen\") %&gt;%\n  mutate(site_name = factor(site_name, levels = donnerorder))\ntempdat &lt;- fill_missing_dates(tempdat, dates = date, groups = site_name, pad_ends = FALSE)  \nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"Donner Blitzen\", date &gt;= date(\"2019-06-01\"), date &lt;= as_date(\"2022-12-31\"))\n# color\npdb1 &lt;- ggplot() +\n  geom_line(data = tempdat, aes(x = date, y = logYield, color = factor(site_name, levels = donnerorder))) +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"Donner und Blitzen River\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n# greyscale\npdb2 &lt;- ggplot() +\n  geom_line(data = tempdat, aes(x = date, y = logYield, group = site_name), color = \"grey\") +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"black\", size = 1) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"Donner und Blitzen River\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\n\nGenerate plot\n\n\nCode\nannotate_figure(egg::ggarrange(pwb1, ppa1, pst1, pfl1, pye1, psn1, pdb1, ncol = 1), left = \"log(Yield, mm/day)\")\n\n\n\n\n\n\n\n\n\nWrite to file\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/EcoD_timeseries_new.jpg\", width = 6, height = 11, units = \"in\", res = 1000)\nannotate_figure(egg::ggarrange(pwb1, ppa1, pst1, pfl1, pye1, psn1, pdb1, ncol = 1), left = \"log(Yield, mm/day)\")\ndev.off()\n\n\npng \n  2",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Objective 1</span>"
    ]
  },
  {
    "objectID": "Qualitative/SpaceTimeVar.html#exceedance-curves",
    "href": "Qualitative/SpaceTimeVar.html#exceedance-curves",
    "title": "12  Objective 1",
    "section": "12.5 Exceedance curves",
    "text": "12.5 Exceedance curves\nSummer exceedance curves and spatial variability in flow relative to (bootstrapped) temporal variability\n\n\nCode\n### WEST BROOK\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"West Brook\", !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = wborder))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"West Brook\", date &gt;= date(\"2020-01-01\"), date &lt;= date(\"2025-01-03\"))\n# exceedance\nexceed_little &lt;- tempdat %&gt;%\n  group_by(site_name) %&gt;%\n  arrange(desc(logYield), .by_group = TRUE) %&gt;%\n  mutate(exceedance = 100/length(logYield)*1:length(logYield)) %&gt;%\n  ungroup()\nexceed_big &lt;- tempdat_big %&gt;%\n  arrange(desc(logYield), .by_group = TRUE) %&gt;%\n  mutate(exceedance = 100/length(logYield)*1:length(logYield))\n# plot\newb1 &lt;- ggplot() +\n  geom_line(data = exceed_little, aes(x = exceedance, y = logYield, color = factor(site_name, levels = wborder))) +\n  geom_line(data = exceed_big, aes(x = exceedance, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  #annotate(\"text\", x = max(c(exceed_big$exceedance, exceed_little$exceedance), na.rm = TRUE), y = max(c(exceed_big$logYield, exceed_little$logYield), na.rm = TRUE), label = \"The West Brook\", hjust = 1, vjust = 1) +\n  scale_x_continuous(expand = c(0.02,0.02)) + scale_y_continuous(expand = c(0.02,0.02)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n# summarize\nexceed_little_sd &lt;- exceed_little %&gt;%\n  mutate(exceedance = round(exceedance, digits = 0)) %&gt;%\n  group_by(site_name, exceedance) %&gt;% \n  summarize(logYield = mean(logYield)) %&gt;%\n  ungroup() %&gt;%\n  group_by(exceedance) %&gt;% \n  summarize(sdyield = sd(logYield)) %&gt;%\n  ungroup()\nexceed_big_sum &lt;- exceed_big %&gt;%\n  mutate(exceedance = round(exceedance, digits = 0)) %&gt;%\n  group_by(exceedance) %&gt;% \n  summarize(logYield = mean(logYield)) %&gt;%\n  ungroup() %&gt;%\n  filter(!is.na(logYield))\n# bootstrap\nnreps &lt;- 1000\nrandsampsd &lt;- c()\nfor (i in 1:nreps) { randsampsd[i] &lt;- sd(sample(exceed_big_sum$logYield, size = nsites, replace = FALSE)) }\nexceed_little_sd_exp &lt;- do.call(\"rbind\", replicate(nreps, exceed_little_sd, simplify = FALSE))\nexceed_little_sd_exp &lt;- exceed_little_sd_exp %&gt;% \n  mutate(sdbigtemp = rep(randsampsd, each = nrow(exceed_little_sd)),\n         replicate = rep(c(1:nreps), each = nrow(exceed_little_sd)),\n         reldiff = ((sdyield-sdbigtemp)/sdbigtemp)*100)\nexceed_little_sd_exp_sum &lt;- exceed_little_sd_exp %&gt;%\n  group_by(exceedance) %&gt;%\n  summarize(q025 = quantile(reldiff, probs = 0.025),\n            q10 = quantile(reldiff, probs = 0.10),\n            q50 = quantile(reldiff, probs = 0.5),\n            q90 = quantile(reldiff, probs = 0.90),\n            q975 = quantile(reldiff, probs = 0.975))\n# plot\nvwb1 &lt;- exceed_little_sd_exp_sum %&gt;% \n  ggplot() + \n  geom_ribbon(aes(x = exceedance, ymin = q025, ymax = q975), fill = \"grey85\") +\n  geom_ribbon(aes(x = exceedance, ymin = q10, ymax = q90), fill = \"grey70\") +\n  geom_line(aes(x = exceedance, y = q50), color = \"black\", size = 1) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  scale_x_continuous(expand = c(0.02,0.02)) + scale_y_continuous(expand = c(0.02,0.02)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\n\n### PAINE RUN\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Paine Run\", !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = paineorder))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"Paine Run\", date &gt;= as_date(\"2018-11-07\"), date &lt;= as_date(\"2023-05-15\"))\n# exceedance\nexceed_little &lt;- tempdat %&gt;%\n  group_by(site_name) %&gt;%\n  arrange(desc(logYield), .by_group = TRUE) %&gt;%\n  mutate(exceedance = 100/length(logYield)*1:length(logYield)) %&gt;%\n  ungroup()\nexceed_big &lt;- tempdat_big %&gt;%\n  arrange(desc(logYield), .by_group = TRUE) %&gt;%\n  mutate(exceedance = 100/length(logYield)*1:length(logYield))\n# plot\nepa1 &lt;- ggplot() +\n  geom_line(data = exceed_little, aes(x = exceedance, y = logYield, color = factor(site_name, levels = paineorder))) +\n  geom_line(data = exceed_big, aes(x = exceedance, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  #annotate(\"text\", x = max(c(exceed_big$exceedance, exceed_little$exceedance), na.rm = TRUE), y = max(c(exceed_big$logYield, exceed_little$logYield), na.rm = TRUE), label = \"Paine Run\", hjust = 1, vjust = 1) +\n  scale_x_continuous(expand = c(0.02,0.02)) + scale_y_continuous(expand = c(0.02,0.02)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n# summarize\nexceed_little_sd &lt;- exceed_little %&gt;%\n  mutate(exceedance = round(exceedance, digits = 0)) %&gt;%\n  group_by(site_name, exceedance) %&gt;% \n  summarize(logYield = mean(logYield)) %&gt;%\n  ungroup() %&gt;%\n  group_by(exceedance) %&gt;% \n  summarize(sdyield = sd(logYield)) %&gt;%\n  ungroup()\nexceed_big_sum &lt;- exceed_big %&gt;%\n  mutate(exceedance = round(exceedance, digits = 0)) %&gt;%\n  group_by(exceedance) %&gt;% \n  summarize(logYield = mean(logYield)) %&gt;%\n  ungroup() %&gt;%\n  filter(!is.na(logYield))\n# bootstrap\nnreps &lt;- 1000\nrandsampsd &lt;- c()\nfor (i in 1:nreps) { randsampsd[i] &lt;- sd(sample(exceed_big_sum$logYield, size = nsites, replace = FALSE)) }\nexceed_little_sd_exp &lt;- do.call(\"rbind\", replicate(nreps, exceed_little_sd, simplify = FALSE))\nexceed_little_sd_exp &lt;- exceed_little_sd_exp %&gt;% \n  mutate(sdbigtemp = rep(randsampsd, each = nrow(exceed_little_sd)),\n         replicate = rep(c(1:nreps), each = nrow(exceed_little_sd)),\n         reldiff = ((sdyield-sdbigtemp)/sdbigtemp)*100)\nexceed_little_sd_exp_sum &lt;- exceed_little_sd_exp %&gt;%\n  group_by(exceedance) %&gt;%\n  summarize(q025 = quantile(reldiff, probs = 0.025),\n            q10 = quantile(reldiff, probs = 0.10),\n            q50 = quantile(reldiff, probs = 0.5),\n            q90 = quantile(reldiff, probs = 0.90),\n            q975 = quantile(reldiff, probs = 0.975))\n# plot\nvpa1 &lt;- exceed_little_sd_exp_sum %&gt;% \n  ggplot() + \n  geom_ribbon(aes(x = exceedance, ymin = q025, ymax = q975), fill = \"grey85\") +\n  geom_ribbon(aes(x = exceedance, ymin = q10, ymax = q90), fill = \"grey70\") +\n  geom_line(aes(x = exceedance, y = q50), color = \"black\", size = 1) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  scale_x_continuous(expand = c(0.02,0.02)) + scale_y_continuous(expand = c(0.02,0.02)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\n\n### STAUNTON RIVER\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Staunton River\", !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = stauntorder))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"Staunton River\", date &gt;= as_date(\"2018-11-07\"), date &lt;= as_date(\"2022-10-19\"))\n# exceedance\nexceed_little &lt;- tempdat %&gt;%\n  group_by(site_name) %&gt;%\n  arrange(desc(logYield), .by_group = TRUE) %&gt;%\n  mutate(exceedance = 100/length(logYield)*1:length(logYield)) %&gt;%\n  ungroup()\nexceed_big &lt;- tempdat_big %&gt;%\n  arrange(desc(logYield), .by_group = TRUE) %&gt;%\n  mutate(exceedance = 100/length(logYield)*1:length(logYield))\n# plot\nest1 &lt;- ggplot() +\n  geom_line(data = exceed_little, aes(x = exceedance, y = logYield, color = factor(site_name, levels = stauntorder))) +\n  geom_line(data = exceed_big, aes(x = exceedance, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  #annotate(\"text\", x = max(c(exceed_big$exceedance, exceed_little$exceedance), na.rm = TRUE), y = max(c(exceed_big$logYield, exceed_little$logYield), na.rm = TRUE), label = \"Staunton River\", hjust = 1, vjust = 1) +\n  scale_x_continuous(expand = c(0.02,0.02)) + scale_y_continuous(expand = c(0.02,0.02)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n# summarize\nexceed_little_sd &lt;- exceed_little %&gt;%\n  mutate(exceedance = round(exceedance, digits = 0)) %&gt;%\n  group_by(site_name, exceedance) %&gt;% \n  summarize(logYield = mean(logYield)) %&gt;%\n  ungroup() %&gt;%\n  group_by(exceedance) %&gt;% \n  summarize(sdyield = sd(logYield)) %&gt;%\n  ungroup()\nexceed_big_sum &lt;- exceed_big %&gt;%\n  mutate(exceedance = round(exceedance, digits = 0)) %&gt;%\n  group_by(exceedance) %&gt;% \n  summarize(logYield = mean(logYield)) %&gt;%\n  ungroup() %&gt;%\n  filter(!is.na(logYield))\n# bootstrap\nnreps &lt;- 1000\nrandsampsd &lt;- c()\nfor (i in 1:nreps) { randsampsd[i] &lt;- sd(sample(exceed_big_sum$logYield, size = nsites, replace = FALSE)) }\nexceed_little_sd_exp &lt;- do.call(\"rbind\", replicate(nreps, exceed_little_sd, simplify = FALSE))\nexceed_little_sd_exp &lt;- exceed_little_sd_exp %&gt;% \n  mutate(sdbigtemp = rep(randsampsd, each = nrow(exceed_little_sd)),\n         replicate = rep(c(1:nreps), each = nrow(exceed_little_sd)),\n         reldiff = ((sdyield-sdbigtemp)/sdbigtemp)*100)\nexceed_little_sd_exp_sum &lt;- exceed_little_sd_exp %&gt;%\n  group_by(exceedance) %&gt;%\n  summarize(q025 = quantile(reldiff, probs = 0.025),\n            q10 = quantile(reldiff, probs = 0.10),\n            q50 = quantile(reldiff, probs = 0.5),\n            q90 = quantile(reldiff, probs = 0.90),\n            q975 = quantile(reldiff, probs = 0.975))\n# plot\nvst1 &lt;- exceed_little_sd_exp_sum %&gt;% \n  ggplot() + \n  geom_ribbon(aes(x = exceedance, ymin = q025, ymax = q975), fill = \"grey85\") +\n  geom_ribbon(aes(x = exceedance, ymin = q10, ymax = q90), fill = \"grey70\") +\n  geom_line(aes(x = exceedance, y = q50), color = \"black\", size = 1) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  scale_x_continuous(expand = c(0.02,0.02)) + scale_y_continuous(expand = c(0.02,0.02)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\n\n### FLATHEAD\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Flathead\", date &gt;= date(\"2017-07-29\"), date &lt;= date(\"2023-12-11\"), !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = flatorder))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"Flathead\", date &gt;= date(\"2017-07-29\"), date &lt;= date(\"2023-12-11\"))\n# exceedance\nexceed_little &lt;- tempdat %&gt;%\n  group_by(site_name) %&gt;%\n  arrange(desc(logYield), .by_group = TRUE) %&gt;%\n  mutate(exceedance = 100/length(logYield)*1:length(logYield)) %&gt;%\n  ungroup()\nexceed_big &lt;- tempdat_big %&gt;%\n  arrange(desc(logYield), .by_group = TRUE) %&gt;%\n  mutate(exceedance = 100/length(logYield)*1:length(logYield))\n# plot\nefl1 &lt;- ggplot() +\n  geom_line(data = exceed_little, aes(x = exceedance, y = logYield, color = factor(site_name, levels = flatorder))) +\n  geom_line(data = exceed_big, aes(x = exceedance, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  #annotate(\"text\", x = max(c(exceed_big$exceedance, exceed_little$exceedance), na.rm = TRUE), y = max(c(exceed_big$logYield, exceed_little$logYield), na.rm = TRUE), label = \"Flathead River\", hjust = 1, vjust = 1) +\n  scale_x_continuous(expand = c(0.02,0.02)) + scale_y_continuous(expand = c(0.02,0.02)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n# summarize\nexceed_little_sd &lt;- exceed_little %&gt;%\n  mutate(exceedance = round(exceedance, digits = 0)) %&gt;%\n  group_by(site_name, exceedance) %&gt;% \n  summarize(logYield = mean(logYield)) %&gt;%\n  ungroup() %&gt;%\n  group_by(exceedance) %&gt;% \n  summarize(sdyield = sd(logYield)) %&gt;%\n  ungroup()\nexceed_big_sum &lt;- exceed_big %&gt;%\n  mutate(exceedance = round(exceedance, digits = 0)) %&gt;%\n  group_by(exceedance) %&gt;% \n  summarize(logYield = mean(logYield)) %&gt;%\n  ungroup() %&gt;%\n  filter(!is.na(logYield))\n# bootstrap\nnreps &lt;- 1000\nrandsampsd &lt;- c()\nfor (i in 1:nreps) { randsampsd[i] &lt;- sd(sample(exceed_big_sum$logYield, size = nsites, replace = FALSE)) }\nexceed_little_sd_exp &lt;- do.call(\"rbind\", replicate(nreps, exceed_little_sd, simplify = FALSE))\nexceed_little_sd_exp &lt;- exceed_little_sd_exp %&gt;% \n  mutate(sdbigtemp = rep(randsampsd, each = nrow(exceed_little_sd)),\n         replicate = rep(c(1:nreps), each = nrow(exceed_little_sd)),\n         reldiff = ((sdyield-sdbigtemp)/sdbigtemp)*100)\nexceed_little_sd_exp_sum &lt;- exceed_little_sd_exp %&gt;%\n  group_by(exceedance) %&gt;%\n  summarize(q025 = quantile(reldiff, probs = 0.025),\n            q10 = quantile(reldiff, probs = 0.10),\n            q50 = quantile(reldiff, probs = 0.5),\n            q90 = quantile(reldiff, probs = 0.90),\n            q975 = quantile(reldiff, probs = 0.975))\n# plot\nvfl1 &lt;- exceed_little_sd_exp_sum %&gt;% \n  ggplot() + \n  geom_ribbon(aes(x = exceedance, ymin = q025, ymax = q975), fill = \"grey85\") +\n  geom_ribbon(aes(x = exceedance, ymin = q10, ymax = q90), fill = \"grey70\") +\n  geom_line(aes(x = exceedance, y = q50), color = \"black\", size = 1) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  scale_x_continuous(expand = c(0.02,0.02)) + scale_y_continuous(expand = c(0.02,0.02)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\n\n### YELLOWSTONE\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Shields River\", !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = yellorder))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"Shields River\", date &gt;= date(\"2015-04-01\"), date &lt;= date(\"2023-12-31\"))\n# exceedance\nexceed_little &lt;- tempdat %&gt;%\n  group_by(site_name) %&gt;%\n  arrange(desc(logYield), .by_group = TRUE) %&gt;%\n  mutate(exceedance = 100/length(logYield)*1:length(logYield)) %&gt;%\n  ungroup()\nexceed_big &lt;- tempdat_big %&gt;%\n  arrange(desc(logYield), .by_group = TRUE) %&gt;%\n  mutate(exceedance = 100/length(logYield)*1:length(logYield))\n# plot\neye1 &lt;- ggplot() +\n  geom_line(data = exceed_little, aes(x = exceedance, y = logYield, color = factor(site_name, levels = yellorder))) +\n  geom_line(data = exceed_big, aes(x = exceedance, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  #annotate(\"text\", x = max(c(exceed_big$exceedance, exceed_little$exceedance), na.rm = TRUE), y = max(c(exceed_big$logYield, exceed_little$logYield), na.rm = TRUE), label = \"Yellowstone River\", hjust = 1, vjust = 1) +\n  scale_x_continuous(expand = c(0.02,0.02)) + scale_y_continuous(expand = c(0.02,0.02)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n# summarize\nexceed_little_sd &lt;- exceed_little %&gt;%\n  mutate(exceedance = round(exceedance, digits = 0)) %&gt;%\n  group_by(site_name, exceedance) %&gt;% \n  summarize(logYield = mean(logYield)) %&gt;%\n  ungroup() %&gt;%\n  group_by(exceedance) %&gt;% \n  summarize(sdyield = sd(logYield)) %&gt;%\n  ungroup()\nexceed_big_sum &lt;- exceed_big %&gt;%\n  mutate(exceedance = round(exceedance, digits = 0)) %&gt;%\n  group_by(exceedance) %&gt;% \n  summarize(logYield = mean(logYield)) %&gt;%\n  ungroup() %&gt;%\n  filter(!is.na(logYield))\n# bootstrap\nnreps &lt;- 1000\nrandsampsd &lt;- c()\nfor (i in 1:nreps) { randsampsd[i] &lt;- sd(sample(exceed_big_sum$logYield, size = nsites, replace = FALSE)) }\nexceed_little_sd_exp &lt;- do.call(\"rbind\", replicate(nreps, exceed_little_sd, simplify = FALSE))\nexceed_little_sd_exp &lt;- exceed_little_sd_exp %&gt;% \n  mutate(sdbigtemp = rep(randsampsd, each = nrow(exceed_little_sd)),\n         replicate = rep(c(1:nreps), each = nrow(exceed_little_sd)),\n         reldiff = ((sdyield-sdbigtemp)/sdbigtemp)*100)\nexceed_little_sd_exp_sum &lt;- exceed_little_sd_exp %&gt;%\n  group_by(exceedance) %&gt;%\n  summarize(q025 = quantile(reldiff, probs = 0.025),\n            q10 = quantile(reldiff, probs = 0.10),\n            q50 = quantile(reldiff, probs = 0.5),\n            q90 = quantile(reldiff, probs = 0.90),\n            q975 = quantile(reldiff, probs = 0.975))\n# plot\nvye1 &lt;- exceed_little_sd_exp_sum %&gt;% \n  ggplot() + \n  geom_ribbon(aes(x = exceedance, ymin = q025, ymax = q975), fill = \"grey85\") +\n  geom_ribbon(aes(x = exceedance, ymin = q10, ymax = q90), fill = \"grey70\") +\n  geom_line(aes(x = exceedance, y = q50), color = \"black\", size = 1) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  scale_x_continuous(expand = c(0.02,0.02)) + scale_y_continuous(expand = c(0.02,0.02)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\n\n### SNAKE\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Snake River\", !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = snakeorder))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"Snake River\", date &gt;= date(\"2016-04-01\"), date &lt;= date(\"2023-10-03\"))\n# exceedance\nexceed_little &lt;- tempdat %&gt;%\n  group_by(site_name) %&gt;%\n  arrange(desc(logYield), .by_group = TRUE) %&gt;%\n  mutate(exceedance = 100/length(logYield)*1:length(logYield)) %&gt;%\n  ungroup()\nexceed_big &lt;- tempdat_big %&gt;%\n  arrange(desc(logYield), .by_group = TRUE) %&gt;%\n  mutate(exceedance = 100/length(logYield)*1:length(logYield))\n# plot\nesn1 &lt;- ggplot() +\n  geom_line(data = exceed_little, aes(x = exceedance, y = logYield, color = factor(site_name, levels = snakeorder))) +\n  geom_line(data = exceed_big, aes(x = exceedance, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  #annotate(\"text\", x = max(c(exceed_big$exceedance, exceed_little$exceedance), na.rm = TRUE), y = max(c(exceed_big$logYield, exceed_little$logYield), na.rm = TRUE), label = \"Snake River\", hjust = 1, vjust = 1) +\n  scale_x_continuous(expand = c(0.02,0.02)) + scale_y_continuous(expand = c(0.02,0.02)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n# summarize\nexceed_little_sd &lt;- exceed_little %&gt;%\n  mutate(exceedance = round(exceedance, digits = 0)) %&gt;%\n  group_by(site_name, exceedance) %&gt;% \n  summarize(logYield = mean(logYield)) %&gt;%\n  ungroup() %&gt;%\n  group_by(exceedance) %&gt;% \n  summarize(sdyield = sd(logYield)) %&gt;%\n  ungroup()\nexceed_big_sum &lt;- exceed_big %&gt;%\n  mutate(exceedance = round(exceedance, digits = 0)) %&gt;%\n  group_by(exceedance) %&gt;% \n  summarize(logYield = mean(logYield)) %&gt;%\n  ungroup() %&gt;%\n  filter(!is.na(logYield))\n# bootstrap\nnreps &lt;- 1000\nrandsampsd &lt;- c()\nfor (i in 1:nreps) { randsampsd[i] &lt;- sd(sample(exceed_big_sum$logYield, size = nsites, replace = FALSE)) }\nexceed_little_sd_exp &lt;- do.call(\"rbind\", replicate(nreps, exceed_little_sd, simplify = FALSE))\nexceed_little_sd_exp &lt;- exceed_little_sd_exp %&gt;% \n  mutate(sdbigtemp = rep(randsampsd, each = nrow(exceed_little_sd)),\n         replicate = rep(c(1:nreps), each = nrow(exceed_little_sd)),\n         reldiff = ((sdyield-sdbigtemp)/sdbigtemp)*100)\nexceed_little_sd_exp_sum &lt;- exceed_little_sd_exp %&gt;%\n  group_by(exceedance) %&gt;%\n  summarize(q025 = quantile(reldiff, probs = 0.025),\n            q10 = quantile(reldiff, probs = 0.10),\n            q50 = quantile(reldiff, probs = 0.5),\n            q90 = quantile(reldiff, probs = 0.90),\n            q975 = quantile(reldiff, probs = 0.975))\n# plot\nvsn1 &lt;- exceed_little_sd_exp_sum %&gt;% \n  ggplot() + \n  geom_ribbon(aes(x = exceedance, ymin = q025, ymax = q975), fill = \"grey85\") +\n  geom_ribbon(aes(x = exceedance, ymin = q10, ymax = q90), fill = \"grey70\") +\n  geom_line(aes(x = exceedance, y = q50), color = \"black\", size = 1) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  scale_x_continuous(expand = c(0.02,0.02)) + scale_y_continuous(expand = c(0.02,0.02)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\n\n### DONNER BLITZEN\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Donner Blitzen\", !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = donnerorder))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"Donner Blitzen\", date &gt;= date(\"2019-06-01\"), date &lt;= as_date(\"2022-12-31\"))\n# exceedance\nexceed_little &lt;- tempdat %&gt;%\n  group_by(site_name) %&gt;%\n  arrange(desc(logYield), .by_group = TRUE) %&gt;%\n  mutate(exceedance = 100/length(logYield)*1:length(logYield)) %&gt;%\n  ungroup()\nexceed_big &lt;- tempdat_big %&gt;%\n  arrange(desc(logYield), .by_group = TRUE) %&gt;%\n  mutate(exceedance = 100/length(logYield)*1:length(logYield))\n# plot\nedb1 &lt;- ggplot() +\n  geom_line(data = exceed_little, aes(x = exceedance, y = logYield, color = factor(site_name, levels = donnerorder))) +\n  geom_line(data = exceed_big, aes(x = exceedance, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  #annotate(\"text\", x = max(c(exceed_big$exceedance, exceed_little$exceedance), na.rm = TRUE), y = max(c(exceed_big$logYield, exceed_little$logYield), na.rm = TRUE), label = \"Donner und Blitzen River\", hjust = 1, vjust = 1) +\n  scale_x_continuous(expand = c(0.02,0.02)) + scale_y_continuous(expand = c(0.02,0.02)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n# summarize\nexceed_little_sd &lt;- exceed_little %&gt;%\n  mutate(exceedance = round(exceedance, digits = 0)) %&gt;%\n  group_by(site_name, exceedance) %&gt;% \n  summarize(logYield = mean(logYield)) %&gt;%\n  ungroup() %&gt;%\n  group_by(exceedance) %&gt;% \n  summarize(sdyield = sd(logYield)) %&gt;%\n  ungroup()\nexceed_big_sum &lt;- exceed_big %&gt;%\n  mutate(exceedance = round(exceedance, digits = 0)) %&gt;%\n  group_by(exceedance) %&gt;% \n  summarize(logYield = mean(logYield)) %&gt;%\n  ungroup() %&gt;%\n  filter(!is.na(logYield))\n# bootstrap\nnreps &lt;- 1000\nrandsampsd &lt;- c()\nfor (i in 1:nreps) { randsampsd[i] &lt;- sd(sample(exceed_big_sum$logYield, size = nsites, replace = FALSE)) }\nexceed_little_sd_exp &lt;- do.call(\"rbind\", replicate(nreps, exceed_little_sd, simplify = FALSE))\nexceed_little_sd_exp &lt;- exceed_little_sd_exp %&gt;% \n  mutate(sdbigtemp = rep(randsampsd, each = nrow(exceed_little_sd)),\n         replicate = rep(c(1:nreps), each = nrow(exceed_little_sd)),\n         reldiff = ((sdyield-sdbigtemp)/sdbigtemp)*100)\nexceed_little_sd_exp_sum &lt;- exceed_little_sd_exp %&gt;%\n  group_by(exceedance) %&gt;%\n  summarize(q025 = quantile(reldiff, probs = 0.025),\n            q10 = quantile(reldiff, probs = 0.10),\n            q50 = quantile(reldiff, probs = 0.5),\n            q90 = quantile(reldiff, probs = 0.90),\n            q975 = quantile(reldiff, probs = 0.975))\n# plot\nvdb1 &lt;- exceed_little_sd_exp_sum %&gt;% \n  ggplot() + \n  geom_ribbon(aes(x = exceedance, ymin = q025, ymax = q975), fill = \"grey85\") +\n  geom_ribbon(aes(x = exceedance, ymin = q10, ymax = q90), fill = \"grey70\") +\n  geom_line(aes(x = exceedance, y = q50), color = \"black\", size = 1) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  scale_x_continuous(expand = c(0.02,0.02)) + scale_y_continuous(expand = c(0.02,0.02)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\n\nGenerate plot\n\n\nCode\nannotate_figure(ggarrange(annotate_figure(egg::ggarrange(ewb1, epa1, est1, efl1, eye1, esn1, edb1, ncol = 1), left = \"log(Yield, mm/day)\"),\n          annotate_figure(egg::ggarrange(vwb1, vpa1, vst1, vfl1, vye1, vsn1, vdb1, ncol = 1), left = \"Relative spatial variation in flow (%)\"),\n          ncol = 2), bottom = \"Exceedance probability\")\n\n\n\n\n\n\n\n\n\nWrite to file\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/EcoD_exceedance_new.jpg\", width = 5.5, height = 11, units = \"in\", res = 1000)\nannotate_figure(ggarrange(annotate_figure(egg::ggarrange(ewb1, epa1, est1, efl1, eye1, esn1, edb1, ncol = 1), left = \"log(Yield, mm/day)\"),\n          annotate_figure(egg::ggarrange(vwb1, vpa1, vst1, vfl1, vye1, vsn1, vdb1, ncol = 1), left = \"Relative spatial variation in flow (%)\"),\n          ncol = 2), bottom = \"Exceedance probability\")\ndev.off()\n\n\npng \n  2 \n\n\n\n12.5.1 Combined plot\n\n\nCode\np &lt;- ggarrange(annotate_figure(egg::ggarrange(pwb1, ppa1, pst1, pfl1, pye1, psn1, pdb1, ncol = 1), \n                               bottom = text_grob(\"Date\\n \", size = 11),  left = text_grob(\"log(Yield, mm/day)\", size = 11, rot = 90)),\n               annotate_figure(egg::ggarrange(ewb1, epa1, est1, efl1, eye1, esn1, edb1, ncol = 1), \n                               bottom = text_grob(\"Exceedance probability \\n(summer only)\", size = 11)),\n               ncol = 2, widths = c(1,0.4))\np\n\n\n\n\n\n\n\n\n\nWrite to file\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/EcoD_tsexed_new.jpg\", width = 8, height = 11, units = \"in\", res = 1000)\np\ndev.off()\n\n\npng \n  2",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Objective 1</span>"
    ]
  },
  {
    "objectID": "Qualitative/SpaceTimeVar.html#ridgeline-plots",
    "href": "Qualitative/SpaceTimeVar.html#ridgeline-plots",
    "title": "12  Objective 1",
    "section": "12.4 Ridgeline plots",
    "text": "12.4 Ridgeline plots\nUnder the current objectives/framework, I’m not sure there is much of a role for these plots. Leaving in for reference\n\n\nCode\nmyridgesfun &lt;- function(subbas, bigG) {\n  td &lt;- dat_clean %&gt;% filter(subbasin == subbas)\n  td2 &lt;- td %&gt;%\n    group_by(subbasin, site_name, designation, CalendarYear, Month, MonthName) %&gt;%\n    summarize(logYield = mean(logYield)) %&gt;%\n    ungroup() %&gt;%\n    mutate(MonthName = factor(MonthName, levels = rev(c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))),\n           CalendarYear = factor(CalendarYear)) \n  \n  tempdat_big &lt;- dat_clean_big %&gt;% \n    filter(site_name == bigG, date &gt;= min(td$date), date &lt;= max(td$date)) %&gt;%\n    group_by(site_name, CalendarYear, Month, MonthName) %&gt;%\n    summarize(logYield = mean(logYield)) %&gt;%\n    ungroup() %&gt;%\n    mutate(MonthName = factor(MonthName, levels = rev(c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))), CalendarYear = factor(CalendarYear))\n    \n  return(ggplot(data = td2) +\n  geom_density_ridges(data = td2, aes(x = logYield, y = MonthName), alpha = 0.5,point_alpha = 0.2) +\n  geom_line(data = td2, aes(x = logYield, y = MonthName, group = site_name, color = site_name), orientation = \"y\", alpha = 0.3) +\n  geom_point(data = td2, aes(x = logYield, y = MonthName, group = site_name, color = site_name), alpha = 0.3) +\n  geom_line(data = tempdat_big, aes(x = logYield, y = MonthName, group = site_name), orientation = \"y\", alpha = 0.5) +\n  geom_point(data =tempdat_big, aes(x = logYield, y = MonthName, group = site_name), alpha = 0.5) +\n  theme_bw() + theme(legend.position = \"none\") +\n  facet_wrap2(~CalendarYear, nrow = 3, ncol = 3, trim_blank = FALSE) +\n  xlab(\"Monthly mean log(Yield, mm/day)\") + ylab(\"\"))\n}\n\n\n\nWest BrookPaine RunStaunton RiverBig CreekCoal CreekMcGee CreekSnake RiverShields RiverDuck CreekDonner Blitzen\n\n\n\n\nCode\nmyridgesfun(subbas = \"West Brook\", bigG = \"South River Conway NWIS\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyridgesfun(subbas = \"Paine Run\", bigG = \"South River Harriston NWIS\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyridgesfun(subbas = \"Staunton River\", bigG = \"Rapidan River NWIS\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyridgesfun(subbas = \"Big Creek\", bigG = \"North Fork Flathead River NWIS\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyridgesfun(subbas = \"Coal Creek\", bigG = \"North Fork Flathead River NWIS\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyridgesfun(subbas = \"McGee Creek\", bigG = \"North Fork Flathead River NWIS\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyridgesfun(subbas = \"Snake River\", bigG = \"Pacific Creek at Moran NWIS\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyridgesfun(subbas = \"Shields River\", bigG = \"Yellowstone River Livingston NWIS\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyridgesfun(subbas = \"Duck Creek\", bigG = \"Yellowstone River Livingston NWIS\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyridgesfun(subbas = \"Donner Blitzen\", bigG = \"Donner Blitzen River nr Frenchglen NWIS\")",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Objective 1</span>"
    ]
  },
  {
    "objectID": "Qualitative/Hysteresis.html",
    "href": "Qualitative/Hysteresis.html",
    "title": "13  Objective 2",
    "section": "",
    "text": "13.1 Data\nPurpose: Explore non-linear and hysteretic relationship between flow at reference vs. at headwater gages\nApproach:\nNotes:\nSite information\nCode\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nLittle g’s\nCode\ndat_clean &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/LittleG_data_clean.csv\")\nBig G’s\nCode\ndat_clean_big &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/BigG_data_clean.csv\")\nClimate\nCode\nclimdf &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/Daymet_climate.csv\")\nclimdf_summ &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/Daymet_climate_summary.csv\")\nWater availability\nCode\nwateravail &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/BigG_wateravailability_annual.csv\")",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Objective 2</span>"
    ]
  },
  {
    "objectID": "Qualitative/Hysteresis.html#trim-data",
    "href": "Qualitative/Hysteresis.html#trim-data",
    "title": "13  Objective 2",
    "section": "13.2 Trim data",
    "text": "13.2 Trim data\nFind little g site/water years with at least 90% data completeness, join big and little g daily yield data\n\n\nCode\n# find little g site/water years with at least 90% data availability\nmysiteyrs &lt;- dat_clean %&gt;% \n  group_by(site_name, basin, subbasin, region, WaterYear) %&gt;% \n  summarize(numdays = n(),\n            totalyield_site = sum(Yield_mm)) %&gt;% \n  ungroup() %&gt;% \n  filter(numdays &gt;= 0.9*365) %&gt;% \n  mutate(forhyst = 1) %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield_z))\n\n# join big G data to little g\n# dat_clean_hyst &lt;- dat_clean %&gt;% \n#   left_join(mysiteyrs) %&gt;%\n#   filter(forhyst == 1) %&gt;%\n#   left_join(dat_clean_big %&gt;% select(basin, date, Yield_mm, logYield) %&gt;% rename(Yield_mm_big = Yield_mm, logYield_big = logYield)) %&gt;%\n#   left_join(wateravail %&gt;% select(basin, WaterYear, totalyield_z))\n\nhystlist &lt;- list()\nfor (i in 1:dim(mysiteyrs)[1]) {\n  tt &lt;- dat_clean %&gt;% filter(site_name == mysiteyrs$site_name[i], WaterYear == mysiteyrs$WaterYear[i])\n  tt &lt;- fill_missing_dates(tt, dates = date, water_year_start = 10, pad_ends = TRUE)\n  tt &lt;- tt %&gt;% \n    mutate(site_name = mysiteyrs$site_name[i],\n           basin = mysiteyrs$basin[i],\n           subbasin = mysiteyrs$subbasin[i],\n           region = mysiteyrs$region[i]) %&gt;%\n    select(site_name, basin, subbasin, region, date, Yield_mm, logYield)\n  tt &lt;- add_date_variables(tt, dates = date, water_year_start = 10)\n  hystlist[[i]] &lt;- tt %&gt;% \n    left_join(dat_clean_big %&gt;% \n                select(basin, date, Yield_mm, logYield) %&gt;% \n                rename(Yield_mm_big = Yield_mm, logYield_big = logYield)) %&gt;%\n    mutate(logYield_big = na.approx(logYield_big)) %&gt;%\n    left_join(wateravail %&gt;% select(basin, WaterYear, totalyield_z))\n}\ndat_clean_hyst &lt;- do.call(rbind, hystlist)\n\n# view data\nmysiteyrs\n\n\n# A tibble: 87 × 9\n   site_name     basin subbasin region WaterYear numdays totalyield_site forhyst\n   &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt;   &lt;int&gt;           &lt;dbl&gt;   &lt;dbl&gt;\n 1 Avery Brook   West… West Br… Mass        2021     365            872.       1\n 2 Avery Brook   West… West Br… Mass        2022     365            602.       1\n 3 Avery Brook   West… West Br… Mass        2023     365           1147.       1\n 4 Avery Brook   West… West Br… Mass        2024     345            993.       1\n 5 Big Creek NW… Flat… Big Cre… Flat        2019     329            566.       1\n 6 Big Creek NW… Flat… Big Cre… Flat        2020     347            719.       1\n 7 Big Creek NW… Flat… Big Cre… Flat        2021     352            554.       1\n 8 Big Creek NW… Flat… Big Cre… Flat        2022     340            842.       1\n 9 Buck Creek    Shie… Shields… Shiel…      2022     329            174.       1\n10 CycloneCreek… Flat… Coal Cr… Flat        2019     354            374.       1\n# ℹ 77 more rows\n# ℹ 1 more variable: totalyield_z &lt;dbl&gt;\n\n\nCode\ndat_clean_hyst\n\n\n# A tibble: 31,778 × 15\n   site_name   basin   subbasin region date       Yield_mm logYield CalendarYear\n   &lt;chr&gt;       &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;  &lt;date&gt;        &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n 1 Avery Brook West B… West Br… Mass   2020-10-01    0.595   -0.226         2020\n 2 Avery Brook West B… West Br… Mass   2020-10-02    0.341   -0.467         2020\n 3 Avery Brook West B… West Br… Mass   2020-10-03    0.288   -0.541         2020\n 4 Avery Brook West B… West Br… Mass   2020-10-04    0.218   -0.662         2020\n 5 Avery Brook West B… West Br… Mass   2020-10-05    0.204   -0.689         2020\n 6 Avery Brook West B… West Br… Mass   2020-10-06    0.209   -0.679         2020\n 7 Avery Brook West B… West Br… Mass   2020-10-07    0.239   -0.621         2020\n 8 Avery Brook West B… West Br… Mass   2020-10-08    0.262   -0.581         2020\n 9 Avery Brook West B… West Br… Mass   2020-10-09    0.221   -0.657         2020\n10 Avery Brook West B… West Br… Mass   2020-10-10    0.245   -0.611         2020\n# ℹ 31,768 more rows\n# ℹ 7 more variables: Month &lt;dbl&gt;, MonthName &lt;fct&gt;, WaterYear &lt;dbl&gt;,\n#   DayofYear &lt;dbl&gt;, Yield_mm_big &lt;dbl&gt;, logYield_big &lt;dbl&gt;, totalyield_z &lt;dbl&gt;",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Objective 2</span>"
    ]
  },
  {
    "objectID": "Qualitative/Hysteresis.html#gg-scatterplots",
    "href": "Qualitative/Hysteresis.html#gg-scatterplots",
    "title": "13  Objective 2",
    "section": "13.3 gG scatterplots",
    "text": "13.3 gG scatterplots\nCreate plotting function\n\n\nCode\nhystplotfun &lt;- function(mysite, wy, months = c(1:12)) {\n  (dat_clean_hyst %&gt;%\n          filter(site_name == mysite, WaterYear == wy, Month %in% months) %&gt;%\n          ggplot(aes(x = logYield_big, y = logYield, color = date)) +\n          geom_segment(aes(xend = c(tail(logYield_big, n = -1), NA), yend = c(tail(logYield, n = -1), NA)), arrow = arrow(length = unit(0.2, \"cm\")), color = \"black\") +\n          geom_point() + \n          geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n          scale_color_gradientn(colors = cet_pal(250, name = \"c2\"), trans = \"date\") +\n          xlim(-1,1.5) + ylim(-1.5,1.8) + \n          #scale_color_scico(palette = \"romaO\") +\n          xlab(\"log(Yield, mm) at reference gage\") + ylab(\"log(Yield, mm) at headwater gage\") +\n          # geom_text(data = annotations, aes(x = xpos, y = ypos, label = annotateText), hjust = \"inward\", vjust = \"inward\") +\n          annotate(geom = \"text\", x = -Inf, y = Inf, label = paste(mysite, \", WY \", wy, sep = \"\"), hjust = -0.1, vjust = 1.5) +\n          theme_bw() + \n          theme(panel.grid.major = element_blank(), \n                panel.grid.minor = element_blank(),\n                panel.background = element_rect(fill = \"grey85\"),\n                axis.title = element_blank()) +\n          theme(plot.margin = margin(0.1,0.1,0,0, \"cm\")) )\n}\n# change to linear color palette\nhystplotfunlin &lt;- function(mysite, wy, months = c(1:12)) {\n  (dat_clean_hyst %&gt;%\n          filter(site_name == mysite, WaterYear == wy, Month %in% months) %&gt;%\n          ggplot(aes(x = logYield_big, y = logYield, color = date)) +\n          geom_segment(aes(xend = c(tail(logYield_big, n = -1), NA), yend = c(tail(logYield, n = -1), NA)), arrow = arrow(length = unit(0.2, \"cm\")), color = \"black\") +\n          geom_point() + \n          geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n          scale_color_gradientn(colors = cet_pal(90, name = \"r1\"), trans = \"date\") +\n          xlim(-1,1.5) + ylim(-1.5,1.8) + \n          #scale_color_scico(palette = \"romaO\") +\n          xlab(\"log(Yield, mm) at reference gage\") + ylab(\"log(Yield, mm) at headwater gage\") +\n          # geom_text(data = annotations, aes(x = xpos, y = ypos, label = annotateText), hjust = \"inward\", vjust = \"inward\") +\n          annotate(geom = \"text\", x = -Inf, y = Inf, label = paste(mysite, \", WY \", wy, sep = \"\"), hjust = -0.1, vjust = 1.5) +\n          theme_bw() + \n          theme(panel.grid.major = element_blank(), \n                panel.grid.minor = element_blank(),\n                panel.background = element_rect(fill = \"grey85\"),\n                axis.title = element_blank()) +\n          theme(plot.margin = margin(0.1,0.1,0,0, \"cm\")) )\n}\n\n\nPlot example sites and years. Generally, in rain-dominated basins the East (top two rows), we see relatively little hysteresis/non-stationarity in the relationship between streamflow in headwaters and at reference gages. In contrast, in snowmelt-dominated basins of the Rocky Mountains, we see much stronger hysteresis/non-stationarity in the relationship between streamflow in headwaters and at reference gages, but this varies considerably among locations.\n\n\nCode\nggarrange(hystplotfun(mysite = \"West Brook NWIS\", wy = 2021) + theme(legend.position = \"none\"),\n          hystplotfun(mysite = \"Jimmy Brook\", wy = 2021) + theme(legend.position = \"none\"),\n          hystplotfun(mysite = \"Sanderson Brook\", wy = 2021) + theme(legend.position = \"none\"),\n          hystplotfun(mysite = \"Avery Brook\", wy = 2021) + theme(legend.position = \"none\"),\n          \n          hystplotfun(mysite = \"Staunton River 10\", wy = 2021) + theme(legend.position = \"none\"),\n          hystplotfun(mysite = \"Staunton River 06\", wy = 2021) + theme(legend.position = \"none\"),\n          hystplotfun(mysite = \"Staunton River 03\", wy = 2021) + theme(legend.position = \"none\"),\n          hystplotfun(mysite = \"Staunton River 02\", wy = 2021) + theme(legend.position = \"none\"),\n          \n          hystplotfun(mysite = \"Big Creek NWIS\", wy = 2020) + theme(legend.position = \"none\"),\n          hystplotfun(mysite = \"WernerCreek\", wy = 2020) + theme(legend.position = \"none\"),\n          hystplotfun(mysite = \"CycloneCreekUpper\", wy = 2020) + theme(legend.position = \"none\"),\n          hystplotfun(mysite = \"McGeeCreekTrib\", wy = 2020) + theme(legend.position = \"none\"),\n          \n          hystplotfun(mysite = \"Buck Creek\", wy = 2022) + theme(legend.position = \"none\"),\n          hystplotfun(mysite = \"Dugout Creek\", wy = 2022) + theme(legend.position = \"none\"),\n          hystplotfun(mysite = \"EF Duck Creek be HF\", wy = 2022) + theme(legend.position = \"none\"),\n          get_legend(hystplotfun(mysite = \"EF Duck Creek be HF\", wy = 2022)),\n          \n          nrow = 4, ncol = 4) %&gt;%\n  annotate_figure(left = text_grob(\"log(Yield, mm) at headwater gage\", rot = 90),\n                  bottom = text_grob(\"log(Yield, mm) at reference gage\"))\n\n\n\n\n\n\n\n\n\nWhat if we just consider the summer (low flow) period, July - September? In some ways, we see an opposite pattern relative to that describe above. In that we see greater hysteretic behavior in rain-dominated basins (driven by frequent summer storms and lagged runoff response) and less hysteretic behavior in snow-dominated basins, as all streams are in recession from the spring snowmelt peak. However, in general, we see greater divergence from a 1:1 relationship in snowmelt vs rain-dominated basins.\n\n\nCode\nggarrange(hystplotfunlin(mysite = \"West Brook NWIS\", wy = 2021, months = c(7:9)) + theme(legend.position = \"none\"),\n          hystplotfunlin(mysite = \"Jimmy Brook\", wy = 2021, months = c(7:9)) + theme(legend.position = \"none\"),\n          hystplotfunlin(mysite = \"Sanderson Brook\", wy = 2021, months = c(7:9)) + theme(legend.position = \"none\"),\n          hystplotfunlin(mysite = \"Avery Brook\", wy = 2021, months = c(7:9)) + theme(legend.position = \"none\"),\n          \n          hystplotfunlin(mysite = \"Staunton River 10\", wy = 2021, months = c(7:9)) + theme(legend.position = \"none\"),\n          hystplotfunlin(mysite = \"Staunton River 06\", wy = 2021, months = c(7:9)) + theme(legend.position = \"none\"),\n          hystplotfunlin(mysite = \"Staunton River 03\", wy = 2021, months = c(7:9)) + theme(legend.position = \"none\"),\n          hystplotfunlin(mysite = \"Staunton River 02\", wy = 2021, months = c(7:9)) + theme(legend.position = \"none\"),\n          \n          hystplotfunlin(mysite = \"Big Creek NWIS\", wy = 2020, months = c(7:9)) + theme(legend.position = \"none\"),\n          hystplotfunlin(mysite = \"WernerCreek\", wy = 2020, months = c(7:9)) + theme(legend.position = \"none\"),\n          hystplotfunlin(mysite = \"CycloneCreekUpper\", wy = 2020, months = c(7:9)) + theme(legend.position = \"none\"),\n          hystplotfunlin(mysite = \"McGeeCreekTrib\", wy = 2020, months = c(7:9)) + theme(legend.position = \"none\"),\n          \n          hystplotfunlin(mysite = \"Buck Creek\", wy = 2022, months = c(7:9)) + theme(legend.position = \"none\"),\n          hystplotfunlin(mysite = \"Dugout Creek\", wy = 2022, months = c(7:9)) + theme(legend.position = \"none\"),\n          hystplotfunlin(mysite = \"EF Duck Creek be HF\", wy = 2022, months = c(7:9)) + theme(legend.position = \"none\"),\n          get_legend(hystplotfunlin(mysite = \"EF Duck Creek be HF\", wy = 2022, months = c(7:9))),\n          \n          nrow = 4, ncol = 4) %&gt;%\n  annotate_figure(left = text_grob(\"log(Yield, mm) at headwater gage\", rot = 90),\n                  bottom = text_grob(\"log(Yield, mm) at reference gage\"))\n\n\n\n\n\n\n\n\n\n\n13.3.1 Interactive\n\n13.3.1.1 West Brook\n\nWB NWISJimmySandersonAvery\n\n\n\n\nCode\nggplotly(hystplotfun(mysite = \"West Brook NWIS\", wy = 2021))\n\n\n\n\n\n\n\n\n\n\nCode\nggplotly(hystplotfun(mysite = \"Jimmy Brook\", wy = 2021))\n\n\n\n\n\n\n\n\n\n\nCode\nggplotly(hystplotfun(mysite = \"Sanderson Brook\", wy = 2021))\n\n\n\n\n\n\n\n\n\n\nCode\nggplotly(hystplotfun(mysite = \"Avery Brook\", wy = 2021))\n\n\n\n\n\n\n\n\n\n\n\n13.3.1.2 Staunton River\n\nSR 10SR 06SR 03SR 02\n\n\n\n\nCode\nggplotly(hystplotfun(mysite = \"Staunton River 10\", wy = 2021))\n\n\n\n\n\n\n\n\n\n\nCode\nggplotly(hystplotfun(mysite = \"Staunton River 06\", wy = 2021))\n\n\n\n\n\n\n\n\n\n\nCode\nggplotly(hystplotfun(mysite = \"Staunton River 03\", wy = 2021))\n\n\n\n\n\n\n\n\n\n\nCode\nggplotly(hystplotfun(mysite = \"Staunton River 02\", wy = 2021))\n\n\n\n\n\n\n\n\n\n\n\n13.3.1.3 Flathead\n\nBig Creek NWISWernerCyclone UpperMcGee Trib\n\n\n\n\nCode\nggplotly(hystplotfun(mysite = \"Big Creek NWIS\", wy = 2020))\n\n\n\n\n\n\n\n\n\n\nCode\nggplotly(hystplotfun(mysite = \"WernerCreek\", wy = 2020))\n\n\n\n\n\n\n\n\n\n\nCode\nggplotly(hystplotfun(mysite = \"CycloneCreekUpper\", wy = 2020))\n\n\n\n\n\n\n\n\n\n\nCode\nggplotly(hystplotfun(mysite = \"McGeeCreekTrib\", wy = 2020))\n\n\n\n\n\n\n\n\n\n\n\n13.3.1.4 Yellowstone\n\nBuckDugoutDuck be HF\n\n\n\n\nCode\nggplotly(hystplotfun(mysite = \"Buck Creek\", wy = 2022))\n\n\n\n\n\n\n\n\n\n\nCode\nggplotly(hystplotfun(mysite = \"Dugout Creek\", wy = 2022))\n\n\n\n\n\n\n\n\n\n\nCode\nggplotly(hystplotfun(mysite = \"EF Duck Creek be HF\", wy = 2022))",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Objective 2</span>"
    ]
  },
  {
    "objectID": "Qualitative/Hysteresis.html#frequency-and-magnitude",
    "href": "Qualitative/Hysteresis.html#frequency-and-magnitude",
    "title": "13  Objective 2",
    "section": "13.4 Frequency and magnitude",
    "text": "13.4 Frequency and magnitude\nCalculate index of hystereis for each event and characterize size-years according the frequency of events and magnitude of hysteretic effects.\nConduct baseflow extraction, event delineation, and calculate event-specific hysteresis index using dynamic time warping (Xue et al. 2024).\n\n\nCode\n# set baseflow extraction and event delineation parameters\nalp &lt;- 0.95\nnumpass &lt;- 3\nthresh &lt;- 0.75\n\n# empty list to story site-year data\nhysteresis_list &lt;- list()\n\nfor (j in 1:nrow(mysiteyrs)) {\n  # filter data by site name and water year\n  dd &lt;- dat_clean_hyst %&gt;% filter(site_name == mysiteyrs$site_name[j], WaterYear == mysiteyrs$WaterYear[j])\n  \n  # baseflow extraction on big G yield\n  dd &lt;- dd %&gt;% \n    filter(!is.na(Yield_mm_big)) %&gt;% \n    mutate(bf = baseflowB(Yield_mm_big, alpha = alp, passes = numpass)$bf, \n           bfi = baseflowB(Yield_mm_big, alpha = alp, passes = numpass)$bfi) %&gt;%\n    ungroup()\n  \n  # delineate events\n  events &lt;- eventBaseflow(dd$Yield_mm_big, BFI_Th = thresh, bfi = dd$bfi)\n  events &lt;- events %&gt;% mutate(len = end - srt + 1)\n  \n  #print(\"Done - baseflow extraction and event delineation\")\n  \n  ## Tidy events\n  # define positions of non-events\n  # srt &lt;- c(1)\n  # end &lt;- c(events$srt[1]-1)\n  # for (i in 2:(dim(events)[1])) {\n  #   srt[i] &lt;- events$end[i-1]+1\n  #   end[i] &lt;- events$srt[i]-1\n  # }\n  # nonevents &lt;- data.frame(tibble(srt, end) %&gt;% \n  #                           mutate(len = end - srt) %&gt;% \n  #                           filter(len &gt;= 0) %&gt;% select(-len) %&gt;% \n  #                           add_row(srt = events$end[dim(events)[1]]+1, end = dim(dd)[1])\n  #                        )\n\n  # create vectors of binary event/non-event and event IDs\n  isevent_vec &lt;- rep(2, times = dim(dd)[1])\n  eventid_vec &lt;- rep(NA, times = dim(dd)[1])\n  for (i in 1:dim(events)[1]) { \n    isevent_vec[c(events[i,1]:events[i,2])] &lt;- 1 \n    eventid_vec[c(events[i,1]:events[i,2])] &lt;- i\n  }\n\n  # # create vector of non-event IDs\n  # noneventid_vec &lt;- rep(NA, times = dim(dd)[1])\n  # for (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n  # \n  # # create vector of \"agnostic events\": combined hydro events and non-events\n  # agnevents &lt;- rbind(events %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\n  # agneventid_vec &lt;- c()\n  # for (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n  # add event/non-event vectors to Big G data\n  dd &lt;- dd %&gt;% \n    mutate(isevent = isevent_vec, \n           eventid = eventid_vec,\n           #noneventid = noneventid_vec,\n           #agneventid = agneventid_vec,\n           big_event_yield = ifelse(isevent_vec == 1, Yield_mm_big, NA),\n           big_nonevent_yield = ifelse(isevent_vec == 2, Yield_mm_big, NA),\n           big_event_quick = big_event_yield - bf) %&gt;%\n    rename(big_bf = bf, big_bfi = bfi)\n  \n  #print(\"Done - tidy events\")\n  \n  # calculate hysteresis index for each event using dynamic time warping\n  event_list &lt;- list()\n  for (i in 1:max(dd$eventid, na.rm = TRUE)) {\n    # filter by each event and normalized big and little Yield\n    ddd &lt;- dd %&gt;% filter(eventid == i, !is.na(logYield), !is.na(logYield_big))\n    dddd &lt;- dd %&gt;% filter(date %in% c(min(ddd$date)-1, max(ddd$date)+1))\n    ddd &lt;- ddd %&gt;% \n      bind_rows(dddd) %&gt;% \n      arrange(date) %&gt;% \n      mutate(weight = (logYield_big - min(logYield_big)) / (max(logYield_big) - min(logYield_big)),\n             yield_little_norm = (logYield - min(logYield)) / (max(logYield) - min(logYield)),\n             yield_big_norm = (logYield_big - min(logYield_big)) / (max(logYield_big) - min(logYield_big)))\n    # ddd %&gt;%\n    #   ggplot(aes(x = yield_big_norm, y = yield_little_norm, color = date)) +\n    #   geom_segment(aes(xend = c(tail(yield_big_norm, n = -1), NA), yend = c(tail(yield_little_norm, n = -1), NA)), \n    #                arrow = arrow(length = unit(0.2, \"cm\")), color = \"black\") +\n    #   geom_point() + \n    #   geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n    #   scale_color_gradientn(colors = cet_pal(250, name = \"r1\"), trans = \"date\") +\n    #   theme_bw() + \n    #   theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  \n    # align data using dynamic time warping, allow for error handling (e.g., skips if either big or little g is constant during event, b/c normalization returns NaN)\n    skip_to_next &lt;- FALSE\n    tryCatch(align &lt;- dtw(x = unlist(ddd %&gt;% select(yield_big_norm)), y = unlist(ddd %&gt;% select(yield_little_norm)), step = asymmetric, keep = TRUE), error = function(e) { skip_to_next &lt;&lt;- TRUE })\n    if(skip_to_next) { next }\n    #align &lt;- dtw(x = unlist(ddd %&gt;% select(yield_big_norm)), y = unlist(ddd %&gt;% select(yield_little_norm)), step = asymmetric, keep = TRUE)\n    # plot(align, type = \"threeway\")\n    # plot(align, type = \"twoway\", offset = -1)\n  \n    # find time-warped distance, S_i in Xue et al. (2024)\n    ddd &lt;- ddd %&gt;% mutate(distance = align$index1 - align$index2)\n    # ddd %&gt;% \n    #   ggplot(aes(x = date, y = distance*weight)) + \n    #   geom_bar(stat = \"identity\") +\n    #   theme_bw()\n  \n    # summarize event\n    event_list[[i]] &lt;- ddd %&gt;% \n      group_by(site_name, basin, subbasin, region, WaterYear) %&gt;%\n      summarize(eventdays = n(),\n                eventid = i,\n                mindate = min(date),\n                maxdate = max(date),\n                totalyieldevent_little = sum(Yield_mm),\n                totalyieldevent_big = sum(Yield_mm_big),\n                hysteresis = sum(ddd$weight * ddd$distance) / sum(ddd$weight) # hysteresis index as in Xue et al (2024)\n                ) %&gt;%\n      ungroup()\n  }\n  #print(\"Done - dynamic time warping\")\n  hysteresis_list[[j]] &lt;- do.call(bind_rows, event_list)\n  print(j)\n}\n\n# bind to tibble\nhysteresis &lt;- do.call(bind_rows, hysteresis_list) %&gt;% \n  left_join(mysiteyrs %&gt;% select(site_name, basin, subbasin, region, WaterYear, numdays, totalyield_site)) %&gt;%\n  mutate(propyield = totalyieldevent_little / totalyield_site)\n\n# write to file\nwrite_csv(hysteresis, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/hysteresis.csv\")\n\n\nLoad hysteresis file\n\n\nCode\nhysteresis &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/hysteresis.csv\")\n# hysteresis &lt;- hysteresis %&gt;% \n#   group_by(subbasin, WaterYear) %&gt;%\n#   mutate(eventid = as.numeric(as.factor(mindate))) %&gt;%\n#   ungroup()\n\n\n\n13.4.1 Visualize hysteresis\nDistribution of hystersis index by subbasin\n\n\nCode\nhysteresis %&gt;%\n  ggplot(aes(x = subbasin, y = hysteresis, fill = subbasin)) + \n  geom_boxplot(outlier.shape = NA) + \n  geom_jitter(height = 0, width = 0.25, alpha = 0.2) +\n  xlab(\"Sub-basin\") + ylab(\"Xue hysteresis index\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n        axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 0.4))\n\n\n\n\n\n\n\n\n\nMagnitude of hysteresis by length of event\n\n\nCode\nhysteresis %&gt;%\n  ggplot(aes(x = eventdays, y = abs(hysteresis), color = subbasin)) + \n  geom_point() +\n  xlab(\"Event length (days)\") + ylab(\"Xue hysteresis index (absolute value)\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nMagnitude of hysteresis by length of event, by subbasin and site\n\n\nCode\nhysteresis %&gt;%\n  #filter(eventdays &gt;= 6) %&gt;%\n  ggplot(aes(x = eventdays, y = abs(hysteresis), color = site_name, group = site_name)) + \n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(~subbasin, scales = \"free\") +\n  xlab(\"Event length (days)\") + ylab(\"Xue hysteresis index (absolute value)\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nMagnitude of hysteresis by proportion of annual yield in event\n\n\nCode\nhysteresis %&gt;%\n  ggplot(aes(x = propyield, y = abs(hysteresis), color = subbasin)) + \n  geom_point() +\n  xlab(\"Proportion of annual yield in event\") + ylab(\"Xue hysteresis index (absolute value)\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nMagnitude of hysteresis by proportion of annual yield in event, by subbasin and site\n\n\nCode\nhysteresis %&gt;%\n  ggplot(aes(x = propyield, y = abs(hysteresis), color = site_name, group = site_name)) + \n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(~subbasin, scales = \"free\") +\n  xlab(\"Proportion of annual yield in event\") + ylab(\"Xue hysteresis index (absolute value)\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n13.4.2 Site-year summary\nCharacterize site-years along axes of mean annual event duration/magnitude and magnitude of hysteres.\nSummarize hysteresis by site and year\n\n\nCode\ntemp &lt;- hysteresis %&gt;% \n  group_by(subbasin, site_name, WaterYear) %&gt;% \n  summarize(freq = n(), \n            meanpropyield = mean(propyield),\n            meanhyst = mean(abs(hysteresis))) %&gt;%\n  mutate(logmeanhyst = log(meanhyst)) %&gt;%\n  ungroup() \ntemp\n\n\n# A tibble: 87 × 7\n   subbasin   site_name       WaterYear  freq meanpropyield meanhyst logmeanhyst\n   &lt;chr&gt;      &lt;chr&gt;               &lt;dbl&gt; &lt;int&gt;         &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;\n 1 Big Creek  Big Creek NWIS       2019     2         0.435    2.02       0.703 \n 2 Big Creek  Big Creek NWIS       2020     3         0.294    0.954     -0.0473\n 3 Big Creek  Big Creek NWIS       2021     6         0.143    0.878     -0.130 \n 4 Big Creek  Big Creek NWIS       2022     7         0.134    0.746     -0.294 \n 5 Big Creek  Hallowat Creek…      2020     2         0.465    0.868     -0.141 \n 6 Big Creek  Hallowat Creek…      2022     6         0.162    1.05       0.0452\n 7 Big Creek  NicolaCreek          2019     2         0.284    3.96       1.38  \n 8 Big Creek  WernerCreek          2019     2         0.407    1.84       0.608 \n 9 Big Creek  WernerCreek          2020     4         0.202    1.43       0.358 \n10 Coal Creek CycloneCreekUp…      2019     2         0.436    2.84       1.04  \n# ℹ 77 more rows\n\n\nCharacterize sites/subbasins along axes of event frequency and magnitude (mean annual proportion of flow within event).\n\n\nCode\nhull &lt;- temp %&gt;% group_by(subbasin) %&gt;% slice(chull(freq, meanpropyield))\ntemp %&gt;%\n  ggplot(aes(x = freq, y = meanpropyield)) + \n  #geom_polygon(data = hull, aes(fill = subbasin), alpha = 0.5) +\n  #geom_smooth(color = \"black\", method = \"lm\") +\n  geom_point(aes(color = subbasin)) + \n  xlab(\"Events per year\") + ylab(\"Proportion of annual yield in event (mean over events)\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nPlot the mean annual magnitude (absolute value) of event-specific hysteresis by event frequency (events per year), with LOESS smoothing.\n\n\nCode\np1 &lt;- temp %&gt;%\n  ggplot(aes(x = freq, y = (meanhyst))) + \n  geom_smooth(color = \"black\") +\n  #geom_smooth(color = \"black\", method = \"glm\", formula = y~x, method.args = list(family = gaussian(link = 'log'))) +\n  geom_point(aes(color = subbasin)) + \n  xlab(\"Events per year\") + ylab(\"Mean annual magnitude of hysteresis\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\np2 &lt;- temp %&gt;%\n  ggplot(aes(x = meanpropyield, y = (meanhyst))) + \n  geom_smooth(color = \"black\") +\n  #geom_smooth(color = \"black\", method = \"glm\", formula = y~x, method.args = list(family = gaussian(link = 'log'))) +\n  geom_point(aes(color = subbasin)) + \n  xlab(\"Proportion of annual yield in event\") + ylab(\"Mean annual magnitude of hysteresis\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\nggarrange(p1, p2, nrow = 1, common.legend = TRUE, legend = \"right\")\n\n\n\n\n\n\n\n\n\nSame as above but plot on log scale (magnitude):\n\n\nCode\np1 &lt;- temp %&gt;%\n  ggplot(aes(x = freq, y = logmeanhyst)) + \n  geom_smooth(color = \"black\", method = \"lm\") +\n  geom_point(aes(color = subbasin)) + \n  xlab(\"Events per year\") + ylab(\"(log) Mean annual magnitude of hysteresis\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\np2 &lt;- temp %&gt;%\n  ggplot(aes(x = meanpropyield, y = logmeanhyst)) + \n  geom_smooth(color = \"black\", method = \"lm\") +\n  geom_point(aes(color = subbasin)) + \n  xlab(\"Proportion of annual yield in event\") + ylab(\"(log) Mean annual magnitude of hysteresis\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\nggarrange(p1, p2, nrow = 1, common.legend = TRUE, legend = \"right\")\n\n\n\n\n\n\n\n\n\nReplace regression line with convex hulls\n\n\nCode\nhull &lt;- temp %&gt;% group_by(subbasin) %&gt;% slice(chull(freq, logmeanhyst))\np1 &lt;- temp %&gt;%\n  ggplot(aes(x = freq, y = logmeanhyst)) + \n  geom_polygon(data = hull, aes(fill = subbasin), alpha = 0.4) +\n  geom_point(aes(color = subbasin)) + \n  xlab(\"Events per year\") + ylab(\"(log) Mean annual magnitude of hysteresis\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\nhull &lt;- temp %&gt;% group_by(subbasin) %&gt;% slice(chull(meanpropyield, logmeanhyst))\np2 &lt;- temp %&gt;%\n  ggplot(aes(x = meanpropyield, y = logmeanhyst)) + \n  geom_polygon(data = hull, aes(fill = subbasin), alpha = 0.4) +\n  geom_point(aes(color = subbasin)) + \n  xlab(\"Proportion of annual yield in event\") + ylab(\"(log) Mean annual magnitude of hysteresis\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\nggarrange(p1, p2, nrow = 1, common.legend = TRUE, legend = \"right\")\n\n\n\n\n\n\n\n\n\nAlternatively, plot frequency by magnitude and with point color/size. I don’t think this tells the story as well as the convex hull plots.\n\n\nCode\np1 &lt;- temp %&gt;%\n  ggplot(aes(x = meanpropyield, y = freq)) + \n  # geom_polygon(data = hull, aes(fill = subbasin), alpha = 0.5) +\n  geom_point(aes(color = subbasin, size = logmeanhyst)) + \n  scale_size_continuous(range = c(0.1,5)) +\n  xlab(\"Proportion of annual yield in event\") + ylab(\"Events per year\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\np2 &lt;- temp %&gt;%\n  ggplot(aes(x = meanpropyield, y = freq)) + \n  # geom_polygon(data = hull, aes(fill = subbasin), alpha = 0.5) +\n  geom_point(aes(color = logmeanhyst), size = 2) + \n  xlab(\"Proportion of annual yield in event\") + ylab(\"Events per year\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\nggarrange(p1, p2, nrow = 1)",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Objective 2</span>"
    ]
  },
  {
    "objectID": "Qualitative/Hysteresis.html#single-events",
    "href": "Qualitative/Hysteresis.html#single-events",
    "title": "13  Objective 2",
    "section": "13.5 Single events",
    "text": "13.5 Single events\n\n\nCode\nmycols &lt;- c(brewer.pal(8, \"Dark2\"), \"dodgerblue\", \"darkorchid\")\n\nevents &lt;- hysteresis %&gt;% filter(subbasin == \"Staunton River\", WaterYear == 2020, eventid == 2)\nlength(unique(events$mindate))\n\n\n[1] 1\n\n\nCode\nlength(unique(events$maxdate))\n\n\n[1] 1\n\n\nCode\ndat_clean_hyst %&gt;% \n  filter(subbasin == unique(events$subbasin), \n         date &gt;= unique(events$mindate), \n         date &lt;= unique(events$maxdate)) %&gt;%\n  ggplot(aes(x = logYield_big, y = logYield, group = site_name, color = site_name)) +\n  geom_segment(aes(xend = c(tail(logYield_big, n = -1), NA), yend = c(tail(logYield, n = -1), NA)), \n               arrow = arrow(length = unit(0.2, \"cm\")), color = \"black\") +\n  geom_point() + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #scale_color_gradientn(colors = cet_pal(250, name = \"r1\"), trans = \"date\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\ndat_clean_hyst %&gt;% \n  filter(subbasin == unique(events$subbasin), \n         date &gt;= unique(events$mindate), \n         date &lt;= unique(events$maxdate)) %&gt;%\n  ggplot(aes(x = logYield_big, y = logYield, group = site_name, color = site_name)) +\n  geom_segment(aes(xend = c(tail(logYield_big, n = -1), NA), yend = c(tail(logYield, n = -1), NA)), \n               arrow = arrow(length = unit(0.2, \"cm\")), color = \"black\") +\n  geom_point() + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #scale_color_gradientn(colors = cet_pal(250, name = \"r1\"), trans = \"date\") +\n  facet_wrap(~site_name) +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Objective 2</span>"
    ]
  },
  {
    "objectID": "Qualitative/Hysteresis.html#test-pit",
    "href": "Qualitative/Hysteresis.html#test-pit",
    "title": "13  Objective 2",
    "section": "13.6 Test pit",
    "text": "13.6 Test pit\nConduct baseflow separation, event delineation, and dynamic time warping as above, but only for a single site year. For troubleshooting and data visualization\nSet parameters and site-year\n\n\nCode\nalp &lt;- 0.95\nnumpass &lt;- 3\nthresh &lt;- 0.75\ndd &lt;- dat_clean_hyst %&gt;% filter(site_name == \"McGeeCreekLower\", WaterYear == 2019)\n\n\nbaseflow separation\n\n\nCode\ndd &lt;- dd %&gt;% \n  filter(!is.na(Yield_mm_big)) %&gt;% \n  mutate(bf = baseflowB(Yield_mm_big, alpha = alp, passes = numpass)$bf, \n         bfi = baseflowB(Yield_mm_big, alpha = alp, passes = numpass)$bfi) %&gt;%\n  ungroup()\nhead(dd)\n\n\nEvent delineation\n\n\nCode\nevents &lt;- eventBaseflow(dd$Yield_mm_big, BFI_Th = thresh, bfi = dd$bfi)\nevents &lt;- events %&gt;% mutate(len = end - srt + 1)\n(events)\n\n\nTidy events: now add variables to the Big G time series data specifying events and non-events\n\n\nCode\n# define positions of non-events\nsrt &lt;- c(1)\nend &lt;- c(events$srt[1]-1)\nfor (i in 2:(dim(events)[1])) {\n  srt[i] &lt;- events$end[i-1]+1\n  end[i] &lt;- events$srt[i]-1\n}\nnonevents &lt;- data.frame(tibble(srt, end) %&gt;% mutate(len = end - srt) %&gt;% filter(len &gt;= 0) %&gt;% select(-len) %&gt;% add_row(srt = events$end[dim(events)[1]]+1, end = dim(dd)[1]))\n\n# create vectors of binary event/non-event and event IDs\nisevent_vec &lt;- rep(2, times = dim(dd)[1])\neventid_vec &lt;- rep(NA, times = dim(dd)[1])\nfor (i in 1:dim(events)[1]) { \n  isevent_vec[c(events[i,1]:events[i,2])] &lt;- 1 \n  eventid_vec[c(events[i,1]:events[i,2])] &lt;- i\n}\n\n# create vector of non-event IDs\nnoneventid_vec &lt;- rep(NA, times = dim(dd)[1])\nfor (i in 1:dim(nonevents)[1]) { noneventid_vec[c(nonevents[i,1]:nonevents[i,2])] &lt;- i }\n\n# create vector of \"agnostic events\": combined hydro events and non-events\nagnevents &lt;- rbind(events %&gt;% select(srt, end) %&gt;% mutate(event = 1), nonevents %&gt;% mutate(event = 0)) %&gt;% arrange((srt))\nagneventid_vec &lt;- c()\nfor (i in 1:dim(agnevents)[1]){ agneventid_vec[c(agnevents[i,1]:agnevents[i,2])] &lt;- i }\n\n# add event/non-event vectors to Big G data\ndd &lt;- dd %&gt;% \n  mutate(isevent = isevent_vec, \n         eventid = eventid_vec,\n         noneventid = noneventid_vec,\n         agneventid = agneventid_vec,\n         big_event_yield = ifelse(isevent_vec == 1, Yield_mm_big, NA),\n         big_nonevent_yield = ifelse(isevent_vec == 2, Yield_mm_big, NA),\n         big_event_quick = big_event_yield - bf) %&gt;%\n  rename(big_bf = bf, big_bfi = bfi)\n(dd)\n\n\nView time series data with Big G event delineation\n\n\nCode\ndd %&gt;% select(date, Yield_mm_big, Yield_mm, big_event_yield, big_nonevent_yield) %&gt;% dygraph() %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") %&gt;% dyOptions(fillGraph = TRUE, drawGrid = FALSE, axisLineWidth = 1.5)\n\n\nView hysteresis loops: g~G\n\n\nCode\ndd %&gt;%\n  filter(isevent == 1) %&gt;%\n  ggplot(aes(x = logYield_big, y = logYield, color = date)) +\n  geom_segment(aes(xend = c(tail(logYield_big, n = -1), NA), yend = c(tail(logYield, n = -1), NA)), \n               arrow = arrow(length = unit(0.2, \"cm\")), color = \"black\") +\n  geom_point() + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  scale_color_gradientn(colors = cet_pal(250, name = \"r1\"), trans = \"date\") + \n  facet_wrap(~eventid) +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\nSelect and view specific event and normalize data\n\n\nCode\nddd &lt;- dd %&gt;% filter(eventid == 1, !is.na(logYield), !is.na(logYield_big))\ndddd &lt;- dd %&gt;% filter(date %in% c(min(ddd$date)-1, max(ddd$date)+1))\nddd &lt;- ddd %&gt;% \n  bind_rows(dddd) %&gt;% \n  arrange(date) %&gt;% \n  mutate(weight = (logYield_big - min(logYield_big, na.rm = TRUE)) / (max(logYield_big, na.rm = TRUE) - min(logYield_big, na.rm = TRUE)),\n         yield_little_norm = (logYield - min(logYield, na.rm = TRUE)) / (max(logYield, na.rm = TRUE) - min(logYield, na.rm = TRUE)),\n         yield_big_norm = (logYield_big - min(logYield_big, na.rm = TRUE)) / (max(logYield_big, na.rm = TRUE) - min(logYield_big, na.rm = TRUE)))\n\nddd %&gt;%\n  ggplot(aes(x = yield_big_norm, y = yield_little_norm, color = date)) +\n  geom_segment(aes(xend = c(tail(yield_big_norm, n = -1), NA), yend = c(tail(yield_little_norm, n = -1), NA)), \n               arrow = arrow(length = unit(0.2, \"cm\")), color = \"black\") +\n  geom_point() + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  scale_color_gradientn(colors = cet_pal(250, name = \"r1\"), trans = \"date\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\nAlign data using dynamic time warping\n\n\nCode\nalign &lt;- dtw(x = unlist(ddd %&gt;% select(yield_big_norm)), y = unlist(ddd %&gt;% select(yield_little_norm)), step = asymmetric, keep = TRUE)\n# align &lt;- dtw(x = unlist(ddd %&gt;% select(Yield_mm_big)), y = unlist(ddd %&gt;% select(Yield_mm)), step = asymmetric, keep = TRUE)\nplot(align, type = \"threeway\")\nplot(align, type = \"twoway\", offset = -1)\n\n\nCalculate hysteresis index as in Xue et al (2024)\n\n\nCode\nddd &lt;- ddd %&gt;% mutate(distance = align$index1 - align$index2)\nddd %&gt;% \n  ggplot(aes(x = date, y = distance*weight)) + \n  geom_bar(stat = \"identity\") +\n  theme_bw()\nsum(ddd$weight * ddd$distance) / sum(ddd$weight)",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Objective 2</span>"
    ]
  },
  {
    "objectID": "Qualitative/ModeledQ.html",
    "href": "Qualitative/ModeledQ.html",
    "title": "14  Objective 3",
    "section": "",
    "text": "14.1 Data\nPurpose: Quantify the suitability of existing modeling techniques for predicting streamflow in headwater systems.\nApproach:\nSite information\nCode\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nLittle g’s\nCode\ndat_clean &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/LittleG_data_clean.csv\")\nBig G’s\nCode\ndat_clean_big &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/BigG_data_clean.csv\")\nClimate\nCode\nclimdf &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/Daymet_climate.csv\")\nclimdf_summ &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/Daymet_climate_summary.csv\")\nWater availability\nCode\nwateravail &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/BigG_wateravailability_annual.csv\")",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Objective 3</span>"
    ]
  },
  {
    "objectID": "Qualitative/ModeledQ.html#stream-stats",
    "href": "Qualitative/ModeledQ.html#stream-stats",
    "title": "14  Objective 3",
    "section": "14.2 Stream Stats",
    "text": "14.2 Stream Stats\nWrite out point shape files for each state to feed into Stream Stats batch processor\n\n\nCode\nsiteinfo_sp_wy &lt;- siteinfo_sp %&gt;% filter(region == \"Snake\")\nst_write(siteinfo_sp_wy, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/points/points_wy.shp\")\n\nsiteinfo_sp_mt &lt;- siteinfo_sp %&gt;% filter(region %in% c(\"Flat\", \"Shields\"))\nst_write(siteinfo_sp_mt, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/points/points_mt.shp\")\n\nsiteinfo_sp_ma &lt;- siteinfo_sp %&gt;% filter(region == \"Mass\")\nst_write(siteinfo_sp_ma, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/points/points_ma.shp\")\n\nsiteinfo_sp_va &lt;- siteinfo_sp %&gt;% filter(region %in% c(\"Shen\"))\nst_write(siteinfo_sp_va, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/points/points_va.shp\")\n\nsiteinfo_sp_or &lt;- siteinfo_sp %&gt;% filter(region %in% c(\"Oreg\"))\nst_write(siteinfo_sp_or, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/points/points_or.shp\")\n\n\nList geodatabase layer names\n\n\nCode\nst_layers(dsn = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/StreamStats/points_mt7617/points_mt7617.gdb\")\n\n\nDriver: OpenFileGDB \nAvailable layers:\n            layer_name geometry_type features fields crs_name\n1 GlobalWatershedPoint         Point       39      8   WGS 84\n2      GlobalWatershed Multi Polygon       39     28   WGS 84\n3      CHARACTERISTICS            NA     1921     11     &lt;NA&gt;\n4            FLOWSTATS            NA     6763     16     &lt;NA&gt;\n\n\nRead watershed boundaries\n\n\nCode\nsheds_montana &lt;- st_read(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/StreamStats/points_mt7617/points_mt7617.gdb\", layer = \"GlobalWatershed\")\n\n\nReading layer `GlobalWatershed' from data source \n  `C:\\Users\\jbaldock\\OneDrive - DOI\\Documents\\USGS\\EcoDrought\\EcoDrought Working\\EcoDrought-Analysis\\CompareModeledQ\\StreamStats\\points_mt7617\\points_mt7617.gdb' \n  using driver `OpenFileGDB'\nSimple feature collection with 39 features and 28 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -114.8904 ymin: 43.9457 xmax: -109.7226 ymax: 49.46148\nGeodetic CRS:  WGS 84\n\n\nCode\nsheds_massach &lt;- st_read(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/StreamStats/points_ma7625/points_ma7625.gdb\", layer = \"GlobalWatershed\")\n\n\nReading layer `GlobalWatershed' from data source \n  `C:\\Users\\jbaldock\\OneDrive - DOI\\Documents\\USGS\\EcoDrought\\EcoDrought Working\\EcoDrought-Analysis\\CompareModeledQ\\StreamStats\\points_ma7625\\points_ma7625.gdb' \n  using driver `OpenFileGDB'\nSimple feature collection with 13 features and 25 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -72.82306 ymin: 42.4123 xmax: -72.62871 ymax: 42.54973\nGeodetic CRS:  WGS 84\n\n\nCode\nsheds_oregon &lt;- st_read(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/StreamStats/points_or7626/points_or7626.gdb\", layer = \"GlobalWatershed\")\n\n\nReading layer `GlobalWatershed' from data source \n  `C:\\Users\\jbaldock\\OneDrive - DOI\\Documents\\USGS\\EcoDrought\\EcoDrought Working\\EcoDrought-Analysis\\CompareModeledQ\\StreamStats\\points_or7626\\points_or7626.gdb' \n  using driver `OpenFileGDB'\nSimple feature collection with 7 features and 41 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -118.9295 ymin: 42.48917 xmax: -118.561 ymax: 42.79204\nGeodetic CRS:  WGS 84\n\n\nCode\nsheds_virginia &lt;- st_read(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/StreamStats/points_va7627/points_va7627.gdb\", layer = \"GlobalWatershed\")\n\n\nReading layer `GlobalWatershed' from data source \n  `C:\\Users\\jbaldock\\OneDrive - DOI\\Documents\\USGS\\EcoDrought\\EcoDrought Working\\EcoDrought-Analysis\\CompareModeledQ\\StreamStats\\points_va7627\\points_va7627.gdb' \n  using driver `OpenFileGDB'\nSimple feature collection with 32 features and 20 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -79.24034 ymin: 37.88165 xmax: -78.02949 ymax: 38.7622\nGeodetic CRS:  WGS 84\n\n\nCode\nsheds_wyoming &lt;- st_read(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/StreamStats/points_wy7628/points_wy7628.gdb\", layer = \"GlobalWatershed\")\n\n\nReading layer `GlobalWatershed' from data source \n  `C:\\Users\\jbaldock\\OneDrive - DOI\\Documents\\USGS\\EcoDrought\\EcoDrought Working\\EcoDrought-Analysis\\CompareModeledQ\\StreamStats\\points_wy7628\\points_wy7628.gdb' \n  using driver `OpenFileGDB'\nSimple feature collection with 14 features and 17 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -110.5241 ymin: 43.64373 xmax: -110.1598 ymax: 43.87029\nGeodetic CRS:  WGS 84\n\n\nCode\nsheds &lt;- bind_rows(sheds_massach, sheds_montana, sheds_oregon, sheds_virginia, sheds_wyoming)\nmapview(sheds) \n\n\n\n\n\n\nFind sites that were delineated incorrectly\n\n\nCode\noptions(scipen=999)\nbadsites &lt;- tibble(sheds) %&gt;% select(Name, Shape_Area, DRNAREA, ELEV) %&gt;% rename(site_id = Name) %&gt;% left_join(siteinfo %&gt;% select(site_id, site_name, area_sqmi, elev_ft)) %&gt;% select(site_id, site_name, DRNAREA, area_sqmi) %&gt;% mutate(percerror = (DRNAREA - area_sqmi) / area_sqmi) %&gt;% filter(percerror &gt;= 0.15 | percerror &lt;= -0.15)\nbadsites\n\n\n# A tibble: 15 × 5\n   site_id site_name                      DRNAREA area_sqmi percerror\n   &lt;chr&gt;   &lt;chr&gt;                            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 WW      West Whately Brook           0.0399        0.493    -0.919\n 2 WL      West Brook Lower             0.086         8.51     -0.990\n 3 JB      Jimmy Brook                  7.87          0.974     7.08 \n 4 SH08    Shields River ab Dugout     11.1           8.68      0.279\n 5 SH06    Lodgepole Creek              2.2           1.36      0.619\n 6 SH05    Dugout Creek                11.1           2.39      3.64 \n 7 BIG_002 LangfordCreekLower           0.1           3.99     -0.975\n 8 RAP     Rapidan River NWIS           0.0000386   115        -1.00 \n 9 PI_09FL Piney River 09               0.36          4.28     -0.916\n10 LEI     Leidy Creek Mouth NWIS       0.000811      5.17     -1.00 \n11 PCM     Pacific Creek at Moran NWIS  0.34        166.       -0.998\n12 SP10    SF Spread Creek Upper        0.000348     35.1      -1.00 \n13 SP09    SF Spread Creek Lower       72            44.3       0.627\n14 SP08    Rock Creek                   0.0000772     4.74     -1.00 \n15 SP03    Leidy Creek Lower            0.00112       5.17     -1.00 \n\n\nStream stats site information\n\n\nCode\nstreamstats_info &lt;- tibble(sheds) %&gt;% select(Name, DRNAREA) %&gt;% rename(site_id = Name) %&gt;% left_join(siteinfo %&gt;% select(site_id, site_name))\n# streamstats_info\n\n\nRead flow statistics from geodatabases\n\n\nCode\nmontana &lt;- st_read(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/StreamStats/points_mt7617/points_mt7617.gdb\", layer = \"FLOWSTATS\")\n\n\nReading layer `FLOWSTATS' from data source \n  `C:\\Users\\jbaldock\\OneDrive - DOI\\Documents\\USGS\\EcoDrought\\EcoDrought Working\\EcoDrought-Analysis\\CompareModeledQ\\StreamStats\\points_mt7617\\points_mt7617.gdb' \n  using driver `OpenFileGDB'\n\n\nCode\nmassach &lt;- st_read(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/StreamStats/points_ma7625/points_ma7625.gdb\", layer = \"FLOWSTATS\")\n\n\nReading layer `FLOWSTATS' from data source \n  `C:\\Users\\jbaldock\\OneDrive - DOI\\Documents\\USGS\\EcoDrought\\EcoDrought Working\\EcoDrought-Analysis\\CompareModeledQ\\StreamStats\\points_ma7625\\points_ma7625.gdb' \n  using driver `OpenFileGDB'\n\n\nCode\noregon &lt;- st_read(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/StreamStats/points_or7626/points_or7626.gdb\", layer = \"FLOWSTATS\")\n\n\nReading layer `FLOWSTATS' from data source \n  `C:\\Users\\jbaldock\\OneDrive - DOI\\Documents\\USGS\\EcoDrought\\EcoDrought Working\\EcoDrought-Analysis\\CompareModeledQ\\StreamStats\\points_or7626\\points_or7626.gdb' \n  using driver `OpenFileGDB'\n\n\nCode\nvirginia &lt;- st_read(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/StreamStats/points_va7627/points_va7627.gdb\", layer = \"FLOWSTATS\")\n\n\nReading layer `FLOWSTATS' from data source \n  `C:\\Users\\jbaldock\\OneDrive - DOI\\Documents\\USGS\\EcoDrought\\EcoDrought Working\\EcoDrought-Analysis\\CompareModeledQ\\StreamStats\\points_va7627\\points_va7627.gdb' \n  using driver `OpenFileGDB'\n\n\nCode\nwyoming &lt;- st_read(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/StreamStats/points_wy7628/points_wy7628.gdb\", layer = \"FLOWSTATS\")\n\n\nReading layer `FLOWSTATS' from data source \n  `C:\\Users\\jbaldock\\OneDrive - DOI\\Documents\\USGS\\EcoDrought\\EcoDrought Working\\EcoDrought-Analysis\\CompareModeledQ\\StreamStats\\points_wy7628\\points_wy7628.gdb' \n  using driver `OpenFileGDB'\n\n\nCode\nstreamstats &lt;- bind_rows(montana, massach, oregon, virginia, wyoming) %&gt;% filter(!Name %in% c(badsites$site_id)) %&gt;% rename(site_id = Name) %&gt;% left_join(siteinfo %&gt;% select(site_id, site_name)) %&gt;% left_join(streamstats_info)\nhead(streamstats)\n\n\n  site_id RegionID                             RegionName AreaPercent AreaSqMi\n1     NFF   GC1906                  Crippen_Bue_Region_13          61 947.3549\n2     NFF   GC1828                        USA_Bieger_2015          60 937.1283\n3     NFF   GC1828                        USA_Bieger_2015          60 937.1283\n4     NFF   GC1828                        USA_Bieger_2015          60 937.1283\n5     NFF   GC1818 Northern_Rocky_Mountains_P_Bieger_2015          60 937.1283\n6     NFF   GC1818 Northern_Rocky_Mountains_P_Bieger_2015          60 937.1283\n   StatLabel                                StatName    Value\n1 PKMAX_CB_R      Maximum Flood Crippen Bue Regional 2.46e+05\n2 XABNKF_U_B Bieger_USA_channel_cross_sectional_area 9.05e+02\n3 DBANKF_U_B                Bieger_USA_channel_depth 5.77e+00\n4 WBANKF_U_B                Bieger_USA_channel_width 1.65e+02\n5 XABNKF_P_B   Bieger_P_channel_cross_sectional_area 8.52e+02\n6 DBANKF_P_B                  Bieger_P_channel_depth 5.53e+00\n                  Units Years PIl PIu SE SEp PC CitationID\n1 cubic feet per second    NA  NA  NA NA  NA NA        186\n2           square feet     0  NA  NA NA  NA NA        160\n3                  feet     0  NA  NA NA  NA NA        160\n4                  feet     0  NA  NA NA  NA NA        160\n5           square feet     0  NA  NA NA  NA NA        160\n6                  feet     0  NA  NA NA  NA NA        160\n                       site_name DRNAREA\n1 North Fork Flathead River NWIS  1556.2\n2 North Fork Flathead River NWIS  1556.2\n3 North Fork Flathead River NWIS  1556.2\n4 North Fork Flathead River NWIS  1556.2\n5 North Fork Flathead River NWIS  1556.2\n6 North Fork Flathead River NWIS  1556.2\n\n\nView provided flow statistics for each state. What is relevant to this paper?\n\nMontana: annual & monthly duration (80, 50, 20), monthly mean flow, 7 day 10 year low flow\nMassachusetts: annual duration (99, 98, 95, 90, 85, 80, 75, 70, 60, 50), 7 day 10 and 2 year low flow\nOregon: annual and monthly duration (95, 50, 25, 10, 5), monthly and annual 7 day 10 and 2 year low flow\nVirginia: lots of flow flow stats including 7 day 10 and 2 year low flow\nWyoming: nothing relevant\n\n\n\nCode\nprint(\"MONTANA\")\nunique(montana$StatName)\nprint(\"MASSACHUSETTS\")\nunique(massach$StatName)\nprint(\"OREGON\")\nunique(oregon$StatName)\nprint(\"VIRGINA\")\nunique(virginia$StatName)\nprint(\"WYOMING\")\nunique(wyoming$StatName)\n\n\nAvailability of flow statistics varies greatly by state. What statistics do all states have in common (minus Wyoming)? Only 7 day 10 year low flow is relevant.\n\n\nCode\nReduce(intersect, list(unique(montana$StatName), unique(massach$StatName), unique(oregon$StatName), unique(virginia$StatName)))\n\n\n [1] \"Maximum Flood Crippen Bue Regional\"     \n [2] \"Bieger_USA_channel_cross_sectional_area\"\n [3] \"Bieger_USA_channel_depth\"               \n [4] \"Bieger_USA_channel_width\"               \n [5] \"Bieger_P_channel_cross_sectional_area\"  \n [6] \"Bieger_P_channel_depth\"                 \n [7] \"Bieger_P_channel_width\"                 \n [8] \"Bieger_D_channel_cross_sectional_area\"  \n [9] \"Bieger_D_channel_depth\"                 \n[10] \"Bieger_D_channel_width\"                 \n[11] \"7 Day 10 Year Low Flow\"                 \n\n\n\n14.2.1 West Brook exceedance\nFor the West Brook, plot (annual) observed and StreamStats exceedance/duration curves and calculate absolute error\n\n\nCode\n# set up\nvars &lt;- unique(massach$StatName)[grep(\"Duration\", unique(massach$StatName))][-1]\nsites &lt;- c(\"Avery Brook\", \"Sanderson Brook\", \"Mitchell Brook\", \"Obear Brook Lower\", \"West Brook NWIS\", \"West Brook Upper\")\npreds &lt;- list()\nexceed &lt;- list()\njoined &lt;- list()\njoined_full &lt;- list()\n\n# calcualate \nfor (i in 1:length(sites)) {\n  obs &lt;- dat_clean %&gt;% filter(site_name == sites[i])\n  # stream stats duration\n  p &lt;- streamstats %&gt;% \n    filter(site_name == unique(obs$site_name), StatName %in% vars) %&gt;% \n    mutate(exceedance = parse_number(StatName)) %&gt;% \n    mutate(flow_cms = Value*0.02831683199881, area_sqkm = DRNAREA*2.58999)\n  p &lt;- add_daily_yield(data = p %&gt;% select(site_id, site_name, DRNAREA, area_sqkm, StatName, exceedance, flow_cms), values = flow_cms, basin_area = as.numeric(unique(p$area_sqkm)))\n  p &lt;- p %&gt;% mutate(logYield = log(Yield_mm))\n  preds[[i]] &lt;- p\n  # calculate exceedance probability by site\n  exceeddat &lt;- obs %&gt;% \n    filter(!is.na(logYield)) %&gt;%\n    arrange(desc(logYield)) %&gt;%\n    mutate(exceedance = 100/length(logYield)*1:length(logYield))\n  exceed[[i]] &lt;- exceeddat\n  # join observed and streamstats exceedance, calculate error\n  j &lt;- exceeddat %&gt;% \n    select(site_name, exceedance, logYield) %&gt;%\n    mutate(exceedance = round(exceedance, digits = 0)) %&gt;%\n    group_by(site_name, exceedance) %&gt;%\n    summarize(logYield = mean(logYield)) %&gt;%\n    ungroup() %&gt;%\n    left_join(p %&gt;%\n                select(site_name, exceedance, logYield) %&gt;%\n                rename(logYield_ss = logYield)) %&gt;%\n    mutate(error_abs = logYield_ss - logYield,\n           error_abs_real = exp(logYield_ss) - exp(logYield),\n           error_rel = (exp(logYield_ss) - exp(logYield)) / exp(logYield))\n  joined[[i]] &lt;- j %&gt;% filter(!is.na(error_abs))\n  joined_full[[i]] &lt;- j\n}\npreds &lt;- do.call(rbind, preds) \nexceed &lt;- do.call(rbind, exceed)\njoined &lt;- do.call(rbind, joined)\njoined_full &lt;- do.call(rbind, joined_full)\njoined_mean &lt;- joined %&gt;% group_by(exceedance) %&gt;% summarize(error_abs = mean(error_abs, na.rm = TRUE))\n\n# preds &lt;- preds %&gt;% mutate(site_name = factor(site_name, levels = sites))\n# exceed &lt;- exceed %&gt;% mutate(site_name = factor(site_name, levels = sites))\n# joined &lt;- joined %&gt;% mutate(site_name = factor(site_name, levels = sites))\n\n# calculate among size variation for StreamStats and observed exceedance \nvardat_ss &lt;- joined %&gt;% group_by(exceedance) %&gt;% summarize(exdsd = sd(logYield_ss))\nvardat_obs &lt;- joined_full %&gt;% group_by(exceedance) %&gt;% summarize(exdsd = sd(logYield))\n\n# tibble for site labels\nsiteslabs &lt;- tibble(site_name = sites)\n\n\n\nColorNo color\n\n\n\n\nCode\n### Colored by site\n# exceedance curves\np1 &lt;- ggplot() +\n  geom_line(data = exceed, aes(x = exceedance, y = logYield, color = site_name), size = 1) +\n  geom_line(data = preds, aes(x = exceedance, y = logYield), color = \"black\") + \n  geom_point(data = preds, aes(x = exceedance, y = logYield), color = \"black\") +\n  geom_text(data = siteslabs, aes(x = Inf, y = Inf, label = site_name), vjust = 1.5, hjust = 1.05, size = 3) +\n  facet_wrap(~site_name, nrow = 3) +\n  xlab(\"Exceedance probability\") + ylab(\"log(Yield, mm)\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n                     panel.grid = element_blank(), strip.text.x = element_blank(), strip.background = element_blank(),\n                     legend.position = \"none\")\n# absolute error\np2 &lt;- ggplot(data = joined) +\n  geom_line(aes(x = exceedance, y = error_abs, group = site_name, color = site_name)) +\n  geom_point(aes(x = exceedance, y = error_abs, group = site_name, color = site_name)) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  geom_line(data = joined_mean, aes(x = exceedance, y = error_abs), size = 1) +\n  xlab(\"Exceedance probability\") + ylab(\"Absolute error\") + ylim(-2.1,0) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n                     legend.position = \"none\")\n# combine\nannotate_figure(ggarrange(p1, p2, ncol = 2, labels = \"auto\"), top = text_grob(\"The West Brook, Massachusetts\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n### No Color\n# exceedance curves\np1 &lt;- ggplot() +\n  geom_line(data = exceed, aes(x = exceedance, y = logYield), size = 1) +\n  geom_line(data = preds, aes(x = exceedance, y = logYield), color = \"red\") + \n  geom_point(data = preds, aes(x = exceedance, y = logYield), color = \"red\") +\n  geom_text(data = siteslabs, aes(x = Inf, y = Inf, label = site_name), vjust = 1.5, hjust = 1.05, size = 3) +\n  facet_wrap(~site_name, nrow = 3) +\n  xlab(\"Exceedance probability\") + ylab(\"log(Yield, mm)\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n                     panel.grid = element_blank(), strip.text.x = element_blank(), strip.background = element_blank(),\n                     legend.position = \"none\")\n# absolute error\np2 &lt;- ggplot(data = joined) +\n  geom_line(aes(x = exceedance, y = error_abs, group = site_name)) +\n  geom_point(aes(x = exceedance, y = error_abs, group = site_name)) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  geom_line(data = joined_mean, aes(x = exceedance, y = error_abs), size = 1, col = \"red\") +\n  xlab(\"Exceedance probability\") + ylab(\"Absolute error\") + ylim(-2.1,0) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n                     legend.position = \"none\")\n# combine\nannotate_figure(ggarrange(p1, p2, ncol = 2, labels = \"auto\"), top = text_grob(\"The West Brook, Massachusetts\"))\n\n\n\n\n\n\n\n\n\n\n\n\nDoes StreamStats misrepresent among-site variation in flow duration?\n\n\nCode\np1 &lt;- ggplot() +\n  geom_line(data = vardat_obs, aes(x = exceedance, y = exdsd), size = 1, color = \"grey60\") +\n  geom_line(data = vardat_ss, aes(x = exceedance, y = exdsd), color = \"black\") + \n  geom_point(data = vardat_ss, aes(x = exceedance, y = exdsd), color = \"black\") +\n  xlab(\"Exceedance probability\") + ylab(\"Among-site standard deviation in log(Yield, mm)\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\np2 &lt;- vardat_obs %&gt;% \n  left_join(vardat_ss %&gt;% rename(exdsd_ss = exdsd)) %&gt;% \n  mutate(diff = exdsd_ss - exdsd) %&gt;%\n  filter(!is.na(diff)) %&gt;%\n  ggplot() +\n  geom_line(aes(x = exceedance, y = diff)) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  xlab(\"Exceedance probability\") + ylab(\"Difference\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) \n\nannotate_figure(ggarrange(p1, p2, ncol = 2, labels = \"auto\"), top = text_grob(\"The West Brook, Massachusetts\"))\n\n\n\n\n\n\n\n\n\n\n\n14.2.2 Flathead mean monthly yield\nFor the Flathead (Big Creek), plot observed and StreamStats mean monthly flow/yield and calculate absolute error\n\n\nCode\n# set up\nvars &lt;- unique(montana$StatName)[grep(\"Mean Flow\", unique(montana$StatName))]\nsites &lt;- c(\"Hallowat Creek NWIS\", \"HallowattCreekLower\", \"WernerCreek\", \"LangfordCreekUpper\", \"Big Creek NWIS\", \"McGeeCreekLower\")\npreds_list &lt;- list()\nobs_list &lt;- list()\nhull_list &lt;- list()\njoin_list &lt;- list()\n\n# calcualate \nfor (i in 1:length(sites)) {\n  # filter observed data\n  obs &lt;- dat_clean %&gt;% \n  filter(site_name == sites[i]) %&gt;%\n    mutate(MonthName = factor(MonthName, levels = c(\"Oct\", \"Nov\", \"Dec\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\")))\n  # calculate monthly means\n  obs_mon &lt;- obs %&gt;%\n    group_by(site_name, WaterYear, MonthName) %&gt;%\n    summarize(logYield = mean(logYield)) %&gt;%\n    ungroup() %&gt;%\n    mutate(MonthName = factor(MonthName, levels = c(\"Oct\", \"Nov\", \"Dec\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\")),\n           WaterYear = factor(WaterYear)) %&gt;% \n    complete(site_name, WaterYear, MonthName)\n  # get monthly min/max for ribbon\n  hull &lt;- obs_mon %&gt;% \n    group_by(site_name, MonthName) %&gt;% \n    summarize(min_logYield = min(logYield, na.rm = TRUE), max_logYield = max(logYield, na.rm = TRUE)) %&gt;% \n    ungroup()\n  # get StreamStats mean monthly flow\n  preds &lt;- streamstats %&gt;% \n    filter(site_name == sites[i], StatName %in% vars, !is.na(AreaSqMi)) %&gt;% \n    mutate(MonthName = substr(StatName, 1, nchar(StatName)-10),\n           Month = parse_number(StatLabel)) %&gt;% \n    mutate(MonthName = factor(recode(MonthName, \"January\" = \"Jan\", \"February\" = \"Feb\", \"March\" = \"Mar\", \"April\" = \"Apr\", \"June\" = \"Jun\", \"July\" = \"Jul\", \"August\" = \"Aug\", \"September\" = \"Sep\", \"October\" = \"Oct\", \"November\" = \"Nov\", \"December\" = \"Dec\"), levels = c(\"Oct\", \"Nov\", \"Dec\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\"))) %&gt;%\n    mutate(flow_cms = Value*0.02831683199881, area_sqkm = AreaSqMi*2.58999)\n  preds &lt;- add_daily_yield(data = preds %&gt;% select(site_id, site_name, area_sqkm, MonthName, Month, flow_cms), values = flow_cms, basin_area = as.numeric(unique(preds$area_sqkm)))\n  preds &lt;- preds %&gt;% mutate(logYield = log(Yield_mm))\n  # join and calculate error\n  join_list[[i]] &lt;- obs_mon %&gt;%\n    left_join(preds %&gt;% select(site_name, MonthName, logYield) %&gt;% rename(logYield_ss = logYield)) %&gt;%\n    mutate(error_abs = logYield_ss - logYield,\n           error_abs_real = exp(logYield_ss) - exp(logYield),\n           error_rel = (exp(logYield_ss) - exp(logYield)) / exp(logYield))\n  # store in list\n  preds_list[[i]] &lt;- preds\n  obs_list[[i]] &lt;- obs_mon\n  hull_list[[i]] &lt;- hull\n}\npreds &lt;- do.call(rbind, preds_list) \nobs_mon &lt;- do.call(rbind, obs_list)\nhull &lt;- do.call(rbind, hull_list)\njoined &lt;- do.call(rbind, join_list)\njoined_mean &lt;- joined %&gt;% group_by(MonthName) %&gt;% summarise(error_abs = mean(error_abs, na.rm = TRUE))\n\n# tibble for site labels\nsiteslabs &lt;- tibble(site_name = sites, site_lab = c(\"Hallowatt Upper\", \"Hallowatt Lower\", \"Werner\", \"Langford Upper\", \"Big NWIS\", \"McGee Lower\"))\n\n# calculate among site variation for StreamStats and observed mean monthly flow (mean across years) \nvardat &lt;- preds %&gt;% \n  group_by(MonthName) %&gt;% \n  summarize(qsd_ss = sd(logYield)) %&gt;%\n  ungroup() %&gt;%\n  left_join(obs_mon %&gt;% \n  group_by(site_name, MonthName) %&gt;% \n  summarize(logYield = mean(logYield, na.rm = TRUE)) %&gt;% \n  ungroup() %&gt;% \n  group_by(MonthName) %&gt;%\n  summarize(qsd_obs = sd(logYield)) %&gt;%\n  ungroup()) %&gt;%\n  mutate(diff = qsd_ss - qsd_obs, nummon = as.numeric(MonthName))\n\n\n\nColorNo color\n\n\n\n\nCode\n### Colored by site\n# observed and StreamStats monthly flow\np1 &lt;- ggplot() +\n  geom_ribbon(data = hull, aes(ymin = min_logYield, ymax = max_logYield, x = as.numeric(MonthName), fill = site_name), alpha = 0.3) +\n  geom_line(data = obs_mon, aes(y = logYield, x = as.numeric(MonthName), group = WaterYear, color = site_name)) +\n  geom_point(data = obs_mon, aes(y = logYield, x = as.numeric(MonthName), group = WaterYear, shape = WaterYear, color = site_name)) +\n  geom_line(data = preds, aes(y = logYield, x = as.numeric(MonthName), group = site_name), color = \"black\") +\n  geom_point(data = preds, aes(y = logYield, x = as.numeric(MonthName)), color = \"black\") +\n  geom_text(data = siteslabs, aes(x = -Inf, y = Inf, label = site_lab), vjust = 1.5, hjust = -0.05, size = 3) +\n  facet_wrap(~site_name, ncol = 2) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     strip.text.x = element_blank(), strip.background = element_blank()) +  \n  ylab(\"Monthly mean log(Yield)\") + xlab(\"Month\") +\n  scale_x_continuous(breaks = 1:12, labels = c(\"O\", \"N\", \"D\", \"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\"))\n# absolute error by month\np2 &lt;- ggplot() +\n  geom_line(data = joined, aes(x = as.numeric(MonthName), y = error_abs, shape = WaterYear, color = site_name)) +\n  geom_point(data = joined, aes(x = as.numeric(MonthName), y = error_abs, shape = WaterYear, color = site_name)) +\n  geom_line(data = joined_mean, aes(x = as.numeric(MonthName), y = error_abs), size = 1) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  xlab(\"Month\") + ylab(\"Absolute error\") +\n  scale_x_continuous(breaks = 1:12, labels = c(\"O\", \"N\", \"D\", \"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\")) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n                     legend.position = \"none\")\n# combine\nannotate_figure(ggarrange(p1, p2, ncol = 2, labels = \"auto\"), top = text_grob(\"North Fork Flathead River, Montana\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n### No color\n# observed and StreamStats monthly flow\np1 &lt;- ggplot() +\n  geom_ribbon(data = hull, aes(ymin = min_logYield, ymax = max_logYield, x = as.numeric(MonthName)), fill = \"grey80\") +\n  geom_line(data = obs_mon, aes(y = logYield, x = as.numeric(MonthName), group = WaterYear)) +\n  geom_point(data = obs_mon, aes(y = logYield, x = as.numeric(MonthName), group = WaterYear, shape = WaterYear)) +\n  geom_line(data = preds, aes(y = logYield, x = as.numeric(MonthName), group = site_name), color = \"red\") +\n  geom_point(data = preds, aes(y = logYield, x = as.numeric(MonthName)), color = \"red\") +\n  geom_text(data = siteslabs, aes(x = -Inf, y = Inf, label = site_lab), vjust = 1.5, hjust = -0.05, size = 3) +\n  facet_wrap(~site_name, ncol = 2) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     strip.text.x = element_blank(), strip.background = element_blank()) +  \n  ylab(\"Monthly mean log(Yield)\") + xlab(\"Month\") +\n  scale_x_continuous(breaks = 1:12, labels = c(\"O\", \"N\", \"D\", \"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\"))\n# absolute error by month\np2 &lt;- ggplot() +\n  geom_line(data = joined, aes(x = as.numeric(MonthName), y = error_abs, group = interaction(site_name, WaterYear))) +\n  geom_point(data = joined, aes(x = as.numeric(MonthName), y = error_abs, shape = WaterYear)) +\n  geom_line(data = joined_mean, aes(x = as.numeric(MonthName), y = error_abs), size = 1, col = \"red\") +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  xlab(\"Month\") + ylab(\"Absolute error\") +\n  scale_x_continuous(breaks = 1:12, labels = c(\"O\", \"N\", \"D\", \"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\")) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n                     legend.position = \"none\")\n# combine\nannotate_figure(ggarrange(p1, p2, ncol = 2, labels = \"auto\"), top = text_grob(\"North Fork Flathead River, Montana\"))\n\n\n\n\n\n\n\n\n\n\n\n\nDoes StreamStats misrepresent among-site variation in mean monthly yield?\n\n\nCode\np1 &lt;- vardat %&gt;%\n  ggplot() +\n  geom_line(aes(x = nummon, y = qsd_obs), size = 1, color = \"grey60\") +\n  geom_line(aes(x = nummon, y = qsd_ss), color = \"black\") + \n  geom_point(aes(x = nummon, y = qsd_ss), color = \"black\") +\n  xlab(\"Month\") + ylab(\"Among-site standard deviation in log(Yield, mm)\") +\n  scale_x_continuous(breaks = 1:12, labels = c(\"O\", \"N\", \"D\", \"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\")) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\np2 &lt;- vardat %&gt;%\n  ggplot() +\n  geom_line(aes(x = nummon, y = diff)) + \n  xlab(\"Month\") + ylab(\"Difference\") +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  scale_x_continuous(breaks = 1:12, labels = c(\"O\", \"N\", \"D\", \"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\")) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\nannotate_figure(ggarrange(p1, p2, ncol = 2, labels = \"auto\"), top = text_grob(\"North Fork Flathead River, Montana\"))",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Objective 3</span>"
    ]
  },
  {
    "objectID": "Qualitative/ModeledQ.html#prms",
    "href": "Qualitative/ModeledQ.html#prms",
    "title": "14  Objective 3",
    "section": "14.3 PRMS",
    "text": "14.3 PRMS",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Objective 3</span>"
    ]
  },
  {
    "objectID": "Qualitative/ModeledQ.html#um-climatology",
    "href": "Qualitative/ModeledQ.html#um-climatology",
    "title": "14  Objective 3",
    "section": "14.4 UM Climatology",
    "text": "14.4 UM Climatology\n\n14.4.1 Get predictions\nPull streamflow predictions from Montana Climate Office’s (University of Montana) Streamflow API. The finest spatial resolution of streamflow predictions is HUC-10. This means that all sites within subbasins have the same predicted streamflow. This makes we wonder how relevant/useful these comparisons are, beyond g/G comparisons shown for objective 1.\nGet HUC-10 watershed codes\n\n\nCode\nmyhucs &lt;- c()\nfor (i in 1:dim(siteinfo_sp)[1]) { myhucs[i] &lt;- get_huc(AOI = siteinfo_sp[i,], type = \"huc10\")$huc10 }\nsiteinfo &lt;- siteinfo %&gt;% mutate(huc10 = myhucs)\nmyhucs &lt;- unique(myhucs)\n#length(myhucs)\n\n\nQuery UM Climatology\n\n\nCode\nrequest = httr::GET(\n  # can replace this with /predictions/raw, the only query parameter that isn't shared is aggregations.\n  \"https://data.climate.umt.edu/streamflow-api/predictions/\",\n  query = list(\n    locations = paste(myhucs, collapse = \",\"),\n    date_start = \"2015-01-01\",\n    date_end = \"2025-01-01\",\n    aggregations = \"mean\", \n    as_csv = TRUE,\n    units = \"mm\"\n  )\n)\numpreds &lt;- httr::content(request)\numpreds &lt;- umpreds %&gt;% rename(huc10 = location)\nprint(umpreds)\nwrite_csv(umpreds, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/UM_Climatology_PredictedQ.shp\")\n\n\nLoad UM Climatrology predicted flow data\n\n\nCode\numpreds &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/CompareModeledQ/UM_Climatology_PredictedQ.shp\")\numpreds\n\n\n# A tibble: 58,464 × 5\n   huc10      version  date       metric value\n   &lt;chr&gt;      &lt;chr&gt;    &lt;date&gt;     &lt;chr&gt;  &lt;dbl&gt;\n 1 0108020106 vPUB2025 2015-01-01 mean    2.14\n 2 0108020106 vPUB2025 2015-01-02 mean    1.86\n 3 0108020106 vPUB2025 2015-01-03 mean    1.93\n 4 0108020106 vPUB2025 2015-01-04 mean    4.00\n 5 0108020106 vPUB2025 2015-01-05 mean    4.04\n 6 0108020106 vPUB2025 2015-01-06 mean    3.07\n 7 0108020106 vPUB2025 2015-01-07 mean    2.43\n 8 0108020106 vPUB2025 2015-01-08 mean    2.16\n 9 0108020106 vPUB2025 2015-01-09 mean    2.03\n10 0108020106 vPUB2025 2015-01-10 mean    1.90\n# ℹ 58,454 more rows\n\n\nJoin to observed data\n\n\nCode\ndat_umpred &lt;- dat_clean %&gt;%\n  left_join(siteinfo %&gt;% select(site_name, huc10)) %&gt;%\n  left_join(umpreds %&gt;% select(huc10, date, value)) \n\n\n\n\n14.4.2 View predictions\n\n14.4.2.1 All HUCs\nPlot all time series data\n\n\nCode\numpreds %&gt;% \n  ggplot(aes(x = date, y = value)) + \n  geom_line() +\n  facet_wrap(~huc10, scales = \"free_y\")\n\n\n\n\n\n\n\n\n\n\n\n14.4.2.2 Compare gG\nCompare predicted (red) and observed (black) streamflow data for select sites/basins. For some sites, modeled flow captures the general patterns/shapes of observed hydrographs well, but accuracy is reduced at fine temporal resolutions. For other sites, modeled flow fails to capture both the general and finer resolution asepcts of observed data.\n\nJimmyStaunton 06Hallowatt Creek NWISSF Spread Ck LowerDugout CreekDB ab Indian NWIS\n\n\n\n\nCode\ndat_umpred %&gt;% filter(site_name == \"Jimmy Brook\") %&gt;% select(date, Yield_mm, value) %&gt;% dygraph() %&gt;% dySeries(\"Yield_mm\", color = \"black\") %&gt;% dySeries(\"value\", color = \"red\") %&gt;% dyRangeSelector() %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") \n\n\n\n\n\n\n\n\n\n\nCode\ndat_umpred %&gt;% filter(site_name == \"Staunton River 06\") %&gt;% select(date, Yield_mm, value) %&gt;% dygraph() %&gt;% dySeries(\"Yield_mm\", color = \"black\") %&gt;% dySeries(\"value\", color = \"red\") %&gt;% dyRangeSelector()  %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") \n\n\n\n\n\n\n\n\n\n\nCode\ndat_umpred %&gt;% filter(site_name == \"Hallowat Creek NWIS\") %&gt;% select(date, Yield_mm, value) %&gt;% dygraph() %&gt;% dySeries(\"Yield_mm\", color = \"black\") %&gt;% dySeries(\"value\", color = \"red\") %&gt;% dyRangeSelector()  %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") \n\n\n\n\n\n\n\n\n\n\nCode\ndat_umpred %&gt;% filter(site_name == \"SF Spread Creek Lower\") %&gt;% select(date, Yield_mm, value) %&gt;% dygraph() %&gt;% dySeries(\"Yield_mm\", color = \"black\") %&gt;% dySeries(\"value\", color = \"red\") %&gt;% dyRangeSelector()  %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") \n\n\n\n\n\n\n\n\n\n\nCode\ndat_umpred %&gt;% filter(site_name == \"Dugout Creek\") %&gt;% select(date, Yield_mm, value) %&gt;% dygraph() %&gt;% dySeries(\"Yield_mm\", color = \"black\") %&gt;% dySeries(\"value\", color = \"red\") %&gt;% dyRangeSelector()  %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") \n\n\n\n\n\n\n\n\n\n\nCode\ndat_umpred %&gt;% filter(site_name == \"Donner Blitzen ab Indian NWIS\") %&gt;% select(date, Yield_mm, value) %&gt;% dygraph() %&gt;% dySeries(\"Yield_mm\", color = \"black\") %&gt;% dySeries(\"value\", color = \"red\") %&gt;% dyRangeSelector()  %&gt;% dyAxis(\"y\", label = \"Yield (mm)\") \n\n\n\n\n\n\n\n\n\n\n\n\n14.4.3 Efficiency\nNSE scores and categories per Moriasi et al. “Model evaluation guidelines for systematic quantification of accuracy in watershed simulations.” Transactions of the ASABE 50.3 (2007): 885-900.\n\n\n\nCategory\nNSE range\n\n\n\n\nVery good\n0.75-1.00\n\n\nGood\n0.65-0.75\n\n\nSatisfactory\n0.50-0.65\n\n\nUnsatisfactory\n&lt;0.50\n\n\n\nNote that there is no effort to ensure consistant data availability among sites/basins/years. Would it be better to restrict these?\n\n14.4.3.1 Overall\nNSE by subbasin for all available data.\n\n\nCode\ndat_umpred %&gt;% \n  group_by(site_name, subbasin) %&gt;% \n  summarize(nse = NSE(sim = log(value), obs = log(Yield_mm))) %&gt;%\n  ungroup() %&gt;%\n  mutate(subbasin = factor(subbasin, levels = c(\"West Brook\", \"Paine Run\", \"Staunton River\", \"Big Creek\", \"Coal Creek\", \"McGee Creek\", \"Snake River\", \"Shields River\", \"Duck Creek\", \"Donner Blitzen\"))) %&gt;%\n  ggplot(aes(x = subbasin, y = nse)) +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = 0.50, alpha = 0.3, fill = \"red\") +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.50, ymax = 0.65, alpha = 0.3, fill = \"orange\") +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.65, ymax = 0.75, alpha = 0.3, fill = \"yellow\") +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.75, ymax = 1.00, alpha = 0.3, fill = \"green\") +\n  geom_boxplot(fill = \"grey\", outlier.shape = NA) +\n  geom_jitter(height = 0, width = 0.2, shape = 1) +\n  geom_abline(slope = 0, intercept = 1, color = \"black\", linetype = \"dashed\") +\n  xlab(\"Sub-basin\") + ylab(\"Nash-Sutcliffe efficiency\") + ggtitle(\"All data\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n        axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 0.4)) +\n  scale_y_continuous(limits = c(-8.5,1), expand = c(0,0))\n\n\n\n\n\n\n\n\n\nNSE by subbasin, summer (July-August) only, all available years.\n\n\nCode\ndat_umpred %&gt;% \n  filter(Month %in% c(7:9)) %&gt;%\n  group_by(site_name, subbasin) %&gt;% \n  summarize(nse = NSE(sim = log(value), obs = log(Yield_mm))) %&gt;%\n  ungroup() %&gt;%\n  mutate(subbasin = factor(subbasin, levels = c(\"West Brook\", \"Paine Run\", \"Staunton River\", \"Big Creek\", \"Coal Creek\", \"McGee Creek\", \"Snake River\", \"Shields River\", \"Duck Creek\", \"Donner Blitzen\"))) %&gt;%\n  ggplot(aes(x = subbasin, y = nse)) +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = 0.50, alpha = 0.3, fill = \"red\") +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.50, ymax = 0.65, alpha = 0.3, fill = \"orange\") +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.65, ymax = 0.75, alpha = 0.3, fill = \"yellow\") +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.75, ymax = 1.00, alpha = 0.3, fill = \"green\") +\n  geom_boxplot(fill = \"grey\", outlier.shape = NA) +\n  geom_jitter(height = 0, width = 0.2, shape = 1) +\n  geom_abline(slope = 0, intercept = 1, color = \"black\", linetype = \"dashed\") +\n  xlab(\"Sub-basin\") + ylab(\"Nash-Sutcliffe efficiency\") + ggtitle(\"July-September\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n        axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 0.4)) +\n  scale_y_continuous(limits = c(-12.5,1), expand = c(0,0))\n\n\n\n\n\n\n\n\n\n\n\n14.4.3.2 By time\nHow does NSE vary through time?\nNSE by subbasin and month, pooled across all available years\n\n\nCode\ndat_umpred %&gt;% \n  group_by(site_name, subbasin, MonthName) %&gt;% \n  summarize(nse = NSE(sim = log(value), obs = log(Yield_mm))) %&gt;%\n  ungroup() %&gt;%\n  mutate(subbasin = factor(subbasin, levels = c(\"West Brook\", \"Paine Run\", \"Staunton River\", \"Big Creek\", \"Coal Creek\", \"McGee Creek\", \"Snake River\", \"Shields River\", \"Duck Creek\", \"Donner Blitzen\")),\n         MonthName = factor(MonthName, levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))) %&gt;%\n  ggplot(aes(x = MonthName, y = nse)) +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = 0.50, alpha = 0.3, fill = \"red\") +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.50, ymax = 0.65, alpha = 0.3, fill = \"orange\") +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.65, ymax = 0.75, alpha = 0.3, fill = \"yellow\") +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.75, ymax = 1.00, alpha = 0.3, fill = \"green\") +\n  geom_point(aes(group = site_name)) +\n  geom_abline(slope = 0, intercept = 1, color = \"black\", linetype = \"dashed\") +\n  scale_x_discrete(labels = c(\"Jan\" = \"J\", \"Feb\" = \"F\", \"Mar\" = \"M\", \"Apr\" = \"A\", \"May\" = \"M\", \"Jun\" = \"J\", \"Jul\" = \"J\", \"Aug\" = \"A\", \"Sep\" = \"S\", \"Oct\" = \"O\", \"Nov\" = \"N\", \"Dec\" = \"D\")) +\n  xlab(\"Month\") + ylab(\"Nash-Sutcliffe efficiency\") + ggtitle(\"All data\") +\n  facet_wrap(~subbasin, scales = \"free_y\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +\n  scale_y_continuous(expand = c(0,0))\n\n\n\n\n\n\n\n\n\nFor the West Brook, show NSE by time and site, no pooling.\n\n\nCode\ndat_umpred %&gt;% \n  mutate(yearmonth = floor_date(date, \"month\")) %&gt;% \n  filter(subbasin == \"West Brook\") %&gt;%\n  group_by(site_name, subbasin, yearmonth) %&gt;% \n  summarize(nobs = n(), nse = NSE(sim = log(value), obs = log(Yield_mm))) %&gt;%\n  ungroup() %&gt;%\n  filter(nobs &gt;= 25) %&gt;%\n  ggplot(aes(x = yearmonth, y = nse)) + \n  # annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = 0.50, alpha = 0.3, fill = \"red\") +\n  # annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.50, ymax = 0.65, alpha = 0.3, fill = \"orange\") +\n  # annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.65, ymax = 0.75, alpha = 0.3, fill = \"yellow\") +\n  # annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.75, ymax = 1.00, alpha = 0.3, fill = \"green\") +\n  geom_point(aes(color = site_name)) +\n  geom_line(aes(color = site_name)) +\n  geom_abline(slope = 0, intercept = 1, color = \"black\", linetype = \"dashed\") +\n  xlab(\"Time\") + ylab(\"Nash-Sutcliffe efficiency\") + ggtitle(\"West Brook (truncated y-axis limits)\") +\n  #facet_wrap(~subbasin, scales = \"free\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +\n  ylim(-50,1)\n\n\n\n\n\n\n\n\n\n\n\n14.4.3.3 Timescale\nOften, ecological studyies use flow data aggregated at coarser temporal resolutions. How does efficiency change with the time scale of aggregation? Do flow predictions become more accurate when aggregated from daily to weekly or monthly means?\nAggregate data (or not), calculate NSE for each site, and combine.\n\n\nCode\ndaily &lt;- dat_umpred %&gt;% \n  group_by(site_name, subbasin) %&gt;% \n  summarize(nse = NSE(sim = log(value), obs = log(Yield_mm))) %&gt;%\n  ungroup() %&gt;%\n  mutate(timescale = \"day\")\n\nweekly &lt;- dat_umpred %&gt;% \n  mutate(date = floor_date(date, \"week\")) %&gt;% \n  group_by(site_name, subbasin, date) %&gt;% \n  summarise(nobs = n(), Yield_mm = mean(Yield_mm), value = mean(value)) %&gt;%\n  ungroup() %&gt;%\n  filter(nobs == 7) %&gt;%\n  group_by(site_name, subbasin) %&gt;% \n  summarize(nse = NSE(sim = log(value), obs = log(Yield_mm))) %&gt;%\n  ungroup() %&gt;%\n  mutate(timescale = \"week\")\n\nmonthly &lt;- dat_umpred %&gt;% \n  mutate(date = floor_date(date, \"month\")) %&gt;% \n  group_by(site_name, subbasin, date) %&gt;% \n  summarise(nobs = n(), Yield_mm = mean(Yield_mm), value = mean(value)) %&gt;%\n  ungroup() %&gt;%\n  filter(nobs &gt;= 27) %&gt;%\n  group_by(site_name, subbasin) %&gt;% \n  summarize(nse = NSE(sim = log(value), obs = log(Yield_mm))) %&gt;%\n  ungroup() %&gt;%\n  mutate(timescale = \"month\")\n\ntimescale &lt;- bind_rows(daily, weekly, monthly) %&gt;%\n  mutate(timescale = factor(timescale, levels = c(\"day\", \"week\", \"month\"))) \n\n\nPlot all sites\n\n\nCode\ntimescale %&gt;%\n  ggplot(aes(x = timescale, y = nse, group = site_name)) +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = 0.50, alpha = 0.3, fill = \"red\") +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.50, ymax = 0.65, alpha = 0.3, fill = \"orange\") +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.65, ymax = 0.75, alpha = 0.3, fill = \"yellow\") +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.75, ymax = 1.00, alpha = 0.3, fill = \"green\") +\n  geom_point() +\n  geom_line() +\n  xlab(\"Time scale\") + ylab(\"Nash-Sutcliffe efficiency\") + \n  theme_bw() + ylim(-6,1) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +\n  scale_y_continuous(limits = c(-14,1), expand = c(0,0))\n\n\n\n\n\n\n\n\n\nPlot all sites, facet by subbasin\n\n\nCode\ntimescale %&gt;%\n  mutate(subbasin = factor(subbasin, levels = c(\"West Brook\", \"Paine Run\", \"Staunton River\", \"Big Creek\", \"Coal Creek\", \"McGee Creek\", \"Snake River\", \"Shields River\", \"Duck Creek\", \"Donner Blitzen\"))) %&gt;%\n  ggplot(aes(x = timescale, y = nse, group = site_name)) +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = 0.50, alpha = 0.3, fill = \"red\") +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.50, ymax = 0.65, alpha = 0.3, fill = \"orange\") +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.65, ymax = 0.75, alpha = 0.3, fill = \"yellow\") +\n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.75, ymax = 1.00, alpha = 0.3, fill = \"green\") +\n  geom_point() +\n  geom_line() +\n  xlab(\"Time scale\") + ylab(\"Nash-Sutcliffe efficiency\") + \n  theme_bw() +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +\n  facet_wrap(~subbasin, scales = \"free_y\")\n\n\n\n\n\n\n\n\n\nGenerally, aggregating daily flow predictions to weekly or monthly means does not substantially change the accuracy of predicted data. However, there is a slight trend for accuracy (NSE) to increase with temporal aggregation for sites at which daily predictions are already fairly accurate. In contrast, for sites for which daily predictions are not accurate, temporal aggregation further decreases accuracy.",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Objective 3</span>"
    ]
  },
  {
    "objectID": "Qualitative/LowFlow.html",
    "href": "Qualitative/LowFlow.html",
    "title": "15  Objective 4",
    "section": "",
    "text": "15.1 Data\nPurpose: Demonstrate spatial variation in drought-related low flow conditions across headwater stream networks.\nApproach:\nSite information\nCode\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nLittle g’s\nCode\ndat_clean &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/LittleG_data_clean.csv\")\nBig G’s\nCode\ndat_clean_big &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/BigG_data_clean.csv\")\nClimate\nCode\nclimdf &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/Daymet_climate.csv\")\nclimdf_summ &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/Daymet_climate_summary.csv\")\nWater availability\nCode\n# wateravail &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/BigG_wateravailability_annual.csv\")\nwateravail &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/BigG_wateravailability_annual.csv\") %&gt;%\n  filter(!is.na(totalyield), !is.na(totalyield_sum)) %&gt;%\n  group_by(site_name) %&gt;%\n  mutate(tyz_perc = percentile(totalyield_z),\n         tyz_sum_perc = percentile(totalyield_sum_z)) %&gt;%\n  mutate(tyz_perc = ifelse(is.na(tyz_perc), 0, tyz_perc),\n         tyz_sum_perc = ifelse(is.na(tyz_sum_perc), 0, tyz_sum_perc)) %&gt;%\n  ungroup()\nCode\n# get range of years for little g data\ndaterange &lt;- dat_clean %&gt;% group_by(basin) %&gt;% summarize(minyear = year(min(date)), maxyear = year(max(date)))\n\n# spread ecod years\nmylist &lt;- vector(\"list\", length = dim(daterange)[1])\nfor (i in 1:dim(daterange)[1]) {\n  mylist[[i]] &lt;- tibble(basin = daterange$basin[i], WaterYear = seq(from = daterange$minyear[i], to = daterange$maxyear[i], by = 1))\n}\nyrdf &lt;- do.call(rbind, mylist) %&gt;% mutate(ecodyr = \"yes\")",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Objective 4</span>"
    ]
  },
  {
    "objectID": "Qualitative/LowFlow.html#low-flow-thresholds",
    "href": "Qualitative/LowFlow.html#low-flow-thresholds",
    "title": "15  Objective 4",
    "section": "15.3 Low flow thresholds",
    "text": "15.3 Low flow thresholds\n\n15.3.1 Basin scale\nGenerate fixed and time varying (by day of year) drought/low flow thresholds from long-term (1970-2025) big G streamflow data. Quantiles in ~0.05 increments from 0.02 to 0.50.\n\n\nCode\n# calculate site-level fixed low flow thresholds\ndat_clean_big_fixed &lt;- dat_clean_big %&gt;% \n  filter(!is.na(basin)) %&gt;%\n  group_by(site_name, basin, subbasin, region) %&gt;%\n  summarize(thresh_50_fix = quantile(Yield_mm, probs = 0.50, na.rm = TRUE),\n            thresh_45_fix = quantile(Yield_mm, probs = 0.45, na.rm = TRUE),\n            thresh_40_fix = quantile(Yield_mm, probs = 0.40, na.rm = TRUE),\n            thresh_35_fix = quantile(Yield_mm, probs = 0.35, na.rm = TRUE),\n            thresh_30_fix = quantile(Yield_mm, probs = 0.30, na.rm = TRUE),\n            thresh_25_fix = quantile(Yield_mm, probs = 0.25, na.rm = TRUE),\n            thresh_20_fix = quantile(Yield_mm, probs = 0.20, na.rm = TRUE),\n            thresh_15_fix = quantile(Yield_mm, probs = 0.15, na.rm = TRUE),\n            thresh_10_fix = quantile(Yield_mm, probs = 0.10, na.rm = TRUE),\n            thresh_05_fix = quantile(Yield_mm, probs = 0.05, na.rm = TRUE),\n            thresh_02_fix = quantile(Yield_mm, probs = 0.02, na.rm = TRUE)) %&gt;%\n  ungroup()\n(dat_clean_big_fixed)\n\n\n# A tibble: 8 × 15\n  site_name      basin subbasin region thresh_50_fix thresh_45_fix thresh_40_fix\n  &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n1 Battle Run NW… Pine… Piney R… Shen           0.586         0.513         0.439\n2 Donner Blitze… Donn… Donner … Oreg           0.272         0.246         0.227\n3 North Fork Fl… Flat… Flathead Flat           0.729         0.644         0.579\n4 Pacific Creek… Snak… Snake R… Snake          0.364         0.336         0.313\n5 Rapidan River… Stau… Staunto… Shen           0.830         0.731         0.642\n6 South River C… West… West Br… Mass           1.34          1.18          1.02 \n7 South River H… Pain… Paine R… Shen           0.704         0.624         0.557\n8 Yellowstone R… Shie… Shields… Shiel…         0.500         0.466         0.438\n# ℹ 8 more variables: thresh_35_fix &lt;dbl&gt;, thresh_30_fix &lt;dbl&gt;,\n#   thresh_25_fix &lt;dbl&gt;, thresh_20_fix &lt;dbl&gt;, thresh_15_fix &lt;dbl&gt;,\n#   thresh_10_fix &lt;dbl&gt;, thresh_05_fix &lt;dbl&gt;, thresh_02_fix &lt;dbl&gt;\n\n\nCode\n# calculate site-level variable (by doy) low flow thresholds\ndat_clean_big_variable &lt;- dat_clean_big %&gt;% \n  filter(!is.na(basin)) %&gt;%\n  group_by(site_name, basin, subbasin, region, doy_calendar) %&gt;%\n  summarize(thresh_50_var = quantile(Yield_mm, probs = 0.50, na.rm = TRUE),\n            thresh_45_var = quantile(Yield_mm, probs = 0.45, na.rm = TRUE),\n            thresh_40_var = quantile(Yield_mm, probs = 0.40, na.rm = TRUE),\n            thresh_35_var = quantile(Yield_mm, probs = 0.35, na.rm = TRUE),\n            thresh_30_var = quantile(Yield_mm, probs = 0.30, na.rm = TRUE),\n            thresh_25_var = quantile(Yield_mm, probs = 0.25, na.rm = TRUE),\n            thresh_20_var = quantile(Yield_mm, probs = 0.20, na.rm = TRUE),\n            thresh_15_var = quantile(Yield_mm, probs = 0.15, na.rm = TRUE),\n            thresh_10_var = quantile(Yield_mm, probs = 0.10, na.rm = TRUE),\n            thresh_05_var = quantile(Yield_mm, probs = 0.05, na.rm = TRUE),\n            thresh_02_var = quantile(Yield_mm, probs = 0.02, na.rm = TRUE)) %&gt;%\n  ungroup()\n(dat_clean_big_variable)\n\n\n# A tibble: 2,928 × 16\n   site_name      basin subbasin region doy_calendar thresh_50_var thresh_45_var\n   &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n 1 Battle Run NW… Pine… Piney R… Shen              1         0.732         0.687\n 2 Battle Run NW… Pine… Piney R… Shen              2         0.754         0.702\n 3 Battle Run NW… Pine… Piney R… Shen              3         0.815         0.727\n 4 Battle Run NW… Pine… Piney R… Shen              4         0.860         0.802\n 5 Battle Run NW… Pine… Piney R… Shen              5         0.805         0.732\n 6 Battle Run NW… Pine… Piney R… Shen              6         0.751         0.690\n 7 Battle Run NW… Pine… Piney R… Shen              7         0.859         0.790\n 8 Battle Run NW… Pine… Piney R… Shen              8         0.787         0.732\n 9 Battle Run NW… Pine… Piney R… Shen              9         0.805         0.784\n10 Battle Run NW… Pine… Piney R… Shen             10         0.820         0.732\n# ℹ 2,918 more rows\n# ℹ 9 more variables: thresh_40_var &lt;dbl&gt;, thresh_35_var &lt;dbl&gt;,\n#   thresh_30_var &lt;dbl&gt;, thresh_25_var &lt;dbl&gt;, thresh_20_var &lt;dbl&gt;,\n#   thresh_15_var &lt;dbl&gt;, thresh_10_var &lt;dbl&gt;, thresh_05_var &lt;dbl&gt;,\n#   thresh_02_var &lt;dbl&gt;\n\n\nJoin drought thresholds derived from big G to little g’s\n\n\nCode\nmydroughtlevels &lt;- c(\"none\", \"q50\", \"q45\", \"q40\", \"q35\", \"q30\", \"q25\", \"q20\", \"q15\", \"q10\", \"q05\", \"q02\")\n\n# little gs\ndat_clean_little_join &lt;- dat_clean %&gt;% \n  left_join(dat_clean_big_fixed %&gt;% select(-c(site_name, subbasin))) %&gt;%\n  left_join(dat_clean_big_variable %&gt;% select(-c(site_name, subbasin))) %&gt;%\n  mutate(month = month(date),\n         year = year(date),\n         designation = \"little\",\n         drought_fix = ifelse(Yield_mm &lt;= thresh_50_fix & Yield_mm &gt; thresh_45_fix, \"q50\",\n                              ifelse(Yield_mm &lt;= thresh_45_fix & Yield_mm &gt; thresh_40_fix, \"q45\",\n                                     ifelse(Yield_mm &lt;= thresh_40_fix & Yield_mm &gt; thresh_35_fix, \"q40\",\n                                            ifelse(Yield_mm &lt;= thresh_35_fix & Yield_mm &gt; thresh_30_fix, \"q35\",\n                                                   ifelse(Yield_mm &lt;= thresh_30_fix & Yield_mm &gt; thresh_25_fix, \"q30\",\n                                                          ifelse(Yield_mm &lt;= thresh_25_fix & Yield_mm &gt; thresh_20_fix, \"q25\",\n                                                                 ifelse(Yield_mm &lt;= thresh_20_fix & Yield_mm &gt; thresh_15_fix, \"q20\",\n                                                                        ifelse(Yield_mm &lt;= thresh_15_fix & Yield_mm &gt; thresh_10_fix, \"q15\",\n                                                                               ifelse(Yield_mm &lt;= thresh_10_fix & Yield_mm &gt; thresh_05_fix, \"q10\",\n                                                                                      ifelse(Yield_mm &lt;= thresh_05_fix & Yield_mm &gt; thresh_02_fix, \"q05\",  \n                                                                                             ifelse(Yield_mm &lt;= thresh_02_fix, \"q02\", \"none\"))))))))))),\n         drought_var = ifelse(Yield_mm &lt;= thresh_50_var & Yield_mm &gt; thresh_45_var, \"q50\",\n                              ifelse(Yield_mm &lt;= thresh_45_var & Yield_mm &gt; thresh_40_var, \"q45\",\n                                     ifelse(Yield_mm &lt;= thresh_40_var & Yield_mm &gt; thresh_35_var, \"q40\",\n                                            ifelse(Yield_mm &lt;= thresh_35_var & Yield_mm &gt; thresh_30_var, \"q35\",\n                                                   ifelse(Yield_mm &lt;= thresh_30_var & Yield_mm &gt; thresh_25_var, \"q30\",\n                                                          ifelse(Yield_mm &lt;= thresh_25_var & Yield_mm &gt; thresh_20_var, \"q25\",\n                                                                 ifelse(Yield_mm &lt;= thresh_20_var & Yield_mm &gt; thresh_15_var, \"q20\",\n                                                                        ifelse(Yield_mm &lt;= thresh_15_var & Yield_mm &gt; thresh_10_var, \"q15\",\n                                                                               ifelse(Yield_mm &lt;= thresh_10_var & Yield_mm &gt; thresh_05_var, \"q10\",\n                                                                                      ifelse(Yield_mm &lt;= thresh_05_var & Yield_mm &gt; thresh_02_var, \"q05\", \n                                                                                             ifelse(Yield_mm &lt;= thresh_02_var, \"q02\", \"none\")))))))))))) %&gt;%\n  mutate(drought_fix = factor(ifelse(is.na(Yield_mm), NA, drought_fix), levels = mydroughtlevels),\n         drought_var = factor(ifelse(is.na(Yield_mm), NA, drought_var), levels = mydroughtlevels)) \n\n# big gs\ndat_clean_big_join &lt;- dat_clean_big %&gt;% \n  left_join(dat_clean_big_fixed %&gt;% select(-c(site_name, subbasin))) %&gt;%\n  left_join(dat_clean_big_variable %&gt;% select(-c(site_name, subbasin))) %&gt;%\n  mutate(month = month(date),\n         year = year(date),\n         designation = \"big\",\n         drought_fix = ifelse(Yield_mm &lt;= thresh_50_fix & Yield_mm &gt; thresh_45_fix, \"q50\",\n                              ifelse(Yield_mm &lt;= thresh_45_fix & Yield_mm &gt; thresh_40_fix, \"q45\",\n                                     ifelse(Yield_mm &lt;= thresh_40_fix & Yield_mm &gt; thresh_35_fix, \"q40\",\n                                            ifelse(Yield_mm &lt;= thresh_35_fix & Yield_mm &gt; thresh_30_fix, \"q35\",\n                                                   ifelse(Yield_mm &lt;= thresh_30_fix & Yield_mm &gt; thresh_25_fix, \"q30\",\n                                                          ifelse(Yield_mm &lt;= thresh_25_fix & Yield_mm &gt; thresh_20_fix, \"q25\",\n                                                                 ifelse(Yield_mm &lt;= thresh_20_fix & Yield_mm &gt; thresh_15_fix, \"q20\",\n                                                                        ifelse(Yield_mm &lt;= thresh_15_fix & Yield_mm &gt; thresh_10_fix, \"q15\",\n                                                                               ifelse(Yield_mm &lt;= thresh_10_fix & Yield_mm &gt; thresh_05_fix, \"q10\",\n                                                                                      ifelse(Yield_mm &lt;= thresh_05_fix & Yield_mm &gt; thresh_02_fix, \"q05\", \n                                                                                             ifelse(Yield_mm &lt;= thresh_02_fix, \"q02\", \"none\"))))))))))),\n         drought_var = ifelse(Yield_mm &lt;= thresh_50_var & Yield_mm &gt; thresh_45_var, \"q50\",\n                              ifelse(Yield_mm &lt;= thresh_45_var & Yield_mm &gt; thresh_40_var, \"q45\",\n                                     ifelse(Yield_mm &lt;= thresh_40_var & Yield_mm &gt; thresh_35_var, \"q40\",\n                                            ifelse(Yield_mm &lt;= thresh_35_var & Yield_mm &gt; thresh_30_var, \"q35\",\n                                                   ifelse(Yield_mm &lt;= thresh_30_var & Yield_mm &gt; thresh_25_var, \"q30\",\n                                                          ifelse(Yield_mm &lt;= thresh_25_var & Yield_mm &gt; thresh_20_var, \"q25\",\n                                                                 ifelse(Yield_mm &lt;= thresh_20_var & Yield_mm &gt; thresh_15_var, \"q20\",\n                                                                        ifelse(Yield_mm &lt;= thresh_15_var & Yield_mm &gt; thresh_10_var, \"q15\",\n                                                                               ifelse(Yield_mm &lt;= thresh_10_var & Yield_mm &gt; thresh_05_var, \"q10\",\n                                                                                      ifelse(Yield_mm &lt;= thresh_05_var & Yield_mm &gt; thresh_02_var, \"q05\",  \n                                                                                             ifelse(Yield_mm &lt;= thresh_02_var, \"q02\", \"none\")))))))))))) %&gt;%\n  mutate(drought_fix = factor(ifelse(is.na(Yield_mm), NA, drought_fix), levels = mydroughtlevels),\n         drought_var = factor(ifelse(is.na(Yield_mm), NA, drought_var), levels = mydroughtlevels)) \ndat_clean_big_join_sub &lt;- dat_clean_big_join %&gt;% left_join(yrdf) %&gt;% filter(ecodyr == \"yes\")\n\n# join data\ndat_clean_join &lt;- bind_rows(dat_clean_little_join, dat_clean_big_join_sub)\n\n\n\n\n15.3.2 Site specific\nDrought/low flow delineation is somewhat complicated by the fact that some streams simply have greater yield than others. For example, at groundwater-dominated sites, the above approach will never detect low flow conditions based on big G thresholds, but this doesn’t mean that flow at that site isn’t lower than normal (for that site). This is most obvious in the Snake River basin, where NF Spread Creek Upper never experiences drought (because this is presumably a gaining reach) and Rock and Grouse Creeks are in a perpetual state of drought (presumable these are losing reaches). This is a classic “At which level of organization do I standardize my data?” question: are general differences in flow volume among sites signal or noise? But perhaps more importantly, this is a question of “what is drought?” Is drought relative to some larger regional metric (e.g., big G)? Or is it a local phenomenon, where the specifics of individual streams and reaches matter.\nFor each site individually, generate (fixed) drought/low flow thresholds using the same quantiles same as above: ~0.05 increments from 0.02 to 0.50. Restrict data to selected basins, sites, and years with (nearly) complete summer (July, August, September) data over the selected periods/locations. (Standardization needs to be done over comparable time periods, at least among sites within basins).\nRequire 95% data availability across all water years for site to be included!\nOrganize data, get site-level low flow threshold values, and denote drought periods\n\n\nCode\n# Require 95% data availability!\nmonthss &lt;- c(7:9)\n\n# grab data and bind, z-score Yield\ndat_clean_sub &lt;- bind_rows(\n  dat_clean %&gt;% filter(basin == \"West Brook\", WaterYear %in% c(2020:2023), Month %in% monthss, !site_name %in% c(\"Mitchell Brook\", \"West Brook Lower\")) %&gt;%\n    bind_rows(dat_clean_big %&gt;% filter(basin == \"West Brook\", WaterYear %in% c(2020:2023), Month %in% monthss)),\n  \n  dat_clean %&gt;% filter(basin == \"Staunton River\", WaterYear %in% c(2019:2022), Month %in% monthss) %&gt;%\n    bind_rows(dat_clean_big %&gt;% filter(basin == \"Staunton River\", WaterYear %in% c(2019:2022), Month %in% monthss)),\n  \n  dat_clean %&gt;% filter(basin == \"Flathead\", WaterYear %in% c(2019:2021), Month %in% monthss, !site_name %in% c(\"BigCreekLower\", \"LangfordCreekUpper\", \"WernerCreek\", \"CycloneCreekMiddle\", \"CoalCreekMiddle\", \"McGeeCreekUpper\")) %&gt;%\n    bind_rows(dat_clean_big %&gt;% filter(basin == \"Flathead\", WaterYear %in% c(2019:2021), Month %in% monthss)),\n  \n  # dat_clean %&gt;% filter(subbasin == \"Big Creek\", WaterYear %in% c(2019:2021), Month %in% monthss, !site_name %in% c(\"BigCreekLower\", \"LangfordCreekUpper\", \"NicolaCreek\", \"WernerCreek\")) %&gt;%\n  #   bind_rows(dat_clean_big %&gt;% filter(basin == \"Flathead\", WaterYear %in% c(2019:2021), Month %in% monthss) %&gt;% mutate(subbasin = \"Big Creek\")),\n  # \n  # dat_clean %&gt;% filter(subbasin == \"Coal Creek\", WaterYear %in% c(2019:2021), Month %in% monthss, !site_name %in% c(\"CycloneCreekMiddle\", \"CoalCreekMiddle\", \"CoalCreekHeadwaters\")) %&gt;%\n  #   bind_rows(dat_clean_big %&gt;% filter(basin == \"Flathead\", WaterYear %in% c(2019:2021), Month %in% monthss) %&gt;% mutate(subbasin = \"Coal Creek\")),\n  \n  dat_clean %&gt;% filter(basin == \"Snake River\", WaterYear %in% c(2020:2022), Month %in% monthss, !site_name %in% c(\"Spread Creek Dam\")) %&gt;%\n    bind_rows(dat_clean_big %&gt;% filter(basin == \"Snake River\", WaterYear %in% c(2020:2022), Month %in% monthss)),\n  \n  dat_clean %&gt;% filter(basin == \"Shields River\", WaterYear %in% c(2017, 2019, 2020, 2022), Month %in% monthss, !site_name %in% c(\"Shields River Valley Ranch\", \"Buck Creek\", \"Lodgepole Creek\")) %&gt;% group_by(site_name) %&gt;%\n    bind_rows(dat_clean_big %&gt;% filter(basin == \"Shields River\", WaterYear %in% c(2017, 2019, 2020, 2022), Month %in% monthss)),\n  \n  # dat_clean %&gt;% filter(subbasin == \"Shields River\", WaterYear %in% c(2019, 2020, 2023), Month %in% monthss, !site_name %in% c(\"Shields River Valley Ranch\")) %&gt;% group_by(site_name) %&gt;%\n  #   bind_rows(dat_clean_big %&gt;% filter(basin == \"Shields River\", WaterYear %in% c(2019, 2020, 2023), Month %in% monthss)),\n  # \n  # dat_clean %&gt;% filter(subbasin == \"Duck Creek\", WaterYear %in% c(2017:2022), Month %in% monthss) %&gt;%\n  #   bind_rows(dat_clean_big %&gt;% filter(basin == \"Shields River\", WaterYear %in% c(2017:2022), Month %in% monthss) %&gt;% mutate(subbasin = \"Duck Creek\")),\n  \n  dat_clean %&gt;% filter(basin == \"Donner Blitzen\", WaterYear %in% c(2019:2022), Month %in% monthss) %&gt;%\n    bind_rows(dat_clean_big %&gt;% filter(basin == \"Donner Blitzen\", WaterYear %in% c(2019:2022), Month %in% monthss))\n) %&gt;%\n  group_by(site_name) %&gt;%\n  mutate(z_Yield_mm = scale(Yield_mm, center = TRUE, scale = TRUE)[,1]) %&gt;%\n  ungroup()\n\n# get low flow thresholds\ndat_clean_sub_thresh &lt;- dat_clean_sub %&gt;% \n  group_by(site_name) %&gt;%\n  summarize(thresh_50_fix = quantile(z_Yield_mm, probs = 0.50, na.rm = TRUE),\n            thresh_45_fix = quantile(z_Yield_mm, probs = 0.45, na.rm = TRUE),\n            thresh_40_fix = quantile(z_Yield_mm, probs = 0.40, na.rm = TRUE),\n            thresh_35_fix = quantile(z_Yield_mm, probs = 0.35, na.rm = TRUE),\n            thresh_30_fix = quantile(z_Yield_mm, probs = 0.30, na.rm = TRUE),\n            thresh_25_fix = quantile(z_Yield_mm, probs = 0.25, na.rm = TRUE),\n            thresh_20_fix = quantile(z_Yield_mm, probs = 0.20, na.rm = TRUE),\n            thresh_15_fix = quantile(z_Yield_mm, probs = 0.15, na.rm = TRUE),\n            thresh_10_fix = quantile(z_Yield_mm, probs = 0.10, na.rm = TRUE),\n            thresh_05_fix = quantile(z_Yield_mm, probs = 0.05, na.rm = TRUE),\n            thresh_02_fix = quantile(z_Yield_mm, probs = 0.02, na.rm = TRUE)) %&gt;%\n  ungroup()\ndat_clean_sub_thresh\n\n\n# A tibble: 52 × 12\n   site_name           thresh_50_fix thresh_45_fix thresh_40_fix thresh_35_fix\n   &lt;chr&gt;                       &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n 1 Avery Brook                -0.263        -0.308        -0.336        -0.348\n 2 Big Creek NWIS             -0.380        -0.421        -0.474        -0.532\n 3 BigCreekUpper              -0.435        -0.488        -0.532        -0.576\n 4 CoalCreekHeadwaters        -0.345        -0.359        -0.368        -0.379\n 5 CoalCreekLower             -0.378        -0.443        -0.507        -0.553\n 6 CoalCreekNorth             -0.349        -0.429        -0.488        -0.548\n 7 Crandall Creek             -0.347        -0.465        -0.526        -0.588\n 8 CycloneCreekLower          -0.225        -0.313        -0.405        -0.457\n 9 CycloneCreekUpper          -0.504        -0.555        -0.596        -0.617\n10 Deep Creek                 -0.340        -0.396        -0.441        -0.488\n# ℹ 42 more rows\n# ℹ 7 more variables: thresh_30_fix &lt;dbl&gt;, thresh_25_fix &lt;dbl&gt;,\n#   thresh_20_fix &lt;dbl&gt;, thresh_15_fix &lt;dbl&gt;, thresh_10_fix &lt;dbl&gt;,\n#   thresh_05_fix &lt;dbl&gt;, thresh_02_fix &lt;dbl&gt;\n\n\nCode\n# join thresholds to data and denote drought periods\ndat_clean_sub &lt;- dat_clean_sub %&gt;% \n  left_join(dat_clean_sub_thresh) %&gt;%\n  mutate(month = month(date),\n         year = year(date),\n         drought_fix = ifelse(z_Yield_mm &lt;= thresh_50_fix & z_Yield_mm &gt; thresh_45_fix, \"q50\",\n                              ifelse(z_Yield_mm &lt;= thresh_45_fix & z_Yield_mm &gt; thresh_40_fix, \"q45\",\n                                     ifelse(z_Yield_mm &lt;= thresh_40_fix & z_Yield_mm &gt; thresh_35_fix, \"q40\",\n                                            ifelse(z_Yield_mm &lt;= thresh_35_fix & z_Yield_mm &gt; thresh_30_fix, \"q35\",\n                                                   ifelse(z_Yield_mm &lt;= thresh_30_fix & z_Yield_mm &gt; thresh_25_fix, \"q30\",\n                                                          ifelse(z_Yield_mm &lt;= thresh_25_fix & z_Yield_mm &gt; thresh_20_fix, \"q25\",\n                                                                 ifelse(z_Yield_mm &lt;= thresh_20_fix & z_Yield_mm &gt; thresh_15_fix, \"q20\",\n                                                                        ifelse(z_Yield_mm &lt;= thresh_15_fix & z_Yield_mm &gt; thresh_10_fix, \"q15\",\n                                                                               ifelse(z_Yield_mm &lt;= thresh_10_fix & z_Yield_mm &gt; thresh_05_fix, \"q10\",\n                                                                                      ifelse(z_Yield_mm &lt;= thresh_05_fix & z_Yield_mm &gt; thresh_02_fix, \"q05\",  \n                                                                                             ifelse(z_Yield_mm &lt;= thresh_02_fix, \"q02\", \"none\")))))))))))) %&gt;%\n  mutate(drought_fix = factor(ifelse(is.na(Yield_mm), NA, drought_fix), levels = mydroughtlevels)) \ndat_clean_sub\n\n\n# A tibble: 16,731 × 31\n   site_name   basin    subbasin region date       flow_mean tempc_mean Yield_mm\n   &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;  &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n 1 Avery Brook West Br… West Br… Mass   2020-07-01     1.34        16.0    0.446\n 2 Avery Brook West Br… West Br… Mass   2020-07-02     0.963       16.1    0.321\n 3 Avery Brook West Br… West Br… Mass   2020-07-03     2.40        17.3    0.800\n 4 Avery Brook West Br… West Br… Mass   2020-07-04     3.31        17.4    1.10 \n 5 Avery Brook West Br… West Br… Mass   2020-07-05     1.38        17.5    0.460\n 6 Avery Brook West Br… West Br… Mass   2020-07-06     0.965       17.5    0.322\n 7 Avery Brook West Br… West Br… Mass   2020-07-07     0.778       17.3    0.259\n 8 Avery Brook West Br… West Br… Mass   2020-07-08     0.795       17.3    0.265\n 9 Avery Brook West Br… West Br… Mass   2020-07-09     1.07        17.9    0.356\n10 Avery Brook West Br… West Br… Mass   2020-07-10    14.3         19.4    4.76 \n# ℹ 16,721 more rows\n# ℹ 23 more variables: CalendarYear &lt;dbl&gt;, Month &lt;dbl&gt;, MonthName &lt;chr&gt;,\n#   WaterYear &lt;dbl&gt;, DayofYear &lt;dbl&gt;, logYield &lt;dbl&gt;, designation &lt;chr&gt;,\n#   doy_calendar &lt;dbl&gt;, z_Yield_mm &lt;dbl&gt;, thresh_50_fix &lt;dbl&gt;,\n#   thresh_45_fix &lt;dbl&gt;, thresh_40_fix &lt;dbl&gt;, thresh_35_fix &lt;dbl&gt;,\n#   thresh_30_fix &lt;dbl&gt;, thresh_25_fix &lt;dbl&gt;, thresh_20_fix &lt;dbl&gt;,\n#   thresh_15_fix &lt;dbl&gt;, thresh_10_fix &lt;dbl&gt;, thresh_05_fix &lt;dbl&gt;, …",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Objective 4</span>"
    ]
  },
  {
    "objectID": "Qualitative/LowFlow.html#low-flow-heatmaps",
    "href": "Qualitative/LowFlow.html#low-flow-heatmaps",
    "title": "15  Objective 4",
    "section": "15.4 Low flow heatmaps",
    "text": "15.4 Low flow heatmaps\nCreate heatmap functions\n\n\nCode\n# fixed drought threshold\nheatmapfun_fix &lt;- function(bas, months, bigG) {\n  dd &lt;- dat_clean_join %&gt;% filter(basin == bas | site_name == bigG, month %in% months)\n  mysites &lt;- c(unique(unlist(dd %&gt;% filter(designation == \"big\") %&gt;% select(site_name))),\n               unique(unlist(dd %&gt;% filter(designation == \"little\") %&gt;% select(site_name))))\n  myrect &lt;- dd %&gt;% group_by(WaterYear) %&gt;% summarize(mindate = min(date), maxdate = max(date)) %&gt;% ungroup()\n  p &lt;- dd %&gt;%\n    ggplot() +\n    geom_tile(aes(x = date, y = factor(site_name, levels = rev(mysites)), fill = drought_fix)) +\n    scale_fill_viridis(option = \"A\", direction = -1, discrete = TRUE, limits = mydroughtlevels) +\n    geom_rect(data = myrect, aes(xmin = mindate, xmax = maxdate, ymin = length(mysites)-0.5, ymax = length(mysites)+0.5), \n              color = \"grey70\", fill = NA, size = 1.25) +\n    xlab(\"Date\") + ylab(\"Site\") +\n    #facet_wrap(~WaterYear, scales = \"free_x\") + \n    facet_wrap2(~WaterYear, scales = \"free_x\", nrow = 3, ncol = 3, trim_blank = FALSE) +\n    theme_bw() + theme(axis.title = element_blank())\nreturn(p)\n}\n# variable drought threshold\nheatmapfun_var &lt;- function(bas, months, bigG) {\n  dd &lt;- dat_clean_join %&gt;% filter(basin == bas | site_name == bigG, month %in% months)\n  mysites &lt;- c(unique(unlist(dd %&gt;% filter(designation == \"big\") %&gt;% select(site_name))),\n               unique(unlist(dd %&gt;% filter(designation == \"little\") %&gt;% select(site_name))))\n  myrect &lt;- dd %&gt;% group_by(WaterYear) %&gt;% summarize(mindate = min(date), maxdate = max(date)) %&gt;% ungroup()\n  p &lt;- dd %&gt;%\n    ggplot() +\n    geom_tile(aes(x = date, y = factor(site_name, levels = rev(mysites)), fill = drought_var)) +\n    scale_fill_viridis(option = \"A\", direction = -1, discrete = TRUE, limits = mydroughtlevels) +\n    geom_rect(data = myrect, aes(xmin = mindate, xmax = maxdate, ymin = length(mysites)-0.5, ymax = length(mysites)+0.5), \n              color = \"grey70\", fill = NA, size = 1.25) +\n    xlab(\"Date\") + ylab(\"Site\") +\n    #facet_wrap(~WaterYear, scales = \"free_x\") +\n    facet_wrap2(~WaterYear, scales = \"free_x\", nrow = 3, ncol = 3, trim_blank = FALSE) +\n    theme_bw() + theme(axis.title = element_blank())\nreturn(p)\n}\n# site-level drought threshold\nheatmapfun_site &lt;- function(bas, months, bigG) {\n  dd &lt;- dat_clean_sub %&gt;% filter(basin == bas)\n  mysites &lt;- c(unique(unlist(dd %&gt;% filter(site_name != bigG) %&gt;% select(site_name))), bigG)\n  myrect &lt;- dd %&gt;% group_by(WaterYear) %&gt;% summarize(mindate = min(date), maxdate = max(date)) %&gt;% ungroup()\n  p &lt;- dd %&gt;%\n    ggplot() +\n    geom_tile(aes(x = date, y = factor(site_name, levels = (mysites)), fill = drought_fix)) +\n    scale_fill_viridis(option = \"A\", direction = -1, discrete = TRUE, limits = mydroughtlevels) +\n    geom_rect(data = myrect, aes(xmin = mindate, xmax = maxdate, ymin = length(mysites)-0.5, ymax = length(mysites)+0.5), \n              color = \"grey70\", fill = NA, size = 1.25) +\n    xlab(\"Date\") + ylab(\"Site\") +\n    #facet_wrap(~WaterYear, scales = \"free_x\") + \n    facet_wrap2(~WaterYear, scales = \"free_x\", nrow = 2, ncol = 3, trim_blank = FALSE) +\n    theme_bw() + theme(axis.title = element_blank())\nreturn(p)\n}\n\n\n\n15.4.1 Fixed threshold\n\nWest BrookPaine RunStaunton RiverFlatheadSnake RiverYellowstone RiverDonner Blitzen\n\n\n\n\nCode\nheatmapfun_fix(bas = \"West Brook\", bigG = \"South River Conway NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_fix(bas = \"Paine Run\", bigG = \"South River Harriston NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_fix(bas = \"Staunton River\", bigG = \"Rapidan River NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_fix(bas = \"Flathead\", bigG = \"North Fork Flathead River NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_fix(bas = \"Snake River\", bigG = \"Pacific Creek at Moran NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_fix(bas = \"Shields River\", bigG = \"Yellowstone River Livingston NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_fix(bas = \"Donner Blitzen\", bigG = \"Donner Blitzen River nr Frenchglen NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15.4.2 Variable threshold\n\nWest BrookPaine RunStaunton RiverFlatheadSnake RiverYellowstone RiverDonner Blitzen\n\n\n\n\nCode\nheatmapfun_var(bas = \"West Brook\", bigG = \"South River Conway NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_var(bas = \"Paine Run\", bigG = \"South River Harriston NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_var(bas = \"Staunton River\", bigG = \"Rapidan River NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_var(bas = \"Flathead\", bigG = \"North Fork Flathead River NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_var(bas = \"Snake River\", bigG = \"Pacific Creek at Moran NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_var(bas = \"Shields River\", bigG = \"Yellowstone River Livingston NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_var(bas = \"Donner Blitzen\", bigG = \"Donner Blitzen River nr Frenchglen NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15.4.3 Site-specific threshold\n\nWest BrookStaunton RiverFlatheadSnake RiverYellowstone RiverDonner Blitzen\n\n\n\n\nCode\nheatmapfun_site(bas = \"West Brook\", bigG = \"South River Conway NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_site(bas = \"Staunton River\", bigG = \"Rapidan River NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_site(bas = \"Flathead\", bigG = \"North Fork Flathead River NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_site(bas = \"Snake River\", bigG = \"Pacific Creek at Moran NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_site(bas = \"Shields River\", bigG = \"Yellowstone River Livingston NWIS\", months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nheatmapfun_site(bas = \"Donner Blitzen\", bigG = \"Donner Blitzen River nr Frenchglen NWIS\", months = c(7:9))",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Objective 4</span>"
    ]
  },
  {
    "objectID": "Qualitative/LowFlow.html#deficit-and-duration",
    "href": "Qualitative/LowFlow.html#deficit-and-duration",
    "title": "15  Objective 4",
    "section": "15.5 Deficit and duration",
    "text": "15.5 Deficit and duration\n\n15.5.1 Fixed threshold\nCalculate daily deficit, then summarize deficit magnitude and duration by site and month.\n\n\nCode\n# calculate daily deficit\ndat_clean_join_deficit &lt;- dat_clean_join %&gt;%\n  mutate(deficit_50_fix = ifelse(Yield_mm &lt; thresh_50_fix, thresh_50_fix - Yield_mm, 0),\n         deficit_45_fix = ifelse(Yield_mm &lt; thresh_45_fix, thresh_45_fix - Yield_mm, 0),\n         deficit_40_fix = ifelse(Yield_mm &lt; thresh_40_fix, thresh_40_fix - Yield_mm, 0),\n         deficit_35_fix = ifelse(Yield_mm &lt; thresh_35_fix, thresh_35_fix - Yield_mm, 0),\n         deficit_30_fix = ifelse(Yield_mm &lt; thresh_30_fix, thresh_30_fix - Yield_mm, 0),\n         deficit_25_fix = ifelse(Yield_mm &lt; thresh_25_fix, thresh_25_fix - Yield_mm, 0),\n         deficit_20_fix = ifelse(Yield_mm &lt; thresh_20_fix, thresh_20_fix - Yield_mm, 0),\n         deficit_15_fix = ifelse(Yield_mm &lt; thresh_15_fix, thresh_15_fix - Yield_mm, 0),\n         deficit_10_fix = ifelse(Yield_mm &lt; thresh_10_fix, thresh_10_fix - Yield_mm, 0),\n         deficit_05_fix = ifelse(Yield_mm &lt; thresh_05_fix, thresh_05_fix - Yield_mm, 0),\n         deficit_02_fix = ifelse(Yield_mm &lt; thresh_02_fix, thresh_02_fix - Yield_mm, 0),\n         \n         deficit_50_var = ifelse(Yield_mm &lt; thresh_50_var, thresh_50_var - Yield_mm, 0),\n         deficit_45_var = ifelse(Yield_mm &lt; thresh_45_var, thresh_45_var - Yield_mm, 0),\n         deficit_40_var = ifelse(Yield_mm &lt; thresh_40_var, thresh_40_var - Yield_mm, 0),\n         deficit_35_var = ifelse(Yield_mm &lt; thresh_35_var, thresh_35_var - Yield_mm, 0),\n         deficit_30_var = ifelse(Yield_mm &lt; thresh_30_var, thresh_30_var - Yield_mm, 0),\n         deficit_25_var = ifelse(Yield_mm &lt; thresh_25_var, thresh_25_var - Yield_mm, 0),\n         deficit_20_var = ifelse(Yield_mm &lt; thresh_20_var, thresh_20_var - Yield_mm, 0),\n         deficit_15_var = ifelse(Yield_mm &lt; thresh_15_var, thresh_15_var - Yield_mm, 0),\n         deficit_10_var = ifelse(Yield_mm &lt; thresh_10_var, thresh_10_var - Yield_mm, 0),\n         deficit_05_var = ifelse(Yield_mm &lt; thresh_05_var, thresh_05_var - Yield_mm, 0),\n         deficit_02_var = ifelse(Yield_mm &lt; thresh_02_var, thresh_02_var - Yield_mm, 0))\n\n# # fill missing dates\n# dat_clean_join_deficit &lt;- fill_missing_dates(dat_clean_join_deficit, dates = date, groups = site_name, pad_ends = TRUE)\n# \n# # fill ragged basin, subbasin, region, date variables\n# dat_clean_join_deficit &lt;- dat_clean_join_deficit %&gt;% \n#   select(-c(basin, subbasin, region, CalendarYear, Month, MonthName, WaterYear, DayofYear, designation)) %&gt;% \n#   left_join(siteinfo %&gt;% \n#               mutate(designation = ifelse(site_name %in% unique(dat_clean_big$site_name), \"big\", \"little\")) %&gt;% \n#               select(site_name, basin, subbasin, region, designation))\n# dat_clean_join_deficit &lt;- add_date_variables(dat_clean_join_deficit, dates = date, water_year_start = 10)\n# \n# # summarize by month\n# defdur_month &lt;- dat_clean_join_deficit %&gt;% \n#   group_by(site_name, basin, subbasin, region, designation, CalendarYear, Month, MonthName, WaterYear) %&gt;% \n#   summarize(ndays = n(), \n#             duration_50_fix = sum(deficit_50_fix &gt; 0),\n#             duration_45_fix = sum(deficit_45_fix &gt; 0),\n#             duration_40_fix = sum(deficit_40_fix &gt; 0),\n#             duration_35_fix = sum(deficit_35_fix &gt; 0),\n#             duration_30_fix = sum(deficit_30_fix &gt; 0),\n#             duration_25_fix = sum(deficit_25_fix &gt; 0),\n#             duration_20_fix = sum(deficit_20_fix &gt; 0),\n#             duration_15_fix = sum(deficit_15_fix &gt; 0),\n#             duration_10_fix = sum(deficit_10_fix &gt; 0),\n#             duration_05_fix = sum(deficit_05_fix &gt; 0),\n#             duration_02_fix = sum(deficit_02_fix &gt; 0),\n#             \n#             duration_50_var = sum(deficit_50_var &gt; 0),\n#             duration_45_var = sum(deficit_45_var &gt; 0),\n#             duration_40_var = sum(deficit_40_var &gt; 0),\n#             duration_35_var = sum(deficit_35_var &gt; 0),\n#             duration_30_var = sum(deficit_30_var &gt; 0),\n#             duration_25_var = sum(deficit_25_var &gt; 0),\n#             duration_20_var = sum(deficit_20_var &gt; 0),\n#             duration_15_var = sum(deficit_15_var &gt; 0),\n#             duration_10_var = sum(deficit_10_var &gt; 0),\n#             duration_05_var = sum(deficit_05_var &gt; 0),\n#             duration_02_var = sum(deficit_02_var &gt; 0),\n#             \n#             deficit_50_fix = sum(deficit_50_fix),\n#             deficit_45_fix = sum(deficit_45_fix),\n#             deficit_40_fix = sum(deficit_40_fix),\n#             deficit_35_fix = sum(deficit_35_fix),\n#             deficit_30_fix = sum(deficit_30_fix),\n#             deficit_25_fix = sum(deficit_25_fix),\n#             deficit_20_fix = sum(deficit_20_fix),\n#             deficit_15_fix = sum(deficit_15_fix),\n#             deficit_10_fix = sum(deficit_10_fix),\n#             deficit_05_fix = sum(deficit_05_fix),\n#             deficit_02_fix = sum(deficit_02_fix),\n#             \n#             deficit_50_var = sum(deficit_50_var),\n#             deficit_45_var = sum(deficit_45_var),\n#             deficit_40_var = sum(deficit_40_var),\n#             deficit_35_var = sum(deficit_35_var),\n#             deficit_30_var = sum(deficit_30_var),\n#             deficit_25_var = sum(deficit_25_var),\n#             deficit_20_var = sum(deficit_20_var),\n#             deficit_15_var = sum(deficit_15_var),\n#             deficit_10_var = sum(deficit_10_var),\n#             deficit_05_var = sum(deficit_05_var),\n#             deficit_02_var = sum(deficit_02_var)) %&gt;%\n#   ungroup() %&gt;%\n#   left_join(wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z))\n\n# summarize by summer\ndefdur_ssn &lt;- dat_clean_join_deficit %&gt;% \n  filter(!is.na(Yield_mm), Month %in% c(7:9)) %&gt;% \n  group_by(site_name, basin, subbasin, region, designation, CalendarYear, WaterYear) %&gt;% \n  summarize(ndays = n(),\n            propdays = ndays/(31+31+30), \n            duration_50_fix_prop = sum(deficit_50_fix &gt; 0) / ndays,\n            duration_45_fix_prop = sum(deficit_45_fix &gt; 0) / ndays,\n            duration_40_fix_prop = sum(deficit_40_fix &gt; 0) / ndays,\n            duration_35_fix_prop = sum(deficit_35_fix &gt; 0) / ndays,\n            duration_30_fix_prop = sum(deficit_30_fix &gt; 0) / ndays,\n            duration_25_fix_prop = sum(deficit_25_fix &gt; 0) / ndays,\n            duration_20_fix_prop = sum(deficit_20_fix &gt; 0) / ndays,\n            duration_15_fix_prop = sum(deficit_15_fix &gt; 0) / ndays,\n            duration_10_fix_prop = sum(deficit_10_fix &gt; 0) / ndays,\n            duration_05_fix_prop = sum(deficit_05_fix &gt; 0) / ndays,\n            duration_02_fix_prop = sum(deficit_02_fix &gt; 0) / ndays,\n            \n            duration_50_var_prop = sum(deficit_50_var &gt; 0) / ndays,\n            duration_45_var_prop = sum(deficit_45_var &gt; 0) / ndays,\n            duration_40_var_prop = sum(deficit_40_var &gt; 0) / ndays,\n            duration_35_var_prop = sum(deficit_35_var &gt; 0) / ndays,\n            duration_30_var_prop = sum(deficit_30_var &gt; 0) / ndays,\n            duration_25_var_prop = sum(deficit_25_var &gt; 0) / ndays,\n            duration_20_var_prop = sum(deficit_20_var &gt; 0) / ndays,\n            duration_15_var_prop = sum(deficit_15_var &gt; 0) / ndays,\n            duration_10_var_prop = sum(deficit_10_var &gt; 0) / ndays,\n            duration_05_var_prop = sum(deficit_05_var &gt; 0) / ndays,\n            duration_02_var_prop = sum(deficit_02_var &gt; 0) / ndays,\n            \n            deficit_50_fix = sum(deficit_50_fix),\n            deficit_45_fix = sum(deficit_45_fix),\n            deficit_40_fix = sum(deficit_40_fix),\n            deficit_35_fix = sum(deficit_35_fix),\n            deficit_30_fix = sum(deficit_30_fix),\n            deficit_25_fix = sum(deficit_25_fix),\n            deficit_20_fix = sum(deficit_20_fix),\n            deficit_15_fix = sum(deficit_15_fix),\n            deficit_10_fix = sum(deficit_10_fix),\n            deficit_05_fix = sum(deficit_05_fix),\n            deficit_02_fix = sum(deficit_02_fix),\n            \n            deficit_50_var = sum(deficit_50_var),\n            deficit_45_var = sum(deficit_45_var),\n            deficit_40_var = sum(deficit_40_var),\n            deficit_35_var = sum(deficit_35_var),\n            deficit_30_var = sum(deficit_30_var),\n            deficit_25_var = sum(deficit_25_var),\n            deficit_20_var = sum(deficit_20_var),\n            deficit_15_var = sum(deficit_15_var),\n            deficit_10_var = sum(deficit_10_var),\n            deficit_05_var = sum(deficit_05_var),\n            deficit_02_var = sum(deficit_02_var)) %&gt;%\n  ungroup() %&gt;%\n  filter(propdays &gt;= 0.70) %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z))\n\n\nCreate plotting functions\n\n\nCode\ndurationplotfun &lt;- function(bas, bigG, months, wateryears, dropsites = NA) {\n  # filter and summarize data\n  # dd &lt;- defdur_month %&gt;% \n  #   filter(subbasin == subbas | site_name == bigG, Month %in% months, WaterYear %in% wateryears, !site_name %in% dropsites) %&gt;%\n  #   mutate(WaterYear = factor(WaterYear, levels = wateryears)) %&gt;% \n  #   group_by(site_name, designation, WaterYear, totalyield_z) %&gt;%\n  #   summarize(duration_50_fix_prop = sum(duration_50_fix) / sum(ndays),\n  #             duration_45_fix_prop = sum(duration_45_fix) / sum(ndays),\n  #             duration_40_fix_prop = sum(duration_40_fix) / sum(ndays),\n  #             duration_35_fix_prop = sum(duration_35_fix) / sum(ndays),\n  #             duration_30_fix_prop = sum(duration_30_fix) / sum(ndays),\n  #             duration_25_fix_prop = sum(duration_25_fix) / sum(ndays),\n  #             duration_20_fix_prop = sum(duration_20_fix) / sum(ndays),\n  #             duration_15_fix_prop = sum(duration_15_fix) / sum(ndays),\n  #             duration_10_fix_prop = sum(duration_10_fix) / sum(ndays),\n  #             duration_05_fix_prop = sum(duration_05_fix) / sum(ndays),\n  #             duration_02_fix_prop = sum(duration_02_fix) / sum(ndays)) %&gt;%\n  #   ungroup()\n  dd &lt;- defdur_ssn %&gt;% \n    filter(basin == bas | site_name == bigG, WaterYear %in% wateryears, !site_name %in% dropsites) %&gt;%\n    mutate(WaterYear = factor(WaterYear, levels = wateryears))\n\n  # order sites, Big G first\n  mysites &lt;- c(unique(unlist(dd %&gt;% filter(designation == \"big\") %&gt;% select(site_name))),\n               unique(unlist(dd %&gt;% filter(designation == \"little\") %&gt;% select(site_name))))\n\n  # among site StDev ~ percentile\n  p_sds &lt;- dd %&gt;% \n    gather(duration_50_fix_prop:duration_02_fix_prop, key = \"metric\", value = \"duration\") %&gt;%\n    mutate(quant = as.numeric(gsub(\".*?([0-9]+).*\", \"\\\\1\", metric)) ) %&gt;% \n    filter(designation == \"little\") %&gt;%\n    group_by(WaterYear, totalyield_z, metric, quant) %&gt;%\n    summarize(sddur = sd(duration, na.rm = TRUE)) %&gt;%\n    ungroup() %&gt;%\n    #left_join(dd %&gt;% filter(site_name == bigG) %&gt;% select(WaterYear, duration_50_fix_prop) %&gt;% rename(dur50 = duration_50_fix_prop)) %&gt;%\n    left_join(wateravail %&gt;% filter(site_name == bigG) %&gt;% select(WaterYear, tyz_sum_perc) %&gt;% mutate(WaterYear = as.factor(WaterYear))) %&gt;%\n    ggplot(aes(x = quant, y = sddur, color = tyz_sum_perc, group = WaterYear, shape = WaterYear)) +\n    geom_point() +\n    scale_color_gradient(low = \"red\", high = \"blue\", limits = c(0,100)) +\n    stat_smooth() +\n    xlab(\"Low flow threshold (percentile)\") + ylab(\"Among-site SD(duration)\") +\n    theme_bw() + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n          legend.position = \"bottom\", legend.direction = \"vertical\", legend.key.height = unit(0.3, 'cm')) \n  \n  # barplot 50th perc\n  p30 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = duration_50_fix_prop)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,1) +\n    ylab(\"Days below low flow threshold (%JAS)\") + ggtitle(\"50th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 25th perc.\n  p20 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = duration_25_fix_prop)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,1) +\n    ylab(\"Days below low flow threshold (%JAS)\") + ggtitle(\"25th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 10th perc.\n  p10 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = duration_10_fix_prop)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,1) +\n    ylab(\"Days below low flow threshold (%JAS)\") + ggtitle(\"10th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 5th perc.\n  p05 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = duration_05_fix_prop)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,1) +\n    ylab(\"Days below low flow threshold (%JAS)\") + ggtitle(\"5th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 2nd perc\n  p02 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = duration_02_fix_prop)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,1) +\n    ylab(\"Days below low flow threshold (%JAS)\") + ggtitle(\"2nd perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n  # arrange plots\n  egg::ggarrange(p02 + theme(plot.margin = margin(r = 1, t = 5, b = 5)), \n                 p05 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)), \n                 p10 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)), \n                 p20 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)), \n                 p30 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)),\n                 p_sds,\n                 nrow = 1, widths = c(1,1,1,1,1,2.5))\n}\n\n\ndeficitplotfun &lt;- function(bas, bigG, months, wateryears, dropsites = NA) {\n  # filter and summarize data\n  # dd &lt;- defdur_month %&gt;% \n  #   filter(subbasin == subbas | site_name == bigG, Month %in% months, WaterYear %in% wateryears, !site_name %in% dropsites) %&gt;%\n  #   mutate(WaterYear = factor(WaterYear, levels = wateryears)) %&gt;% \n  #   group_by(site_name, designation, WaterYear, totalyield_z) %&gt;%\n  #   summarize(deficit_50_fix = sum(deficit_50_fix),\n  #             deficit_45_fix = sum(deficit_45_fix),\n  #             deficit_40_fix = sum(deficit_40_fix),\n  #             deficit_35_fix = sum(deficit_35_fix),\n  #             deficit_30_fix = sum(deficit_30_fix),\n  #             deficit_25_fix = sum(deficit_25_fix),\n  #             deficit_20_fix = sum(deficit_20_fix),\n  #             deficit_15_fix = sum(deficit_15_fix),\n  #             deficit_10_fix = sum(deficit_10_fix),\n  #             deficit_05_fix = sum(deficit_05_fix),\n  #             deficit_02_fix = sum(deficit_02_fix)) %&gt;%\n  #   ungroup()\n  dd_all &lt;- defdur_ssn %&gt;% filter(basin == bas | site_name == bigG, WaterYear %in% wateryears, !site_name %in% dropsites) \n  dd &lt;- defdur_ssn %&gt;% \n    filter(basin == bas | site_name == bigG, WaterYear %in% wateryears, !site_name %in% dropsites) %&gt;%\n    mutate(WaterYear = factor(WaterYear, levels = wateryears))\n  \n  # get y-axis limit\n  ymax &lt;- max(dd %&gt;% select(deficit_50_fix:deficit_02_fix))\n\n  # order sites, Big G first\n  mysites &lt;- c(unique(unlist(dd %&gt;% filter(designation == \"big\") %&gt;% select(site_name))),\n               unique(unlist(dd %&gt;% filter(designation == \"little\") %&gt;% select(site_name))))\n\n  # among site StDev ~ percentile\n  p_sds &lt;- dd %&gt;% \n    gather(deficit_50_fix:deficit_02_fix, key = \"metric\", value = \"deficit\") %&gt;%\n    mutate(quant = as.numeric(gsub(\".*?([0-9]+).*\", \"\\\\1\", metric)) ) %&gt;% \n    filter(designation == \"little\") %&gt;%\n    group_by(WaterYear, totalyield_z, metric, quant) %&gt;%\n    summarize(sddur = sd(deficit, na.rm = TRUE)) %&gt;%\n    ungroup() %&gt;%\n    #left_join(dd %&gt;% filter(site_name == bigG) %&gt;% select(WaterYear, deficit_50_fix) %&gt;% rename(def50 = deficit_50_fix)) %&gt;%\n    left_join(wateravail %&gt;% filter(site_name == bigG) %&gt;% select(WaterYear, tyz_sum_perc) %&gt;% mutate(WaterYear = as.factor(WaterYear))) %&gt;%\n    ggplot(aes(x = quant, y = sddur, color = tyz_sum_perc, group = WaterYear, shape = WaterYear)) +\n    geom_point() +\n    scale_color_gradient(low = \"red\", high = \"blue\", limits = c(0,100)) +\n    stat_smooth() +\n    xlab(\"Low flow threshold (percentile)\") + ylab(\"Among-site SD(deficit)\") +\n    theme_bw() + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n          legend.position = \"bottom\", legend.direction = \"vertical\", legend.key.height = unit(0.3, 'cm'))\n  \n  # barplot 50th perc\n  p30 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = deficit_50_fix)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,ymax) +\n    ylab(\"Drought deficit (mm, JAS)\") + ggtitle(\"50th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 25th perc.\n  p20 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = deficit_25_fix)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,ymax) +\n    ylab(\"Drought deficit (mm, JAS)\") + ggtitle(\"25th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 10th perc.\n  p10 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = deficit_10_fix)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,ymax) +\n    ylab(\"Drought deficit (mm, JAS)\") + ggtitle(\"10th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 5th perc.\n  p05 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = deficit_05_fix)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,ymax) +\n    ylab(\"Drought deficit (mm, JAS)\") + ggtitle(\"5th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 2nd perc\n  p02 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = deficit_02_fix)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,ymax) +\n    ylab(\"Drought deficit (JAS)\") + ggtitle(\"2nd perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n  # arrange plots\n  egg::ggarrange(p02 + theme(plot.margin = margin(r = 1, t = 5, b = 5)), \n                 p05 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)), \n                 p10 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)), \n                 p20 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)), \n                 p30 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)),\n                 p_sds,\n                 nrow = 1, widths = c(1,1,1,1,1,2.5))\n}\n\n\n\n15.5.1.1 Duration\nShow proportion of days (July - September) below different low flow thresholds (derived from long-term Big G data) for each site during a relatively wet year and a dry year. Then, for each year, plot the relationship between the among site (little g’s only) standard deviation of low flow duration and the low flow threshold used to calculate duration\n\nWest BrookStaunton RiverFlatheadSnake RiverYellowstone RiverDonner Blitzen\n\n\n\n\nCode\ndurationplotfun(bas = \"West Brook\", bigG = \"South River Conway NWIS\", months = c(7:9), wateryears = c(2020, 2021))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndurationplotfun(bas = \"Staunton River\", bigG = \"Rapidan River NWIS\", months = c(7:9), wateryears = c(2019, 2020))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndurationplotfun(bas = \"Flathead\", bigG = \"North Fork Flathead River NWIS\", months = c(7:9), wateryears = c(2020, 2021), dropsites = c(\"BigCreekLower\", \"LangfordCreekUpper\", \"WernerCreek\", \"CycloneCreekMiddle\", \"CoalCreekMiddle\", \"McGeeCreekUpper\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndurationplotfun(bas = \"Snake River\", bigG = \"Pacific Creek at Moran NWIS\", months = c(7:9), wateryears = c(2021, 2022))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndurationplotfun(bas = \"Shields River\", bigG = \"Yellowstone River Livingston NWIS\", months = c(7:9), wateryears = c(2020, 2019), dropsites = c(\"Shields River Valley Ranch\", \"Buck Creek\", \"Lodgepole Creek\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndurationplotfun(bas = \"Donner Blitzen\", bigG = \"Donner Blitzen River nr Frenchglen NWIS\", months = c(7:9), wateryears = c(2022, 2020))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15.5.1.2 Deficit\nShow total drought deficit (mm) relative to different low flow thresholds (derived from long-term Big G data) for each site during a relatively wet year and a dry year. Then, for each year, plot the relationship between the among site (little g’s only) standard deviation of deficit and the low flow threshold used to calculate deficit\n\nWest BrookStaunton RiverFlatheadSnake RiverYellowstone RiverDonner Blitzen\n\n\n\n\nCode\ndeficitplotfun(bas = \"West Brook\", bigG = \"South River Conway NWIS\", months = c(7:9), wateryears = c(2020, 2021))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndeficitplotfun(bas = \"Staunton River\", bigG = \"Rapidan River NWIS\", months = c(7:9), wateryears = c(2019, 2020))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndeficitplotfun(bas = \"Flathead\", bigG = \"North Fork Flathead River NWIS\", months = c(7:9), wateryears = c(2020, 2021), dropsites = c(\"BigCreekLower\", \"LangfordCreekUpper\", \"WernerCreek\", \"CycloneCreekMiddle\", \"CoalCreekMiddle\", \"McGeeCreekUpper\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndeficitplotfun(bas = \"Snake River\", bigG = \"Pacific Creek at Moran NWIS\", months = c(7:9), wateryears = c(2021, 2022))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndeficitplotfun(bas = \"Shields River\", bigG = \"Yellowstone River Livingston NWIS\", months = c(7:9), wateryears = c(2020, 2019), dropsites = c(\"Shields River Valley Ranch\", \"Buck Creek\", \"Lodgepole Creek\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndeficitplotfun(bas = \"Donner Blitzen\", bigG = \"Donner Blitzen River nr Frenchglen NWIS\", months = c(7:9), wateryears = c(2022, 2020))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15.5.2 Site-level threshold\nOrganize data\n\n\nCode\ndat_clean_sub_deficit &lt;- dat_clean_sub %&gt;%\n  mutate(deficit_50_fix = ifelse(z_Yield_mm &lt; thresh_50_fix, abs(thresh_50_fix - z_Yield_mm), 0),\n         deficit_45_fix = ifelse(z_Yield_mm &lt; thresh_45_fix, abs(thresh_45_fix - z_Yield_mm), 0),\n         deficit_40_fix = ifelse(z_Yield_mm &lt; thresh_40_fix, abs(thresh_40_fix - z_Yield_mm), 0),\n         deficit_35_fix = ifelse(z_Yield_mm &lt; thresh_35_fix, abs(thresh_35_fix - z_Yield_mm), 0),\n         deficit_30_fix = ifelse(z_Yield_mm &lt; thresh_30_fix, abs(thresh_30_fix - z_Yield_mm), 0),\n         deficit_25_fix = ifelse(z_Yield_mm &lt; thresh_25_fix, abs(thresh_25_fix - z_Yield_mm), 0),\n         deficit_20_fix = ifelse(z_Yield_mm &lt; thresh_20_fix, abs(thresh_20_fix - z_Yield_mm), 0),\n         deficit_15_fix = ifelse(z_Yield_mm &lt; thresh_15_fix, abs(thresh_15_fix - z_Yield_mm), 0),\n         deficit_10_fix = ifelse(z_Yield_mm &lt; thresh_10_fix, abs(thresh_10_fix - z_Yield_mm), 0),\n         deficit_05_fix = ifelse(z_Yield_mm &lt; thresh_05_fix, abs(thresh_05_fix - z_Yield_mm), 0),\n         deficit_02_fix = ifelse(z_Yield_mm &lt; thresh_02_fix, abs(thresh_02_fix - z_Yield_mm), 0))\n\n# summarize by summer\ndefdur_ssn_sub &lt;- dat_clean_sub_deficit %&gt;% \n  filter(!is.na(Yield_mm), Month %in% c(7:9)) %&gt;% \n  group_by(site_name, basin, subbasin, region, designation, CalendarYear, WaterYear) %&gt;% \n  summarize(ndays = n(),\n            propdays = ndays/(31+31+30), \n            duration_50_fix_prop = sum(deficit_50_fix &gt; 0) / ndays,\n            duration_45_fix_prop = sum(deficit_45_fix &gt; 0) / ndays,\n            duration_40_fix_prop = sum(deficit_40_fix &gt; 0) / ndays,\n            duration_35_fix_prop = sum(deficit_35_fix &gt; 0) / ndays,\n            duration_30_fix_prop = sum(deficit_30_fix &gt; 0) / ndays,\n            duration_25_fix_prop = sum(deficit_25_fix &gt; 0) / ndays,\n            duration_20_fix_prop = sum(deficit_20_fix &gt; 0) / ndays,\n            duration_15_fix_prop = sum(deficit_15_fix &gt; 0) / ndays,\n            duration_10_fix_prop = sum(deficit_10_fix &gt; 0) / ndays,\n            duration_05_fix_prop = sum(deficit_05_fix &gt; 0) / ndays,\n            duration_02_fix_prop = sum(deficit_02_fix &gt; 0) / ndays,\n            \n            deficit_50_fix = sum(deficit_50_fix),\n            deficit_45_fix = sum(deficit_45_fix),\n            deficit_40_fix = sum(deficit_40_fix),\n            deficit_35_fix = sum(deficit_35_fix),\n            deficit_30_fix = sum(deficit_30_fix),\n            deficit_25_fix = sum(deficit_25_fix),\n            deficit_20_fix = sum(deficit_20_fix),\n            deficit_15_fix = sum(deficit_15_fix),\n            deficit_10_fix = sum(deficit_10_fix),\n            deficit_05_fix = sum(deficit_05_fix),\n            deficit_02_fix = sum(deficit_02_fix)) %&gt;%\n  ungroup() %&gt;%\n  mutate(designation = ifelse(is.na(designation), \"big\", designation)) %&gt;%\n  filter(propdays &gt;= 0.70) %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z))\n\n# keep raw days for binomial model\ndefdur_ssn_sub2 &lt;- dat_clean_sub_deficit %&gt;% \n  filter(!is.na(Yield_mm), Month %in% c(7:9)) %&gt;% \n  group_by(site_name, basin, subbasin, region, designation, CalendarYear, WaterYear) %&gt;% \n  summarize(ndays = n(),\n            propdays = ndays/(31+31+30), \n            duration_50_fix = sum(deficit_50_fix &gt; 0),\n            duration_45_fix = sum(deficit_45_fix &gt; 0),\n            duration_40_fix = sum(deficit_40_fix &gt; 0),\n            duration_35_fix = sum(deficit_35_fix &gt; 0),\n            duration_30_fix = sum(deficit_30_fix &gt; 0),\n            duration_25_fix = sum(deficit_25_fix &gt; 0),\n            duration_20_fix = sum(deficit_20_fix &gt; 0),\n            duration_15_fix = sum(deficit_15_fix &gt; 0),\n            duration_10_fix = sum(deficit_10_fix &gt; 0),\n            duration_05_fix = sum(deficit_05_fix &gt; 0),\n            duration_02_fix = sum(deficit_02_fix &gt; 0),\n            \n            deficit_50_fix = sum(deficit_50_fix),\n            deficit_45_fix = sum(deficit_45_fix),\n            deficit_40_fix = sum(deficit_40_fix),\n            deficit_35_fix = sum(deficit_35_fix),\n            deficit_30_fix = sum(deficit_30_fix),\n            deficit_25_fix = sum(deficit_25_fix),\n            deficit_20_fix = sum(deficit_20_fix),\n            deficit_15_fix = sum(deficit_15_fix),\n            deficit_10_fix = sum(deficit_10_fix),\n            deficit_05_fix = sum(deficit_05_fix),\n            deficit_02_fix = sum(deficit_02_fix)) %&gt;%\n  ungroup() %&gt;%\n  mutate(designation = ifelse(is.na(designation), \"big\", designation)) %&gt;%\n  filter(propdays &gt;= 0.70) %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z))\n\n\nCreate plotting functions. These are the same as defined above, but instead grab the “defdur_ssn_sub” object for site-level low flow thresholds.\n\n\nCode\ndurationplotfun_sub &lt;- function(bas, bigG, months, wateryears, dropsites = NA) {\n  # filter and summarize data\n  dd &lt;- defdur_ssn_sub %&gt;% \n    filter(basin == bas | site_name == bigG, WaterYear %in% wateryears, !site_name %in% dropsites) %&gt;%\n    mutate(WaterYear = factor(WaterYear, levels = wateryears))\n\n  # order sites, Big G first\n  mysites &lt;- c(unique(unlist(dd %&gt;% filter(designation == \"big\") %&gt;% select(site_name))),\n               unique(unlist(dd %&gt;% filter(designation == \"little\") %&gt;% select(site_name))))\n\n  # among site StDev ~ percentile\n  p_sds &lt;- dd %&gt;% \n    gather(duration_50_fix_prop:duration_02_fix_prop, key = \"metric\", value = \"duration\") %&gt;%\n    mutate(quant = as.numeric(gsub(\".*?([0-9]+).*\", \"\\\\1\", metric)) ) %&gt;% \n    filter(designation == \"little\") %&gt;%\n    group_by(WaterYear, totalyield_z, metric, quant) %&gt;%\n    summarize(sddur = sd(duration, na.rm = TRUE)) %&gt;%\n    ungroup() %&gt;%\n    #left_join(dd %&gt;% filter(site_name == bigG) %&gt;% select(WaterYear, duration_25_fix_prop) %&gt;% rename(dur25 = duration_25_fix_prop)) %&gt;%\n    left_join(wateravail %&gt;% filter(site_name == bigG) %&gt;% select(WaterYear, tyz_sum_perc) %&gt;% mutate(WaterYear = as.factor(WaterYear))) %&gt;%\n    ggplot(aes(x = quant, y = sddur, color = tyz_sum_perc, group = WaterYear, shape = WaterYear)) +\n    stat_smooth() +\n    geom_point() +\n    scale_color_gradient(low = \"red\", high = \"blue\", limits = c(0,100)) +\n    xlab(\"Low flow threshold (percentile)\") + ylab(\"Among-site SD(duration)\") +\n    theme_bw() + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n          legend.position = \"bottom\", legend.direction = \"vertical\", legend.key.height = unit(0.3, 'cm')) \n  \n  # barplot 50th perc\n  p30 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = duration_50_fix_prop)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,1) +\n    ylab(\"Days below low flow threshold (%JAS)\") + ggtitle(\"50th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 25th perc.\n  p20 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = duration_25_fix_prop)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,1) +\n    ylab(\"Days below low flow threshold (%JAS)\") + ggtitle(\"25th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 10th perc.\n  p10 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = duration_10_fix_prop)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,1) +\n    ylab(\"Days below low flow threshold (%JAS)\") + ggtitle(\"10th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 5th perc.\n  p05 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = duration_05_fix_prop)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,1) +\n    ylab(\"Days below low flow threshold (%JAS)\") + ggtitle(\"5th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 2nd perc\n  p02 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = duration_02_fix_prop)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,1) +\n    ylab(\"Days below low flow threshold (%JAS)\") + ggtitle(\"2nd perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n  # arrange plots\n  egg::ggarrange(p02 + theme(plot.margin = margin(r = 1, t = 5, b = 5)), \n                 p05 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)), \n                 p10 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)), \n                 p20 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)), \n                 p30 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)),\n                 p_sds,\n                 nrow = 1, widths = c(1,1,1,1,1,2.5))\n}\n\n\ndeficitplotfun_sub &lt;- function(bas, bigG, months, wateryears, dropsites = NA) {\n  # filter and summarize data\n  dd_all &lt;- defdur_ssn_sub %&gt;% filter(basin == bas | site_name == bigG, WaterYear %in% wateryears, !site_name %in% dropsites) \n  dd &lt;- defdur_ssn_sub %&gt;% \n    filter(basin == bas | site_name == bigG, WaterYear %in% wateryears, !site_name %in% dropsites) %&gt;%\n    mutate(WaterYear = factor(WaterYear, levels = wateryears))\n  \n  # get y-axis limit\n  ymax &lt;- max(dd %&gt;% select(deficit_50_fix:deficit_02_fix))\n\n  # order sites, Big G first\n  mysites &lt;- c(unique(unlist(dd %&gt;% filter(designation == \"big\") %&gt;% select(site_name))),\n               unique(unlist(dd %&gt;% filter(designation == \"little\") %&gt;% select(site_name))))\n\n  # among site StDev ~ percentile\n  p_sds &lt;- dd %&gt;% \n    gather(deficit_50_fix:deficit_02_fix, key = \"metric\", value = \"deficit\") %&gt;%\n    mutate(quant = as.numeric(gsub(\".*?([0-9]+).*\", \"\\\\1\", metric)) ) %&gt;% \n    filter(designation == \"little\") %&gt;%\n    group_by(WaterYear, totalyield_z, metric, quant) %&gt;%\n    summarize(sddur = sd(deficit, na.rm = TRUE)) %&gt;%\n    ungroup() %&gt;%\n    #left_join(dd %&gt;% filter(site_name == bigG) %&gt;% select(WaterYear, deficit_25_fix) %&gt;% rename(def25 = deficit_25_fix)) %&gt;%\n    left_join(wateravail %&gt;% filter(site_name == bigG) %&gt;% select(WaterYear, tyz_sum_perc) %&gt;% mutate(WaterYear = as.factor(WaterYear))) %&gt;%\n    ggplot(aes(x = quant, y = sddur, color = tyz_sum_perc, group = WaterYear, shape = WaterYear)) +\n    stat_smooth() +\n    geom_point() +\n    scale_color_gradient(low = \"red\", high = \"blue\", limits = c(0,100)) +\n    xlab(\"Low flow threshold (percentile)\") + ylab(\"Among-site SD(deficit)\") +\n    theme_bw() + \n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n          legend.position = \"bottom\", legend.direction = \"vertical\", legend.key.height = unit(0.3, 'cm'))\n  \n  # barplot 50th perc\n  p30 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = deficit_50_fix)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,ymax) +\n    ylab(\"Drought deficit (mm, JAS)\") + ggtitle(\"50th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 25th perc.\n  p20 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = deficit_25_fix)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,ymax) +\n    ylab(\"Drought deficit (mm, JAS)\") + ggtitle(\"25th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 10th perc.\n  p10 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = deficit_10_fix)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,ymax) +\n    ylab(\"Drought deficit (mm, JAS)\") + ggtitle(\"10th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 5th perc.\n  p05 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = deficit_05_fix)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,ymax) +\n    ylab(\"Drought deficit (mm, JAS)\") + ggtitle(\"5th perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n  # barplot 2nd perc\n  p02 &lt;- dd %&gt;% \n    ggplot(aes(x = factor(site_name, levels = (mysites)), y = deficit_02_fix)) +\n    geom_bar(aes(fill = designation), stat = \"identity\") +\n    scale_fill_manual(values = c(\"grey20\", \"grey55\")) +\n    facet_wrap2(~WaterYear, ncol = 1, strip = strip_themed(background_x = elem_list_rect(fill = alpha(unique(layer_data(p_sds)[,1]), 0.5)))) +\n    ylim(0,ymax) +\n    ylab(\"Drought deficit (JAS)\") + ggtitle(\"2nd perc.\") +\n    theme_bw() + \n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n          legend.position = \"none\", axis.title.x = element_blank(),\n          panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n  # arrange plots\n  egg::ggarrange(p02 + theme(plot.margin = margin(r = 1, t = 5, b = 5)), \n                 p05 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)), \n                 p10 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)), \n                 p20 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)), \n                 p30 + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), plot.margin = margin(r = 1, l = 1)),\n                 p_sds,\n                 nrow = 1, widths = c(1,1,1,1,1,2.5))\n}\n\n\n\n15.5.2.1 Duration\nShow proportion of days (July - September) below different low flow thresholds (derived from temporally restricted, site-specific data) for each site during a relatively wet year and a dry year. Then, for each year, plot the relationship between the among site (little g’s only) standard deviation of low flow duration and the low flow threshold used to calculate duration\n\nWest BrookStaunton RiverFlatheadSnake RiverYellowstone RiverDonner Blitzen\n\n\n\n\nCode\ndurationplotfun_sub(bas = \"West Brook\", bigG = \"South River Conway NWIS\", months = c(7:9), wateryears = c(2022, 2020, 2021, 2023))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndurationplotfun_sub(bas = \"Staunton River\", bigG = \"Rapidan River NWIS\", months = c(7:9), wateryears = c(2019, 2022, 2021, 2020))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndurationplotfun_sub(bas = \"Flathead\", bigG = \"North Fork Flathead River NWIS\", months = c(7:9), wateryears = c(2019, 2021, 2020))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndurationplotfun_sub(bas = \"Snake River\", bigG = \"Pacific Creek at Moran NWIS\", months = c(7:9), wateryears = c(2021, 2020, 2022))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndurationplotfun_sub(bas = \"Shields River\", bigG = \"Yellowstone River Livingston NWIS\", months = c(7:9), wateryears = c(2020, 2019, 2023, 2017), dropsites = c(\"Shields River Valley Ranch\", \"Buck Creek\", \"Lodgepole Creek\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndurationplotfun_sub(bas = \"Donner Blitzen\", bigG = \"Donner Blitzen River nr Frenchglen NWIS\", months = c(7:9), wateryears = c(2021,2020,2022, 2019))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15.5.2.2 Deficit\nShow total drought deficit (mm) relative to different low flow thresholds (derived from long-term Big G data) for each site during a relatively wet year and a dry year. Then, for each year, plot the relationship between the among site (little g’s only) standard deviation of deficit and the low flow threshold used to calculate deficit\n\nWest BrookStaunton RiverFlatheadSnake RiverYellowstone RiverDonner Blitzen\n\n\n\n\nCode\ndeficitplotfun_sub(bas = \"West Brook\", bigG = \"South River Conway NWIS\", months = c(7:9), wateryears = c(2022, 2020, 2021, 2023))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndeficitplotfun_sub(bas = \"Staunton River\", bigG = \"Rapidan River NWIS\", months = c(7:9), wateryears = c(2019, 2022, 2021, 2020))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndeficitplotfun_sub(bas = \"Flathead\", bigG = \"North Fork Flathead River NWIS\", months = c(7:9), wateryears = c(2019, 2021, 2020))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndeficitplotfun_sub(bas = \"Snake River\", bigG = \"Pacific Creek at Moran NWIS\", months = c(7:9), wateryears = c(2021, 2020, 2022))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndeficitplotfun_sub(bas = \"Shields River\", bigG = \"Yellowstone River Livingston NWIS\", months = c(7:9), wateryears = c(2020, 2019, 2023, 2017), dropsites = c(\"Shields River Valley Ranch\", \"Buck Creek\", \"Lodgepole Creek\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndeficitplotfun_sub(bas = \"Donner Blitzen\", bigG = \"Donner Blitzen River nr Frenchglen NWIS\", months = c(7:9), wateryears = c(2021,2020,2022, 2019))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15.5.3 Summary plots\nWhat is the relationship between regional water availability (total summer flow percentile from long-term big G flow data) and spatial variation in little g drought duration and deficit?\nHypothesis: spatial variation in drought duration and deficit increases in dry years as controls on little G streamflow shift from regional to local (catchment) scales. (This follows directly from objective 1, but specifically considers low flow conditions).\n\n15.5.3.1 Fixed threshold\nFirst, using drought as defined from fixed thresholds (low flow thresholds derived from long-term big G records are applied to each little G)\n\n\nCode\ndefdur_ssn2 &lt;- defdur_ssn %&gt;% \n  filter(designation == \"little\") %&gt;%\n  left_join(defdur_ssn_sub %&gt;% \n              filter(designation == \"little\") %&gt;%\n              select(site_name, basin, WaterYear) %&gt;%\n              group_by(basin, WaterYear) %&gt;%\n              ungroup() %&gt;%\n              mutate(nsites = length(unique(site_name)))) %&gt;%\n  filter(nsites &gt;= 0) %&gt;%\n  mutate(basin = ifelse(basin == \"Shields River\", \"Yellowstone River\",\n                        ifelse(basin == \"Flathead\", \"Flathead River\", basin))) %&gt;%\n  mutate(basin = factor(basin, levels = c(\"West Brook\", \"Staunton River\", \"Flathead River\", \"Yellowstone River\", \"Snake River\", \"Donner Blitzen\")))\n\nwateravail2 &lt;- wateravail %&gt;% \n  mutate(basin = ifelse(basin == \"Shields River\", \"Yellowstone River\",\n                        ifelse(basin == \"Flathead\", \"Flathead River\", basin))) %&gt;%\n  mutate(basin = factor(basin, levels = c(\"West Brook\", \"Piney River\", \"Staunton River\", \"Paine Run\", \"Flathead River\", \"Yellowstone River\", \"Snake River\", \"Donner Blitzen\")))\n\n\n\nDuration: basins combinedDuration: by basinDeficit: basins combinedDeficift: by basin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummarize relationships across thresholds: how does the definition of “low flow”/“drought” change the way we understand the effect of regional water availability on spatial variation in low flow conditions?\n\n\nCode\ncolnums &lt;- c(8:18)\neffecttib &lt;- tibble(threshold = rep(NA, times = length(colnums)),\n                    int_est = rep(NA, times = length(colnums)),\n                    int_se = rep(NA, times = length(colnums)),\n                    slo_est = rep(NA, times = length(colnums)),\n                    slo_se = rep(NA, times = length(colnums)))\n\nfor (i in 1:length(colnums)) {\n  effecttib$threshold[i] &lt;- parse_number(names(defdur_ssn2)[colnums[i]+2])\n  dd &lt;- defdur_ssn2 %&gt;%\n    filter(designation == \"little\") %&gt;%\n    group_by(basin, WaterYear) %&gt;%\n    summarize_at(colnums[i], sd) %&gt;%\n    ungroup() %&gt;%\n    left_join(wateravail2 %&gt;% select(basin, WaterYear, tyz_sum_perc)) %&gt;%\n    rename(sddur = 3)\n  mymod &lt;- summary(lm(sddur ~ tyz_sum_perc, data = dd))\n  effecttib$int_est[i] &lt;- mymod$coefficients[1,1]\n  effecttib$int_se[i] &lt;- mymod$coefficients[1,2]\n  effecttib$slo_est[i] &lt;- mymod$coefficients[2,1]\n  effecttib$slo_se[i] &lt;- mymod$coefficients[2,2]\n}\n\np1 &lt;- effecttib %&gt;%\n  ggplot(aes(x = threshold, y = int_est)) +\n  geom_line(color = \"grey\") +\n  geom_point() + \n  geom_errorbar(aes(ymin = int_est-int_se, ymax = int_est+int_se), width = 1) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  xlab(\"Low flow threshold (percentile)\") + ylab(\"Intercept (spatial variation at\\n0% regional water availability)\") +\n  theme_classic()\n\np2 &lt;- effecttib %&gt;%\n  ggplot(aes(x = threshold, y = slo_est)) +\n  geom_line(color = \"grey\") +\n  geom_point() + \n  geom_errorbar(aes(ymin = slo_est-slo_se, ymax = slo_est+slo_se), width = 1) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  xlab(\"Low flow threshold (percentile)\") + ylab(\"Slope (effect of regional water\\navailability on spatial variation)\") +\n  theme_classic()\n\negg::ggarrange(p1, p2, nrow = 2)\n\n\n\n\n\n\n\n\n\n\n\n15.5.3.2 Site-level threshold\nSecond, using drought as defined from site-specific thresholds (low flow thresholds derived for each site individually)\n\n\nCode\ndefdur_ssn_sub2 &lt;- defdur_ssn_sub %&gt;%\n  mutate(basin = ifelse(basin == \"Shields River\", \"Yellowstone River\",\n                        ifelse(basin == \"Flathead\", \"Flathead River\", basin))) %&gt;%\n  mutate(basin = factor(basin, levels = c(\"West Brook\", \"Piney River\", \"Staunton River\", \"Paine Run\", \n                                          \"Flathead River\", \"Yellowstone River\", \"Snake River\", \"Donner Blitzen\")))\n\n\n\nDuration: basins combinedDuration: by basinDeficit: basins combinedDeficit: by basin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\np1 &lt;- defdur_ssn_sub %&gt;%\n  filter(designation == \"little\") %&gt;%\n  group_by(basin, WaterYear) %&gt;%\n  summarize(sddur = sd(deficit_02_fix)) %&gt;%\n  ungroup() %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield:tyz_sum_perc)) %&gt;%\n  ggplot(aes(x = tyz_sum_perc, y = sddur, color = basin)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_point(aes(color = basin)) +\n  #facet_wrap(~basin) +\n  annotate(\"text\", label = \"2nd perc.\", x = Inf, y = Inf, hjust = 1, vjust = 1) +\n  theme_bw() + theme(panel.grid = element_blank(), axis.title = element_blank(), axis.text.x = element_blank(), legend.position = \"none\") + \n  ylim(0,6)\n\np2 &lt;- defdur_ssn_sub %&gt;%\n  filter(designation == \"little\") %&gt;%\n  group_by(basin, WaterYear) %&gt;%\n  summarize(sddur = sd(deficit_05_fix)) %&gt;%\n  ungroup() %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield:tyz_sum_perc)) %&gt;%\n  ggplot(aes(x = tyz_sum_perc, y = sddur, color = basin)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_point(aes(color = basin)) +\n  #facet_wrap(~basin) +\n  annotate(\"text\", label = \"5th perc.\", x = Inf, y = Inf, hjust = 1, vjust = 1) +\n  theme_bw() + theme(panel.grid = element_blank(), axis.title = element_blank(), axis.text = element_blank()) + ylim(0,6)\n\np3 &lt;- defdur_ssn_sub %&gt;%\n  filter(designation == \"little\") %&gt;%\n  group_by(basin, WaterYear) %&gt;%\n  summarize(sddur = sd(deficit_10_fix)) %&gt;%\n  ungroup() %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield:tyz_sum_perc)) %&gt;%\n  ggplot(aes(x = tyz_sum_perc, y = sddur, color = basin)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_point(aes(color = basin)) +\n  #facet_wrap(~basin) +\n  annotate(\"text\", label = \"10th perc.\", x = Inf, y = Inf, hjust = 1, vjust = 1) +\n  theme_bw() + theme(panel.grid = element_blank(), axis.title = element_blank(), legend.position = \"none\") + ylim(0,6)\n\np4 &lt;- defdur_ssn_sub %&gt;%\n  filter(designation == \"little\") %&gt;%\n  group_by(basin, WaterYear) %&gt;%\n  summarize(sddur = sd(deficit_20_fix)) %&gt;%\n  ungroup() %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield:tyz_sum_perc)) %&gt;%\n  ggplot(aes(x = tyz_sum_perc, y = sddur, color = basin)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_point(aes(color = basin)) +\n  #facet_wrap(~basin) +\n  annotate(\"text\", label = \"20th perc.\", x = Inf, y = Inf, hjust = 1, vjust = 1) +\n  theme_bw() + theme(panel.grid = element_blank(), axis.title = element_blank(), axis.text.y = element_blank(), legend.position = \"none\") + ylim(0,6)\n\nannotate_figure(egg::ggarrange(p1, p2, p3, p4), \n                left = \"Among-site variation in drought deficit (SD)\", bottom = \"Regional water availability (percentile)\")\n\n\n\n\n\n\n\n\n\n\n\n\nSummarize relationships across thresholds: how does the definition of “low flow”/“drought” change the way we understand the effect of regional water availability on spatial variation in low flow conditions?\n\n\nCode\ncolnums &lt;- c(8:18)\neffecttib &lt;- tibble(threshold = rep(NA, times = length(colnums)),\n                    int_est = rep(NA, times = length(colnums)),\n                    int_se = rep(NA, times = length(colnums)),\n                    slo_est = rep(NA, times = length(colnums)),\n                    slo_se = rep(NA, times = length(colnums)))\n\nfor (i in 1:length(colnums)) {\n  effecttib$threshold[i] &lt;- parse_number(names(defdur_ssn_sub2)[colnums[i]+2])\n  dd &lt;- defdur_ssn_sub2 %&gt;%\n    filter(designation == \"little\") %&gt;%\n    group_by(basin, WaterYear) %&gt;%\n    summarize_at(colnums[i], sd) %&gt;%\n    ungroup() %&gt;%\n    left_join(wateravail2 %&gt;% select(basin, WaterYear, tyz_sum_perc)) %&gt;%\n    rename(sddur = 3)\n  mymod &lt;- summary(lm(sddur ~ tyz_sum_perc, data = dd))\n  effecttib$int_est[i] &lt;- mymod$coefficients[1,1]\n  effecttib$int_se[i] &lt;- mymod$coefficients[1,2]\n  effecttib$slo_est[i] &lt;- mymod$coefficients[2,1]\n  effecttib$slo_se[i] &lt;- mymod$coefficients[2,2]\n}\n\np1 &lt;- effecttib %&gt;%\n  ggplot(aes(x = threshold, y = int_est)) +\n  geom_line(color = \"grey\") +\n  geom_point() + \n  geom_errorbar(aes(ymin = int_est-int_se, ymax = int_est+int_se), width = 1) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  xlab(\"Low flow threshold (percentile)\") + ylab(\"Intercept (spatial variation at\\n0% regional water availability)\") +\n  theme_classic()\n\np2 &lt;- effecttib %&gt;%\n  ggplot(aes(x = threshold, y = slo_est)) +\n  geom_line(color = \"grey\") +\n  geom_point() + \n  geom_errorbar(aes(ymin = slo_est-slo_se, ymax = slo_est+slo_se), width = 1) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  xlab(\"Low flow threshold (percentile)\") + ylab(\"Slope (effect of regional water\\navailability on spatial variation)\") +\n  theme_classic()\n\negg::ggarrange(p1, p2, nrow = 2)",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Objective 4</span>"
    ]
  },
  {
    "objectID": "Qualitative/Boxes.html",
    "href": "Qualitative/Boxes.html",
    "title": "16  Boxes",
    "section": "",
    "text": "16.1 Data\nPurpose: Use boxes to highlight additional details of the data, vignettes, and case studies that demonstrate spatiotemporal streamflow heterogeneity\nSite information\nCode\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nLittle g’s\nCode\ndat_clean &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/LittleG_data_clean.csv\")\nBig G’s\nCode\ndat_clean_big &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/BigG_data_clean.csv\")\nClimate\nCode\nclimdf &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/Daymet_climate.csv\")\nclimdf_summ &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/Daymet_climate_summary.csv\")\nWater availability\nCode\nwateravail &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/BigG_wateravailability_annual.csv\")",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Boxes</span>"
    ]
  },
  {
    "objectID": "Qualitative/Boxes.html#box-1",
    "href": "Qualitative/Boxes.html#box-1",
    "title": "16  Boxes",
    "section": "16.2 Box 1",
    "text": "16.2 Box 1\nPurpose: Show what high-resolution temporal data (hourly) reveals about network diversity in streamflow response to individual storms (peak flow magnitude and timing and recession rates) and during low flow (diel fluctuations)",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Boxes</span>"
    ]
  },
  {
    "objectID": "Qualitative/Boxes.html#box-2",
    "href": "Qualitative/Boxes.html#box-2",
    "title": "16  Boxes",
    "section": "16.3 Box 2",
    "text": "16.3 Box 2\nThe Wedge Model for the West Brook\nPurpose: At coarser time scales (summarized by event/baseflow periods), show how streamflow heterogeneity expands and contracts during wet to dry periods.",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Boxes</span>"
    ]
  },
  {
    "objectID": "Qualitative/Boxes.html#box-3",
    "href": "Qualitative/Boxes.html#box-3",
    "title": "16  Boxes",
    "section": "16.4 Box 3",
    "text": "16.4 Box 3\nPurpose: Show what high-resolution spatial data reveals about network diversity in streamflow at a single point in time.",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Boxes</span>"
    ]
  },
  {
    "objectID": "Qualitative/Boxes.html#box-4",
    "href": "Qualitative/Boxes.html#box-4",
    "title": "16  Boxes",
    "section": "16.5 Box 4",
    "text": "16.5 Box 4\nPurpose: Explore the effect of groundwater on relative summer (July-September) water availability.\nLoad PASTA daily derived parameters: summarize as July-September site-specific means (across all years)\n\n\nCode\npasta &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Covariates/pasta_derived_parameters_daily.csv\") %&gt;%\n  mutate(Month = month(date)) %&gt;%\n  rename(CalendarYear = year) %&gt;%\n  filter(Month %in% c(7:9)) %&gt;%\n  group_by(site_name) %&gt;%\n  summarize(meanRatio = mean(meanRatio, na.rm = TRUE),\n            phaseLag = mean(phaseLag, na.rm = TRUE),\n            amplitudeRatio = mean(amplitudeRatio, na.rm = TRUE))\npasta\n\n\n# A tibble: 73 × 4\n   site_name           meanRatio phaseLag amplitudeRatio\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n 1 Avery Brook             0.891     2.31          0.264\n 2 BigCreekLower           0.936     2.22          0.376\n 3 BigCreekMiddle          0.840     1.29          0.411\n 4 BigCreekUpper           0.664     2.31          0.179\n 5 Buck Creek              0.699     1.19          0.353\n 6 CoalCreekHeadwaters     0.670     2.11          0.209\n 7 CoalCreekLower          0.843     2.91          0.503\n 8 CoalCreekMiddle         0.692     1.27          0.223\n 9 CoalCreekNorth          0.733     2.49          0.246\n10 Crandall Creek          0.758     1.76          0.612\n# ℹ 63 more rows\n\n\nCreate flow by groundwater plotting function.\n\n\nCode\nmdaystib &lt;- tibble(Month = c(1:12), mdays = c(31,28,31,30,31,30,31,31,30,31,30,31))\n\ngwflowfun &lt;- function (subbas, years, dropsites, months = c(1:12)) {\n  dat_clean %&gt;% \n  filter(subbasin == subbas, CalendarYear %in% years, Month %in% months) %&gt;%\n  group_by(site_name, subbasin, designation, CalendarYear) %&gt;% #, Month, MonthName) %&gt;%\n  summarise(ss = n(),\n            logYield = mean(logYield, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  #left_join(mdaystib) %&gt;%\n  mutate(pdays = ss/92#,\n         #YearMonth = paste(CalendarYear, \"_\", Month, sep = \"\")\n         ) %&gt;%\n  filter(pdays &gt; 0.9,\n         !site_name %in% dropsites) %&gt;%\n  group_by(CalendarYear) %&gt;%\n  mutate(z_logYield = scale(logYield, center = TRUE, scale = TRUE)[,1]) %&gt;%\n  ungroup() %&gt;%\n  left_join(pasta) %&gt;%\n  ggplot(aes(x = amplitudeRatio, y = z_logYield)) +\n  geom_abline(intercept = 0, slope = 0, linetype = 2) +\n  geom_smooth(method = \"lm\", color = \"black\") +\n  geom_point(aes(color = site_name)) +\n  facet_wrap(~CalendarYear, nrow = 1) +\n  #facet_wrap2(~CalendarYear, nrow = 1, ncol = 5, trim_blank = FALSE) +\n  #facet_grid(cols = vars(Month), rows = vars(CalendarYear)) + \n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) \n}\n\n\nPlot the relationship between standardized annual summer mean discharge and amplitude ratio from PASTA, where lower amplitude ratio values are indicative of greater groundwater availability. Mean flow for each site is standardized by year to remove interannual variation in climate/regional water availability\n\nWest BrookStaunton RiverSnake RiverShields River\n\n\n\n\nCode\ngwflowfun(subbas = \"West Brook\", dropsites = c(\"West Brook Reservoir\", \"Mitchell Brook\"), years = c(2020:2024))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ngwflowfun(subbas = \"Staunton River\", dropsites = NA, years = c(2019:2022))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ngwflowfun(subbas = \"Snake River\", dropsites = NA, years = c(2018, 2020:2022), months = c(7:9))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ngwflowfun(subbas = \"Shields River\", dropsites = NA, years = c(2017,2019,2020,2022,2023), months = c(7:9))",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Boxes</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffKS.html",
    "href": "Big G Little g/GgDiffKS.html",
    "title": "17  G-g Difference (KS)",
    "section": "",
    "text": "17.1 Site info and daily data\nPurpose: Explore effects of monthly/annual water availability on Big-little difference using non-parametric Kolmogorov-Smirnov tests\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# flow/yield (and temp) data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\") %&gt;%\n  filter(!site_name %in% c(\"WoundedBuckCreek\", \"Brackett Creek\"))\n\n# add water/climate year variables\ndat &lt;- add_date_variables(dat, dates = date, water_year_start = 4)",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>G-g Difference (KS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffKS.html#separate-and-join-g-g",
    "href": "Big G Little g/GgDiffKS.html#separate-and-join-g-g",
    "title": "17  G-g Difference (KS)",
    "section": "17.2 Separate and join G-g",
    "text": "17.2 Separate and join G-g\n\n\nCode\n# pull out big G data\ndat_big &lt;- dat %&gt;% filter(site_name %in% c(\"West Brook NWIS\", \"Paine Run 10\", \"Piney River 10\", \"Staunton River 10\", \"Spread Creek Dam\", \"BigCreekLower\", \"Shields River ab Smith NWIS\", \"Donner Blitzen River nr Frenchglen NWIS\")) \n\n# pull out little G data, assign big G site name\ndat_little &lt;- dat %&gt;% \n  filter(designation %in% c(\"little\", \"medium\"), !subbasin %in% c(\"Coal Creek\", \"McGee Creek\", \"Duck Creek\", \"Flathead\"),\n         !site_name %in% c(\"West Brook NWIS\", \"West Brook 0\", \"Paine Run 10\", \"Piney River 10\", \"Staunton River 10\", \"Spread Creek Dam\", \"Shields River ab Smith NWIS\", \"BigCreekLower\")) %&gt;%\n  mutate(site_name_big = ifelse(subbasin == \"Big Creek\", \"BigCreekLower\",\n                                ifelse(subbasin == \"West Brook\", \"West Brook NWIS\", \n                                       ifelse(subbasin == \"Paine Run\", \"Paine Run 10\", \n                                              ifelse(subbasin == \"Piney River\", \"Piney River 10\",\n                                                     ifelse(subbasin == \"Staunton River\", \"Staunton River 10\",\n                                                            ifelse(subbasin == \"Shields River\", \"Shields River ab Smith NWIS\",\n                                                                   ifelse(subbasin == \"Snake River\", \"Spread Creek Dam\", \"Donner Blitzen River nr Frenchglen NWIS\"))))))))\n\n# Join big-little discharge data\ndat_Gg &lt;- dat_little %&gt;%\n  select(site_name, site_name_big, basin, subbasin, date, Month, MonthName, WaterYear, Yield_filled_mm_7) %&gt;% rename(yield_little = Yield_filled_mm_7) %&gt;%\n  left_join(dat_big %&gt;% select(site_name, date, Yield_filled_mm_7) %&gt;% rename(site_name_big = site_name, yield_big = Yield_filled_mm_7)) %&gt;%\n  drop_na() %&gt;% mutate(MonthName = as.character(MonthName))\n\n# table\ndat_Gg %&gt;% group_by(subbasin) %&gt;% summarize(site_name_big = unique(site_name_big)) %&gt;% kable(caption = \"Big G gage names for each focal sub-basin.\")\n\n\n\nBig G gage names for each focal sub-basin.\n\n\nsubbasin\nsite_name_big\n\n\n\n\nBig Creek\nBigCreekLower\n\n\nDonner Blitzen\nDonner Blitzen River nr Frenchglen NWIS\n\n\nPaine Run\nPaine Run 10\n\n\nShields River\nShields River ab Smith NWIS\n\n\nSnake River\nSpread Creek Dam\n\n\nStaunton River\nStaunton River 10\n\n\nWest Brook\nWest Brook NWIS\n\n\n\n\n\nView unique little g site names\n\n\nCode\nsort(unique(dat_Gg$site_name))\n\n\n [1] \"Avery Brook\"                      \"Avery Brook NWIS\"                \n [3] \"Big Creek NWIS\"                   \"BigCreekMiddle\"                  \n [5] \"BigCreekUpper\"                    \"Buck Creek\"                      \n [7] \"Crandall Creek\"                   \"Deep Creek\"                      \n [9] \"Donner Blitzen ab Fish NWIS\"      \"Donner Blitzen ab Indian NWIS\"   \n[11] \"Donner Blitzen nr Burnt Car NWIS\" \"Dugout Creek\"                    \n[13] \"Dugout Creek NWIS\"                \"Fish Creek NWIS\"                 \n[15] \"Grizzly Creek\"                    \"Grouse Creek\"                    \n[17] \"Hallowat Creek NWIS\"              \"HallowattCreekLower\"             \n[19] \"Jimmy Brook\"                      \"LangfordCreekLower\"              \n[21] \"LangfordCreekUpper\"               \"Leidy Creek Mouth\"               \n[23] \"Leidy Creek Mouth NWIS\"           \"Leidy Creek Upper\"               \n[25] \"Lodgepole Creek\"                  \"Mitchell Brook\"                  \n[27] \"NF Spread Creek Lower\"            \"NF Spread Creek Upper\"           \n[29] \"NicolaCreek\"                      \"Obear Brook Lower\"               \n[31] \"Paine Run 01\"                     \"Paine Run 02\"                    \n[33] \"Paine Run 06\"                     \"Paine Run 07\"                    \n[35] \"Paine Run 08\"                     \"Rock Creek\"                      \n[37] \"Sanderson Brook\"                  \"SF Spread Creek Lower\"           \n[39] \"SF Spread Creek Lower NWIS\"       \"SF Spread Creek Upper\"           \n[41] \"Shields River ab Dugout\"          \"SkookoleelCreek\"                 \n[43] \"Staunton River 02\"                \"Staunton River 03\"               \n[45] \"Staunton River 06\"                \"Staunton River 07\"               \n[47] \"Staunton River 09\"                \"WernerCreek\"                     \n[49] \"West Brook Lower\"                 \"West Brook Reservoir\"            \n[51] \"West Brook Upper\"                 \"West Whately Brook\"",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>G-g Difference (KS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffKS.html#compute-gg-difference",
    "href": "Big G Little g/GgDiffKS.html#compute-gg-difference",
    "title": "17  G-g Difference (KS)",
    "section": "17.3 Compute Gg Difference",
    "text": "17.3 Compute Gg Difference\n\n\nCode\nmysites &lt;- unique(dat_Gg$site_name)\nkscompare_list &lt;- list()\nfor (i in 1:length(mysites)) {\n  d &lt;- dat_Gg %&gt;% filter(site_name == mysites[i])\n  yrs &lt;- unique(d$WaterYear)\n  kscompare_list_yr &lt;- list()\n  for(j in 1:length(yrs)) {\n    dy &lt;- d %&gt;% filter(WaterYear == yrs[j])\n    mypvals_monthly &lt;- tibble(site_name = rep(NA, times = 12), \n                              site_name_big = rep(NA, times = 12), \n                              WaterYear = rep(NA, times = 12),\n                              Month = rep(NA, times = 12),\n                              MonthName = rep(NA, times = 12),\n                              days = rep(NA, times = 12),\n                              stat = rep(NA, times = 12),\n                              pval = rep(NA, times = 12))\n    for(k in 1:12) {\n      dym &lt;- dy %&gt;% filter(Month == k)\n      if(dim(dym)[1] &lt; 25) next\n      mytest &lt;- ks.test(dym$yield_little, dym$yield_big, exact = TRUE)\n      mypvals_monthly$site_name[k] &lt;- mysites[i]\n      mypvals_monthly$site_name_big[k] &lt;- unique(dym$site_name_big)\n      mypvals_monthly$WaterYear[k] &lt;- yrs[j]\n      mypvals_monthly$Month[k] &lt;- k\n      mypvals_monthly$MonthName[k] &lt;- unique(dym$MonthName)\n      mypvals_monthly$days[k] &lt;- dim(dym)[1]\n      mypvals_monthly$stat[k] &lt;- mytest$statistic\n      mypvals_monthly$pval[k] &lt;- mytest$p.value\n      }\n    kscompare_list_yr[[j]] &lt;- mypvals_monthly\n    }\n  kscompare_list[[i]] &lt;- do.call(rbind, kscompare_list_yr)\n}\nkscompare &lt;- do.call(rbind, kscompare_list) %&gt;% drop_na()\n\n\nView relationship between KS test statistic and p-value\n\n\nCode\nplot(pval ~ stat, kscompare, xlab = \"KS test statistic\", ylab = \"p-value\")\n\n\n\n\n\n\n\n\n\nView distribution of KS test statistics and p-values\n\n\nCode\nhist(kscompare$stat)\n\n\n\n\n\n\n\n\n\nCode\nhist(kscompare$pval)",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>G-g Difference (KS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffKS.html#calculate-total-yield",
    "href": "Big G Little g/GgDiffKS.html#calculate-total-yield",
    "title": "17  G-g Difference (KS)",
    "section": "17.4 Calculate total yield",
    "text": "17.4 Calculate total yield\n\n\nCode\n# Get total annual and monthly Big G yield and join to KS diffs\n\n# get total annual yield by big G site\ntotyield_annual &lt;- dat_big %&gt;% \n  group_by(site_name, WaterYear, basin, subbasin) %&gt;% \n  summarize(days = n(), yield_annual = sum(Yield_filled_mm, na.rm = TRUE)) %&gt;%\n  filter(!is.na(yield_annual), days &gt;= 360) %&gt;%\n  ungroup() %&gt;%\n  rename(site_name_big = site_name) %&gt;%\n  select(site_name_big, WaterYear, yield_annual) %&gt;%\n  ungroup()\n\n# get total monthly yield by big G site\ntotyield_monthly &lt;- dat_big %&gt;% \n  group_by(site_name, WaterYear, basin, subbasin, Month) %&gt;% \n  summarize(days = n(), yield_monthly = sum(Yield_filled_mm, na.rm = TRUE)) %&gt;%\n  filter(!is.na(yield_monthly), days &gt;= 28) %&gt;%\n  ungroup() %&gt;%\n  rename(site_name_big = site_name) %&gt;%\n  select(site_name_big, WaterYear, Month, yield_monthly) %&gt;%\n  ungroup()",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>G-g Difference (KS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffKS.html#explore-gg-diff-by-water-availability",
    "href": "Big G Little g/GgDiffKS.html#explore-gg-diff-by-water-availability",
    "title": "17  G-g Difference (KS)",
    "section": "17.5 Explore Gg diff by water availability",
    "text": "17.5 Explore Gg diff by water availability\nHypothesis: during wetter periods (months/years) flow regimes become more similar among locations within stream networks (i.e., positive relationship between monthly/annual total yield and KS-test p-value)\nHow might this vary among basins that differ in primary water source (rain vs. snow) and among sites within basins (due to surface vs. subsurface controls on flow)?\n\n\nCode\n# join KS comparison df with annual/monthly water availability\nkscompare &lt;- kscompare %&gt;% left_join(totyield_annual) %&gt;% left_join(totyield_monthly) %&gt;%\n  mutate(MonthName = factor(MonthName, levels = c(\"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\", \"Jan\", \"Feb\", \"Mar\"))) %&gt;%\n  left_join(siteinfo %&gt;% select(site_name, basin))\n\n\n\n17.5.1 Global relationship\nPlot relationship between log(monthly total yield) and log(KS p-value) for all basins, sites, and months combined\n\n\nCode\nkscompare %&gt;% ggplot(aes(x = log(yield_monthly), y = log(pval))) + \n  geom_point(aes(group = MonthName, color = MonthName)) + \n  geom_smooth(method = \"lm\") + geom_abline(slope = 0, intercept = log(0.05), linetype = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\n17.5.2 Basin-level effects\n\n\nCode\n# Plot all sites, facet by basin\nkscompare %&gt;% ggplot(aes(x = log(yield_monthly), y = log(pval))) + \n  geom_point(aes(group = MonthName, color = MonthName)) + facet_wrap(~ basin) + \n  geom_smooth(method = \"lm\") + geom_abline(slope = 0, intercept = log(0.05), linetype = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\n17.5.3 Basin and site effects\n\n\nCode\nmybasins &lt;- unique(kscompare$basin)\nmyplots &lt;- list()\nfor (i in 1:length(mybasins)) {\n  myplots[[i]] &lt;- kscompare %&gt;% \n    filter(basin == mybasins[i]) %&gt;%\n    ggplot(aes(x = log(yield_monthly), y = log(pval))) + \n    geom_point(aes(group = MonthName, color = MonthName)) + \n    facet_wrap(~ site_name) + \n    geom_smooth(method = \"lm\") + \n    geom_abline(slope = 0, intercept = log(0.05), linetype = \"dashed\")\n}\n\n\n\nBig CreekWest BrookPaine RunStaunton RiverShields RiverSnake RiverDonner Blitzen",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>G-g Difference (KS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffJAGS.html",
    "href": "Big G Little g/GgDiffJAGS.html",
    "title": "18  G-g Difference (JAGS)",
    "section": "",
    "text": "18.1 Data\nPurpose: Model effects of monthly/annual water availability on Big-little difference using JAGS",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>G-g Difference (JAGS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffJAGS.html#data",
    "href": "Big G Little g/GgDiffJAGS.html#data",
    "title": "18  G-g Difference (JAGS)",
    "section": "",
    "text": "18.1.1 Site info and daily data\n\n\nCode\n# site information and locations\nsiteinfo &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_SiteInformation.csv\")\nsiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\n\n\n\n\n\n\nCode\n# flow/yield (and temp) data \ndat &lt;- read_csv(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/EcoDrought_FlowTempData_DailyWeekly.csv\") %&gt;%\n  filter(!site_name %in% c(\"WoundedBuckCreek\", \"Brackett Creek\"))\n\n# add water/climate year variables\ndat &lt;- add_date_variables(dat, dates = date, water_year_start = 4)\n\n\n\n\n18.1.2 Separate and join G-g\n\n\nCode\n# pull out big G data\ndat_big &lt;- dat %&gt;% filter(site_name %in% c(\"West Brook NWIS\", \"Paine Run 10\", \"Piney River 10\", \"Staunton River 10\", \"Spread Creek Dam\", \"BigCreekLower\", \"Shields River ab Smith NWIS\", \"Donner Blitzen River nr Frenchglen NWIS\")) \n\n# pull out little G data, assign big G site name\ndat_little &lt;- dat %&gt;% \n  filter(designation %in% c(\"little\", \"medium\"), !subbasin %in% c(\"Coal Creek\", \"McGee Creek\", \"Duck Creek\", \"Flathead\"),\n         !site_name %in% c(\"West Brook NWIS\", \"West Brook 0\", \"Paine Run 10\", \"Piney River 10\", \"Staunton River 10\", \"Spread Creek Dam\", \"Shields River ab Smith NWIS\", \"BigCreekLower\")) %&gt;%\n  mutate(site_name_big = ifelse(subbasin == \"Big Creek\", \"BigCreekLower\",\n                                ifelse(subbasin == \"West Brook\", \"West Brook NWIS\", \n                                       ifelse(subbasin == \"Paine Run\", \"Paine Run 10\", \n                                              ifelse(subbasin == \"Piney River\", \"Piney River 10\",\n                                                     ifelse(subbasin == \"Staunton River\", \"Staunton River 10\",\n                                                            ifelse(subbasin == \"Shields River\", \"Shields River ab Smith NWIS\",\n                                                                   ifelse(subbasin == \"Snake River\", \"Spread Creek Dam\", \"Donner Blitzen River nr Frenchglen NWIS\"))))))))\n\n# Join big-little discharge data\ndat_Gg &lt;- dat_little %&gt;%\n  select(site_name, site_name_big, basin, subbasin, date, Month, MonthName, WaterYear, Yield_filled_mm_7) %&gt;% rename(yield_little = Yield_filled_mm_7) %&gt;%\n  left_join(dat_big %&gt;% select(site_name, date, Yield_filled_mm_7) %&gt;% rename(site_name_big = site_name, yield_big = Yield_filled_mm_7)) %&gt;%\n  drop_na() %&gt;% mutate(MonthName = as.character(MonthName))\n\n# table\ndat_Gg %&gt;% group_by(subbasin) %&gt;% summarise(site_name_big = unique(site_name_big)) %&gt;% kable(caption = \"Big G gage names for each focal sub-basin.\")\n\n\n\nBig G gage names for each focal sub-basin.\n\n\nsubbasin\nsite_name_big\n\n\n\n\nBig Creek\nBigCreekLower\n\n\nDonner Blitzen\nDonner Blitzen River nr Frenchglen NWIS\n\n\nPaine Run\nPaine Run 10\n\n\nShields River\nShields River ab Smith NWIS\n\n\nSnake River\nSpread Creek Dam\n\n\nStaunton River\nStaunton River 10\n\n\nWest Brook\nWest Brook NWIS\n\n\n\n\n\n\n\n18.1.3 Calculate total yield\n\n\nCode\n# Get total annual and monthly Big G yield and join to KS diffs\n\n# get total annual yield by big G site\ntotyield_annual &lt;- dat_big %&gt;% \n  group_by(site_name, WaterYear, basin, subbasin) %&gt;% \n  summarise(days = n(), yield_annual = sum(Yield_filled_mm, na.rm = TRUE)) %&gt;%\n  filter(!is.na(yield_annual), days &gt;= 360) %&gt;%\n  ungroup() %&gt;%\n  rename(site_name_big = site_name) %&gt;%\n  select(site_name_big, WaterYear, yield_annual) %&gt;%\n  ungroup()\n\n# get total monthly yield by big G site\ntotyield_monthly &lt;- dat_big %&gt;% \n  group_by(site_name, WaterYear, basin, subbasin, Month) %&gt;% \n  summarise(days = n(), yield_monthly = sum(Yield_filled_mm, na.rm = TRUE)) %&gt;%\n  filter(!is.na(yield_monthly), days &gt;= 28) %&gt;%\n  ungroup() %&gt;%\n  rename(site_name_big = site_name) %&gt;%\n  select(site_name_big, WaterYear, Month, yield_monthly) %&gt;%\n  ungroup()\n\n\n\n\n18.1.4 Final dataset\nJoin and filter G-g data to relevant basin(s) and years: currently, West Brook CY 2021 only!\n\n\nCode\n# wide format to enable direct difference calculation (Attempt 1)\ndat_Gg2 &lt;- dat_Gg %&gt;% left_join(totyield_annual) %&gt;% left_join(totyield_monthly) %&gt;% \n  filter(basin == \"West Brook\", site_name != \"Avery Broook NWIS\", WaterYear == 2021) %&gt;% \n  mutate(site_name_cd = as.numeric(as.factor(site_name)),\n         z_log_yield_monthly = as.numeric(scale(log(yield_monthly), center = TRUE, scale = TRUE)),\n         month_radian = as_radians((Month/12)*360))\n\n# long format for more standard intercept model (Attempt 2)\ndat_Gg3 &lt;- dat_Gg2 %&gt;% select(site_name, site_name_cd, Month, month_radian, WaterYear, yield_little, yield_big, z_log_yield_monthly) %&gt;%\n  gather(key = \"ind\", value = \"yield\", yield_little, yield_big) %&gt;% mutate(indnum = as.numeric(as.factor(ind))-1)\nhead(dat_Gg3)\n\n\n# A tibble: 6 × 9\n  site_name  site_name_cd Month month_radian WaterYear z_log_yield_monthly ind  \n  &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;               &lt;dbl&gt; &lt;chr&gt;\n1 Avery Bro…            1     4         2.09      2021                1.18 yiel…\n2 Avery Bro…            1     4         2.09      2021                1.18 yiel…\n3 Avery Bro…            1     4         2.09      2021                1.18 yiel…\n4 Avery Bro…            1     4         2.09      2021                1.18 yiel…\n5 Avery Bro…            1     4         2.09      2021                1.18 yiel…\n6 Avery Bro…            1     4         2.09      2021                1.18 yiel…\n# ℹ 2 more variables: yield &lt;dbl&gt;, indnum &lt;dbl&gt;\n\n\nExplore G-g data\n\n\nCode\ndat_Gg2 %&gt;% group_by(WaterYear, Month) %&gt;% summarise(z_log_yield_monthly = unique(z_log_yield_monthly)) %&gt;% \n  ggplot(aes(x = Month, y = z_log_yield_monthly)) + geom_point() + geom_smooth()\n\n\n\n\n\nStandardized (log) total monthly yield at Big G during CY 2021\n\n\n\n\n\n\nCode\ndat_Gg3 %&gt;% ggplot() + geom_boxplot(aes(x = as.factor(Month), y = log(yield), fill = ind)) + facet_wrap(~site_name)\n\n\n\n\n\nDistribution of (log) yield at G-g over time, by site\n\n\n\n\n\n\nCode\ndat_Gg2 %&gt;% \n  group_by(site_name, Month) %&gt;% \n  summarise(yield_little = mean(log(yield_little), na.rm = TRUE), \n            yield_big = mean(log(yield_big), na.rm = TRUE),\n            z_log_yield_monthly = unique(z_log_yield_monthly)) %&gt;%\n  mutate(Qd = yield_little - yield_big) %&gt;% \n  ggplot(aes(x = Month, y = Qd)) + geom_point() + geom_smooth() + ylab(\"mean[log(g) - log(G)]\") + \n  facet_wrap(~site_name) + geom_abline(intercept = 0, slope = 0, linetype = \"dashed\")\n\n\n\n\n\nG-g difference in (log) monthly mean yield over time\n\n\n\n\n\n\nCode\ndat_Gg2 %&gt;% \n  group_by(site_name, Month) %&gt;% \n  summarise(yield_little = mean(log(yield_little), na.rm = TRUE), \n            yield_big = mean(log(yield_big), na.rm = TRUE),\n            z_log_yield_monthly = unique(z_log_yield_monthly)) %&gt;%\n  mutate(Qd = yield_little - yield_big) %&gt;% \n  ggplot(aes(x = z_log_yield_monthly, y = Qd)) + geom_point() + geom_smooth(method = \"lm\") + \n  ylab(\"mean[log(g) - log(G)]\") + facet_wrap(~site_name) + geom_abline(intercept = 0, slope = 0, linetype = \"dashed\")\n\n\n\n\n\nG-g difference in (log) monthly mean yield as a function of (log) total monthly yield at G",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>G-g Difference (JAGS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffJAGS.html#declare-the-jags-model",
    "href": "Big G Little g/GgDiffJAGS.html#declare-the-jags-model",
    "title": "18  G-g Difference (JAGS)",
    "section": "18.2 Declare the JAGS model",
    "text": "18.2 Declare the JAGS model\nFirst attempt tries to model the difference as a derived parameter (like the growth model), but this maintains the temporal structure of the data, and we are primarily interested in the difference in the distributions\n\n\nCode\ncat(\"model {\n\n##--- LIKELIHOOD ---------------------------------------------------##\n\nfor (i in 1:nObs) {\n  Qg[i] ~ dnorm(mu[i], pow(sigma, -2))\n  mu[i] &lt;- QG[i] - Qd[i]\n  Qd[i] &lt;- alpha[sites[i]] + beta[sites[i]] * yield[i]\n  \n  # Log-likelihood\n  loglik[i] &lt;- logdensity.norm(Qg[i], mu[i], pow(sigma, -2))\n  }\n\n\n##--- PRIORS --------------------------------------------------------##\n\n# Process error is shared among sites\nsigma ~ dunif(0.001, 100)\n\n# Site-specific parameters\nfor (k in 1:nSites) {\n  alpha[k] ~ dnorm(alpha.mu, pow(sigma.alpha, -2))\n  beta[k] ~ dnorm(beta.mu, pow(sigma.beta, -2))\n  }\n\n# Global parameters\nalpha.mu ~ dnorm(0, pow(10, -2))\nbeta.mu ~ dnorm(0, pow(10, -2))\n\n# Site-level variation in alpha and beta\nsigma.alpha ~ dunif(0.001, 100)\nsigma.beta ~ dunif(0.001, 100)\n\n}\", file = \"./Big G Little g/JAGS Models/GgMod.txt\")\n\n\nSecond attempt is a more standard intercept model.\n\n“alpha” is the mean monthly yield at Big-G, which is shared among sites\n“beta1” is a Little-g offset to the intercept, which describes the site-level mean G-g difference\n“beta2” describes the effect of water availability (log total monthly yield at Big G) on the site-level mean G-g difference.\n\nNote that this is only “turned on” for little-g (ind[i] = 1)\n\nShould add covariates on sigma to deal with unequal variance among groups\n\n\n\nCode\ncat(\"model {\n\n##--- LIKELIHOOD ---------------------------------------------------##\n\nfor (i in 1:nObs) {\n  Q[i] ~ dnorm(mu[i], pow(sigma, -2))\n  mu[i] &lt;- alpha[months[i]] + beta1[sites[i]] * ind[i] + beta2[sites[i]] * ind[i] * yieldtot[i]\n  \n  # Log-likelihood\n  loglik[i] &lt;- logdensity.norm(Q[i], mu[i], pow(sigma, -2))\n  }\n\n\n##--- PRIORS --------------------------------------------------------##\n\n# Process error is shared among sites\nsigma ~ dunif(0.001, 100)\n\n# Site-specific parameters\nfor (j in 1:nSites) {\n  beta1[j] ~ dnorm(0, pow(10, -2))\n  beta2[j] ~ dnorm(0, pow(10, -2))\n  }\n\nfor(k in 1:nMonths) {\n  alpha[k] ~ dnorm(0, pow(10, -2))\n  }\n\n}\", file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod.txt\")",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>G-g Difference (JAGS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffJAGS.html#fit-the-jags-model",
    "href": "Big G Little g/GgDiffJAGS.html#fit-the-jags-model",
    "title": "18  G-g Difference (JAGS)",
    "section": "18.3 Fit the JAGS model",
    "text": "18.3 Fit the JAGS model\n\n\nCode\n# gather data for JAGS\n# jags.data &lt;- list(\"nObs\" = dim(dat_Gg2)[1], \"nSites\" = length(unique(dat_Gg2$site_name_cd)), \"sites\" = dat_Gg2$site_name_cd, \n#                   \"Qg\" = dat_Gg2$yield_little, \"QG\" = dat_Gg2$yield_big, \"yield\" = dat_Gg2$z_yield_monthly)\njags.data &lt;- list(\"nObs\" = dim(dat_Gg3)[1], \"nSites\" = length(unique(dat_Gg3$site_name_cd)), \"nMonths\" = length(unique(dat_Gg3$Month)), \n                  \"sites\" = dat_Gg3$site_name_cd, \"months\" = dat_Gg3$Month,\n                  \"Q\" = log(dat_Gg3$yield+0.01), \"ind\" = dat_Gg3$indnum, \"yieldtot\" = dat_Gg3$z_log_yield_monthly)\n\n# parameters to monitor\n# jags.params &lt;- c(\"alpha\", \"alpha.mu\", \"sigma.alpha\", \"beta\", \"beta.mu\", \"sigma.beta\", \"sigma\", \"loglik\")\njags.params &lt;- c(\"alpha\", \"beta1\", \"beta2\", \"sigma\", \"loglik\")\n\n# run in jags\nmod_0 &lt;- jags.parallel(data = jags.data, inits = NULL, parameters.to.save = jags.params,\n                       model.file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod.txt\",\n                       n.chains = 6, n.thin = 20, n.burnin = 1000, n.iter = 5000, DIC = TRUE)\n# saveRDS(mod_0, \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Big G Little g/JAGS Models/GgMod.RDS\")\n\n\nAny problematic R-hat values?\n\n\nCode\nmod_0$BUGSoutput$summary[,8][mod_0$BUGSoutput$summary[,8] &gt; 1.01]\n\n\nloglik[411] loglik[618] loglik[710] \n   1.010734    1.010492    1.010209 \n\n\n\n18.3.1 View traceplots\n\n\nCode\nMCMCtrace(mod_0, ind = TRUE, params = c(\"alpha\", \"beta1\", \"beta2\", \"sigma\"), pdf = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n18.3.2 Get MCMC samples and summary\n\n\nCode\ntop_mod &lt;- mod_0\n# generate MCMC samples and store as an array\nmodelout &lt;- top_mod$BUGSoutput\nMcmcList &lt;- vector(\"list\", length = dim(modelout$sims.array)[2])\nfor(i in 1:length(McmcList)) { McmcList[[i]] = as.mcmc(modelout$sims.array[,i,]) }\n# rbind MCMC samples from 10 chains \nMcmcdat &lt;- rbind(McmcList[[1]], McmcList[[2]], McmcList[[3]], McmcList[[4]], McmcList[[5]], McmcList[[6]])\nparam.summary &lt;- modelout$summary\nhead(param.summary)\n\n\n                mean         sd       2.5%        25%         50%         75%\nalpha[1]  0.59568531 0.02638917  0.5436847  0.5777065  0.59598800  0.61348801\nalpha[2] -0.09285564 0.02604134 -0.1432750 -0.1101489 -0.09325746 -0.07525745\nalpha[3]  0.49066445 0.02564605  0.4400611  0.4732223  0.49017450  0.50739094\nalpha[4]  1.27031184 0.02555007  1.2214453  1.2523105  1.27030194  1.28782775\nalpha[5]  0.55785916 0.02648229  0.5064006  0.5406703  0.55804078  0.57554557\nalpha[6] -1.55636636 0.02595081 -1.6059092 -1.5743114 -1.55681564 -1.53864122\n               97.5%      Rhat n.eff\nalpha[1]  0.64672138 0.9993902  1200\nalpha[2] -0.04258177 1.0030019   780\nalpha[3]  0.53995110 1.0029285   790\nalpha[4]  1.32114123 1.0022643   930\nalpha[5]  0.61039691 1.0043291   650\nalpha[6] -1.50654107 1.0000613  1200",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>G-g Difference (JAGS)</span>"
    ]
  },
  {
    "objectID": "Big G Little g/GgDiffJAGS.html#plot-model-output",
    "href": "Big G Little g/GgDiffJAGS.html#plot-model-output",
    "title": "18  G-g Difference (JAGS)",
    "section": "18.4 Plot model output",
    "text": "18.4 Plot model output\n\n\nCode\n# control panel\nnvals &lt;- 100\nnsim &lt;- 50\nnsites &lt;- length(unique(dat_Gg3$site_name_cd))\nx_seq &lt;- seq(from = min(dat_Gg2$z_log_yield_monthly), to = max(dat_Gg2$z_log_yield_monthly), length.out = nvals)\n\n# predict from model\npred_arr &lt;- array(NA, dim = c(nsim, nvals, nsites))\nfor (k in 1:nsites) {\n  for (j in 1:nsim) {\n    pred_arr[j,,k] &lt;- Mcmcdat[j,paste(\"beta1[\", k, \"]\", sep = \"\")] + Mcmcdat[j,paste(\"beta2[\", k, \"]\", sep = \"\")] * x_seq\n  }\n}\n# pred_dist_lin &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nrgs)\n# for (i in 1:nrow(pred_dist_lin)) { pred_dist_lin[i,] &lt;- exp(Mcmcdat[i,\"alpha\"] + Mcmcdat[i,\"beta1\"]*pdist) }\n# pred_dist_tran &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nrgs)\n# for (i in 1:nrow(pred_dist_tran)) { pred_dist_tran[i,] &lt;-  pred_dist_lin[i,] / rowSums(pred_dist_lin)[i] }\n# pred_lower &lt;- apply(pred_dist_tran, MARGIN = 2, quantile, prob = 0.025)\n# pred_upper &lt;- apply(pred_dist_tran, MARGIN = 2, quantile, prob = 0.975)\n# pred_median &lt;- apply(pred_dist_tran, MARGIN = 2, quantile, prob = 0.5)\n\n\n\n\nCode\npar(mar = c(5,5,2,12))\nmycols &lt;- brewer.pal(9, \"Set1\")\nplot(seq(from = range(pred_arr)[1], to = range(pred_arr)[2], length.out = nvals) ~ x_seq, type = \"n\", xlab = \"(log) Monthly total yield at Big G (z-score)\", ylab = \"Little g deviation from Big G\")\nfor (k in 1:nsites) {\n  for (j in 1:nsim) {\n    lines(pred_arr[j,,k] ~ x_seq, col = alpha(mycols[k], 0.3))\n  }\n}\nabline(h = 0, lty = 2)\npar(xpd = TRUE)\nlegend(\"right\", inset = c(-0.4,0), legend = unlist(dat_Gg3 %&gt;% group_by(site_name) %&gt;% summarise(stcd = unique(site_name_cd)) %&gt;% select(site_name)), fill = mycols, bty = \"n\")\n\n\n\n\n\nG-g mean difference in (log) yield as a function of (log) total monthly yield at G",
    "crumbs": [
      "DEPRECATED",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>G-g Difference (JAGS)</span>"
    ]
  },
  {
    "objectID": "Qualitative/Hysteresis.html#by-event",
    "href": "Qualitative/Hysteresis.html#by-event",
    "title": "13  Objective 2",
    "section": "13.5 By event",
    "text": "13.5 By event\n\n\nCode\nmycols &lt;- c(brewer.pal(8, \"Dark2\"), \"dodgerblue\", \"darkorchid\")\n\nevents &lt;- hysteresis %&gt;% filter(subbasin == \"Staunton River\", WaterYear == 2020, eventid == 2)\nlength(unique(events$mindate))\n\n\n[1] 1\n\n\nCode\nlength(unique(events$maxdate))\n\n\n[1] 1\n\n\nCode\ndat_clean_hyst %&gt;% \n  filter(subbasin == unique(events$subbasin), \n         date &gt;= unique(events$mindate), \n         date &lt;= unique(events$maxdate)) %&gt;%\n  ggplot(aes(x = logYield_big, y = logYield, group = site_name, color = site_name)) +\n  geom_segment(aes(xend = c(tail(logYield_big, n = -1), NA), yend = c(tail(logYield, n = -1), NA)), \n               arrow = arrow(length = unit(0.2, \"cm\")), color = \"black\") +\n  geom_point() + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #scale_color_gradientn(colors = cet_pal(250, name = \"r1\"), trans = \"date\") +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\n\nCode\ndat_clean_hyst %&gt;% \n  filter(subbasin == unique(events$subbasin), \n         date &gt;= unique(events$mindate), \n         date &lt;= unique(events$maxdate)) %&gt;%\n  ggplot(aes(x = logYield_big, y = logYield, group = site_name, color = site_name)) +\n  geom_segment(aes(xend = c(tail(logYield_big, n = -1), NA), yend = c(tail(logYield, n = -1), NA)), \n               arrow = arrow(length = unit(0.2, \"cm\")), color = \"black\") +\n  geom_point() + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") + \n  #scale_color_gradientn(colors = cet_pal(250, name = \"r1\"), trans = \"date\") +\n  facet_wrap(~site_name) +\n  theme_bw() + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nCode\ntemp2 &lt;- hysteresis %&gt;% \n  #filter(subbasin == \"West Brook\") %&gt;%\n  mutate(eventid_global = paste(WaterYear, eventid, sep = \"-\")) %&gt;%\n  group_by(subbasin, eventid_global, mindate, totalyieldevent_big) %&gt;%\n  summarize(nsites = n(), sdhyst = sd(hysteresis), meanhyst = mean(abs(hysteresis)), sd_totalyieldevent_little = sd(totalyieldevent_little)) %&gt;%\n  ungroup()\n\ntemp2$antecedant &lt;- NA\nfor (i in 1:dim(temp2)[1]) {\n  temp2$antecedant[i] &lt;- sum(unlist(dat_clean_big %&gt;% filter(subbasin == unique(temp2$subbasin), date &lt; temp2$mindate[i], date &gt;= temp2$mindate[i]-days(30)) %&gt;% select(Yield_mm)))\n}\nhead(temp2)\n\n\n# A tibble: 6 × 9\n  subbasin  eventid_global mindate    totalyieldevent_big nsites sdhyst meanhyst\n  &lt;chr&gt;     &lt;chr&gt;          &lt;date&gt;                   &lt;dbl&gt;  &lt;int&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1 Big Creek 2019-1         2018-10-26               14.9       3  0.815    2.08 \n2 Big Creek 2019-2         2019-03-21              188.        1 NA        4.91 \n3 Big Creek 2019-2         2019-03-21              291.        1 NA        2.18 \n4 Big Creek 2019-2         2019-03-21              352.        1 NA        1.77 \n5 Big Creek 2020-1         2019-12-21                2.38      3  0.355    0.937\n6 Big Creek 2020-2         2020-01-31                2.19      2  0        0.226\n# ℹ 2 more variables: sd_totalyieldevent_little &lt;dbl&gt;, antecedant &lt;dbl&gt;\n\n\nLarger events at big G (cumulative flow) tend to be associated with larger events at little g’s.\n\n\nCode\nhysteresis %&gt;% #filter(subbasin == \"West Brook\") %&gt;%\n  mutate(eventid_global = paste(WaterYear, eventid, sep = \"-\")) %&gt;%\n  ggplot(aes(x = totalyieldevent_big, y = totalyieldevent_little)) + \n  geom_point(aes(color = eventid_global)) +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +\n  geom_quantile(color = \"black\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\") +\n  facet_wrap(~subbasin, scales = \"free\")\n\n\n\n\n\n\n\n\n\nVariation among little g flow volume also increases with event magnitude.\n\n\nCode\ntemp2 %&gt;%\n  ggplot(aes(x = log(totalyieldevent_big), y = log(sd_totalyieldevent_little))) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  xlab(\"(log) Cumulative yield at big G\") + ylab(\"(log) SD cumulative yield at little G\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\") +\n  facet_wrap(~subbasin, scales = \"free\")\n\n\n\n\n\n\n\n\n\nEvents with greater average hysteresis also tend to be more variable among the little g’s\n\n\nCode\np1 &lt;- temp2 %&gt;%\n  ggplot(aes(x = meanhyst, y = sdhyst)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  xlab(\"Mean hysteresis (among little g's)\") + ylab(\"SD hysteresis (among little g's)\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n\np2 &lt;- temp2 %&gt;%\n  ggplot(aes(x = log(meanhyst), y = log(sdhyst))) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  xlab(\"(log) Mean hysteresis (among little g's)\") + ylab(\"(log) SD hysteresis (among little g's)\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n\nggarrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\n\n\nGenerally, larger events (cumulative yield at big G) lead to greater mean hysteresis among little g’s and more variation in hysteresis among little g’s\n\n\nCode\np1 &lt;- temp2 %&gt;%\n  filter(sdhyst &gt; 0) %&gt;%\n  ggplot(aes(x = (totalyieldevent_big), y = (meanhyst))) +\n  geom_point() +\n  geom_smooth() +\n  xlab(\"Cumulative yield at big G\") + ylab(\"Mean hysteresis\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n\np2 &lt;- temp2 %&gt;%\n  filter(sdhyst &gt; 0) %&gt;%\n  ggplot(aes(x = (totalyieldevent_big), y = (sdhyst))) +\n  geom_point() +\n  geom_smooth() +\n  xlab(\"Cumulative yield at big G\") + ylab(\"SD hysteresis)\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n\np3 &lt;- temp2 %&gt;%\n  filter(sdhyst &gt; 0) %&gt;%\n  ggplot(aes(x = log(totalyieldevent_big), y = log(meanhyst))) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  xlab(\"(log) Cumulative yield at big G\") + ylab(\"(log) Mean hysteresis\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n\np4 &lt;- temp2 %&gt;%\n  filter(sdhyst &gt; 0) %&gt;%\n  ggplot(aes(x = log(totalyieldevent_big), y = log(sdhyst))) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  xlab(\"(log) Cumulative yield at big G\") + ylab(\"(log) SD hysteresis\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n\nggarrange(p1, p2, p3, p4, nrow = 2, ncol = 2)\n\n\n\n\n\n\n\n\n\nEvents with greater average hysteresis also tend to be more variable among the little g’s\n\n\nCode\np1 &lt;- temp2 %&gt;%\n  ggplot(aes(x = antecedant, y = meanhyst)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  xlab(\"Antecedant cumulative flow (30 days)\") + ylab(\"Mean hysteresis\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n\np2 &lt;- temp2 %&gt;%\n  ggplot(aes(x = antecedant, y = sdhyst)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  xlab(\"Antecedant cumulative flow (30 days)\") + ylab(\"SD hysteresis\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\")\n\nggarrange(p1, p2, ncol = 2)",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Objective 2</span>"
    ]
  },
  {
    "objectID": "Qualitative/SpaceTimeVar.html#order-sites",
    "href": "Qualitative/SpaceTimeVar.html#order-sites",
    "title": "12  Objective 1",
    "section": "12.2 Order sites",
    "text": "12.2 Order sites\nFor colors, order sites from downstream to upstream (roughly) and by subbasin (if appropriate)\n\n\nCode\nwborder &lt;- c(\"West Brook NWIS\", \"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")\npaineorder &lt;- c(\"Paine Run 10\", \"Paine Run 08\", \"Paine Run 07\", \"Paine Run 06\", \"Paine Run 02\", \"Paine Run 01\")\nstauntorder &lt;- c(\"Staunton River 10\", \"Staunton River 09\", \"Staunton River 07\", \"Staunton River 06\", \"Staunton River 03\", \"Staunton River 02\")\nflatorder &lt;- c(\"BigCreekLower\", \"LangfordCreekLower\", \"LangfordCreekUpper\", \"Big Creek NWIS\", \"BigCreekUpper\", \"HallowattCreekLower\", \"NicolaCreek\", \"WernerCreek\", \"Hallowat Creek NWIS\", \"CoalCreekLower\", \"CycloneCreekLower\", \"CycloneCreekMiddle\", \"CycloneCreekUpper\", \"CoalCreekMiddle\", \"CoalCreekNorth\", \"CoalCreekHeadwaters\", \"McGeeCreekLower\", \"McGeeCreekTrib\", \"McGeeCreekUpper\")\nyellorder &lt;- c(\"Shields River Valley Ranch\", \"Deep Creek\", \"Crandall Creek\", \"Buck Creek\", \"Dugout Creek\", \"Shields River ab Dugout\", \"Lodgepole Creek\", \"EF Duck Creek be HF\", \"EF Duck Creek ab HF\", \"Henrys Fork\")\nsnakeorder &lt;- c(\"Spread Creek Dam\", \"Rock Creek\", \"NF Spread Creek Lower\", \"NF Spread Creek Upper\", \"Grizzly Creek\", \"SF Spread Creek Lower\", \"Grouse Creek\", \"SF Spread Creek Upper\", \"Leidy Creek Mouth\")\ndonnerorder &lt;- c(\"Fish Creek NWIS\", \"Donner Blitzen ab Fish NWIS\", \"Donner Blitzen nr Burnt Car NWIS\", \"Donner Blitzen ab Indian NWIS\")",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Objective 1</span>"
    ]
  },
  {
    "objectID": "Qualitative/SpaceTimeVar.html#flow-range",
    "href": "Qualitative/SpaceTimeVar.html#flow-range",
    "title": "12  Objective 1",
    "section": "12.6 Flow Range",
    "text": "12.6 Flow Range\nHow does the range of (summer) flow change with water availability?\nFirst, on daily values:\n\n\nCode\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"West Brook\", !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = wborder))\ntempdat &lt;- tempdat %&gt;% left_join(dat_clean_big %&gt;% filter(basin == \"West Brook\") %&gt;% select(basin, date, logYield) %&gt;% rename(logYield_big = logYield))\ntempdat &lt;- tempdat %&gt;% group_by(date) %&gt;% summarize(nsites = n(), lgrange = range(logYield)[2] - range(logYield)[1], logYield_big = unique(logYield_big))\np1 &lt;- tempdat %&gt;% filter(nsites == 10) %&gt;% \n  ggplot(aes(x = logYield_big, y = log(lgrange), group = year(date))) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  ggtitle(\"West Brook\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n                     axis.text = element_text(color = \"black\"), legend.position = \"none\")\n\n\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Paine Run\", !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = wborder))\ntempdat &lt;- tempdat %&gt;% left_join(dat_clean_big %&gt;% filter(basin == \"Paine Run\") %&gt;% select(basin, date, logYield) %&gt;% rename(logYield_big = logYield))\ntempdat &lt;- tempdat %&gt;% group_by(date) %&gt;% summarize(nsites = n(), lgrange = range(logYield)[2] - range(logYield)[1], logYield_big = unique(logYield_big))\np2 &lt;- tempdat %&gt;% filter(nsites == 5) %&gt;%\n  ggplot(aes(x = logYield_big, y = log(lgrange), group = year(date))) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  ggtitle(\"Paine Run\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n                     axis.text = element_text(color = \"black\"), legend.position = \"none\")\n\n\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Staunton River\", !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = wborder))\ntempdat &lt;- tempdat %&gt;% left_join(dat_clean_big %&gt;% filter(basin == \"Staunton River\") %&gt;% select(basin, date, logYield) %&gt;% rename(logYield_big = logYield))\ntempdat &lt;- tempdat %&gt;% group_by(date) %&gt;% summarize(nsites = n(), lgrange = range(logYield)[2] - range(logYield)[1], logYield_big = unique(logYield_big))\np3 &lt;- tempdat %&gt;% filter(nsites == 6) %&gt;% \n  ggplot(aes(x = logYield_big, y = log(lgrange), group = year(date))) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  ggtitle(\"Staunton River\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n                     axis.text = element_text(color = \"black\"), legend.position = \"none\")\n\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Flathead\", !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = wborder))\ntempdat &lt;- tempdat %&gt;% left_join(dat_clean_big %&gt;% filter(basin == \"Flathead\") %&gt;% select(basin, date, logYield) %&gt;% rename(logYield_big = logYield))\ntempdat &lt;- tempdat %&gt;% group_by(date) %&gt;% summarize(nsites = n(), lgrange = range(logYield)[2] - range(logYield)[1], logYield_big = unique(logYield_big))\np4 &lt;- tempdat %&gt;% filter(nsites &gt;= 10) %&gt;% \n  ggplot(aes(x = logYield_big, y = log(lgrange), group = year(date))) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  ggtitle(\"Flathead River\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n                     axis.text = element_text(color = \"black\"), legend.position = \"none\")\n\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Shields River\", !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = wborder))\ntempdat &lt;- tempdat %&gt;% left_join(dat_clean_big %&gt;% filter(basin == \"Shields River\") %&gt;% select(basin, date, logYield) %&gt;% rename(logYield_big = logYield))\ntempdat &lt;- tempdat %&gt;% group_by(date) %&gt;% summarize(nsites = n(), lgrange = range(logYield)[2] - range(logYield)[1], logYield_big = unique(logYield_big))\np5 &lt;- tempdat %&gt;% filter(nsites == 9) %&gt;% \n  ggplot(aes(x = logYield_big, y = log(lgrange), group = year(date))) + \n  geom_point() + \n  geom_smooth() + \n  ggtitle(\"Yellowstone River\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n                     axis.text = element_text(color = \"black\"), legend.position = \"none\")\n\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Snake River\", !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = wborder))\ntempdat &lt;- tempdat %&gt;% left_join(dat_clean_big %&gt;% filter(basin == \"Snake River\") %&gt;% select(basin, date, logYield) %&gt;% rename(logYield_big = logYield))\ntempdat &lt;- tempdat %&gt;% group_by(date) %&gt;% summarize(nsites = n(), lgrange = range(logYield)[2] - range(logYield)[1], logYield_big = unique(logYield_big))\np6 &lt;- tempdat %&gt;% filter(nsites == 9) %&gt;% \n  ggplot(aes(x = logYield_big, y = log(lgrange), group = year(date))) + \n  geom_point() +\n  geom_smooth(method = \"lm\") + \n  ggtitle(\"Snake River\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n                     axis.text = element_text(color = \"black\"), legend.position = \"none\")\n\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Donner Blitzen\", !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = wborder))\ntempdat &lt;- tempdat %&gt;% left_join(dat_clean_big %&gt;% filter(basin == \"Donner Blitzen\") %&gt;% select(basin, date, logYield) %&gt;% rename(logYield_big = logYield))\ntempdat &lt;- tempdat %&gt;% group_by(date) %&gt;% summarize(nsites = n(), lgrange = range(logYield)[2] - range(logYield)[1], logYield_big = unique(logYield_big))\np7 &lt;- tempdat %&gt;% filter(nsites == 4) %&gt;% \n  ggplot(aes(x = logYield_big, y = log(lgrange), group = year(date))) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  ggtitle(\"Donner Blitzen\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n                     axis.text = element_text(color = \"black\"), legend.position = \"none\")\n\n\nannotate_figure(egg::ggarrange(p1 + theme(axis.title.x = element_blank(), axis.title.y = element_blank()), \n                               p2 + theme(axis.title.x = element_blank(), axis.title.y = element_blank()), \n                               p3 + theme(axis.title.x = element_blank(), axis.title.y = element_blank()), \n                               p4 + theme(axis.title.x = element_blank(), axis.title.y = element_blank()), \n                               p5 + theme(axis.title.x = element_blank(), axis.title.y = element_blank()), \n                               p6 + theme(axis.title.x = element_blank(), axis.title.y = element_blank()), \n                               p7 + theme(axis.title.x = element_blank(), axis.title.y = element_blank())),\n                bottom = \"log(Yield at big G)\", left = \"Range of little g log(Yield) (logged)\")\n\n\n\n\n\n\n\n\n\nNow compare distributions\n\n\nCode\nportfolioplot &lt;- function(bas, orderr, type = c(\"interann\", \"annual\", \"scatter\"), wtryrs) {\n  # filter data\n  tempdat &lt;- dat_clean %&gt;% \n    filter(basin == bas, !is.na(logYield), Month %in% c(7:9), WaterYear %in% wtryrs) %&gt;%\n    mutate(site_name = factor(site_name, levels = orderr))\n  nsites &lt;- length(unique(tempdat$site_name))\n  tempdat_big &lt;- dat_clean_big %&gt;% filter(basin == bas, !is.na(logYield), Month %in% c(7:9), WaterYear %in% unique(tempdat$WaterYear))\n\n  # calculate variability for reference gage\n  varbig &lt;- tempdat_big %&gt;% \n    group_by(WaterYear) %&gt;% \n    summarize(bigrange = range(logYield)[2]-range(logYield)[1],\n              bigsd = sd(logYield),\n              bigvar = var(logYield)) %&gt;%\n    ungroup()\n\n  # calculate total summer water availability from reference gage\n  #summerflow &lt;- tempdat_big %&gt;% group_by(WaterYear) %&gt;% summarize(summeryield = sum(Yield_mm), summeryield_log = log(sum(Yield_mm))) %&gt;% ungroup()\n  #wateravail2 &lt;- wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z)\n\n\n  # calculate relative variation\n  pedat &lt;- tempdat %&gt;% \n    group_by(basin, WaterYear) %&gt;% \n    summarize(nsites = length(unique(site_name)),\n              littlerange = range(logYield)[2]-range(logYield)[1],\n              littlesd = sd(logYield),\n              littlevar = var(logYield)) %&gt;% \n    ungroup() %&gt;% \n    left_join(varbig) %&gt;%\n    mutate(pe_range = ((littlerange-bigrange)/bigrange),\n           pe_sd = ((littlesd-bigsd)/bigsd),\n           pe_var = ((littlevar-bigvar)/bigvar)) %&gt;%\n    left_join(wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z, totalyield_sum, totalyield_sum_z)) %&gt;% \n    filter(WaterYear %in% wtryrs) %&gt;%\n    mutate(wylab = substr(WaterYear, 3, 4))\n\n  # interannual\n  pint &lt;- ggplot() + \n    geom_density(data = tempdat, aes(x = logYield, y = ..scaled.., color = site_name, fill = site_name), size = 0.8) +\n    scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n    scale_fill_manual(values = alpha(cet_pal(nsites, name = \"i1\"), 0.1)) +\n    geom_density(data = tempdat_big, aes(x = logYield, y = ..scaled..), color = \"grey40\", fill = alpha(\"grey40\", 0.2), size = 0.8) +\n    xlab(\"Summer log(Yield)\") + ylab(\"Scaled density\") +\n    theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n                       axis.text = element_text(color = \"black\"), legend.position = \"none\")\n\n  # annual\n  pann &lt;- ggplot() +\n    geom_density(data = tempdat, aes(x = logYield, y = ..scaled.., color = site_name, fill = site_name), size = 0.8) +\n    scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n    scale_fill_manual(values = alpha(cet_pal(nsites, name = \"i1\"), 0.1)) +\n    geom_density(data = tempdat_big, aes(x = logYield, y = ..scaled..), color = \"grey40\", fill = alpha(\"grey40\", 0.2), size = 0.8) +\n    xlab(\"Summer log(Yield)\") + ylab(\"Scaled density\") +\n    theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n                       axis.text = element_text(color = \"black\"), legend.position = \"none\") +\n    facet_wrap(~factor(WaterYear, levels = as.numeric(unlist(pedat %&gt;% arrange(totalyield_sum_z) %&gt;% select(WaterYear)))))\n\n  # portfolio effect by water availability\n  ppew &lt;- pedat %&gt;% \n    ggplot(aes(x = totalyield_sum_z, y = pe_range, label = wylab)) + \n    geom_smooth(method = \"lm\", color = \"black\") + \n    geom_point(shape = 21, fill = \"skyblue1\", size = 3) +\n    geom_text(vjust = -0.7, color = \"grey40\") +\n    xlab(\"Water availability\") + ylab(\"Relative difference in range\") +\n    theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.text = element_text(color = \"black\")) +     \n    guides(color = guide_legend(title=\"Water year\"))\n\n  if(type == \"interannual\") { return(pint) }\n  if(type == \"annual\") { return(pann) }\n  if(type == \"scatter\") { return(ppew) }\n  if(type == \"table\") { return(pedat) }\n}\n\n\nGenerate plots\n\nWest BrookPaine RunStaunton RiverFlatheadYellowstoneSnake RiverDonner Blitzen\n\n\n\n\nCode\ndenwb\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndenpa\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndenst\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndenfl\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndenye\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndensn\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndendb",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Objective 1</span>"
    ]
  },
  {
    "objectID": "Qualitative/SpaceTimeVar.html#monthly-means",
    "href": "Qualitative/SpaceTimeVar.html#monthly-means",
    "title": "12  Objective 1",
    "section": "12.9 Monthly means",
    "text": "12.9 Monthly means\n\n12.9.1 Ridgeline plots\nFor each basin, use ridgeline plots to show distribution of daily flow values and monthly means by month, year, and site.\n\n\nCode\nmyridgesfun &lt;- function(bas, orderr) {\n  nsites &lt;- length(orderr)\n  # daily data\n  td &lt;- dat_clean %&gt;% filter(basin == bas) %&gt;%\n    mutate(MonthName = factor(MonthName, levels = rev(c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))),\n           CalendarYear = factor(CalendarYear)) \n  # summarize by month\n  td2 &lt;- td %&gt;%\n    group_by(subbasin, site_name, designation, CalendarYear, Month, MonthName) %&gt;%\n    summarize(logYield = mean(logYield)) %&gt;%\n    ungroup() %&gt;%\n    mutate(MonthName = factor(MonthName, levels = rev(c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))),\n           CalendarYear = factor(CalendarYear)) \n  # big g data\n  tempdat_big &lt;- dat_clean_big %&gt;% \n    filter(basin == bas, date &gt;= min(td$date), date &lt;= max(td$date)) %&gt;%\n    group_by(site_name, CalendarYear, Month, MonthName) %&gt;%\n    summarize(logYield = mean(logYield)) %&gt;%\n    ungroup() %&gt;%\n    mutate(MonthName = factor(MonthName, levels = rev(c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))), \n           CalendarYear = factor(CalendarYear))\n    \n  return(ggplot(data = td2) +\n  geom_density_ridges(data = td, aes(x = logYield, y = MonthName), alpha = 0.5) +\n  geom_line(data = td2, aes(x = logYield, y = MonthName, group = site_name, color = factor(site_name, levels = orderr)), orientation = \"y\", alpha = 0.4) +\n  geom_point(data = td2, aes(x = logYield, y = MonthName, group = site_name, color = factor(site_name, levels = orderr)), alpha = 0.4) +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  geom_line(data = tempdat_big, aes(x = logYield, y = MonthName, group = site_name), orientation = \"y\", alpha = 0.5) +\n  geom_point(data = tempdat_big, aes(x = logYield, y = MonthName, group = site_name), alpha = 0.5) +\n  theme_bw() + theme(legend.position = \"none\", panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +\n  facet_wrap2(~CalendarYear, nrow = 3, ncol = 3, trim_blank = FALSE) +\n  xlab(\"log(Yield, mm/day)\") + ylab(\"\"))\n}\n\n\n\nWest BrookPaine RunStaunton RiverFlatheadYellowstoneSnake RiverDonner Blitzen\n\n\n\n\nCode\nmyridgesfun(bas = \"West Brook\", orderr = wborder)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyridgesfun(bas = \"Paine Run\", orderr = paineorder)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyridgesfun(bas = \"Staunton River\", orderr = stauntorder)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyridgesfun(bas = \"Flathead\", orderr = flatorder)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyridgesfun(bas = \"Shields River\", orderr = yellorder)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyridgesfun(bas = \"Snake River\", orderr = snakeorder)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmyridgesfun(bas = \"Donner Blitzen\", orderr = donnerorder)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12.9.2 Repeatability\nHow repeatable is monthly mean flow among sites within basins? I.e., sites with higher than average yield always higher than average, or do lines cross frequently?\nCalculate reputability (R) using the rptR package (Stoffel et al. 2017). Also see related papers by Nakagawa and Schielzeth. Repeatibility is calculated on mean monthly flow z-scored by month and year, which removes the effect of monthly and interannual variation in water availability. Results are very similar to models fit using raw yield data with big G flow as a fixed effect.\nGenerally, repeatibility appears to be greater for snowmelt-dominated basins, particularly in the summer. The “all data” plot is more difficult to interpret as we mostly have seasonal data in the snowmelt basins, particularly the Yellowstone and Snake. In actuality, I would expect the opposite pattern if we had complete time series data for all basins: low reputability for snowmelt basins and high repeatability for rainfall basins (for the same reasons as bow tie vs. wedge).\n\n\nCode\nrp1 &lt;- rpttib %&gt;% \n  filter(basin != \"Donner Blitzen\", type == \"zscore\") %&gt;%\n  mutate(basin = ifelse(basin == \"Paine Run\", \"Paine\",\n                        ifelse(basin == \"Staunton River\", \"Staunton\", \n                               ifelse(basin == \"Snake River\", \"Snake\", \n                                      ifelse(basin == \"Shields River\", \"Yellowstone\", basin))))) %&gt;%\n  ggplot(aes(x = rboot, y = factor(basin, levels = rev(c(\"West Brook\", \"Paine\", \"Staunton\", \"Flathead\", \"Yellowstone\", \"Snake\"))))) +\n  geom_density_ridges(quantile_lines = TRUE, quantiles = 2) + \n  xlim(0,1) +\n  theme_bw() + theme(legend.position = \"none\", panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +\n  xlab(\"Bootstrapped repeatability (R)\") + ylab(\"Basin\") + ggtitle(\"All data\") +\n  geom_text(data = rpttib %&gt;% filter(basin != \"Donner Blitzen\", type == \"zscore\") %&gt;%\n  mutate(basin = ifelse(basin == \"Paine Run\", \"Paine\",\n                        ifelse(basin == \"Staunton River\", \"Staunton\", \n                               ifelse(basin == \"Snake River\", \"Snake\", \n                                      ifelse(basin == \"Shields River\", \"Yellowstone\", basin)))))%&gt;% group_by(basin) %&gt;% summarise(rboot = median(rboot)),\n            aes(label = round(rboot, digits = 2)), position = position_nudge(y = -0.1), colour = \"red\", size=3.5)\n\nrp2 &lt;- rpttib_summer %&gt;% \n  filter(basin != \"Donner Blitzen\", type == \"zscore\") %&gt;%\n  mutate(basin = ifelse(basin == \"Paine Run\", \"Paine\",\n                        ifelse(basin == \"Staunton River\", \"Staunton\", \n                               ifelse(basin == \"Snake River\", \"Snake\", \n                                      ifelse(basin == \"Shields River\", \"Yellowstone\", basin))))) %&gt;%\n  ggplot(aes(x = rboot, y = factor(basin, levels = rev(c(\"West Brook\", \"Paine\", \"Staunton\", \"Flathead\", \"Yellowstone\", \"Snake\"))))) +\n  geom_density_ridges(quantile_lines = TRUE, quantiles = 2) + \n  xlim(0,1) +\n  theme_bw() + theme(legend.position = \"none\", panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +\n  xlab(\"Bootstrapped repeatability (R)\") + ylab(\"Basin\") + ggtitle(\"Summer only (JJS)\") +\n  geom_text(data = rpttib_summer %&gt;% filter(basin != \"Donner Blitzen\", type == \"zscore\") %&gt;%\n  mutate(basin = ifelse(basin == \"Paine Run\", \"Paine\",\n                        ifelse(basin == \"Staunton River\", \"Staunton\", \n                               ifelse(basin == \"Snake River\", \"Snake\", \n                                      ifelse(basin == \"Shields River\", \"Yellowstone\", basin)))))%&gt;% group_by(basin) %&gt;% summarise(rboot = median(rboot)),\n            aes(label = round(rboot, digits = 2)), position = position_nudge(y = -0.1), colour = \"red\", size=3.5) \n\n# rp1\n# rp2\n\n\n\n\n12.9.3 Combined figure\n\n\nCode\nmyridgesfun2 &lt;- function(bas, orderr, calyr) {\n  nsites &lt;- length(orderr)\n  # daily data\n  td &lt;- dat_clean %&gt;% filter(basin == bas, CalendarYear == calyr) %&gt;%\n    mutate(MonthName = factor(MonthName, levels = rev(c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))),\n           CalendarYear = factor(CalendarYear)) \n  # summarize by month\n  td2 &lt;- td %&gt;%\n    group_by(subbasin, site_name, designation, CalendarYear, Month, MonthName) %&gt;%\n    summarize(logYield = mean(logYield)) %&gt;%\n    ungroup() %&gt;%\n    mutate(MonthName = factor(MonthName, levels = rev(c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))),\n           CalendarYear = factor(CalendarYear)) \n  # big g data\n  tempdat_big &lt;- dat_clean_big %&gt;% \n    filter(basin == bas, date &gt;= min(td$date), date &lt;= max(td$date)) %&gt;%\n    group_by(site_name, CalendarYear, Month, MonthName) %&gt;%\n    summarize(logYield = mean(logYield)) %&gt;%\n    ungroup() %&gt;%\n    mutate(MonthName = factor(MonthName, levels = rev(c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))), \n           CalendarYear = factor(CalendarYear))\n    \n  return(ggplot(data = td2) +\n  geom_density_ridges(data = td, aes(x = logYield, y = MonthName), alpha = 0.5) +\n  geom_line(data = td2, aes(x = logYield, y = MonthName, group = site_name, color = factor(site_name, levels = orderr)), orientation = \"y\", alpha = 0.8) +\n  geom_point(data = td2, aes(x = logYield, y = MonthName, group = site_name, color = factor(site_name, levels = orderr)), alpha = 0.8) +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  geom_line(data = tempdat_big, aes(x = logYield, y = MonthName, group = site_name), orientation = \"y\", alpha = 0.5) +\n  geom_point(data = tempdat_big, aes(x = logYield, y = MonthName, group = site_name), alpha = 0.5) +\n  theme_bw() + theme(legend.position = \"none\", panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n                     axis.title = element_blank(), axis.text = element_blank(), plot.title = element_text(size = 11)) +\n  xlim(-2.5,2)\n  #facet_wrap2(~CalendarYear, nrow = 3, ncol = 3, trim_blank = FALSE) +\n  #xlab(\"log(Yield, mm/day)\") + ylab(\"\")\n  ) \n}\n\n\n\n\nCode\n# arranged\nggarrange(p1, p2, ncol = 2, widths = c(1,0.7))",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Objective 1</span>"
    ]
  },
  {
    "objectID": "Qualitative/SpaceTimeVar.html#radial",
    "href": "Qualitative/SpaceTimeVar.html#radial",
    "title": "12  Objective 1",
    "section": "12.10 Radial",
    "text": "12.10 Radial\nUse rose/radial plots to show differences in key flow metrics among sites within the West Brook. While these metrics/plots provide helpful summaries of flow regimes and variation among sites, extending to other regions/basins is not possible given the extent of seasonal/missing data.\nCalculate flow metrics for each site:\n\n\nCode\n# filter data to WB and days with complete data availability across all sites\ndat_wb2 &lt;- dat_clean %&gt;%\n  filter(basin == \"West Brook\") %&gt;%\n  select(date, site_name, Yield_mm) %&gt;%\n  spread(key = site_name, value = Yield_mm) %&gt;% \n  drop_na() %&gt;%\n  gather(key = site_name, value = Yield_mm, 2:ncol(.)) %&gt;%\n  mutate(logYield = log(Yield_mm))\n\n# histograms of flow values by site\n# dat_wb2 %&gt;% ggplot() + geom_histogram(aes(x = Yield_mm)) + facet_wrap(~site_name)\n# dat_wb2 %&gt;% ggplot() + geom_histogram(aes(x = logYield)) + facet_wrap(~site_name)\n\n# Caclculate metrics, loosely based on the seven fundamental daily streamflow statistics (Archfield et al. 2014)\ndat_wb_clean_sum &lt;- dat_wb2 %&gt;% \n  group_by(site_name) %&gt;%\n  summarize(yield_mean = mean(logYield),\n            yield_min = min(logYield),\n            yield_relmax = max(logYield)/mean(logYield),\n            yield_cv = sd(Yield_mm)/mean(Yield_mm),\n            yield_skew = skewness(Yield_mm),\n            #yield_kurt = kurtosis(Yield_mm),\n            yield_ar1c = cor(logYield, lag(logYield), method = \"pearson\", use = \"complete.obs\")) %&gt;%\n  ungroup() %&gt;%\n  mutate(site_name = factor(site_name, levels = wborder)) %&gt;%\n  arrange(desc(site_name))\nnsites &lt;- nrow(dat_wb_clean_sum)\n\n# pairs plots to show correlation among metrics\nggpairs(dat_wb_clean_sum[,c(2:7)])\n\n\n\n\n\n\n\n\n\nGenerate plot\n\n\nCode\n# summarize min/max\nsumdat &lt;- data.frame(dat_wb_clean_sum %&gt;% select(c(2:7)))\nrownames(sumdat) &lt;- dat_wb_clean_sum$site_name\nminmax &lt;- data.frame(rbind(dat_wb_clean_sum %&gt;% select(c(2:7)) %&gt;% summarize_all(min),\n                dat_wb_clean_sum %&gt;% select(c(2:7)) %&gt;% summarize_all(max)))\nrownames(minmax) &lt;- c(\"Min\", \"Max\")\ndf &lt;- rbind(minmax, sumdat)\n\n# bind min/max and site-specific data for radial plot\nsum_minmax &lt;- rbind(dat_wb_clean_sum %&gt;% select(c(2:7)) %&gt;% summarize_all(min),\n                      dat_wb_clean_sum %&gt;% select(c(2:7)) %&gt;% summarize_all(max),\n                      dat_wb_clean_sum[i, c(2:7)])\n\n# plotting function\ncreate_beautiful_radarchart &lt;- function(data, color = \"#00AFBB\", \n                                        vlabels = colnames(data), vlcex = 0.7,\n                                        caxislabels = NULL, title = NULL, ...){\n  radarchart(\n    data, axistype = 1,\n    # Customize the polygon\n    pcol = color, pfcol = scales::alpha(color, 0.1), plwd = 2, plty = 1,\n    # Customize the grid\n    cglcol = \"grey\", cglty = 1, cglwd = 0.8,\n    # Customize the axis\n    axislabcol = \"grey\", \n    # Variable labels\n    vlcex = vlcex, vlabels = vlabels,\n    caxislabels = caxislabels, title = title, ...\n  )\n}\n\npar(mar = c(1,1,1,1))\n# generate plot\ncreate_beautiful_radarchart(\n  data = df,\n  color = cet_pal(nsites, name = \"i1\"),\n)\n# legend\nlegend(\n  x = \"right\", legend = rownames(df[-c(1,2),]), horiz = FALSE,\n  bty = \"n\", pch = 20 , col = cet_pal(nsites, name = \"i1\"),\n  text.col = \"black\", cex = 1, pt.cex = 1.5\n  )",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Objective 1</span>"
    ]
  },
  {
    "objectID": "Qualitative/SpaceTimeVar.html#cvpe",
    "href": "Qualitative/SpaceTimeVar.html#cvpe",
    "title": "12  Objective 1",
    "section": "12.11 CVPE",
    "text": "12.11 CVPE\nUse CVPE (mean-variance Portfolio Effect, Anderson et al. 2013) to explore the effect site-level heterogeneity in flow regimes on network\n\n\nCode\n# filter to basin\ndat_sub &lt;- dat_clean %&gt;% filter(basin == \"West Brook\")\n\n# meta-system (network)\ndat_sub_meta &lt;- dat_sub %&gt;% group_by(date) %&gt;% summarize(sumYield = sum(flow_mean)) %&gt;% ungroup() %&gt;% mutate(meta = \"meta\")\nmetacv_tib &lt;- dat_sub_meta %&gt;% group_by(meta) %&gt;% summarize(mean = mean(sumYield, na.rm = TRUE), var = var(sumYield, na.rm = TRUE)) %&gt;% ungroup()\nmetacv &lt;- sd(dat_sub_meta$sumYield) / mean(dat_sub_meta$sumYield)\n\n# by site\nmycvs &lt;- dat_sub %&gt;% group_by(site_name) %&gt;% summarize(mean = mean(flow_mean, na.rm = TRUE), var = var(flow_mean, na.rm = TRUE), cv = sd(flow_mean, na.rm = TRUE) / mean(flow_mean, na.rm = TRUE)) %&gt;% ungroup()\nggplot() + \n  geom_abline(intercept = 0, slope = 2, linetype = \"dashed\") +\n  geom_smooth(data = mycvs, aes(x = log(mean), y = log(var)), method = \"lm\", color = \"black\") + \n  geom_point(data = mycvs, aes(x = log(mean), y = log(var), color = site_name)) + \n  geom_point(data = metacv_tib, aes(x = log(mean), y = log(var))) +\n  xlab(\"log(mean flow, cfs)\") + ylab(\"log(variance)\")\n\n\n\n\n\n\n\n\n\nCode\n# Average-CV PE\nmean(mycvs$cv) / metacv\n\n\n[1] NA\n\n\n\n\nCode\n# filter to basin\ndat_sub &lt;- dat_clean %&gt;% filter(basin == \"West Brook\")\n\n# meta-system (network)\ndat_sub_meta &lt;- dat_sub %&gt;% group_by(date) %&gt;% summarize(sumYield = sum(Yield_mm)) %&gt;% ungroup() %&gt;% mutate(meta = \"meta\")\nmetacv_tib &lt;- dat_sub_meta %&gt;% group_by(meta) %&gt;% summarize(mean = mean(sumYield, na.rm = TRUE), var = var(sumYield, na.rm = TRUE)) %&gt;% ungroup()\nmetacv &lt;- sd(dat_sub_meta$sumYield) / mean(dat_sub_meta$sumYield)\n\n# by site\nmycvs &lt;- dat_sub %&gt;% group_by(site_name) %&gt;% summarize(mean = mean(Yield_mm, na.rm = TRUE), var = var(Yield_mm, na.rm = TRUE), cv = sd(Yield_mm, na.rm = TRUE) / mean(Yield_mm, na.rm = TRUE)) %&gt;% ungroup()\nggplot() + \n  geom_abline(intercept = 0, slope = 2, linetype = \"dashed\") +\n  geom_smooth(data = mycvs, aes(x = log(mean), y = log(var)), method = \"lm\", color = \"black\") + \n  geom_point(data = mycvs, aes(x = log(mean), y = log(var), color = site_name)) + \n  geom_point(data = metacv_tib, aes(x = log(mean), y = log(var))) +\n  xlab(\"log(mean yield, mm/day)\") + ylab(\"log(variance)\")\n\n\n\n\n\n\n\n\n\nCode\n# Average-CV PE\nmean(mycvs$cv) / metacv\n\n\n[1] 1.082323",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Objective 1</span>"
    ]
  },
  {
    "objectID": "Qualitative/SpaceTimeVar.html#old",
    "href": "Qualitative/SpaceTimeVar.html#old",
    "title": "12  Objective 1",
    "section": "12.12 OLD",
    "text": "12.12 OLD\n\nBig Creek\n\n\nCoal Creek\n\n\nMcGee Creek\n\n\nShields River\n\n\nDuck Creek\nPlotting function\n\n\nCode\n# set up color palette\nmycols &lt;- c(brewer.pal(8, \"Dark2\"), \"dodgerblue\", \"darkorchid\")\n\n# create plotting function\nmyplotfun &lt;- function(subbas, lab, bigG) {\n  data_sub &lt;- dat_clean %&gt;% filter(subbasin == subbas)\n  par(mar = c(1.7,1.7,0.1,0.1), mgp = c(2.5,0.6,0))\n  plot(logYield ~ date, data_sub, type = \"n\", xlab = \"\", ylab = \"\")\n  #tempdat_little &lt;- data_sub %&gt;% filter(designation == \"little\")\n  tempdat_little &lt;- fill_missing_dates(data_sub, dates = date, groups = site_name, pad_ends = FALSE)\n  tempdat_big &lt;- dat_clean_big %&gt;% filter(site_name == bigG, date &gt;= min(tempdat_little$date), date &lt;= max(tempdat_little$date))\n  #tempdat_big &lt;- data_sub %&gt;% filter(designation == \"big\")\n  tempdat_big &lt;- fill_missing_dates(tempdat_big, dates = date, groups = site_name, pad_ends = FALSE)\n  mysites &lt;- sort(unique(tempdat_little$site_name))\n  for (i in 1:length(mysites)) {\n    lines(logYield ~ date, tempdat_little %&gt;% filter(site_name == mysites[i]), col = mycols[i], lwd = 0.7)\n    }\n  lines(logYield ~ date, tempdat_big, col = \"white\", lwd = 1.7)\n  lines(logYield ~ date, tempdat_big, col = \"black\", lwd = 1)\n  usr &lt;- par(\"usr\")\n  par(usr = c(0,1,0,1))\n  text(0.02, 0.9, labels = lab, cex = 1.2)\n  par(usr = usr)\n}\n\n\nGenerate plot\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/EcoD_timeseries.jpg\", width = 8, height = 12, units = \"in\", res = 1000)\n\npar(mfrow = c(10,1), oma = c(0.5,2,0.5,0.5))\n\n# West Brook\nmyplotfun(subbas = \"West Brook\", lab = \"(a)\", bigG = \"South River Conway NWIS\")\n\n# Paine\nmyplotfun(subbas = \"Paine Run\", lab = \"(b)\", bigG = \"South River Harriston NWIS\")\n\n# Staunton River\nmyplotfun(subbas = \"Staunton River\", lab = \"(c)\", bigG = \"Rapidan River NWIS\")\n\n# Big Creek\nmyplotfun(subbas = \"Big Creek\", lab = \"(d)\", bigG = \"North Fork Flathead River NWIS\")\n\n# Coal Creek\nmyplotfun(subbas = \"Coal Creek\", lab = \"(e)\", bigG = \"North Fork Flathead River NWIS\")\n\n# McGee Creek\nmyplotfun(subbas = \"McGee Creek\", lab = \"(f)\", bigG = \"North Fork Flathead River NWIS\")\n\n# Snake River\nmyplotfun(subbas = \"Snake River\", lab = \"(g)\", bigG = \"Pacific Creek at Moran NWIS\")\n\n# Shields River\nmyplotfun(subbas = \"Shields River\", lab = \"(h)\", bigG = \"Yellowstone River Livingston NWIS\")\n\n# Duck Creek\nmyplotfun(subbas = \"Duck Creek\", lab = \"(i)\", bigG = \"Yellowstone River Livingston NWIS\")\n\n# Donner Blitzen\nmyplotfun(subbas = \"Donner Blitzen\", lab = \"(j)\", bigG = \"Donner Blitzen River nr Frenchglen NWIS\")\n\n# common axis label\nmtext(\"log(Daily yield, mm)\", outer = TRUE, side = 2, line = 0.5)\n\ndev.off()\n\n\nPlotting functions\n\n\nCode\n# create plotting function\nmyplotfun_ex &lt;- function(subbas, lab) {\n  # filter to subbasin and get site designation\n  \n}  \n\n\n# CV of little g Yield by exceedance probability\nmyplotfun_cv &lt;- function(subbas, lab) {\n  # filter to subbasin and get site designation\n  data_sub &lt;- dat_clean %&gt;% filter(subbasin == subbas)\n  sitesdesig &lt;- data_sub %&gt;% group_by(site_name) %&gt;% summarize(designation = unique(designation)) %&gt;% ungroup()\n  # calculate exceedance probability by site\n  exeeddat &lt;- data_sub %&gt;% \n    select(date, site_name, logYield) %&gt;%\n    spread(key = site_name, value = logYield) %&gt;% \n    drop_na() %&gt;%\n    gather(key = site_name, value = logYield, 2:ncol(.)) %&gt;%\n    group_by(site_name) %&gt;%\n    arrange(desc(logYield), .by_group = TRUE) %&gt;%\n    mutate(exceedance = 100/length(logYield)*1:length(logYield)) %&gt;%\n    ungroup() %&gt;%\n    left_join(sitesdesig)\n  exeeddat_little &lt;- exeeddat %&gt;% filter(designation == \"little\")\n  exeeddat_big &lt;- exeeddat %&gt;% filter(designation == \"big\")\n  # set up plot\n  par(mar = c(1.7,1.7,0.1,0.1), mgp = c(2.5,0.6,0))\n  mysites &lt;- sort(unique(exeeddat_little$site_name))\n  tiblist &lt;- list()\n  for (i in 1:length(mysites)) {\n    tt &lt;- exeeddat %&gt;% filter(site_name == mysites[i])\n    mylinint &lt;- approx(x = tt$exceedance, y = tt$logYield, xout = seq(from = 0, to = 100, by = 1))\n    tiblist[[i]] &lt;- tibble(site_name = mysites[i], exceedance = mylinint$x, logYield = mylinint$y)\n  }\n  cvtib &lt;- do.call(bind_rows, tiblist) %&gt;%\n    group_by(exceedance) %&gt;%\n    summarize(sdf = sd(logYield)) %&gt;%\n    ungroup()\n  plot(sdf ~ exceedance, cvtib, type = \"l\", col = \"grey40\", lwd = 2, ylim = c(0,0.8))\n  # panel label\n  usr &lt;- par(\"usr\")\n  par(usr = c(0,1,0,1))\n  text(0.92, 0.9, labels = lab, cex = 1.2)\n  par(usr = usr)\n}  \n\n\nPlot exceedance\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/EcoD_exceedance_JAS.jpg\", width = 4, height = 8, units = \"in\", res = 1000)\npar(mfrow = c(5,2), oma = c(2,2,0.5,0.5))\nmyplotfun_ex(subbas = \"West Brook\", lab = \"(a)\")\nmyplotfun_ex(subbas = \"Paine Run\", lab = \"(b)\")\nmyplotfun_ex(subbas = \"Staunton River\", lab = \"(c)\")\nmyplotfun_ex(subbas = \"Big Creek\", lab = \"(d)\")\nmyplotfun_ex(subbas = \"Coal Creek\", lab = \"(e)\")\nmyplotfun_ex(subbas = \"McGee Creek\", lab = \"(f)\")\nmyplotfun_ex(subbas = \"Snake River\", lab = \"(g)\")\nmyplotfun_ex(subbas = \"Shields River\", lab = \"(h)\")\nmyplotfun_ex(subbas = \"Duck Creek\", lab = \"(i)\")\nmyplotfun_ex(subbas = \"Donner Blitzen\", lab = \"(j)\")\nmtext(\"log(Daily yield, mm)\", outer = TRUE, side = 2, line = 0.5)\nmtext(\"Exceedance probability\", outer = TRUE, side = 1, line = 0.5)\ndev.off()\n\n#![July-September flow exceedance curves for sites in 10 headwater stream networks.](EcoD_exceedance_JAS.jpg)\n\n\nPlot CV by exceedance\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/EcoD_exceedance_cv.jpg\", width = 4, height = 8, units = \"in\", res = 1000)\npar(mfrow = c(5,2), oma = c(2,2,0.5,0.5))\nmyplotfun_cv(subbas = \"West Brook\", lab = \"(a)\")\nmyplotfun_cv(subbas = \"Paine Run\", lab = \"(b)\")\nmyplotfun_cv(subbas = \"Staunton River\", lab = \"(c)\")\nmyplotfun_cv(subbas = \"Big Creek\", lab = \"(d)\")\nmyplotfun_cv(subbas = \"Coal Creek\", lab = \"(e)\")\nmyplotfun_cv(subbas = \"McGee Creek\", lab = \"(f)\")\nmyplotfun_cv(subbas = \"Snake River\", lab = \"(g)\")\nmyplotfun_cv(subbas = \"Shields River\", lab = \"(h)\")\nmyplotfun_cv(subbas = \"Duck Creek\", lab = \"(i)\")\nmyplotfun_cv(subbas = \"Donner Blitzen\", lab = \"(j)\")\nmtext(\"SD of log(daily yield, mm) at little g's\", outer = TRUE, side = 2, line = 0.5)\nmtext(\"Exceedance probability\", outer = TRUE, side = 1, line = 0.5)\ndev.off()\n\n#![July-September spatial variation in flow exceedance probabilities for 10 headwater stream networks.](EcoD_exceedance_cv_JAS.jpg)",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Objective 1</span>"
    ]
  },
  {
    "objectID": "Qualitative/SpaceTimeVar.html#map-objects",
    "href": "Qualitative/SpaceTimeVar.html#map-objects",
    "title": "12  Objective 1",
    "section": "12.3 Map objects",
    "text": "12.3 Map objects\nCurrently not being used…",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Objective 1</span>"
    ]
  },
  {
    "objectID": "Qualitative/SpaceTimeVar.html#median-summer-flow",
    "href": "Qualitative/SpaceTimeVar.html#median-summer-flow",
    "title": "12  Objective 1",
    "section": "12.7 Median summer flow",
    "text": "12.7 Median summer flow\n\nWest BrookPaine RunStaunton RiverFlatheadYellowstoneSnakeDonner Blitzen\n\n\n\n\nCode\nbas &lt;- \"West Brook\"\norderr &lt;- wborder\nwtryrs &lt;- c(2020:2024)\n\n# sheds and network\nmysheds &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Watersheds/Mass_Watersheds.shp\")\nmysheds &lt;- mysheds[mysheds$site_id == \"WBR\",]\nmynet &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Streams/Mass_Streams.shp\")\ncrs(mynet) &lt;- crs(mysheds)\nmynet &lt;- crop(mynet, mysheds)\n\n# get lakes\nlakes &lt;- get_waterbodies(AOI = siteinfo_sp %&gt;% filter(site_name == \"West Brook NWIS\"), buffer = 10000)\nlakes &lt;- lakes %&gt;% filter(gnis_name %in% c(\"Northampton Reservoir Upper\", \"Northampton Reservoir\"))\n\n# little g points\nmylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% wborder) %&gt;% mutate(site_name = factor(site_name, levels = wborder))\n\n\n# filter data\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == bas, !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = orderr))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == bas, !is.na(logYield), Month %in% c(7:9), WaterYear %in% unique(tempdat$WaterYear))\n\n  # calculate variability for reference gage\nvarbig &lt;- tempdat_big %&gt;% \n  group_by(WaterYear) %&gt;% \n  summarize(bigrange = range(logYield)[2]-range(logYield)[1],\n            bigsd = sd(logYield),\n            bigvar = var(logYield)) %&gt;%\n  ungroup()\n\n# calculate total summer water availability from reference gage\n#summerflow &lt;- tempdat_big %&gt;% group_by(WaterYear) %&gt;% summarize(summeryield = sum(Yield_mm), summeryield_log = log(sum(Yield_mm))) %&gt;% ungroup()\n#wateravail2 &lt;- wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z)\n\n# calculate relative variation\npedat &lt;- tempdat %&gt;% \n  group_by(basin, WaterYear) %&gt;% \n  summarize(nsites = length(unique(site_name)),\n            littlerange = range(logYield)[2]-range(logYield)[1],\n            littlesd = sd(logYield),\n            littlevar = var(logYield)) %&gt;% \n  ungroup() %&gt;% \n  left_join(varbig) %&gt;%\n  mutate(pe_range = ((littlerange-bigrange)/bigrange),\n         pe_sd = ((littlesd-bigsd)/bigsd),\n         pe_var = ((littlevar-bigvar)/bigvar)) %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z, totalyield_sum, totalyield_sum_z, tyz_perc, tyz_sum_perc)) %&gt;% \n  filter(WaterYear %in% wtryrs) %&gt;%\n  mutate(wylab = substr(WaterYear, 3, 4)) %&gt;%\n  arrange(totalyield_sum_z)\n  \n# calculate annual median summer flow\nannmed &lt;- tempdat %&gt;%\n  #filter(WaterYear %in% c(lowyr, highyr)) %&gt;%\n  group_by(site_name, WaterYear) %&gt;%\n  summarize(medlogYield = median(logYield, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# arrange years by total annual yield\nwtryrs_arranged &lt;- as.numeric(unlist(pedat %&gt;% select(WaterYear)))\n\n# plot it\nplotlist_wb &lt;- list()\nfor(i in 1:length(wtryrs_arranged)) {\n  mylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i]))\n  mylittleg_sheds &lt;- sheds %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i])) %&gt;% arrange(desc(area_sqmi))\n  plotlist_wb[[i]] &lt;- local({\n    i &lt;- i\n    ggplot() +\n      geom_sf(data = st_as_sf(mysheds), color = \"black\", fill = \"white\", linewidth = 0.4) + \n      geom_sf(data = mylittleg_sheds, aes(fill = medlogYield), color = \"black\") +\n      scale_fill_viridis(option = \"A\", direction = 1, limits = range(annmed$medlogYield), na.value = \"grey\") +\n      geom_sf(data = st_as_sf(mynet), color = \"white\", linewidth = 1, lineend = \"round\") +\n      geom_sf(data = st_as_sf(mynet), color = \"royalblue4\", linewidth = 0.6, lineend = \"round\") +\n      geom_sf(data = lakes, color = \"white\", fill = \"lightskyblue1\", linewidth = 0.7) +\n      geom_sf(data = lakes, color = \"royalblue4\", fill = \"lightskyblue1\", linewidth = 0.5) +\n      geom_sf(data = mylittleg, shape = 21, fill = \"white\", size = 2) +\n      labs(fill = \"Median\\nsummer\\nlog(Yield)\") + #annotation_scale() +\n      coord_sf(xlim = range(st_coordinates(mylittleg_sheds)[,1]), ylim = range(st_coordinates(mylittleg_sheds)[,2])) +\n      theme_bw() + theme(axis.title.x = element_blank(), axis.title.y = element_blank(), legend.position = \"none\", axis.text = element_blank()) +\n      annotate(\"label\", x = Inf, y = Inf, label = paste(pedat$WaterYear[i], \" (\", pedat$tyz_sum_perc[i], \"%)\", sep = \"\"), vjust = 1.15, hjust = 1.05, size = 5)})\n}\nggarrange(plotlist = plotlist_wb, common.legend = TRUE, legend = \"right\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nbas &lt;- \"Paine Run\"\norderr &lt;- paineorder\nwtryrs &lt;- c(2019:2022)\n\nmysheds &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Watersheds/Shen_Watersheds.shp\")\nmysheds &lt;- mysheds[mysheds$site_id == \"PA_10FL\",]\nmynet &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Streams/Shen_Streams.shp\")\ncrs(mynet) &lt;- crs(mysheds)\nmynet &lt;- crop(mynet, mysheds)\n\n# hillshade\nmyrast &lt;- rast(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Data/Spatial data/Elevation/Shenandoah_DEM_10m_nc.tif\")\nmyrast &lt;- mask(crop(myrast, mysheds), mysheds)\nslo &lt;- terrain(myrast, \"slope\", unit = \"radians\") \nasp &lt;- terrain(myrast, \"aspect\", unit = \"radians\")\nhill &lt;- shade(slope = slo, aspect = asp, angle = 40, direction = 270)\nhilldf &lt;- as.data.frame(hill, xy = TRUE)\n\n# little g points\nmylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% orderr)\n\n\n# filter data\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == bas, !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = orderr))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == bas, !is.na(logYield), Month %in% c(7:9), WaterYear %in% unique(tempdat$WaterYear))\n\n  # calculate variability for reference gage\nvarbig &lt;- tempdat_big %&gt;% \n  group_by(WaterYear) %&gt;% \n  summarize(bigrange = range(logYield)[2]-range(logYield)[1],\n            bigsd = sd(logYield),\n            bigvar = var(logYield)) %&gt;%\n  ungroup()\n\n# calculate total summer water availability from reference gage\n#summerflow &lt;- tempdat_big %&gt;% group_by(WaterYear) %&gt;% summarize(summeryield = sum(Yield_mm), summeryield_log = log(sum(Yield_mm))) %&gt;% ungroup()\n#wateravail2 &lt;- wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z)\n\n# calculate relative variation\npedat &lt;- tempdat %&gt;% \n  group_by(basin, WaterYear) %&gt;% \n  summarize(nsites = length(unique(site_name)),\n            littlerange = range(logYield)[2]-range(logYield)[1],\n            littlesd = sd(logYield),\n            littlevar = var(logYield)) %&gt;% \n  ungroup() %&gt;% \n  left_join(varbig) %&gt;%\n  mutate(pe_range = ((littlerange-bigrange)/bigrange),\n         pe_sd = ((littlesd-bigsd)/bigsd),\n         pe_var = ((littlevar-bigvar)/bigvar)) %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z, totalyield_sum, totalyield_sum_z, tyz_perc, tyz_sum_perc)) %&gt;% \n  filter(WaterYear %in% wtryrs) %&gt;%\n  mutate(wylab = substr(WaterYear, 3, 4)) %&gt;%\n  arrange(totalyield_sum_z)\n  \n# calculate annual median summer flow\nannmed &lt;- tempdat %&gt;%\n  #filter(WaterYear %in% c(lowyr, highyr)) %&gt;%\n  group_by(site_name, WaterYear) %&gt;%\n  summarize(medlogYield = median(logYield, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# arrange years by total annual yield\nwtryrs_arranged &lt;- as.numeric(unlist(pedat %&gt;% select(WaterYear)))\n\n# plot it\nplotlist_pa &lt;- list()\nfor(i in 1:length(wtryrs_arranged)) {\n  mylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i]))\n  mylittleg_sheds &lt;- sheds %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i])) %&gt;% arrange(desc(area_sqmi))\n  plotlist_pa[[i]] &lt;- local({\n    i &lt;- i\n    ggplot() +\n      geom_sf(data = st_as_sf(mysheds), color = \"black\", fill = \"white\", linewidth = 0.4) + \n      geom_sf(data = mylittleg_sheds, aes(fill = medlogYield), color = \"black\") +\n      scale_fill_viridis(option = \"A\", direction = 1, limits = range(annmed$medlogYield), na.value = \"grey\") +\n      geom_sf(data = st_as_sf(mynet), color = \"white\", linewidth = 1, lineend = \"round\") +\n      geom_sf(data = st_as_sf(mynet), color = \"royalblue4\", linewidth = 0.6, lineend = \"round\") +\n      geom_sf(data = mylittleg, shape = 21, fill = \"white\", size = 2) +\n      labs(fill = \"Median\\nsummer\\nlog(Yield)\") + #annotation_scale() +\n      coord_sf(xlim = range(st_coordinates(mylittleg_sheds)[,1]), ylim = range(st_coordinates(mylittleg_sheds)[,2])) +\n      theme_bw() + theme(axis.title.x = element_blank(), axis.title.y = element_blank(), legend.position = \"none\", axis.text = element_blank()) +\n      annotate(\"label\", x = -Inf, y = Inf, label = paste(pedat$WaterYear[i], \" (\", pedat$tyz_sum_perc[i], \"%)\", sep = \"\"), vjust = 1.15, hjust = -0.05, size = 5)})\n}\nggarrange(plotlist = plotlist_pa, common.legend = TRUE, legend = \"right\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nbas &lt;- \"Staunton River\"\norderr &lt;- stauntorder\nwtryrs &lt;- c(2019:2022)\n\nmysheds &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Watersheds/Shen_Watersheds.shp\")\nmysheds &lt;- mysheds[mysheds$site_id == \"SR_10FL\",]\nmynet &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Streams/Shen_Streams.shp\")\ncrs(mynet) &lt;- crs(mysheds)\nmynet &lt;- crop(mynet, mysheds)\n\n# little g points\nmylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% orderr)\n\n# filter data\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == bas, !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = orderr))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == bas, !is.na(logYield), Month %in% c(7:9), WaterYear %in% unique(tempdat$WaterYear))\n\n  # calculate variability for reference gage\nvarbig &lt;- tempdat_big %&gt;% \n  group_by(WaterYear) %&gt;% \n  summarize(bigrange = range(logYield)[2]-range(logYield)[1],\n            bigsd = sd(logYield),\n            bigvar = var(logYield)) %&gt;%\n  ungroup()\n\n# calculate total summer water availability from reference gage\n#summerflow &lt;- tempdat_big %&gt;% group_by(WaterYear) %&gt;% summarize(summeryield = sum(Yield_mm), summeryield_log = log(sum(Yield_mm))) %&gt;% ungroup()\n#wateravail2 &lt;- wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z)\n\n# calculate relative variation\npedat &lt;- tempdat %&gt;% \n  group_by(basin, WaterYear) %&gt;% \n  summarize(nsites = length(unique(site_name)),\n            littlerange = range(logYield)[2]-range(logYield)[1],\n            littlesd = sd(logYield),\n            littlevar = var(logYield)) %&gt;% \n  ungroup() %&gt;% \n  left_join(varbig) %&gt;%\n  mutate(pe_range = ((littlerange-bigrange)/bigrange),\n         pe_sd = ((littlesd-bigsd)/bigsd),\n         pe_var = ((littlevar-bigvar)/bigvar)) %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z, totalyield_sum, totalyield_sum_z, tyz_perc, tyz_sum_perc)) %&gt;% \n  filter(WaterYear %in% wtryrs) %&gt;%\n  mutate(wylab = substr(WaterYear, 3, 4)) %&gt;%\n  arrange(totalyield_sum_z)\n  \n# calculate annual median summer flow\nannmed &lt;- tempdat %&gt;%\n  #filter(WaterYear %in% c(lowyr, highyr)) %&gt;%\n  group_by(site_name, WaterYear) %&gt;%\n  summarize(medlogYield = median(logYield, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# arrange years by total annual yield\nwtryrs_arranged &lt;- as.numeric(unlist(pedat %&gt;% select(WaterYear)))\n\n# plot it\nplotlist_st &lt;- list()\nfor(i in 1:length(wtryrs_arranged)) {\n  mylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i]))\n  mylittleg_sheds &lt;- sheds %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i])) %&gt;% arrange(desc(area_sqmi))\n  plotlist_st[[i]] &lt;- local({\n    i &lt;- i\n    ggplot() +\n      geom_sf(data = st_as_sf(mysheds), color = \"black\", fill = \"white\", linewidth = 0.4) + \n      geom_sf(data = mylittleg_sheds, aes(fill = medlogYield), color = \"black\") +\n      scale_fill_viridis(option = \"A\", direction = 1, limits = range(annmed$medlogYield), na.value = \"grey\") +\n      geom_sf(data = st_as_sf(mynet), color = \"white\", linewidth = 1, lineend = \"round\") +\n      geom_sf(data = st_as_sf(mynet), color = \"royalblue4\", linewidth = 0.6, lineend = \"round\") +\n      geom_sf(data = mylittleg, shape = 21, fill = \"white\", size = 2) +\n      labs(fill = \"Median\\nsummer\\nlog(Yield)\") + #annotation_scale() +\n      coord_sf(xlim = range(st_coordinates(mylittleg_sheds)[,1]), ylim = range(st_coordinates(mylittleg_sheds)[,2])) +\n      theme_bw() + theme(axis.title.x = element_blank(), axis.title.y = element_blank(), legend.position = \"none\", axis.text = element_blank()) +\n      annotate(\"label\", x = Inf, y = Inf, label = paste(pedat$WaterYear[i], \" (\", pedat$tyz_sum_perc[i], \"%)\", sep = \"\"), vjust = 1.15, hjust = 1.05, size = 5)})\n}\nggarrange(plotlist = plotlist_st, common.legend = TRUE, legend = \"right\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nbas &lt;- \"Flathead\"\norderr &lt;- flatorder\nwtryrs &lt;- c(2018:2024)\n\nmysheds &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Watersheds/Flat_Watersheds.shp\")\nmysheds &lt;- mysheds[mysheds$site_id == \"NFF\",]\nmynet &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Streams/Flat_Streams.shp\")\ncrs(mynet) &lt;- crs(mysheds)\nmynet &lt;- crop(mynet, mysheds)\n\n# get lakes\nlakes &lt;- get_waterbodies(AOI = siteinfo_sp %&gt;% filter(site_name == \"North Fork Flathead River NWIS\"), buffer = 100000)\nlakes &lt;- st_transform(lakes, crs(mysheds))\nlakes &lt;- st_intersection(lakes, st_as_sf(mysheds))\nlakes &lt;- lakes %&gt;% filter(gnis_name %in% c(\"Moose Lake\", \"Mud Lake\"))\n\n# points\nmylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% flatorder) %&gt;% mutate(site_name = factor(site_name, levels = flatorder))\nst_geometry(mylittleg)[mylittleg$site_name == \"BigCreekUpper\"] &lt;- st_point(c(-114.31506, 48.57672))\nst_geometry(mylittleg)[mylittleg$site_name == \"HallowattCreekLower\"] &lt;- st_point(c(-114.31914, 48.57256))\n\n\n# filter data\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == bas, !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = orderr))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == bas, !is.na(logYield), Month %in% c(7:9), WaterYear %in% unique(tempdat$WaterYear))\n\n  # calculate variability for reference gage\nvarbig &lt;- tempdat_big %&gt;% \n  group_by(WaterYear) %&gt;% \n  summarize(bigrange = range(logYield)[2]-range(logYield)[1],\n            bigsd = sd(logYield),\n            bigvar = var(logYield)) %&gt;%\n  ungroup()\n\n# calculate total summer water availability from reference gage\n#summerflow &lt;- tempdat_big %&gt;% group_by(WaterYear) %&gt;% summarize(summeryield = sum(Yield_mm), summeryield_log = log(sum(Yield_mm))) %&gt;% ungroup()\n#wateravail2 &lt;- wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z)\n\n# calculate relative variation\npedat &lt;- tempdat %&gt;% \n  group_by(basin, WaterYear) %&gt;% \n  summarize(nsites = length(unique(site_name)),\n            littlerange = range(logYield)[2]-range(logYield)[1],\n            littlesd = sd(logYield),\n            littlevar = var(logYield)) %&gt;% \n  ungroup() %&gt;% \n  left_join(varbig) %&gt;%\n  mutate(pe_range = ((littlerange-bigrange)/bigrange),\n         pe_sd = ((littlesd-bigsd)/bigsd),\n         pe_var = ((littlevar-bigvar)/bigvar)) %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z, totalyield_sum, totalyield_sum_z, tyz_perc, tyz_sum_perc)) %&gt;% \n  filter(WaterYear %in% wtryrs) %&gt;%\n  mutate(wylab = substr(WaterYear, 3, 4)) %&gt;%\n  arrange(totalyield_sum_z)\n  \n# calculate annual median summer flow\nannmed &lt;- tempdat %&gt;%\n  #filter(WaterYear %in% c(lowyr, highyr)) %&gt;%\n  group_by(site_name, WaterYear) %&gt;%\n  summarize(medlogYield = median(logYield, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# arrange years by total annual yield\nwtryrs_arranged &lt;- as.numeric(unlist(pedat %&gt;% select(WaterYear)))\n\n# plot it\nplotlist_fl &lt;- list()\nfor(i in 1:length(wtryrs_arranged)) {\n  mylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i]))\n  mylittleg_sheds &lt;- sheds %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i])) %&gt;% arrange(desc(area_sqmi))\n  plotlist_fl[[i]] &lt;- local({\n    i &lt;- i\n    ggplot() +\n      geom_sf(data = st_as_sf(mysheds), color = \"black\", fill = \"white\", linewidth = 0.4) + \n      geom_sf(data = mylittleg_sheds, aes(fill = medlogYield), color = \"black\") +\n      scale_fill_viridis(option = \"A\", direction = 1, limits = range(annmed$medlogYield), na.value = \"grey\") +\n      geom_sf(data = st_as_sf(mynet), color = \"white\", linewidth = 1, lineend = \"round\") +\n      geom_sf(data = st_as_sf(mynet), color = \"royalblue4\", linewidth = 0.6, lineend = \"round\") +\n      geom_sf(data = mylittleg, shape = 21, fill = \"white\", size = 2) +\n      labs(fill = \"Median\\nsummer\\nlog(Yield)\") + #annotation_scale() +\n      coord_sf(xlim = range(st_coordinates(mylittleg_sheds)[,1]), ylim = range(st_coordinates(mylittleg_sheds)[,2])) +\n      theme_bw() + theme(axis.title.x = element_blank(), axis.title.y = element_blank(), legend.position = \"none\", axis.text = element_blank()) +\n      annotate(\"label\", x = Inf, y = Inf, label = paste(pedat$WaterYear[i], \" (\", pedat$tyz_sum_perc[i], \"%)\", sep = \"\"), vjust = 1.15, hjust = 1.05, size = 5)})\n}\nggarrange(plotlist = plotlist_fl, common.legend = TRUE, legend = \"right\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nbas &lt;- \"Shields River\"\norderr &lt;- yellorder\nwtryrs &lt;- c(2016:2020,2022:2024)\n\nmysheds &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Watersheds/Shields_Watersheds.shp\")\nmysheds &lt;- mysheds[mysheds$site_id %in% c(\"SRS\", \"DU01\"),]\nmynet &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Streams/Shields_Streams.shp\")\ncrs(mynet) &lt;- crs(mysheds)\nmynet &lt;- crop(mynet, mysheds)\n\n# points\nmylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% orderr) %&gt;% mutate(site_name = factor(site_name, levels = orderr)) #%&gt;% filter(subbasin != \"Duck Creek\")\n\n\n# filter data\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == bas, !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = orderr))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == bas, !is.na(logYield), Month %in% c(7:9), WaterYear %in% unique(tempdat$WaterYear))\n\n  # calculate variability for reference gage\nvarbig &lt;- tempdat_big %&gt;% \n  group_by(WaterYear) %&gt;% \n  summarize(bigrange = range(logYield)[2]-range(logYield)[1],\n            bigsd = sd(logYield),\n            bigvar = var(logYield)) %&gt;%\n  ungroup()\n\n# calculate total summer water availability from reference gage\n#summerflow &lt;- tempdat_big %&gt;% group_by(WaterYear) %&gt;% summarize(summeryield = sum(Yield_mm), summeryield_log = log(sum(Yield_mm))) %&gt;% ungroup()\n#wateravail2 &lt;- wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z)\n\n# calculate relative variation\npedat &lt;- tempdat %&gt;% \n  group_by(basin, WaterYear) %&gt;% \n  summarize(nsites = length(unique(site_name)),\n            littlerange = range(logYield)[2]-range(logYield)[1],\n            littlesd = sd(logYield),\n            littlevar = var(logYield)) %&gt;% \n  ungroup() %&gt;% \n  left_join(varbig) %&gt;%\n  mutate(pe_range = ((littlerange-bigrange)/bigrange),\n         pe_sd = ((littlesd-bigsd)/bigsd),\n         pe_var = ((littlevar-bigvar)/bigvar)) %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z, totalyield_sum, totalyield_sum_z, tyz_perc, tyz_sum_perc)) %&gt;% \n  filter(WaterYear %in% wtryrs) %&gt;%\n  mutate(wylab = substr(WaterYear, 3, 4)) %&gt;%\n  arrange(totalyield_sum_z)\n  \n# calculate annual median summer flow\nannmed &lt;- tempdat %&gt;%\n  #filter(WaterYear %in% c(lowyr, highyr)) %&gt;%\n  group_by(site_name, WaterYear) %&gt;%\n  summarize(medlogYield = median(logYield, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# arrange years by total annual yield\nwtryrs_arranged &lt;- as.numeric(unlist(pedat %&gt;% select(WaterYear)))\n\n# plot it\nplotlist_ye &lt;- list()\nfor(i in 1:length(wtryrs_arranged)) {\n  mylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i]))\n  mylittleg_sheds &lt;- sheds %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i])) %&gt;% arrange(desc(area_sqmi))\n  plotlist_ye[[i]] &lt;- local({\n    i &lt;- i\n    ggplot() +\n      geom_sf(data = st_as_sf(mysheds), color = \"black\", fill = \"white\", linewidth = 0.4) + \n      geom_sf(data = mylittleg_sheds, aes(fill = medlogYield), color = \"black\") +\n      scale_fill_viridis(option = \"A\", direction = 1, limits = range(annmed$medlogYield), na.value = \"grey\") +\n      geom_sf(data = st_as_sf(mynet), color = \"white\", linewidth = 1, lineend = \"round\") +\n      geom_sf(data = st_as_sf(mynet), color = \"royalblue4\", linewidth = 0.6, lineend = \"round\") +\n      geom_sf(data = mylittleg, shape = 21, fill = \"white\", size = 2) +\n      labs(fill = \"Median\\nsummer\\nlog(Yield)\") + #annotation_scale() +\n      coord_sf(xlim = range(st_coordinates(mylittleg_sheds)[,1]), ylim = range(st_coordinates(mylittleg_sheds)[,2])) +\n      theme_bw() + theme(axis.title.x = element_blank(), axis.title.y = element_blank(), legend.position = \"none\", axis.text = element_blank()) +\n      annotate(\"label\", x = -Inf, y = -Inf, label = paste(pedat$WaterYear[i], \" (\", pedat$tyz_sum_perc[i], \"%)\", sep = \"\"), vjust = -0.15, hjust = -0.05, size = 5)})\n}\nggarrange(plotlist = plotlist_ye, common.legend = TRUE, legend = \"right\", nrow = 2, ncol = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nbas &lt;- \"Snake River\"\norderr &lt;- snakeorder\nwtryrs &lt;- c(2016:2024)\n\nmysheds &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Watersheds/Snake_Watersheds.shp\")\nmysheds &lt;- mysheds[mysheds$site_id == \"SP11\",]\nmynet &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Streams/Snake_Streams.shp\")\ncrs(mynet) &lt;- crs(mysheds)\nmynet &lt;- crop(mynet, mysheds)\n\n# get lakes\nlakes &lt;- get_waterbodies(AOI = siteinfo_sp %&gt;% filter(site_name == \"Spread Creek Dam\"), buffer = 100000)\nlakes &lt;- st_transform(lakes, crs(mysheds))\nlakes &lt;- st_intersection(lakes, st_as_sf(mysheds))\nlakes &lt;- lakes %&gt;% filter(gnis_name %in% c(\"Leidy Lake\"))\n\n# points\nmylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% snakeorder) %&gt;% mutate(site_name = factor(site_name, levels = snakeorder))\n# edit geometry to reduce overlap\nst_geometry(mylittleg)[mylittleg$site_name == \"SF Spread Creek Lower NWIS\"] &lt;- st_point(c(-110.32226, 43.76118))\nst_geometry(mylittleg)[mylittleg$site_name == \"NF Spread Creek Lower\"] &lt;- st_point(c(-110.3199, 43.766533))\nst_geometry(mylittleg)[mylittleg$site_name == \"Grizzly Creek\"] &lt;- st_point(c(-110.23289, 43.77433))\nst_geometry(mylittleg)[mylittleg$site_name == \"NF Spread Creek Upper\"] &lt;- st_point(c(-110.23405, 43.77227))\nst_geometry(mylittleg)[mylittleg$site_name == \"SF Spread Creek Upper\"] &lt;- st_point(c(-110.31475, 43.73661))\n\n\n# filter data\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == bas, !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = orderr))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == bas, !is.na(logYield), Month %in% c(7:9), WaterYear %in% unique(tempdat$WaterYear))\n\n  # calculate variability for reference gage\nvarbig &lt;- tempdat_big %&gt;% \n  group_by(WaterYear) %&gt;% \n  summarize(bigrange = range(logYield)[2]-range(logYield)[1],\n            bigsd = sd(logYield),\n            bigvar = var(logYield)) %&gt;%\n  ungroup()\n\n# calculate total summer water availability from reference gage\n#summerflow &lt;- tempdat_big %&gt;% group_by(WaterYear) %&gt;% summarize(summeryield = sum(Yield_mm), summeryield_log = log(sum(Yield_mm))) %&gt;% ungroup()\n#wateravail2 &lt;- wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z)\n\n# calculate relative variation\npedat &lt;- tempdat %&gt;% \n  group_by(basin, WaterYear) %&gt;% \n  summarize(nsites = length(unique(site_name)),\n            littlerange = range(logYield)[2]-range(logYield)[1],\n            littlesd = sd(logYield),\n            littlevar = var(logYield)) %&gt;% \n  ungroup() %&gt;% \n  left_join(varbig) %&gt;%\n  mutate(pe_range = ((littlerange-bigrange)/bigrange),\n         pe_sd = ((littlesd-bigsd)/bigsd),\n         pe_var = ((littlevar-bigvar)/bigvar)) %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z, totalyield_sum, totalyield_sum_z, tyz_perc, tyz_sum_perc)) %&gt;% \n  filter(WaterYear %in% wtryrs) %&gt;%\n  mutate(wylab = substr(WaterYear, 3, 4)) %&gt;%\n  arrange(totalyield_sum_z)\n  \n# calculate annual median summer flow\nannmed &lt;- tempdat %&gt;%\n  #filter(WaterYear %in% c(lowyr, highyr)) %&gt;%\n  group_by(site_name, WaterYear) %&gt;%\n  summarize(medlogYield = median(logYield, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# arrange years by total annual yield\nwtryrs_arranged &lt;- as.numeric(unlist(pedat %&gt;% select(WaterYear)))\n\n# plot it\nplotlist_sn &lt;- list()\nfor(i in 1:length(wtryrs_arranged)) {\n  mylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i]))\n  mylittleg_sheds &lt;- sheds %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i])) %&gt;% arrange(desc(area_sqmi))\n  plotlist_sn[[i]] &lt;- local({\n    i &lt;- i\n    ggplot() +\n      geom_sf(data = st_as_sf(mysheds), color = \"black\", fill = \"white\", linewidth = 0.4) + \n      geom_sf(data = mylittleg_sheds, aes(fill = medlogYield), color = \"black\") +\n      scale_fill_viridis(option = \"A\", direction = 1, limits = range(annmed$medlogYield), na.value = \"grey\") +\n      geom_sf(data = st_as_sf(mynet), color = \"white\", linewidth = 1, lineend = \"round\") +\n      geom_sf(data = st_as_sf(mynet), color = \"royalblue4\", linewidth = 0.6, lineend = \"round\") +\n      geom_sf(data = mylittleg, shape = 21, fill = \"white\", size = 2) +\n      labs(fill = \"Median\\nsummer\\nlog(Yield)\") + #annotation_scale() +\n      coord_sf(xlim = range(st_coordinates(mylittleg_sheds)[,1]), ylim = range(st_coordinates(mylittleg_sheds)[,2])) +\n      theme_bw() + theme(axis.title.x = element_blank(), axis.title.y = element_blank(), legend.position = \"none\", axis.text = element_blank()) +\n      annotate(\"label\", x = -Inf, y = -Inf, label = paste(pedat$WaterYear[i], \" (\", pedat$tyz_sum_perc[i], \"%)\", sep = \"\"), vjust = -0.15, hjust = -0.05, size = 5)})\n}\nggarrange(plotlist = plotlist_sn, common.legend = TRUE, legend = \"right\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nbas &lt;- \"Donner Blitzen\"\norderr &lt;- c(donnerorder, \"Donner Blitzen River nr Frenchglen NWIS\")\nwtryrs &lt;- c(2016:2024)\n\nmysheds &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Watersheds/Oreg_Watersheds.shp\")\nmysheds &lt;- mysheds[mysheds$site_id == \"DBF\",]\nmynet &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Streams/Oreg_Streams.shp\")\ncrs(mynet) &lt;- crs(mysheds)\nmynet &lt;- crop(mynet, mysheds)\n\n\n# points\nmylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% orderr) %&gt;% mutate(site_name = factor(site_name, levels = donnerorder))\n# edit geometry to reduce overlap\nst_geometry(mylittleg)[mylittleg$site_name == \"Donner Blitzen ab Fish NWIS\"] &lt;- st_point(c(-118.84315, 42.75476))\nst_geometry(mylittleg)[mylittleg$site_name == \"Fish Creek\"] &lt;- st_point(c(-118.83173, 42.75911))\n\n\n# filter data\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == bas, !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = orderr))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == bas, !is.na(logYield), Month %in% c(7:9), WaterYear %in% unique(tempdat$WaterYear))\n\n  # calculate variability for reference gage\nvarbig &lt;- tempdat_big %&gt;% \n  group_by(WaterYear) %&gt;% \n  summarize(bigrange = range(logYield)[2]-range(logYield)[1],\n            bigsd = sd(logYield),\n            bigvar = var(logYield)) %&gt;%\n  ungroup()\n\n# calculate total summer water availability from reference gage\n#summerflow &lt;- tempdat_big %&gt;% group_by(WaterYear) %&gt;% summarize(summeryield = sum(Yield_mm), summeryield_log = log(sum(Yield_mm))) %&gt;% ungroup()\n#wateravail2 &lt;- wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z)\n\n\n# calculate relative variation\npedat &lt;- tempdat %&gt;% \n  group_by(basin, WaterYear) %&gt;% \n  summarize(nsites = length(unique(site_name)),\n            littlerange = range(logYield)[2]-range(logYield)[1],\n            littlesd = sd(logYield),\n            littlevar = var(logYield)) %&gt;% \n  ungroup() %&gt;% \n  left_join(varbig) %&gt;%\n  mutate(pe_range = ((littlerange-bigrange)/bigrange),\n         pe_sd = ((littlesd-bigsd)/bigsd),\n         pe_var = ((littlevar-bigvar)/bigvar)) %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z, totalyield_sum, totalyield_sum_z, tyz_perc, tyz_sum_perc)) %&gt;% \n  filter(WaterYear %in% wtryrs) %&gt;%\n  mutate(wylab = substr(WaterYear, 3, 4)) %&gt;%\n  arrange(totalyield_sum_z)\n  \n# calculate annual median summer flow\nannmed &lt;- tempdat %&gt;%\n  group_by(site_name, WaterYear) %&gt;%\n  summarize(medlogYield = median(logYield, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  bind_rows(tempdat_big %&gt;%\n  group_by(site_name, WaterYear) %&gt;%\n  summarize(medlogYield = median(logYield, na.rm = TRUE)) %&gt;%\n  ungroup())\n\n# arrange years by total annual yield\nwtryrs_arranged &lt;- as.numeric(unlist(pedat %&gt;% select(WaterYear)))\n\n# plot it\nplotlist_db &lt;- list()\nfor(i in 1:length(wtryrs_arranged)) {\n  mylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i]))\n  mylittleg_sheds &lt;- sheds %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i])) %&gt;% arrange(desc(area_sqmi))\n  plotlist_db[[i]] &lt;- local({\n    i &lt;- i\n    ggplot() +\n      geom_sf(data = st_as_sf(mysheds), color = \"black\", fill = \"white\", linewidth = 0.4) + \n      geom_sf(data = mylittleg_sheds, aes(fill = medlogYield), color = \"black\") +\n      scale_fill_viridis(option = \"A\", direction = 1, limits = range(annmed$medlogYield), na.value = \"grey\") +\n      geom_sf(data = st_as_sf(mynet), color = \"white\", linewidth = 1, lineend = \"round\") +\n      geom_sf(data = st_as_sf(mynet), color = \"royalblue4\", linewidth = 0.6, lineend = \"round\") +\n      geom_sf(data = mylittleg, shape = 21, fill = \"white\", size = 2) +\n      labs(fill = \"Median\\nsummer\\nlog(Yield)\") + #annotation_scale() +\n      coord_sf(xlim = range(st_coordinates(mylittleg_sheds)[,1]), ylim = range(st_coordinates(mylittleg_sheds)[,2])) +\n      theme_bw() + theme(axis.title.x = element_blank(), axis.title.y = element_blank(), legend.position = \"none\", axis.text = element_blank()) +\n      annotate(\"label\", x = -Inf, y = -Inf, label = paste(pedat$WaterYear[i], \" (\", pedat$tyz_sum_perc[i], \"%)\", sep = \"\"), vjust = -0.15, hjust = -0.05, size = 5)})\n}\nggarrange(plotlist = plotlist_db, common.legend = TRUE, legend = \"right\")",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Objective 1</span>"
    ]
  },
  {
    "objectID": "Qualitative/LowFlow.html#order-sites",
    "href": "Qualitative/LowFlow.html#order-sites",
    "title": "15  Objective 4",
    "section": "15.2 Order sites",
    "text": "15.2 Order sites\nFor colors, order sites from downstream to upstream (roughly) and by subbasin (if appropriate)\n\n\nCode\nwborder &lt;- c(\"West Brook NWIS\", \"West Brook Lower\", \"Mitchell Brook\", \"Jimmy Brook\", \"Obear Brook Lower\", \"West Brook Upper\", \"West Brook Reservoir\", \"Sanderson Brook\", \"Avery Brook\", \"West Whately Brook\")\npaineorder &lt;- c(\"Paine Run 10\", \"Paine Run 08\", \"Paine Run 07\", \"Paine Run 06\", \"Paine Run 02\", \"Paine Run 01\")\nstauntorder &lt;- c(\"Staunton River 10\", \"Staunton River 09\", \"Staunton River 07\", \"Staunton River 06\", \"Staunton River 03\", \"Staunton River 02\")\nflatorder &lt;- c(\"BigCreekLower\", \"LangfordCreekLower\", \"LangfordCreekUpper\", \"Big Creek NWIS\", \"BigCreekUpper\", \"HallowattCreekLower\", \"NicolaCreek\", \"WernerCreek\", \"Hallowat Creek NWIS\", \"CoalCreekLower\", \"CycloneCreekLower\", \"CycloneCreekMiddle\", \"CycloneCreekUpper\", \"CoalCreekMiddle\", \"CoalCreekNorth\", \"CoalCreekHeadwaters\", \"McGeeCreekLower\", \"McGeeCreekTrib\", \"McGeeCreekUpper\")\nyellorder &lt;- c(\"Shields River Valley Ranch\", \"Deep Creek\", \"Crandall Creek\", \"Buck Creek\", \"Dugout Creek\", \"Shields River ab Dugout\", \"Lodgepole Creek\", \"EF Duck Creek be HF\", \"EF Duck Creek ab HF\", \"Henrys Fork\")\nsnakeorder &lt;- c(\"Spread Creek Dam\", \"Rock Creek\", \"NF Spread Creek Lower\", \"NF Spread Creek Upper\", \"Grizzly Creek\", \"SF Spread Creek Lower\", \"Grouse Creek\", \"SF Spread Creek Upper\", \"Leidy Creek Mouth\")\ndonnerorder &lt;- c(\"Fish Creek NWIS\", \"Donner Blitzen ab Fish NWIS\", \"Donner Blitzen nr Burnt Car NWIS\", \"Donner Blitzen ab Indian NWIS\")",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Objective 4</span>"
    ]
  },
  {
    "objectID": "Qualitative/LowFlow.html#big-plot",
    "href": "Qualitative/LowFlow.html#big-plot",
    "title": "15  Objective 4",
    "section": "15.7 Big plot",
    "text": "15.7 Big plot\n\n\nCode\n# site-level drought threshold\nheatmapfun_site &lt;- function(bas, months, bigG) {\n  dd &lt;- dat_clean_sub %&gt;% filter(basin == bas)\n  mysites &lt;- c(unique(unlist(dd %&gt;% filter(site_name != bigG) %&gt;% select(site_name))), bigG)\n  myrect &lt;- dd %&gt;% group_by(WaterYear) %&gt;% summarize(mindate = min(date), maxdate = max(date)) %&gt;% ungroup()\n  p &lt;- dd %&gt;%\n    ggplot() +\n    geom_tile(aes(x = date, y = factor(site_name, levels = (mysites)), fill = drought_fix)) +\n    scale_fill_viridis(option = \"A\", direction = -1, discrete = TRUE, limits = mydroughtlevels) +\n    geom_rect(data = myrect, aes(xmin = mindate, xmax = maxdate, ymin = length(mysites)-0.5, ymax = length(mysites)+0.5), \n              color = \"grey70\", fill = NA, size = 1.25) +\n    xlab(\"Date\") + ylab(\"Site\") +\n    #facet_wrap(~WaterYear, scales = \"free_x\") + \n    facet_wrap2(~WaterYear, scales = \"free_x\", nrow = 2, ncol = 3, trim_blank = FALSE) +\n    theme_bw() + theme(axis.title = element_blank())\nreturn(p)\n}",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Objective 4</span>"
    ]
  },
  {
    "objectID": "Qualitative/LowFlow.html#model",
    "href": "Qualitative/LowFlow.html#model",
    "title": "15  Objective 4",
    "section": "15.8 Model",
    "text": "15.8 Model\nHere I tried to model drought duration using a hierarchical binomial model, then estimate the effect of regional water availability on spatial variation drought duration within headwater basins. But most of the parameters do not converge (most notable, the spatial variation parameter), which is probably a result of so few data points (years) per basin.\n\n\nCode\ncat(\"model {\n\n##--- LIKELIHOOD ---------------------------------------------------##\n\n# for (k in 1:nyrs) {\n#   for (j in 1:nsites) {\n#     y[j,k] ~ dbin(p[j,k], N[j,k])\n#     logit(p[j,k]) &lt;- alpha[site_basin[j],k] + u[j,k]\n#     u[j,k] ~ dnorm(basin_effect[site_basin[j],k], pow(sigma_spatial[site_basin[j]], -2))\n#   }\n#   for (b in 1:nbasin) {\n#     log(sigma_spatial[b]) &lt;- beta0 + beta1*water_avail[b,k]\n#   }\n# }\n\n\nfor (i in 1:nobs) {\n  drought_days[i] ~ dbin(p[i], n_days[i])\n  logit(p[i]) &lt;- alpha[basin[i], year[i]] + u[i]\n  u[i] ~ dnorm(0, pow(sigma_spatial[basin[i], year[i]], -2))\n}\n\nfor (b in 1:nbasins) {\n  for (y in 1:nyears) {\n    sigma_spatial[b,y] &lt;- exp(beta0[b] + beta1[b] * regional_water[b,y])\n  }\n}\n\n\nfor (b in 1:nbasins) {\n  beta0[b] ~ dnorm(mu_beta0, pow(100, -2))\n  beta1[b] ~ dnorm(mu_beta1, pow(100, -2))\n  for (y in 1:nyears) {\n    alpha[b,y] ~ dnorm(mu_alpha, pow(100, -2))\n  }\n}\n\nmu_alpha ~ dnorm(0, pow(100, -2))\nmu_beta0 ~ dnorm(0, pow(100, -2))\nmu_beta1 ~ dnorm(0, pow(100, -2))\n\n\n\n##--- PRIORS --------------------------------------------------------##\n\n# for (b in 1:nbasin) {\n#   alpha[b] ~ dnorm(0, pow(10, -2))\n#   \n#   for (k in 1:nyrs) {\n#     basin_effect[b,k] ~ dnorm(0, pow(100, -2))\n#   }\n# }\n\n\n##--- DERIVED VALUES ------------------------------------------------##\n\n\n\n\n}\", file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/LowFlowModel.txt\")\n\n\n\n\nCode\ndefdur_ssn_sub2_sub &lt;- defdur_ssn_sub2 %&gt;%\n  filter(designation == \"little\",\n         basin %in% c(\"West Brook\", \"Staunton River\", \"Snake River\", \"Donner Blitzen\")) %&gt;% \n  select(basin, subbasin, site_name, WaterYear, ndays, duration_10_fix) %&gt;%\n  arrange(basin, WaterYear, site_name) %&gt;%\n  mutate(basin_code = as.numeric(as.factor(basin)),\n         WaterYear_code = as.numeric(as.factor(WaterYear)))\n\nregional_water &lt;- wateravail %&gt;% \n  filter(basin %in% unique(defdur_ssn_sub2_sub$basin),\n         WaterYear %in% unique(defdur_ssn_sub2_sub$WaterYear)) %&gt;%\n  select(basin, WaterYear, totalyield_sum_z) %&gt;%\n  spread(key = WaterYear, value = totalyield_sum_z)\nregional_water_mat &lt;- regional_water[,-1]\n\n\n\n\nCode\n# --- Prepare Data for JAGS ---\n\njags.data &lt;- list(\n  \"nobs\" = dim(defdur_ssn_sub2_sub)[1],\n  \"nbasins\" = length(unique(defdur_ssn_sub2_sub$basin)),\n  \"nyears\" = length(unique(defdur_ssn_sub2_sub$WaterYear)),\n  \"drought_days\" = defdur_ssn_sub2_sub$duration_10_fix,\n  \"n_days\" = defdur_ssn_sub2_sub$ndays,\n  \"basin\" = defdur_ssn_sub2_sub$basin_code,\n  \"year\" = defdur_ssn_sub2_sub$WaterYear_code,\n  \"regional_water\" = regional_water_mat\n)\n\n# parameters to monitor\njags.params &lt;- c(\"mu_alpha\", \"mu_beta0\", \"mu_beta1\", \"alpha\", \"beta0\", \"beta1\", \"sigma_spatial\", \"u\", \"p\")\n\n# run in jags\nmod_0 &lt;- jags(data = jags.data, parameters.to.save = jags.params,\n              model.file = \"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/LowFlowModel.txt\",\n              n.chains = 3, n.thin = 50, n.burnin = 2000, n.iter = 10000, DIC = FALSE)\n\n\nGet MCMC samples and summary\n\n\nCode\ntop_mod &lt;- mod_0\n# generate MCMC samples and store as an array\nmodelout &lt;- top_mod$BUGSoutput\nMcmcList &lt;- vector(\"list\", length = dim(modelout$sims.array)[2])\nfor(i in 1:length(McmcList)) { McmcList[[i]] = as.mcmc(modelout$sims.array[,i,]) }\n# rbind MCMC samples from 10 chains \nMcmcdat &lt;- rbind(McmcList[[1]], McmcList[[2]], McmcList[[3]])\nparam.summary &lt;- modelout$summary\nhead(param.summary)\n\n\nFor global parameters and hyperparameters only…\n\n\nCode\nMCMCtrace(mod_0, ind = TRUE, params = c(\"u\"), pdf = FALSE)",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Objective 4</span>"
    ]
  },
  {
    "objectID": "Qualitative/SpaceTimeVar.html#big-plot",
    "href": "Qualitative/SpaceTimeVar.html#big-plot",
    "title": "12  Objective 1",
    "section": "12.8 Big plot",
    "text": "12.8 Big plot\nCombine interannual distributions of summer flow, scatterplots showing relationship between water availability and relative range among little g’s, and maps of median summer flow in a low and high water year\nRedraw Yellowstone to move upper Shields and Duck Creek closer together\n\n\nCode\nbas &lt;- \"Shields River\"\norderr &lt;- yellorder\nwtryrs &lt;- c(2016:2020,2022:2024)\n\nmysheds &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Watersheds/Shields_Watersheds.shp\")\nmysheds &lt;- mysheds[mysheds$site_id %in% c(\"SRS\", \"DU01\"),]\nmynet &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Streams/Shields_Streams.shp\")\ncrs(mynet) &lt;- crs(mysheds)\nmynet &lt;- crop(mynet, mysheds)\n\n# points\nmylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% orderr) %&gt;% mutate(site_name = factor(site_name, levels = orderr)) #%&gt;% filter(subbasin != \"Duck Creek\")\n\n\n# filter data\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == bas, !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = orderr))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == bas, !is.na(logYield), Month %in% c(7:9), WaterYear %in% unique(tempdat$WaterYear))\n\n  # calculate variability for reference gage\nvarbig &lt;- tempdat_big %&gt;% \n  group_by(WaterYear) %&gt;% \n  summarize(bigrange = range(logYield)[2]-range(logYield)[1],\n            bigsd = sd(logYield),\n            bigvar = var(logYield)) %&gt;%\n  ungroup()\n\n# calculate total summer water availability from reference gage\n#summerflow &lt;- tempdat_big %&gt;% group_by(WaterYear) %&gt;% summarize(summeryield = sum(Yield_mm), summeryield_log = log(sum(Yield_mm))) %&gt;% ungroup()\n#wateravail2 &lt;- wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z)\n\n# calculate relative variation\npedat &lt;- tempdat %&gt;% \n  group_by(basin, WaterYear) %&gt;% \n  summarize(nsites = length(unique(site_name)),\n            littlerange = range(logYield)[2]-range(logYield)[1],\n            littlesd = sd(logYield),\n            littlevar = var(logYield)) %&gt;% \n  ungroup() %&gt;% \n  left_join(varbig) %&gt;%\n  mutate(pe_range = ((littlerange-bigrange)/bigrange),\n         pe_sd = ((littlesd-bigsd)/bigsd),\n         pe_var = ((littlevar-bigvar)/bigvar)) %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z, totalyield_sum, totalyield_sum_z, tyz_perc, tyz_sum_perc)) %&gt;% \n  filter(WaterYear %in% wtryrs) %&gt;%\n  mutate(wylab = substr(WaterYear, 3, 4)) %&gt;%\n  arrange(totalyield_sum_z)\n  \n# calculate annual median summer flow\nannmed &lt;- tempdat %&gt;%\n  #filter(WaterYear %in% c(lowyr, highyr)) %&gt;%\n  group_by(site_name, WaterYear) %&gt;%\n  summarize(medlogYield = median(logYield, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# arrange years by total annual yield\nwtryrs_arranged &lt;- as.numeric(unlist(pedat %&gt;% select(WaterYear)))\n\n\n\n# 2020\nmylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == 2020))\n  mylittleg_sheds &lt;- sheds %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == 2020)) %&gt;% arrange(desc(area_sqmi))\n  mainmap &lt;- ggplot() +\n      geom_sf(data = st_as_sf(mysheds), color = \"black\", fill = \"white\", linewidth = 0.4) + \n      geom_sf(data = mylittleg_sheds, aes(fill = medlogYield), color = \"black\") +\n      scale_fill_viridis(option = \"A\", direction = 1, limits = range(annmed$medlogYield), na.value = \"grey\") +\n      geom_sf(data = st_as_sf(mynet), color = \"white\", linewidth = 1, lineend = \"round\") +\n      geom_sf(data = st_as_sf(mynet), color = \"royalblue4\", linewidth = 0.6, lineend = \"round\") +\n      geom_sf(data = mylittleg, shape = 21, fill = \"white\", size = 2) +\n      labs(fill = \"Median\\nsummer\\nlog(Yield)\") + #annotation_scale() +\n      coord_sf(xlim = c(-110.555,-110.30), ylim = c(46.07,46.23)) +\n      theme_bw() + theme_void() + \n    theme(axis.title.x = element_blank(), axis.title.y = element_blank(), axis.text = element_blank()) +\n      scale_x_continuous(expand = c(0.002, 0.002)) + scale_y_continuous(expand = c(0.002, 0.002)) +\n      annotate(\"label\", x = -Inf, y = Inf, label = \"2020 (47%)\", vjust = 1.15, hjust = -0.05, size = 5)\ndbp1 &lt;- local({\n    i &lt;- i\n    ggdraw(mainmap + theme(legend.position = \"none\")) + \n      draw_plot(\n        {\n          ggplot() +\n            geom_sf(data = st_as_sf(mysheds), color = \"black\", fill = \"white\", linewidth = 0.4) + \n            geom_sf(data = mylittleg_sheds, aes(fill = medlogYield), color = \"black\") +\n            scale_fill_viridis(option = \"A\", direction = 1, limits = range(annmed$medlogYield), na.value = \"grey\") +\n            geom_sf(data = st_as_sf(mynet), color = \"white\", linewidth = 1, lineend = \"round\") +\n            geom_sf(data = st_as_sf(mynet), color = \"royalblue4\", linewidth = 0.6, lineend = \"round\") +\n            geom_sf(data = mylittleg, shape = 21, fill = \"white\", size = 2) +\n            labs(fill = \"Median\\nsummer\\nlog(Yield)\") + #annotation_scale() +\n            coord_sf(xlim = c(-110.31,-110.23), ylim = c(45.865,45.96)) +\n            theme_bw() + theme_void() + theme(legend.position = \"none\") +\n            scale_x_continuous(expand = c(0.002, 0.002)) + scale_y_continuous(expand = c(0.002, 0.002))\n          },\n        x = 0.05, y = 0, width = 0.3, height = 0.5)\n      })\n\n# 2017\nmylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == 2017))\n  mylittleg_sheds &lt;- sheds %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == 2017)) %&gt;% arrange(desc(area_sqmi))\n  mainmap &lt;- ggplot() +\n      geom_sf(data = st_as_sf(mysheds), color = \"black\", fill = \"white\", linewidth = 0.4) + \n      geom_sf(data = mylittleg_sheds, aes(fill = medlogYield), color = \"black\") +\n      scale_fill_viridis(option = \"A\", direction = 1, limits = range(annmed$medlogYield), na.value = \"grey\") +\n      geom_sf(data = st_as_sf(mynet), color = \"white\", linewidth = 1, lineend = \"round\") +\n      geom_sf(data = st_as_sf(mynet), color = \"royalblue4\", linewidth = 0.6, lineend = \"round\") +\n      geom_sf(data = mylittleg, shape = 21, fill = \"white\", size = 2) +\n      labs(fill = \"Median\\nsummer\\nlog(Yield)\") + #annotation_scale() +\n      coord_sf(xlim = c(-110.555,-110.30), ylim = c(46.07,46.23)) +\n      theme_bw() + theme_void() + \n    theme(axis.title.x = element_blank(), axis.title.y = element_blank(), axis.text = element_blank()) +\n      scale_x_continuous(expand = c(0.002, 0.002)) + scale_y_continuous(expand = c(0.002, 0.002)) +\n      annotate(\"label\", x = -Inf, y = Inf, label = \"2017 (67%)\", vjust = 1.15, hjust = -0.05, size = 5)\ndbp2 &lt;- local({\n    i &lt;- i\n    ggdraw(mainmap + theme(legend.position = \"none\")) + \n      draw_plot(\n        {\n          ggplot() +\n            geom_sf(data = st_as_sf(mysheds), color = \"black\", fill = \"white\", linewidth = 0.4) + \n            geom_sf(data = mylittleg_sheds, aes(fill = medlogYield), color = \"black\") +\n            scale_fill_viridis(option = \"A\", direction = 1, limits = range(annmed$medlogYield), na.value = \"grey\") +\n            geom_sf(data = st_as_sf(mynet), color = \"white\", linewidth = 1, lineend = \"round\") +\n            geom_sf(data = st_as_sf(mynet), color = \"royalblue4\", linewidth = 0.6, lineend = \"round\") +\n            geom_sf(data = mylittleg, shape = 21, fill = \"white\", size = 2) +\n            labs(fill = \"Median\\nsummer\\nlog(Yield)\") + #annotation_scale() +\n            coord_sf(xlim = c(-110.31,-110.23), ylim = c(45.865,45.96)) +\n            theme_bw() + theme_void() + theme(legend.position = \"none\") +\n            scale_x_continuous(expand = c(0.002, 0.002)) + scale_y_continuous(expand = c(0.002, 0.002))\n          },\n        x = 0.05, y = 0, width = 0.3, height = 0.5)\n      })\n#ggarrange(dbp1, dbp2, as_ggplot(ggpubr::get_legend(mainmap)), nrow = 1, widths = c(1,1,0.2))\n\n\nGet pieces\n\n\nCode\n# West Brook\np1 &lt;- ggarrange(portfolioplot(bas = \"West Brook\", orderr = wborder, type = \"interannual\", wtryrs = c(2020:2024)) + theme(axis.title.x = element_blank()),\n          portfolioplot(bas = \"West Brook\", orderr = wborder, type = \"scatter\", wtryrs = c(2020:2024)) + theme(axis.title.x = element_blank()),\n          ggarrange(plotlist_wb[[2]] + theme_void() + scale_x_continuous(expand = c(0.002, 0.002)) + scale_y_continuous(expand = c(0.002, 0.002)) + theme(legend.position = \"none\"),\n                    plotlist_wb[[4]] + theme_void() + scale_x_continuous(expand = c(0.002, 0.002)) + scale_y_continuous(expand = c(0.002, 0.002)) + theme(legend.position = \"none\")),\n          widths = c(1,1,2), align = \"h\", nrow = 1)\n\n\n# Paine\np2 &lt;- ggarrange(portfolioplot(bas = \"Paine Run\", orderr = paineorder, type = \"interannual\", wtryrs = c(2019:2022)) + theme(axis.title.x = element_blank()),\n          portfolioplot(bas = \"Paine Run\", orderr = paineorder, type = \"scatter\", wtryrs = c(2019:2022)) + theme(axis.title.x = element_blank()),\n          ggarrange(plotlist_pa[[1]] + theme_void() + scale_x_continuous(expand = c(0.002, 0.002)) + scale_y_continuous(expand = c(0.002, 0.002)) + theme(legend.position = \"none\"), \n                    plotlist_pa[[4]] + theme_void() + scale_x_continuous(expand = c(0.002, 0.002)) + scale_y_continuous(expand = c(0.002, 0.002)) + theme(legend.position = \"none\")),\n          widths = c(1,1,2), align = \"h\", nrow = 1)\n\n\n# Staunton\np3 &lt;- ggarrange(portfolioplot(bas = \"Staunton River\", orderr = stauntorder, type = \"interannual\", wtryrs = c(2019:2022)) + theme(axis.title.x = element_blank()),\n          portfolioplot(bas = \"Staunton River\", orderr = stauntorder, type = \"scatter\", wtryrs = c(2019:2022)) + theme(axis.title.x = element_blank()),\n          ggarrange(plotlist_st[[1]] + theme_void() + scale_x_continuous(expand = c(0.002, 0.002)) + scale_y_continuous(expand = c(0.002, 0.002)) + theme(legend.position = \"none\"), \n                    plotlist_st[[4]] + theme_void() + scale_x_continuous(expand = c(0.002, 0.002)) + scale_y_continuous(expand = c(0.002, 0.002)) + theme(legend.position = \"none\")),\n          widths = c(1,1,2), align = \"h\", nrow = 1)\n\n\n# Flathead\np4 &lt;- ggarrange(portfolioplot(bas = \"Flathead\", orderr = flatorder, type = \"interannual\", wtryrs = c(2018:2024)) + theme(axis.title.x = element_blank()),\n          portfolioplot(bas = \"Flathead\", orderr = flatorder, type = \"scatter\", wtryrs = c(2018:2024)) + theme(axis.title.x = element_blank()),\n          ggarrange(plotlist_fl[[2]] + theme_void() + scale_x_continuous(expand = c(0.003, 0.003)) + scale_y_continuous(expand = c(0.002, 0.002)) + theme(legend.position = \"none\"), \n                    plotlist_fl[[6]] + theme_void() + scale_x_continuous(expand = c(0.003, 0.003)) + scale_y_continuous(expand = c(0.002, 0.002)) + theme(legend.position = \"none\")),\n          widths = c(1,1,2), align = \"h\", nrow = 1)\n\n\n# Yellowstone\np5 &lt;- ggarrange(portfolioplot(bas = \"Shields River\", orderr = yellorder, type = \"interannual\", wtryrs = c(2016:2020,2022:2024)) + theme(axis.title.x = element_blank()),\n          portfolioplot(bas = \"Shields River\", orderr = yellorder, type = \"scatter\", wtryrs = c(2016:2020,2022:2024)) + theme(axis.title.x = element_blank()),\n          ggarrange(dbp1, dbp2, nrow = 1),\n          widths = c(1,1,2), align = \"h\", nrow = 1)\n\n\n# Snake River\np6 &lt;- ggarrange(portfolioplot(bas = \"Snake River\", orderr = snakeorder, type = \"interannual\", wtryrs = c(2016:2024)) + theme(axis.title.x = element_blank()),\n          portfolioplot(bas = \"Snake River\", orderr = snakeorder, type = \"scatter\", wtryrs = c(2016:2024)) + theme(axis.title.x = element_blank()),\n          ggarrange(plotlist_sn[[2]] + theme_void() + scale_x_continuous(expand = c(0.003, 0.003)) + scale_y_continuous(expand = c(0.002, 0.002)) + theme(legend.position = \"none\"), \n                    plotlist_sn[[5]] + theme_void() + scale_x_continuous(expand = c(0.003, 0.003)) + scale_y_continuous(expand = c(0.002, 0.002)) + theme(legend.position = \"none\")),\n          widths = c(1,1,2), align = \"h\", nrow = 1)\n\n\n# Donner Blitzen\np7 &lt;- ggarrange(portfolioplot(bas = \"Donner Blitzen\", orderr = donnerorder, type = \"interannual\", wtryrs = c(2016:2024)),\n          portfolioplot(bas = \"Donner Blitzen\", orderr = donnerorder, type = \"scatter\", wtryrs = c(2016:2024)),\n          ggarrange(plotlist_db[[1]] + theme_void() + scale_x_continuous(expand = c(0.002, 0.002)) + scale_y_continuous(expand = c(0.003, 0.003)) + theme(legend.position = \"none\"), \n                    plotlist_db[[4]] + theme_void() + scale_x_continuous(expand = c(0.002, 0.002)) + scale_y_continuous(expand = c(0.003, 0.003)) + theme(legend.position = \"none\")),\n          widths = c(1,1,2), align = \"h\", nrow = 1)\negg::ggarrange(p1, p2, p3, p4, p5, p6, p7, nrow = 7)\n\n\n\n\n\n\n\n\n\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Qualitative/EcoD_Obj1_bigplot.jpg\", width = 12, height = 20, units = \"in\", res = 1000)\negg::ggarrange(p1, p2, p3, p4, p5, p6, p7, nrow = 7)\ndev.off()\n\n\npng \n  2 \n\n\n\n12.8.1 Presentation figs\nTime series plots, West Brook and Flathead\n\n\nCode\n### FLATHEAD\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Flathead\", date &gt;= date(\"2018-07-29\"), date &lt;= date(\"2023-08-11\")) %&gt;%\n  mutate(site_name = factor(site_name, levels = flatorder))\ntempdat &lt;- fill_missing_dates(tempdat, dates = date, groups = site_name, pad_ends = FALSE)  \nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"Flathead\", date &gt;= date(\"2018-07-29\"), date &lt;= date(\"2023-08-11\"))\n# color\npfl1 &lt;- ggplot() +\n  geom_line(data = tempdat, aes(x = date, y = logYield, color = factor(site_name, levels = flatorder))) +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  ylim(-3,2) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"Flathead River\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\np &lt;- annotate_figure(egg::ggarrange(pwb1, pfl1 + ylim(-2.4,1.72), ncol = 1), left = \"log(Yield, mm/day)\")\nprint(p)\n\n\n\n\n\n\n\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Presentation figs/EcoD_timeseries_WBFlat.jpg\", width = 8, height = 5, units = \"in\", res = 1000)\np\ndev.off()\n\n\npng \n  2 \n\n\nCode\n#### NO LITTLE Gs\n### WEST BROOK\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"West Brook\") %&gt;%\n  mutate(site_name = factor(site_name, levels = wborder))\ntempdat &lt;- fill_missing_dates(tempdat, dates = date, groups = site_name, pad_ends = FALSE)  \nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"West Brook\", date &gt;= date(\"2020-01-01\"), date &lt;= date(\"2025-01-03\"))\n# color\npwb1_nlg &lt;- ggplot() +\n  #geom_line(data = tempdat, aes(x = date, y = logYield, color = factor(site_name, levels = wborder))) +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  ylim(-3,2) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"The West Brook\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\n### FLATHEAD\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == \"Flathead\", date &gt;= date(\"2018-07-29\"), date &lt;= date(\"2023-08-11\")) %&gt;%\n  mutate(site_name = factor(site_name, levels = flatorder))\ntempdat &lt;- fill_missing_dates(tempdat, dates = date, groups = site_name, pad_ends = FALSE)  \nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == \"Flathead\", date &gt;= date(\"2018-07-29\"), date &lt;= date(\"2023-08-11\"))\n# color\npfl1_nlg &lt;- ggplot() +\n  #geom_line(data = tempdat, aes(x = date, y = logYield, color = factor(site_name, levels = flatorder))) +\n  geom_line(data = tempdat_big, aes(x = date, y = logYield), color = \"grey40\") +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  ylim(-2.4,1.72) +\n  annotate(\"text\", x = min(c(tempdat_big$date, tempdat$date), na.rm = TRUE), y = max(c(tempdat_big$logYield, tempdat$logYield), na.rm = TRUE), label = \"Flathead River\", hjust = 0, vjust = 1) +\n  scale_x_date(expand = c(0.02,0.02)) + #scale_y_continuous(expand = c(0,0)) +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\", \n                     axis.title = element_blank(), plot.margin = margin(t = 1, r = 5, b = 2, l = 2), axis.text = element_text(color = \"black\"))\n\np &lt;- annotate_figure(egg::ggarrange(pwb1_nlg, pfl1_nlg, ncol = 1), left = \"log(Yield, mm/day)\")\nprint(p)\n\n\n\n\n\n\n\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Presentation figs/EcoD_timeseries_WBFlat_nolittle.jpg\", width = 8, height = 5, units = \"in\", res = 1000)\np\ndev.off()\n\n\npng \n  2 \n\n\nSummer log(yield) distributions for West Brook and Flathead\n\n\nCode\np &lt;- egg::ggarrange(portfolioplot(bas = \"West Brook\", orderr = wborder, type = \"interannual\", wtryrs = c(2020:2024)) + theme(axis.title = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank(), plot.margin = margin(t = 1, r = 1, b = 2, l = 1)),\n               portfolioplot(bas = \"Flathead\", orderr = flatorder, type = \"interannual\", wtryrs = c(2018:2024)) + theme(axis.title = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank(), plot.margin = margin(t = 1, r = 1, b = 2, l = 1)),\n               nrow = 2)\n\n\n\n\n\n\n\n\n\nCode\nprint(p)\n\n\n\n\n\n\n\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Presentation figs/EcoD_summerdensity_WBFlat.jpg\", width = 2.75, height = 5, units = \"in\", res = 1000)\np\ndev.off()\n\n\npng \n  2 \n\n\nScatterplot: relative difference range vs. regional water availability\n\n\nCode\n# define basin-years to keep\nkeepyears &lt;- bind_rows(\n  tibble(basin = \"West Brook\", WaterYear = c(2020:2024)),\n  tibble(basin = \"Paine Run\", WaterYear = c(2019:2022)),\n  tibble(basin = \"Staunton River\", WaterYear = c(2019:2022)),\n  tibble(basin = \"Flathead\", WaterYear = c(2018:2024)),\n  tibble(basin = \"Shields River\", WaterYear = c(2016:2020,2022:2024)),\n  tibble(basin = \"Snake River\", WaterYear = c(2016:2024)),\n  tibble(basin = \"Donner Blitzen\", WaterYear = c(2016:2024)),\n) %&gt;% mutate(keep = \"yes\")\n\n# standard deviation of median summer flow\n# dat_clean %&gt;%\n#   filter(Month %in% c(7:9)) %&gt;%\n#   group_by(basin, site_name, WaterYear) %&gt;%\n#   summarize(medyield = median(logYield, na.rm = TRUE)) %&gt;%\n#   ungroup() %&gt;%\n#   group_by(basin, WaterYear) %&gt;%\n#   summarize(sdyield = sd(medyield), nsites = n()) %&gt;%\n#   ungroup() %&gt;%\n#   left_join(wateravail %&gt;% select(basin, WaterYear, totalyield:tyz_sum_perc)) %&gt;%\n#   left_join(keepyears) %&gt;% filter(keep == \"yes\") %&gt;%\n#   mutate(basin = ifelse(basin == \"Shields River\", \"Yellowstone River\",\n#                         ifelse(basin == \"Flathead\", \"Flathead River\", basin))) %&gt;%\n#   mutate(basin = factor(basin, levels = c(\"West Brook\", \"Piney River\", \"Staunton River\", \"Paine Run\", \"Flathead River\", \"Yellowstone River\", \"Snake River\", \"Donner Blitzen\"))) %&gt;%\n#   ggplot(aes(x = tyz_sum_perc, y = sdyield)) +\n#   geom_smooth(method = \"lm\", color = \"black\", aes(weight = nsites)) +\n#   geom_point(aes(fill = basin, size = nsites), shape = 21) +\n#   scale_fill_brewer(palette = \"Set2\") +\n#   #facet_wrap(~basin) +\n#   theme_bw() + theme(panel.grid = element_blank())\n\n\n# calculate relative difference in range as above\nmydat &lt;- dat_clean %&gt;% \n  filter(Month %in% c(7:9)) %&gt;%\n  group_by(basin, WaterYear) %&gt;% \n  summarize(nsites = length(unique(site_name)),\n            littlerange = range(logYield)[2]-range(logYield)[1]) %&gt;% \n  ungroup() %&gt;% \n  left_join(dat_clean_big %&gt;% \n              filter(Month %in% c(7:9)) %&gt;% \n              group_by(basin, WaterYear) %&gt;% \n              summarize(bigrange = range(logYield)[2]-range(logYield)[1]) %&gt;%\n              ungroup()) %&gt;%\n  mutate(pe_range = ((littlerange-bigrange)/bigrange)) %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield:tyz_sum_perc)) %&gt;%\n  left_join(keepyears) %&gt;% filter(keep == \"yes\") %&gt;%\n  mutate(basin = ifelse(basin == \"Shields River\", \"Yellowstone River\",\n                        ifelse(basin == \"Flathead\", \"Flathead River\", basin))) %&gt;%\n  mutate(basin = factor(basin, levels = c(\"West Brook\", \"Piney River\", \"Staunton River\", \"Paine Run\", \n                                          \"Flathead River\", \"Yellowstone River\", \"Snake River\", \"Donner Blitzen\"))) \n\n# show linear model summary, weighted by number of sites\nsummary(lm(pe_range ~ tyz_sum_perc, data = mydat, weights = nsites))\n\n\n\nCall:\nlm(formula = pe_range ~ tyz_sum_perc, data = mydat, weights = nsites)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-5.0362 -2.0522 -0.2509  1.0884  6.3945 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.391231   0.267291   8.946 1.12e-10 ***\ntyz_sum_perc -0.018174   0.005199  -3.496  0.00127 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.626 on 36 degrees of freedom\nMultiple R-squared:  0.2534,    Adjusted R-squared:  0.2327 \nF-statistic: 12.22 on 1 and 36 DF,  p-value: 0.001273\n\n\nCode\n# plot\nrandiffplot &lt;- mydat %&gt;%\n  ggplot(aes(x = tyz_sum_perc, y = pe_range)) +\n  geom_smooth(method = \"lm\", mapping = aes(weight = nsites), color = \"black\") +\n  geom_point(aes(fill = basin, size = nsites), shape = 21) +\n  scale_fill_brewer(palette = \"Set2\") +\n  #facet_wrap(~basin) +\n  theme_bw() + theme(panel.grid = element_blank()) +\n  ylab(\"Relative difference in range\") + xlab(\"Regional water availability (percentile)\") +\n  guides(fill = guide_legend(title = \"Basin\", override.aes = list(size = 5)), size = guide_legend(title = \"Number of sites\")) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\")\nprint(randiffplot)\n\n\n\n\n\n\n\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Presentation figs/EcoD_RangeDiff_allsites.jpg\", width = 5, height = 4, units = \"in\", res = 1000)\nrandiffplot\ndev.off()\n\n\npng \n  2 \n\n\n2020/2021 summer flow distributions\n\n\nCode\nbas &lt;- \"West Brook\"\nwtryrs &lt;- c(2020,2021)\n# filter data\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == bas, !is.na(logYield), Month %in% c(7:9), WaterYear %in% wtryrs) %&gt;%\n  mutate(site_name = factor(site_name, levels = orderr))\n\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == bas, !is.na(logYield), Month %in% c(7:9), WaterYear %in% unique(tempdat$WaterYear))\n\n# annual\npann &lt;- ggplot() +\n  geom_density(data = tempdat, aes(x = logYield, y = ..scaled.., color = site_name, fill = site_name), size = 0.8) +\n  scale_color_manual(values = cet_pal(nsites, name = \"i1\")) +\n  scale_fill_manual(values = alpha(cet_pal(nsites, name = \"i1\"), 0.1)) +\n  geom_density(data = tempdat_big, aes(x = logYield, y = ..scaled..), color = \"grey40\", fill = alpha(\"grey40\", 0.2), size = 0.8) +\n  xlab(\"Summer log(Yield)\") + ylab(\"Density\") +\n  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n                     axis.text.y = element_blank(), axis.ticks.y = element_blank(),\n                     axis.text = element_text(color = \"black\"), legend.position = \"none\",\n                     strip.background = element_blank(), strip.text = element_blank()) +\n  facet_wrap(~factor(WaterYear, levels = as.numeric(unlist(pedat %&gt;% arrange(totalyield_sum_z) %&gt;% select(WaterYear)))), ncol = 1)\n\nprint(pann)\n\n\n\n\n\n\n\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Presentation figs/EcoD_summerdensity_WB_annual.jpg\", width = 2.75, height = 5, units = \"in\", res = 1000)\npann\ndev.off()\n\n\npng \n  2 \n\n\n2020/2021 summer flow distributions\n\n\nCode\nbas &lt;- \"West Brook\"\norderr &lt;- wborder\nwtryrs &lt;- c(2020,2021)\n\n# sheds and network\nmysheds &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Watersheds/Mass_Watersheds.shp\")\nmysheds &lt;- mysheds[mysheds$site_id == \"WBR\",]\nmynet &lt;- vect(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/EcoDrought-Analysis/Watershed Delineation/Streams/Mass_Streams.shp\")\ncrs(mynet) &lt;- crs(mysheds)\nmynet &lt;- crop(mynet, mysheds)\n\n# get lakes\nlakes &lt;- get_waterbodies(AOI = siteinfo_sp %&gt;% filter(site_name == \"West Brook NWIS\"), buffer = 10000)\nlakes &lt;- lakes %&gt;% filter(gnis_name %in% c(\"Northampton Reservoir Upper\", \"Northampton Reservoir\"))\n\n# little g points\nmylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% wborder) %&gt;% mutate(site_name = factor(site_name, levels = wborder))\n\n\n# filter data\ntempdat &lt;- dat_clean %&gt;% \n  filter(basin == bas, !is.na(logYield), Month %in% c(7:9)) %&gt;%\n  mutate(site_name = factor(site_name, levels = orderr))\nnsites &lt;- length(unique(tempdat$site_name))\ntempdat_big &lt;- dat_clean_big %&gt;% filter(basin == bas, !is.na(logYield), Month %in% c(7:9), WaterYear %in% unique(tempdat$WaterYear))\n\n  # calculate variability for reference gage\nvarbig &lt;- tempdat_big %&gt;% \n  group_by(WaterYear) %&gt;% \n  summarize(bigrange = range(logYield)[2]-range(logYield)[1],\n            bigsd = sd(logYield),\n            bigvar = var(logYield)) %&gt;%\n  ungroup()\n\n# calculate total summer water availability from reference gage\n#summerflow &lt;- tempdat_big %&gt;% group_by(WaterYear) %&gt;% summarize(summeryield = sum(Yield_mm), summeryield_log = log(sum(Yield_mm))) %&gt;% ungroup()\n#wateravail2 &lt;- wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z)\n\n# calculate relative variation\npedat &lt;- tempdat %&gt;% \n  group_by(basin, WaterYear) %&gt;% \n  summarize(nsites = length(unique(site_name)),\n            littlerange = range(logYield)[2]-range(logYield)[1],\n            littlesd = sd(logYield),\n            littlevar = var(logYield)) %&gt;% \n  ungroup() %&gt;% \n  left_join(varbig) %&gt;%\n  mutate(pe_range = ((littlerange-bigrange)/bigrange),\n         pe_sd = ((littlesd-bigsd)/bigsd),\n         pe_var = ((littlevar-bigvar)/bigvar)) %&gt;%\n  left_join(wateravail %&gt;% select(basin, WaterYear, totalyield, totalyield_z, totalyield_sum, totalyield_sum_z, tyz_perc, tyz_sum_perc)) %&gt;% \n  filter(WaterYear %in% wtryrs) %&gt;%\n  mutate(wylab = substr(WaterYear, 3, 4)) %&gt;%\n  arrange(totalyield_sum_z)\n  \n# calculate annual median summer flow\nannmed &lt;- tempdat %&gt;%\n  #filter(WaterYear %in% c(lowyr, highyr)) %&gt;%\n  group_by(site_name, WaterYear) %&gt;%\n  summarize(medlogYield = median(logYield, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# arrange years by total annual yield\nwtryrs_arranged &lt;- as.numeric(unlist(pedat %&gt;% select(WaterYear)))\n\n# plot it\nplotlist_wb &lt;- list()\nfor(i in 1:length(wtryrs_arranged)) {\n  mylittleg &lt;- siteinfo_sp %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i]))\n  mylittleg_sheds &lt;- sheds %&gt;% filter(site_name %in% orderr) %&gt;% left_join(annmed %&gt;% filter(WaterYear == wtryrs_arranged[i])) %&gt;% arrange(desc(area_sqmi))\n  plotlist_wb[[i]] &lt;- local({\n    i &lt;- i\n    ggplot() +\n      geom_sf(data = st_as_sf(mysheds), color = \"black\", fill = \"white\", linewidth = 0.4) + \n      geom_sf(data = mylittleg_sheds, aes(fill = medlogYield), color = \"black\") +\n      scale_fill_viridis(option = \"A\", direction = 1, limits = range(annmed$medlogYield), na.value = \"grey\") +\n      geom_sf(data = st_as_sf(mynet), color = \"white\", linewidth = 1, lineend = \"round\") +\n      geom_sf(data = st_as_sf(mynet), color = \"royalblue4\", linewidth = 0.6, lineend = \"round\") +\n      geom_sf(data = lakes, color = \"white\", fill = \"lightskyblue1\", linewidth = 0.7) +\n      geom_sf(data = lakes, color = \"royalblue4\", fill = \"lightskyblue1\", linewidth = 0.5) +\n      geom_sf(data = mylittleg, shape = 21, fill = \"white\", size = 2) +\n      labs(fill = \"Median\\nsummer\\nlog(Yield)\") + #annotation_scale() +\n      coord_sf(xlim = range(st_coordinates(mylittleg_sheds)[,1]), ylim = range(st_coordinates(mylittleg_sheds)[,2])) +\n      theme_bw() + theme(axis.title.x = element_blank(), axis.title.y = element_blank(), legend.position = \"none\", axis.text = element_blank()) +\n      theme_void() + scale_x_continuous(expand = c(0.003, 0.003)) + scale_y_continuous(expand = c(0.002, 0.002))\n      #annotate(\"label\", x = Inf, y = Inf, label = paste(pedat$WaterYear[i], \" (\", pedat$tyz_sum_perc[i], \"%)\", sep = \"\"), vjust = 1.15, hjust = 1.05, size = 5)\n      })\n}\np &lt;- ggarrange(plotlist = plotlist_wb, common.legend = TRUE, legend = \"right\", nrow = 2)\nprint(p)\n\n\n\n\n\n\n\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Presentation figs/EcoD_summermedianmap_WB_annual.jpg\", width = 4, height = 6, units = \"in\", res = 1000)\np\ndev.off()\n\n\npng \n  2",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Objective 1</span>"
    ]
  },
  {
    "objectID": "Qualitative/LowFlow.html#presentation-figs",
    "href": "Qualitative/LowFlow.html#presentation-figs",
    "title": "15  Objective 4",
    "section": "15.6 Presentation figs",
    "text": "15.6 Presentation figs\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Presentation figs/EcoD_DroughtDiff_allsites.jpg\", width = 5, height = 4, units = \"in\", res = 1000)\nmycols &lt;- brewer.pal(7, \"Set2\")[-2]\ndefdur_ssn_sub2 %&gt;%\n  filter(designation == \"little\") %&gt;%\n  mutate(logit_duration = log((duration_15_fix_prop+0.001)/(1-(duration_15_fix_prop+0.001)))) %&gt;%\n  group_by(basin, WaterYear) %&gt;%\n  summarize(sddur = sd(duration_15_fix_prop),\n            sddur_logit = sd(logit_duration),\n            nsites = n()) %&gt;%\n  ungroup() %&gt;%\n  left_join(wateravail2 %&gt;% select(basin, WaterYear, totalyield:tyz_sum_perc)) %&gt;%\n  ggplot(aes(x = tyz_sum_perc, y = sddur)) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  geom_smooth(method = \"lm\", color = \"black\", aes(weight = nsites)) +\n  #geom_smooth(method = \"glm\", formula = y+0.000000001~x, method.args = list(family = gaussian(link = 'log'))) +\n  geom_point(aes(fill = basin, size = nsites), shape = 21) +\n  #scale_fill_brewer(palette = \"Set2\") +\n  scale_fill_manual(values = mycols) +\n  ylab(\"Spatial variation in drought duration (SD)\") + xlab(\"Regional water availability (percentile)\") +\n  #facet_wrap(~basin) +\n  #annotate(\"text\", label = \"10th perc.\", x = Inf, y = Inf, hjust = 1, vjust = 1) +\n  theme_bw() + theme(panel.grid = element_blank()) +\n  guides(fill = guide_legend(title = \"Basin\", override.aes = list(size = 5)), size = guide_legend(title = \"Number of sites\"))\ndev.off()\n\n\npng \n  2 \n\n\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Presentation figs/EcoD_DroughtDiff_fixed_allsites.jpg\", width = 5.5, height = 4, units = \"in\", res = 1000)\nmycols &lt;- brewer.pal(7, \"Set2\")[-2]\ndefdur_ssn2 %&gt;%\n  filter(designation == \"little\") %&gt;%\n  group_by(basin, WaterYear) %&gt;%\n  summarize(sddur = sd(duration_05_fix_prop),\n            nsites = n()) %&gt;%\n  ungroup() %&gt;%\n  left_join(wateravail2 %&gt;% select(basin, WaterYear, totalyield:tyz_sum_perc)) %&gt;%\n  ggplot(aes(x = tyz_sum_perc, y = sddur)) +\n  geom_abline(intercept = 0, slope = 0, linetype = \"dashed\") +\n  geom_smooth(method = \"lm\", color = \"black\", aes(weight = nsites)) +\n  geom_point(aes(fill = basin, size = nsites), shape = 21) +\n  # scale_fill_brewer(palette = \"Set2\") +\n  scale_fill_manual(values = mycols) +\n  ylab(\"Spatial variation in drought duration (SD)\") + xlab(\"Regional water availability (percentile)\") +\n  guides(fill = guide_legend(title = \"Basin\", override.aes = list(size = 5)), size = guide_legend(title = \"Number of sites\")) +\n  #facet_wrap(~basin) +\n  #annotate(\"text\", label = \"5th perc.\", x = Inf, y = Inf, hjust = 1, vjust = 1) +\n  theme_bw() + theme(panel.grid = element_blank())\ndev.off()\n\n\npng \n  2 \n\n\n\n\nCode\n# site-level drought threshold\nbas &lt;- \"Flathead\"\nmonths &lt;- c(7:9)\nbigG &lt;- \"North Fork Flathead River NWIS\"\n\ndd &lt;- dat_clean_sub %&gt;% filter(basin == bas, WaterYear %in% c(2021, 2022))\nmysites &lt;- c(unique(unlist(dd %&gt;% filter(site_name != bigG) %&gt;% select(site_name))), bigG)\nmyrect &lt;- dd %&gt;% group_by(WaterYear) %&gt;% summarize(mindate = min(date), maxdate = max(date)) %&gt;% ungroup()\ndd %&gt;%\n    ggplot() +\n    geom_tile(aes(x = date, y = factor(site_name, levels = (mysites)), fill = drought_fix)) +\n    scale_fill_viridis(option = \"A\", direction = -1, discrete = TRUE, limits = mydroughtlevels) +\n    geom_rect(data = myrect, aes(xmin = mindate, xmax = maxdate, ymin = length(mysites)-0.5, ymax = length(mysites)+0.5), \n              color = \"grey70\", fill = NA, size = 1.25) +\n    xlab(\"Date\") + ylab(\"Site\") +\n    #facet_wrap(~WaterYear, scales = \"free_x\") + \n    facet_wrap(~WaterYear, scales = \"free_x\") +\n    theme_bw() + theme(axis.title = element_blank()) +\n  guides(fill = guide_legend(title = \"Low flow\\nthreshold\"))\n\n\n\n\n\n\n\n\n\nCode\njpeg(\"C:/Users/jbaldock/OneDrive - DOI/Documents/USGS/EcoDrought/EcoDrought Working/Presentation figs/EcoD_DroughtTS_fixed_Flathead2021.jpg\", width = 5.5, height = 3.5, units = \"in\", res = 1000)\ndd &lt;- dat_clean_join %&gt;% filter(basin == bas | site_name == bigG, month %in% months, WaterYear %in% c(2021), site_name != \"CycloneCreekMiddle\") %&gt;%\n  mutate(site_name = ifelse(site_name == \"North Fork Flathead River NWIS\", \"NF Flathead NWIS\", site_name))\nmysites &lt;- c(unique(unlist(dd %&gt;% filter(designation == \"big\") %&gt;% select(site_name))),\n             unique(unlist(dd %&gt;% filter(designation == \"little\") %&gt;% select(site_name))))\nmyrect &lt;- dd %&gt;% group_by(WaterYear) %&gt;% summarize(mindate = min(date), maxdate = max(date)) %&gt;% ungroup()\ndd %&gt;%\n  ggplot() +\n  geom_tile(aes(x = date, y = factor(site_name, levels = rev(mysites)), fill = drought_fix)) +\n  scale_fill_viridis(option = \"A\", direction = -1, discrete = TRUE, limits = mydroughtlevels) +\n  geom_rect(data = myrect, aes(xmin = mindate, xmax = maxdate, ymin = length(mysites)-0.5, ymax = length(mysites)+0.5), \n            color = \"grey70\", fill = NA, size = 1.25) +\n  xlab(\"Date\") + ylab(\"Site\") +\n  #facet_wrap(~WaterYear, scales = \"free_x\") + \n  #facet_wrap(~WaterYear, scales = \"free_x\") +\n  theme_bw() + theme(axis.title = element_blank()) +\n  guides(fill = guide_legend(title = \"Low flow\\nthreshold\"))\ndev.off()\n\n\npng \n  2",
    "crumbs": [
      "Paper",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Objective 4</span>"
    ]
  }
]